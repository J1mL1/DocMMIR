[
    {
        "id": "2305.00001",
        "abstract": "  An application of the POCS-based clustering algorithm (POCS stands for\nProjection Onto Convex Set), a novel clustering technique, for feature\nembedding clustering problems is proposed in this paper. The POCS-based\nclustering algorithm applies the POCS's convergence property to clustering\nproblems and has shown competitive performance when compared with that of other\nclassical clustering schemes in terms of clustering error and execution speed.\nSpecifically, the POCS-based clustering algorithm treats each data point as a\nconvex set and applies a parallel projection operation from every cluster\nprototype to corresponding data members in order to minimize the objective\nfunction and update the prototypes. The experimental results on the synthetic\nembedding datasets extracted from the 5 Celebrity Faces and MNIST datasets show\nthat the POCS-based clustering algorithm can perform with favorable results\nwhen compared with those of other classical clustering schemes such as the\nK-Means and Fuzzy C-Means algorithms in feature embedding clustering problems.\n",
        "title": "Feature Embedding Clustering using POCS-based Clustering Algorithm",
        "texts": [
            "Fig. 1. The projection of x onto convex set A is the unique point in A which is closest to x and is denoted as y.",
            "Fig. 2. Graphical interpretation of the parallel POCS for disjoint convex sets.",
            "Fig. 3. Face image samples of Ben Affleck from the 5 Celebrity Faces dataset.",
            "Fig. 4. Typical diagram of an autoencoder network.",
            "Fig. 5. Description of the AE model used in this study: (a) encoder, and (b) decoder.",
            "Fig. 6. Training curves of the used AE model on the MNIST dataset.",
            "Fig. 7. Reconstructed images on MNIST dataset using the autoencoder model described in the paper (top: input image, bottom: reconstructed image).",
            "Table 1. Comparison between the POCS-based clustering and the K-Means++ algorithms in terms of clustering error on different feature embedding sets.",
            "Table 2. Comparison between the POCS-based clustering and the K-Means++ algorithms in terms of execution time (ms) on different feature embedding sets.",
            "Table 3. Comparison between the POCS-based clustering and the K-Means++ algorithms in terms of classification accuracy on different feature embedding sets.",
            "Table 4. Comparison of the K-Means, FCM, and POCSbased clustering algorithms in terms of clustering error on different feature embedding sets.",
            "Table 5. Comparison of the K-Means, FCM, and POCSbased clustering algorithms in terms of execution time (ms) on different feature embedding sets.",
            "Table 6. Comparison of the K-Means, FCM, and POCSbased clustering algorithms in terms of classification accuracy on different feature embedding sets."
        ],
        "imgs": [
            "$2305.00001v1-Figure1-1.png",
            "$2305.00001v1-Figure2-1.png",
            "$2305.00001v1-Figure3-1.png",
            "$2305.00001v1-Figure4-1.png",
            "$2305.00001v1-Figure5-1.png",
            "$2305.00001v1-Figure6-1.png",
            "$2305.00001v1-Figure7-1.png",
            "$2305.00001v1-Table1-1.png",
            "$2305.00001v1-Table2-1.png",
            "$2305.00001v1-Table3-1.png",
            "$2305.00001v1-Table4-1.png",
            "$2305.00001v1-Table5-1.png",
            "$2305.00001v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00003",
        "abstract": "  Computational experiments are exploited in finding a well-designed processing\npath to optimize material structures for desired properties. This requires\nunderstanding the interplay between the processing-(micro)structure-property\nlinkages using a multi-scale approach that connects the macro-scale (process\nparameters) to meso (homogenized properties) and micro (crystallographic\ntexture) scales. Due to the nature of the problem's multi-scale modeling setup,\npossible processing path choices could grow exponentially as the decision tree\nbecomes deeper, and the traditional simulators' speed reaches a critical\ncomputational threshold. To lessen the computational burden for predicting\nmicrostructural evolution under given loading conditions, we develop a neural\nnetwork (NN)-based method with physics-infused constraints. The NN aims to\nlearn the evolution of microstructures under each elementary process. Our\nmethod is effective and robust in finding optimal processing paths. In this\nstudy, our NN-based method is applied to maximize the homogenized stiffness of\na Copper microstructure, and it is found to be 686 times faster while achieving\n0.053% error in the resulting homogenized stiffness compared to the traditional\nfinite element simulator on a 10-process experiment.\n",
        "title": "Neural Network Accelerated Process Design of Polycrystalline\n  Microstructures",
        "texts": [
            "Figure 1: Schematic of the contribution of this study. Data-driven surrogate model is developed to replace the physics-based simulator on the process-structure-property problem.",
            "Figure 2: Finite element discretization of the orientation space for face-centered cubic (FCC) microstructures. The red-colored nodal points show the independent ODF values while the bluecolored nodes indicate the dependent ODFs as a result of the crystallographic symmetries.",
            "Figure 3: The comparison between the predicted textures by the neural network model (a, b and c) and finite element crystal plasticity model (d, e and f) at time steps t=0.3 sec (a and d), t=0.8 sec (b and e), and t=1 sec (c and f).",
            "Figure 4: Training error and testing error (left) on the synthetic dataset. Average stiffness error amount 31 modes (right).",
            "Figure 5: Texture evolution prediction through the optimum processing path by the neural network surrogate model. The figure shows the different steps of deformation processing from an initial texture to a final optimum texture which maximizes an objective function defined for the homogenized elastic stiffness constants of a Copper microstructure. T and C stand for tension and compression, respectively, and XY, XZ & YZ represent the corresponding shear processes.",
            "Figure 6: Texture evolution through the optimum processing path by the physics-based simulator. The figure shows the different steps of deformation processing from an initial texture to a final optimum texture which maximizes an objective function defined for the homogenized elastic stiffness constants of a Copper microstructure. T and C stand for tension and compression, respectively, and XY, XZ & YZ represent the corresponding shear processes.",
            "Figure 7: A single crystal optimum texture is obtained using linear programming to maximize the homogenized elastic stiffness constants without considering processing.",
            "Table 1: The average relative L2 error/stiffness error of neural network predictions compared with FE simulator on each deformation mode. We use binary strings of length 5 to represent different surrogate networks. Each digit represents one of the deformation processing modes (tension, compression, and xy, xz, yz shear). 1 if it is applied, otherwise 0 (e.g., 10010 represents the network that learns the deformation process when tension and xz shear are simultaneously applied)."
        ],
        "imgs": [
            "$2305.00003v2-Figure1-1.png",
            "$2305.00003v2-Figure2-1.png",
            "$2305.00003v2-Figure3-1.png",
            "$2305.00003v2-Figure4-1.png",
            "$2305.00003v2-Figure5-1.png",
            "$2305.00003v2-Figure6-1.png",
            "$2305.00003v2-Figure7-1.png",
            "$2305.00003v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00004",
        "abstract": "  In the present work, accurate determination of single-particle ignition is\nfocused on using high-speed optical diagnostics combined with machine learning\napproaches. Ignition of individual particles in a laminar flow reactor are\nvisualized by simultaneous 10 kHz OH-LIF and DBI measurements. Two coal\nparticle sizes of 90-125{\\mu}m and 160-200{\\mu}m are investigated in\nconventional air and oxy-fuel conditions with increasing oxygen concentrations.\nIgnition delay times are first evaluated with threshold methods, revealing\nobvious deviations compared to the ground truth detected by the human eye.\nThen, residual networks (ResNet) and feature pyramidal networks (FPN) are\ntrained on the ground truth and applied to predict the ignition time.~Both\nnetworks are capable of detecting ignition with significantly higher accuracy\nand precision. Besides, influences of input data and depth of networks on the\nprediction performance of a trained model are examined.~The current study shows\nthat the hierarchical feature extraction of the convolutions networks clearly\nfacilitates data evaluation for high-speed optical measurements and could be\ntransferred to other solid fuel experiments with similar boundary conditions.\n",
        "title": "Accurate ignition detection of solid fuel particles using machine\n  learning",
        "texts": [
            "Figure 1: A schematic experimental layout including optical diagnostics and the laminar flow reactor.",
            "Figure 2: A time-resolved sequence of particle ignition with tign given by the ground truth (manual labeling). (a) OH-LIF raw images. (b) binary OH-LIF images.",
            "Figure 3: Comparison of ignition delay times by the SAS method ti,SAS and the manual label ti,gt for two particle sizes A and B in seven atmospheres.",
            "Figure 4: Ignition time difference ti,RN - ti,gt by using ResNet-18 with the amount of particle events (a) Nev = 14, (b) Nev = 56, (c) Nev = 140, and (d) Nev = 462.",
            "Figure 5: Ignition time difference ti,FPN - ti,gt using different ResNet models in the bottom-up pathway of FPN networks.",
            "Figure 6: Relative probability distributions of ignition time differences ti,det - ti,gt, in which ti,det represents predicted ignition delay times by different approaches."
        ],
        "imgs": [
            "$2305.00004v1-Figure1-1.png",
            "$2305.00004v1-Figure2-1.png",
            "$2305.00004v1-Figure3-1.png",
            "$2305.00004v1-Figure4-1.png",
            "$2305.00004v1-Figure5-1.png",
            "$2305.00004v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00005",
        "abstract": "  Glioblastoma, a highly aggressive primary brain tumor, is associated with\npoor patient outcomes. Although magnetic resonance imaging (MRI) plays a\ncritical role in diagnosing, characterizing, and forecasting glioblastoma\nprogression, public MRI repositories present significant drawbacks, including\ninsufficient postoperative and follow-up studies as well as expert tumor\nsegmentations. To address these issues, we present the \"R\\'io Hortega\nUniversity Hospital Glioblastoma Dataset (RHUH-GBM),\" a collection of\nmultiparametric MRI images, volumetric assessments, molecular data, and\nsurvival details for glioblastoma patients who underwent total or near-total\nenhancing tumor resection. The dataset features expert-corrected segmentations\nof tumor subregions, offering valuable ground truth data for developing\nalgorithms for postoperative and follow-up MRI scans. The public release of the\nRHUH-GBM dataset significantly contributes to glioblastoma research, enabling\nthe scientific community to study recurrence patterns and develop new\ndiagnostic and prognostic models. This may result in more personalized,\neffective treatments and ultimately improved patient outcomes.\n",
        "title": "The Rio Hortega University Hospital Glioblastoma dataset: a\n  comprehensive collection of preoperative, early postoperative and recurrence\n  MRI scans (RHUH-GBM)",
        "texts": [
            "Table 1. Study population demographics of the Río Hortega University Hospital Glioblastoma dataset (RHUH-GBM)"
        ],
        "imgs": [
            "$2305.00005v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00009",
        "abstract": "  The reconstruction of electrical excitation patterns through the unobserved\ndepth of the tissue is essential to realizing the potential of computational\nmodels in cardiac medicine. We have utilized experimental optical-mapping\nrecordings of cardiac electrical excitation on the epicardial and endocardial\nsurfaces of a canine ventricle as observations directing a local ensemble\ntransform Kalman Filter (LETKF) data assimilation scheme. We demonstrate that\nthe inclusion of explicit information about the stimulation protocol can\nmarginally improve the confidence of the ensemble reconstruction and the\nreliability of the assimilation over time. Likewise, we consider the efficacy\nof stochastic modeling additions to the assimilation scheme in the context of\nexperimentally derived observation sets. Approximation error is addressed at\nboth the observation and modeling stages, through the uncertainty of\nobservations and the specification of the model used in the assimilation\nensemble. We find that perturbative modifications to the observations have\nmarginal to deleterious effects on the accuracy and robustness of the state\nreconstruction. Further, we find that incorporating additional information from\nthe observations into the model itself (in the case of stimulus and stochastic\ncurrents) has a marginal improvement on the reconstruction accuracy over a\nfully autonomous model, while complicating the model itself and thus\nintroducing potential for new types of model error. That the inclusion of\nexplicit modeling information has negligible to negative effects on the\nreconstruction implies the need for new avenues for optimization of data\nassimilation schemes applied to cardiac electrical excitation.\n",
        "title": "Reconstructing Cardiac Electrical Excitations from Optical Mapping\n  Recordings",
        "texts": [
            "FIG. 1. Example of the experimental data used for the reconstruction experiments. (a) Epicardial snapshot and (b) endocardial snapshot at time t = 5734 ms, with (c) time traces of the recording at positions labeled by the + (epicardial) and × (endocardial) markers. The thin black curve in (a) and (b) designates the boundary of the opposing surface recording, and the thick black curve designates the boundary of their mutual intersection. The inset dashed square has side-length 3 cm, aligned to the horizontal and vertical axes, and shows the region selected to extract observations for assimilation.",
            "FIG. 10. Uncertain wavefront experiment results, depicting the (a) CRPSa(t) (line) and CRPSo(t) (band), (b) RMSEb(t) (line) plus and minus one standard deviation (band), and (c) SPRDb(t, z) (color) for the reconstruction using the Barone et al. parameter set.",
            "FIG. 11. (a) RMSEb(t) and (b) SPRDb u(t) for the Autonomous, Wave Uncertainty, and Synthetic observations experiments, with the distribution of (right, top) surface errors and (right, bottom) ensemble spread over time.",
            "FIG. 3. Autonomous experiment results, depicting the (a) CRPSa(t) (line) and CRPSo(t) (band), (b) RMSEb(t) (line) plus and minus one standard deviation (band), and (c) SPRDb(t, z) (color) for the reconstruction using the Barone et al. parameter set.",
            "FIG. 6. (a) RMSEb(t) and (b) depth-average SPRDb u(t) for the Free-Run, Autonomous, and Stimulus experiments, with the distribution of (right, top) surface errors and (right, bottom) ensemble spread over time.",
            "FIG. 7. (a) Temporal trace for the Autonomous experiment and associated observations, sampled on the epicardium (z/d = 0) at (x, y) = (0.825, 0.42) cm, and (b) corresponding action potential durations (APD) and amplitudes (APA) (uthr = 0.1).",
            "FIG. 8. Stochastic experiment results, depicting the (a) CRPSa(t) (line) and CRPSo(t) (band), (b) RMSEb(t) (line) plus and minus one standard deviation (band), and (c) SPRDb(t, z) (color) for the reconstruction using the Barone et al. parameter set.",
            "FIG. 9. Synthetic Observations experiment results, depicting the (a) CRPSa(t) (line) and CRPSo(t) (band), (b) RMSEb(t) (line) plus and minus one standard deviation (band), and (c) SPRDb(t, z) (color) for the reconstruction using the Barone et al. parameter set.",
            "TABLE I. Fenton-Karma model parameter values used in dynamical model for the reconstruction of experimental data. ∗Note: as τ− v1 ≡ τ− v2, the switching parameter uv is unspecified in Ref. 1."
        ],
        "imgs": [
            "$2305.00009v2-Figure1-1.png",
            "$2305.00009v2-Figure10-1.png",
            "$2305.00009v2-Figure11-1.png",
            "$2305.00009v2-Figure3-1.png",
            "$2305.00009v2-Figure6-1.png",
            "$2305.00009v2-Figure7-1.png",
            "$2305.00009v2-Figure8-1.png",
            "$2305.00009v2-Figure9-1.png",
            "$2305.00009v2-TableI-1.png"
        ]
    },
    {
        "id": "2305.00011",
        "abstract": "  Sound event detection systems are widely used in various applications such as\nsurveillance and environmental monitoring where data is automatically\ncollected, processed, and sent to a cloud for sound recognition. However, this\nprocess may inadvertently reveal sensitive information about users or their\nsurroundings, hence raising privacy concerns. In this study, we propose a novel\nadversarial training method for learning representations of audio recordings\nthat effectively prevents the detection of speech activity from the latent\nfeatures of the recordings. The proposed method trains a model to generate\ninvariant latent representations of speech-containing audio recordings that\ncannot be distinguished from non-speech recordings by a speech classifier. The\nnovelty of our work is in the optimization algorithm, where the speech\nclassifier's weights are regularly replaced with the weights of classifiers\ntrained in a supervised manner. This increases the discrimination power of the\nspeech classifier constantly during the adversarial training, motivating the\nmodel to generate latent representations in which speech is not\ndistinguishable, even using new speech classifiers trained outside the\nadversarial training loop. The proposed method is evaluated against a baseline\napproach with no privacy measures and a prior adversarial training method,\ndemonstrating a significant reduction in privacy violations compared to the\nbaseline approach. Additionally, we show that the prior adversarial method is\npractically ineffective for this purpose.\n",
        "title": "Adversarial Representation Learning for Robust Privacy Preservation in\n  Audio",
        "texts": [
            "Fig. 1. Problem setup diagram where speech privacy is violated while being sent to a cloud.",
            "Fig. 2. Schematic diagram of the proposed method. F , C, D, and D′ are neural networks and L shows different loss terms in our method. The solid lines illustrate the forward pass. The dashed line shows the forward pass which is active only after P number of epochs. Finally, the dotted line shows the backpropagation of each specific error w.r.t the relevant weights.",
            "Fig. 3. The effect of parameter P on the performance of RDAL on the test data for SAD and SED tasks.",
            "Fig. 4. Estimated density curves using Gaussian kernel to represent continuous probability densities of the predicted probabilities for the test data using baseline (left figure) and RDAL (right figure) methods.",
            "Fig. 5. t-SNE illustration of latent features of the test data obtained by F in RDAL (right figure) compared to the features from F when it is trained in supervised manner for sound events and speech(left figure). The dog barking, glass breaking and gun shot are red, green and blue, respectively. The samples containing speech are marked by “o” and the non-speech samples by “x”.",
            "Table 1. Number of one-second sound event samples in each split, number of male/female speakers, and the duration of speech (in seconds) in our dataset.",
            "Table 2. Results of baseline, naive adversarial learning, and RDAL."
        ],
        "imgs": [
            "$2305.00011v1-Figure1-1.png",
            "$2305.00011v1-Figure2-1.png",
            "$2305.00011v1-Figure3-1.png",
            "$2305.00011v1-Figure4-1.png",
            "$2305.00011v1-Figure5-1.png",
            "$2305.00011v1-Table1-1.png",
            "$2305.00011v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00013",
        "abstract": "  Many new physics scenarios predict multi-photon Higgs resonances. One such\nscenario is the dark axion portal model. The primary decay chain that we study\nis the Higgs to dark photon ($\\gamma_D$) pairs that subsequently decay into a\nphoton ($\\gamma$) and an axion-like particle ($a$). The axion-like particles\nthen decay into photon pairs. Hence, the signal is a six-photon Higgs decay:\n$h\\rightarrow \\gamma_D\\,\\gamma_D\\rightarrow 2\\,\\gamma 2\\,a\\rightarrow 6\\gamma$.\nHowever, depending on the relevant kinematics, the photons can become\nwell-collimated and appear as photon-jets (multiple photons that appear as a\nsingle photon in the detector) or $\\xi$-jets (non-isolated multi-photon signals\nthat do not pass the isolation criterion). These effects cause the true\nsix-photon resonance to appear as other multi-photon signals, such as two and\nfour photons. We classify the mass regions where two, four, and six-photon\nresonances dominate. The four-photon signal is particularly interesting. These\nevents mainly occur when the photons from the axion-like particles are\ncollimated into photon-jets. The decay of the dark photon is then\n$\\gamma_D\\rightarrow \\gamma a\\rightarrow \\gamma+\\gamma$-jet, which is an\napparent violation of the Landau-Yang theorem. We show that current\nmeasurements of $h\\rightarrow 2\\gamma$ and searches for $h\\rightarrow 4\\gamma$\nat the Large Hadron Collider (LHC) can limit ${\\rm BR}(h\\rightarrow\n\\gamma_D\\gamma_D)\\lesssim 10^{-3}$. This model also motivates new searches for\nHiggs decays into six isolated photons or $\\xi$-jets at the LHC. While there\nare currently no dedicated searches, we show that many of the Higgs to six\nisolated photons or $\\xi$-jet events could pass two or three-photon triggers.\nThat is, new physics could be found by reanalyzing existing data. These\nmulti-photon signals provide excellent footing to explore new physics at the\nLHC and beyond.\n",
        "title": "Multi-photon decays of the Higgs boson at the LHC",
        "texts": [
            "FIG. 12: Best constraint on the branching fraction BR(h → γDγD) using the Higgs diphoton resonance search, four-photon resonant search, Higgs mixing angle limits, and Higgs branching ratio to the unknown. The resonance searches require 1% detector efficiency. The contours are upper bounds on BR(h → γDγD) while the heat map is for log10BR(h → γDγD). We assume BR(a→ γγ) = BR(γD → aγ) = 1.",
            "FIG. 2: Maximum branching ratio of the Higgs to two dark photons from (dashed) Higgs fits to the branching fraction of Higgs to the unknown and from (solid) Higgs mixing assuming sin θmax = 0.1 with (black) vD = mγD , (red) vD = 10mγD , (blue) vD = 25mγD , (yellow) vD = 50mγD , and (green) vD = 100mγD .",
            "FIG. 4: Regions with the largest probability of ending in n observed photon final states after merging photons into γobs: (blue) two, (orange) three, (green) four, (purple) five, and (red) six observed photons. No isolation requirements are imposed. The black corner indicates the kinematically forbidden area (mγD < ma).",
            "FIG. 5: Regions with the largest probabilities into n isolated photons and m ξ-jet final states. The light gray (dark gray) region indicates the dominant final states have one (two) ξ-jets. Color coding for other regions: (blue) 2γiso + 0ξ-jet, (green) 4γiso + 0ξ-jet, and (red) 6γiso + 0ξ-jet.",
            "FIG. 6: Estimated detector efficiencies for n photon triggers applied to n isolated photons and zero ξ-jet signals for both (a) ATLAS and (b) CMS. Efficiencies are estimated by placing rapidity [Eqs. (27)-(28)] and transverse momentum requirements on the isolated photons (Tabs. I, II).",
            "FIG. 7: (a) Probability of a signal appearing as a 2γiso + 0ξ-jet final state. (b) Upper bound on the branching fraction BR(h → γDγD) from Higgs diphoton signal strength. A detector efficiency of Eff2(6γ → 2γiso + 0ξ) ≥ 1% is required. In (b) the contours are upper bounds on BR(h → γDγD) while the heat map is for log10BR(h → γDγD). We assume BR(a→ γγ) = BR(γD → aγ) = 1.",
            "FIG. 8: (a) Probability of four-isolated photon + zero-ξ-jet final state. (b) Constraint (dark area) on the branching fraction BR(h→ γDγD) using the Higgs four-photon resonant search from CMS [27] and requiring 1% detector efficiency for the CMS four-photon trigger. In (b) the contours are upper bounds on BR(h→ γDγD) while the heat map is for log10BR(h→ γDγD). We assume BR(a→ γγ) = BR(γD → aγ) = 1."
        ],
        "imgs": [
            "$2305.00013v1-Figure12-1.png",
            "$2305.00013v1-Figure2-1.png",
            "$2305.00013v1-Figure4-1.png",
            "$2305.00013v1-Figure5-1.png",
            "$2305.00013v1-Figure6-1.png",
            "$2305.00013v1-Figure7-1.png",
            "$2305.00013v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00014",
        "abstract": "  The CMS experiment at CERN has reported a possible signal for a resonance at\n146 GeV decaying into the $e\\mu$ final state which, presently, is the only\nexperimental hint for lepton flavour violation in any low- and high-energy\nexperiment. The Froggatt-Nielsen mechanism naturally predicts the existence of\nnew scalars, the flavons, with flavour off-diagonal couplings. We study this\nframework in the context of the CMS result and find that the minimal, purely\nleptophilic model is too restricted to match the claimed signal. Thereafter we\nshow how models with additional flavon couplings to quarks can explain the\nclaimed signal while satisfying all the existing constraints on lepton flavour\nviolation.\n",
        "title": "Production and decays of 146 GeV flavons into $e\\mu$ final state at the\n  LHC",
        "texts": [
            "Figure 1: Left panel: The parameter space excluded by searches for the LFV decays of Higgs boson. The dark gray area is excluded by the h → eµ searches [1], the medium gray area is excluded by the h → eτ searches [5] and the light gray area by the h → µτ searches [5]. Right panel: The parameter regions excluded by the measurements of BR(h→ µµ) (blue area) and BR(h→ ττ) (red area).",
            "Figure 2: Left panel: Cross-section σ(pp → H2 → eµ) as a function of flavon VEV at 13 TeV LHC for different Higgs-flavon mixing angles. Right panel: H2 → eµ branching ratio as a function of flavon VEV. In both panels solid lines correspond to numerical benchmark and the dashed lines correspond to analytical estimate with maximal eµ coupling. In both panels the red area is excluded by BR(h → ττ) and BR(h → µµ) measurements for sin θ = 0.1. For sin θ = 0.2 red and green areas are excluded, and for sin θ = 0.3 all colored areas are excluded.",
            "Figure 3: Left and middle panels: The 1- and 2-loop contributions to µ→ eγ in the case of additional quark couplings. Right panel: The tree-level contribution to µ↔ e conversion in nuclei in the case of additional quark couplings.",
            "Figure 4: Left panel : Regions of the (vφ, mA) parameter space excluded by searches for µ → eγ in the leptophilic model for different values of the mixing angle. Right panel : The LFV constraints in the case of additional quark-flavon couplings for ct = 1.9 and three different values of the charm coupling, cc = −1.9, 0 and 1. The allowed white wedge shaped area continues until the corner of the orange area, but is too fine to be visible by eye.",
            "Figure 5: Left panel: Cross-section σ(pp→ H2 → eµ) as a function of the flavon VEV at the √ s = 13 TeV LHC for different quark couplings as indicated in the figure. The gray shaded region is excluded by µ ↔ e conversion for all values of mA. The horizontal line corresponds to 5.77 fb. Right panel: The relevant branching ratios for the same case. The solid lines correspond to ct = −cc = 1.9, dashed line to 1.7 and dot dashed line to 1.5."
        ],
        "imgs": [
            "$2305.00014v1-Figure1-1.png",
            "$2305.00014v1-Figure2-1.png",
            "$2305.00014v1-Figure3-1.png",
            "$2305.00014v1-Figure4-1.png",
            "$2305.00014v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00015",
        "abstract": "  Emergent bulk properties of matter governed by the strong nuclear force give\nrise to physical phenomena across vastly different scales, ranging from the\nshape of atomic nuclei to the masses and radii of neutron stars. They can be\naccessed on Earth by measuring the spatial extent of the outer skin made of\nneutrons that characterises the surface of heavy nuclei. The isotope\n$^{208}$Pb, owing to its simple structure and neutron excess, has been in this\ncontext the target of many dedicated efforts. Here, we determine the neutron\nskin from measurements of particle distributions and their collective flow in\n$^{208}$Pb+$^{208}$Pb collisions at ultrarelativistic energy performed at the\nLarge Hadron Collider, which are sensitive to the overall size of the colliding\n$^{208}$Pb ions. By means of state-of-the-art global analysis tools within the\nhydrodynamic model of heavy-ion collisions, we infer a neutron skin $\\Delta\nr_{np}=0.217\\pm0.058$ fm, consistent with nuclear theory predictions, and\ncompetitive in accuracy with a recent determination from parity-violating\nasymmetries in polarised electron scattering. We establish thus a new\nexperimental method to systematically measure neutron distributions in the\nground state of atomic nuclei.\n",
        "title": "Determination of the neutron skin of $^{208}$Pb from ultrarelativistic\n  nuclear collisions",
        "texts": [
            "FIG. 1. Neutron skin and collective flow in relativistic nuclear collisions. a: Two ions collide with impact parameter b = 8 fm. Both ions are Lorentz-contracted by a factor γ ≈ 2500, and the relevant dynamics hence effectively takes place in the transverse plane, x⊥ = (x, y). b: The collision deposits energy in the interaction region depending on the extent of the neutron skin of the 208Pb nuclei. We consider ∆rnp = 0.086 fm (top) and ∆rnp = 0.384 (bottom). The neutron skin is varied by keeping the half-width neutron radius, Rn, constant while changing the neutron diffuseness, as displayed by the dotted lines (see also Eqn. (2) below). A larger neutron skin leads to a considerably larger total hadronic cross section, σtot, and the resulting QGP is in addition more diffuse and less elliptical. c: We show a single QGP evolving hydrodynamically and being converted into particles (marked in the figure with their respective symbols) as it cools, while expanding both in z and in the transverse plane. The observation of millions such events leads to characteristic azimuthal anisotropies in the momentum distribution of the produced particles, the most important of which is quantified by the rms value of its second Fourier component, the elliptic flow v2{2}, which reflects the ellipticity of the QGP.",
            "FIG. 2. Signature of the neutron skin on bulk particle production in ultrarelativisitic 208Pb+208Pb collisions. Varying only the neutron skin size at our optimal parameter settings we show the charged particle multiplicity (left), the mean transverse momentum (middle) and the elliptic flow as measured by v2{k} (right) with a comparison to ALICE data [19, 20]. A larger neutron skin leads to more collisions, but per collision the multiplicity is lower at larger centralities. The larger size of the QGP leads to a reduced transverse momentum on average. Smearing of the elliptical shape leads to reduced elliptic flow as measured by v2{2} and v2{4}. Theoretical error bars are statistical only, experimental uncertainties include systematics as well.",
            "FIG. 4. State-of-the-art determinations of the neutron skin of 208Pb. We show the final likelihood distribution of the neutron skin as determined from the LHC data as compared to the values obtained experimentally by the PREX collaboration (including both experimental and theoretical uncertainties in the extraction) [6] and the estimate of ab initio nuclear theory (with an error bar corresponding to a 68% credibility interval) [7].",
            "FIG. 5. Complete correlation matrix among all 26 model parameters. For detailed information about the prior ranges, we refer the reader to Ref. [18]. The only new parameters of this analysis are an, whose prior can be inferred from Fig. 4, aEOS, whose"
        ],
        "imgs": [
            "$2305.00015v1-Figure1-1.png",
            "$2305.00015v1-Figure2-1.png",
            "$2305.00015v1-Figure4-1.png",
            "$2305.00015v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00017",
        "abstract": "  In $U(1)_R$ extensions of supersymmetric models, the bino and its Dirac\npartner, the singlino, can play the role of right-handed neutrinos. The bino\nand the singlino form a pseudo-dirac pair, dubbed the `bi$\\nu$o', which can\ngenerate Standard Model neutrino masses via the inverse seesaw mechanism. We\ninvestigate the prospects for detecting long-lived bi$\\nu$os at SHiP, where GeV\nscale bi$\\nu$os can be copiously produced in the decays of mesons. We show that\nSHiP can probe new regions of parameter space that are complementary to\nsearches for the lepton flavor-violating decay $\\mu \\to e \\gamma$. This\nscenario provides a well-motivated benchmark for future experiments of a\nright-handed neutrino that mixes with all Standard Model neutrinos, and is\ndirectly related to the generation of neutrino masses.\n",
        "title": "Discovering the Origin of Neutrino Masses at SHiP",
        "texts": [
            "FIG. 1. Left : Number of biνos produced at SHiP assuming 5 years of operation and ΛM = 1 TeV. (This messenger scale is taken as a benchmark for comparison to other relevant models.) Right : Branching ratios of the biνo into different final states as a function of the biνo mass MB̃ .",
            "FIG. 2. SHiP sensitivity to biνos assuming 5 years of operation using our conservative method (solid black curve) and the HNL@SHiP method (dashed black curve). The greater sensitivity with the conservative method below MB̃ ∼ 400 MeV is due to the biνo production from kaons, which is not included in the HNL@SHiP package. Existing limits from µ→ eγ [31] are depicted by the gray shaded region below the dashed gray line labelled “µ → eγ”. We also show the projected exclusion limit from the proposed Mu2e experiment [32], which will look for µ→ e conversion in nuclei. BBN constraints are shown by the orange shaded regions. See text for further details."
        ],
        "imgs": [
            "$2305.00017v1-Figure1-1.png",
            "$2305.00017v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00019",
        "abstract": "  Radio jets and the lobes they inflate are common in cool-core clusters and\nare known to play a critical role in regulating the heating and cooling of the\nintracluster medium (ICM). This is an inherently multi-scale problem, and much\neffort has been made to understand the processes governing the inflation of\nlobes and their impact on the cluster, as well as the impact of the environment\non the jet-ICM interaction, on both macro- and microphysical scales.\nDevelopments of new numerical techniques and improving computational resources\nhave seen simulations of jet feedback in galaxy clusters become ever more\nsophisticated. This ranges from modelling ICM plasma physics processes such as\nthe effects of magnetic fields, cosmic rays and viscosity to including jet\nfeedback in cosmologically evolved cluster environments in which the ICM\nthermal and dynamic properties are shaped by large-scale structure formation.\nIn this review, we discuss the progress made over the last ~decade in capturing\nboth the macro- and microphysical processes in numerical simulations,\nhighlighting both the current state of the field as well as open questions and\npotential ways in which these questions can be addressed in the future.\n",
        "title": "Recent Progress in Modeling the Macro- and Micro-Physics of Radio Jet\n  Feedback in Galaxy Clusters",
        "texts": [
            "Figure 1. Diagram illustrating the general processes that occur during and after lobe inflation. Panel A: A fast jet drives into the ambient medium, forms a bow shock and inflates a hot lobe that expands into the ICM. The lobe morphology can depend sensitively on the injected jet properties (e.g., content, velocity, geometry). The expanding shock wave results in a layer of shocked ICM material surrounding the jet lobe. Panel B: As the lobe expansion slows and the jet ceases, the shock driven into the ICM broadens into a sound wave that can detach from the lobes and continue to buoyantly rise through the ICM. Panel C: As the lobe rises dense, low entropy material can be entrained and pulled up in the wake and instabilities can lead to mixing of the lobe and ICM material. Sound waves generated by the lobe expansion can continue to propagate to large distances depending on the ICM viscosity. Panel D: This process continues at late times, with mixing continuing to dilute the lobe material, although the rate at which this occurs can depend sensitively on the ICM physical processes including magnetic fields, viscosity and cluster weather.",
            "Figure 2. Thin temperature projections illustrate how jet injection parameters impact jet and lobe morphologies. All jets are 100 Myr old with each row illustrating the effect of changing one parameter, which from top to bottom are jet power, half opening angle, velocity and resolution, respectively. These quantities take fiducial values of 1046 erg s−1, 10◦, 15000 km s−1 and 1.81× 105 M , unless being varied. (Figure 6 from Huško and Lacey [47], CC BY 4.0)",
            "Figure 3. An illustration of jet-driven shocks within the central 100 kpc of a simulated cluster. The left panel shows the energy dissipation rate while the right-hand panel shows shock Mach numbers, illustrating that stronger shocks and hence higher dissipation rates are seen closer to the jet but that overall the shocks are typically quite weak. (Figure 1 from Li et al. [72], ©AAS, reproduced with permission)",
            "Figure 4. Volume rendering of jet lobes (green) and cold material (red) within a cosmologically evolved galaxy cluster. The top, middle and bottom rows show low, medium and high-power jets, respectively. The small panels show the evolution of the jet lobes for two different viewing angles, while the large panels additionally overlay the gas velocity field. Overall, jet lobes can be displaced, disrupted and mixed by cluster weather and cold structures, with lower-power jets being more susceptible. (Figure 2 from Bourne and Sijacki [173], CC BY 4.0)",
            "Figure 5. Comparisons of simulation results with varied jet composition and assumptions for modeling CR transport. Rows from top to bottom show the results from kinetic-energy dominated jets (KIN), CR dominated jets (CR), and CR dominated jets with diffusion and heating (CRdh). The morphology of jet-inflated lobes tend to be elongated for the KIN case, whereas bubbles inflated by CR dominated jets are wider. Comparisons between the bottom two panels show that CR heating is more efficient and the amount of cold gas is less for the CRdh case, as the CRs can diffuse outside the bubbles and heat the ICM due to hadronic and Coulomb interactions. (Figure 3 from Yang et al. [66], ©AAS, reproduced with permission)",
            "Figure 6. Impact of assumptions about ICM viscosity on the evolution of AGN jet-inflated bubbles. Cases A-D show simulations with no viscosity, isotropic viscosity with full Spitzer values, anisotropic viscosity with full Braginskii values, and anisotropic viscosity limited by microinstabilities, respectively. While the hydrodynamic instabilities are suppressed by viscosity in cases B and C, when the parallel viscosity along magnetic field lines is suppressed by microinstabilities (case D), the viscosity is strongly limited and the bubbles are deformed as in the inviscid case (A). This illustrates the importance of modelling the ICM microphysics in AGN simulations. (Figure 1 from Kingsland et al. [93], ©AAS, reproduced with permission)",
            "Figure 7. Illustration of sound waves generated by jets. The left-hand panel shows the jet and cocoon temperature and density structure, with key features labelled. The right-hand panel shows jet entropy and the acoustic flux density, with structure in the latter illustrating the production of sound waves within shocked ICM material. (Figure 1 from Bambic and Reynolds [184], ©AAS, reproduced with permission)"
        ],
        "imgs": [
            "$2305.00019v1-Figure1-1.png",
            "$2305.00019v1-Figure2-1.png",
            "$2305.00019v1-Figure3-1.png",
            "$2305.00019v1-Figure4-1.png",
            "$2305.00019v1-Figure5-1.png",
            "$2305.00019v1-Figure6-1.png",
            "$2305.00019v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00020",
        "abstract": "  The fragmentation mode of high-mass molecular clumps and the accretion\nprocesses that form the most massive stars ($M\\gtrsim 8M_\\odot$) are still not\nwell understood. To this end, we have undertaken a large observational program\n(CORE) making use of interferometric observations from the Northern Extended\nMillimetre Array (NOEMA) for a sample of 20 luminous ($L>10^4L_\\odot$)\nprotostellar objects in the 1.37 mm wavelength regime in both continuum and\nline emission, reaching $\\sim$0.4\" resolution (800 au at 2 kpc). Using the\ndense gas tracer CH$_3$CN, we find velocity gradients across 13 cores\nperpendicular to the directions of bipolar molecular outflows, making them\nexcellent disk candidates. Specific angular momentum ($j$) radial profiles are\non average $\\sim10^{-3}$ km /s pc and follow $j \\propto r^{1.7}$, consistent\nwith a poorly resolved rotating and infalling envelope/disk model. Fitting the\nvelocity profiles with a Keplerian model, we find protostellar masses in the\nrange of $\\sim 10-25$ $M_\\odot$. Modelling the level population of CH$_3$CN\nlines, we present temperature maps and find median gas temperatures in the\nrange $70-210$ K. We create Toomre $Q$ maps to study the stability of the disks\nand find almost all (11 of 13) disk candidates to be prone to fragmentation due\nto gravitational instabilities at the scales probed by our observations. In\nparticular, disks with masses greater than $\\sim10-20\\%$ of the mass of their\nhost (proto)stars are Toomre unstable, and more luminous protostellar objects\ntend to have disks that are more massive and hence more prone to fragmentation.\nOur finings show that most disks around high-mass protostars are prone to disk\nfragmentation early in their formation due to their high disk to stellar mass\nratio. This impacts the accretion evolution of high-mass protostars which will\nhave significant implications for the formation of the most massive stars.\n",
        "title": "Kinematics and stability of high-mass protostellar disk candidates at\n  sub-arcsecond resolution -- Insights from the IRAM NOEMA large program CORE",
        "texts": [
            "Fig. 1: Intensity-weighted mean velocity (first moment) maps of H2CO (30,3 − 20,2) showing the large-scale kinematics of the full CORE sample. The contours correspond to the continuum maps imaged with uniform weighting as presented in Beuther et al. (2018). The outermost three contours correspond to 5, 10, and 20σ levels, then increasing in steps of 15σ. For IRAS23151, NGC7538 IRS1, NGC7538 IRS9 and AFGL2591 the outermost three contours correspond to 5, 15, and 40σ levels, then increasing in steps of 25σ (see Table 3 for σ values). The synthesised beam is shown in the bottom left corner and a scale bar in the bottom",
            "Fig. 10: Median Q plotted against gas mass (left) and stellar mass (right) for 13 candidate disks within the CORE survey, coloured according to the luminosity of the regions within which they reside. The Toomre-stable disks are marked by triangles.",
            "Fig. 11: Median Q as a function of ( H r ) ( M∗+Mdisk Mdisk ) . The Toomrestable disks are marked by triangles.",
            "Fig. 12: Summary plot showing the kinematics and derived properties for one source in the CORE sample (G75.78). Top left panel: intensity-weighted mean velocity (first moment) map of CH3CN (125 − 115) in colour with 1.37 mm continuum contours. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. The dotted line indicates the position of the strongest velocity gradient tracing the disk, i.e. perpendicular to the rotation axis. The edges of the assumed disk extent are marked with an ×. Top right panel: PV plot of CH3CN (125 − 115) along the cut in the direction of rotation as depicted by the dotted line in the top left panel. The contours correspond to the 6σ level increasing in steps of 24σ. Yellow lines show the Keplerian rotation curves for an enclosed mass of 19 M . The cross in the bottom right corner corresponds to the spatial and spectral resolutions. Bottom left panel: Rotational temperature maps obtained by fitting CH3CN (12K−11K) K = 0−6 and CH3 13CN (12K −11K) K = 0−3 lines with XCLASS in colour and 1.37 mm continuum contours. Bottom right panel: Toomre Q map assuming a protostar is located at the position of the continuum peak as depicted by a star and accounting for the self-gravity of the disk, with 1.37 mm continuum contours. Regions outside of 6σ continuum contours are masked out. The synthesised beam and a scale bar are shown in the bottom of the panels.",
            "Fig. 2: Intensity-weighted mean velocity (first moment) maps of CH3CN (123 − 113) showing the dense gas kinematics for 15 of the 20 sources in the CORE survey. The contours correspond to the 1.37 mm continuum as described in Fig. 1. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively (see Sect. 4.3). The dotted lines indicate the position of the strongest velocity gradient tracing the disk, i.e. perpendicular to the rotation axis. The edges of the assumed disk extent are marked with an ×. The synthesised beam is shown in the bottom left corner and a scale bar in",
            "Fig. 3: Rotational temperature maps obtained by fitting CH3CN (12K − 11K) K = 0 − 6 and CH3 13CN (12K − 11K) K = 0 − 3 lines with XCLASS. The contours correspond to the 1.37 mm continuum as described in Fig. 1. For NGC7538 IRS1, only the region outside the continuum to the south-west is modelled by XCLASS and was scaled towards the continuum peak position following a temperature power-law distribution T ∝ r−0.4. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. The synthesised beam is shown in the bottom left corner and a scale bar in the bottom right corner of each panel. Maps of column density, velocity offset, linewidth, and source size are shown in Appendix E.",
            "Fig. 4: Position–velocity (PV) plots for best fitted transitions listed in Table 5 along cuts in the direction of rotation as depicted by dotted lines in Fig. 2. The width of the cut is the size of a synthesised beam to increase the signal-to-noise ratio. The PV plots of W3(H2O) E and W3(H2O) W make use of the A-array only observations in order to gain more resolution and disentangle the two cores from the circumbinary material. PV plots for all other sources make use of the full dataset observed in the CORE survey. The contours correspond to the 6σ level increasing in steps of 24σ. Yellow lines show the Keplerian rotation curves for enclosed masses, MPV, listed in Table 5 for each source. The inner radii that were masked out (i.e. excluded) in the fitting routine are shown as vertical dotted lines. The fitted central velocities and positions are shown as dashed lines. The zero offset corresponds to the continuum peak position. The crosses in the bottom right corners correspond to the spatial and spectral resolutions.",
            "Fig. 5: Ratio of free-fall to rotational timescale as a function of disk gas mass, showing most of the sources with CH3CN velocity gradients are rotationally supported. The blue and red dots correspond to the values calculated based on the rotational velocities at the edges of the disks on the blueshifted and redshifted sides, as depicted by crosses in Fig. 2 and listed in Table 3. The black dashed line corresponds to theoretical curve of tff/trot for a disk of mass Mgas in Keplerian rotation about a star with mass M∗ = 10 M (see Eq. 4).",
            "Fig. 6: Specific angular momentum radial profiles calculated using Eq. 7 along the cut with the strongest velocity gradient (dotted lines in Fig. 4) (circles), a cut with position angle +10◦ (triangles pointing up), and a cut with position angle −10◦ (triangles pointing down) with respect to the strongest velocity gradient, for the redshifted (red) and blueshifted (blue) sides of the emission. The blue and red filled regions show the error in j sin(i) for the circles. Note that the inclinations are not corrected for as they are not known. The blue and red dashed lines show least-squared power-law fits to the first two data points and extrapolated to larger radii. The values of the fitted slopes are noted in the legends and listed in Table 6 along with the intercepts. The blue and red dotted vertical lines correspond to radii associated with the edges of the disks depicted with × markers in Fig. 2. The black curve shows the maximum specific angular momentum calculated using Eq. 8 for M∗ listed in the sub-panels with the grey region corresponding to M∗ ± 5 M . The grey dashed line shows the j sin(i) ∝ r1.7 slope.",
            "Fig. 7: Toomre Q maps for the best disk candidates in the CORE survey assuming a protostar is located at the position of the continuum peak as depicted by a star and accounting for the self-gravity of the disk (protostellar and gas mass values are listed in Table 7). The contours correspond to the 1.37 mm continuum as described in Fig. 1. Regions outside of 6σ continuum contours are masked out. Fragments detected by ancillary observations are marked by plus symbols in green for AFGL2591 (Suri et al. 2021), IRAS23385 (Cesaroni et al. 2019), and NGC7538 IRS1 (Beuther et al. 2017). The synthesised beam is shown in the bottom left corner and a scale bar in the bottom right corner of each panel.",
            "Fig. 8: Distribution of median and minimum Q as a function of radius shown in solid and dashed blue lines. The dotted horizontal line corresponds to the global median Q computed over the entire disk and listed in Table 7. The dash-dotted red horizontal line shows the critical Q = 2 threshold.",
            "Fig. 9: Box-plot showing the Q distribution versus the ratio of gas to stellar mass, coloured according to the luminosity of the regions within which they reside. The boxes extend from the first to the third quartiles, with a red line at the median Q value. The whiskers extend from the box by ±1.5 times the box size. Disks with Q . 2 are Toomre unstable (i.e. all but Cep A & NGC7538 IRS9).",
            "Fig. A.1: Integrated intensity (zeroth moment) maps of CH3CN (123 − 113) showing the dense gas distribution for 15 of the 20 sources in the CORE survey. The contours and features are as described in Fig. 2.",
            "Fig. A.2: Intensity-weighted velocity dispersion (second moment) maps of CH3CN (123 − 113) showing the dense gas kinematics for 15 of the 20 sources in the CORE survey. The contours and features are as described in Fig. 2.",
            "Fig. B.1: Peak intensity (amplitude) maps of CH3CN (123 − 113) showing the dense gas kinematics for 15 of the 20 sources in the CORE survey obtained by fitting Gaussian profiles to their spectra. The contours and features are as described in Fig. 2.",
            "Fig. B.2: Peak velocity maps of CH3CN (123 − 113) showing the dense gas kinematics for 15 of the 20 sources in the CORE survey obtained by fitting Gaussian profiles to their spectra. The contours and features are as described in Fig. 2.",
            "Fig. B.3: Linewidth (FWHM) maps of CH3CN (123 − 113) showing the dense gas kinematics for 15 of the 20 sources in the CORE survey obtained by fitting Gaussian profiles to their spectra. The contours and features are as described in Fig. 2.",
            "Fig. C.1: Intensity maps of CO (2–1) emission from IRAM 30-m telescope integrated over the blueshifted and redshifted wings of emission, showing the outflow structure. The position of the strongest source in the field is depicted by a star. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. A scale-bar is shown in the bottom right corner of each panel. The map size of the IRAM 30-m observations is 1.5′ by 1.5′ with a half-power beam width of ∼11′′ at this frequency.",
            "Fig. C.2: Intensity maps of 13CO (2 − 1) emission from IRAM 30-m telescope integrated over the blueshifted and redshifted wings of emission, showing the outflow structure. The position of the strongest source in the field is depicted by a star. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. A scale-bar is shown in the bottom right corner of each panel. The map size of the IRAM 30-m observations is 1.5′ by 1.5′ with a half-power beam width of ∼11′′ at this frequency.",
            "Fig. C.3: Intensity maps of 13CO (2 − 1) emission from merged NOEMA and IRAM 30-m data integrated over the blueshifted and redshifted wings of emission, showing the outflow structure. The position of the strongest source in the field is depicted by a star. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. A scale-bar is shown in the bottom right corner of each panel. We did not merge the data for the pilot sources as we did not observe this target with the most compact NOEMA configuration (D-array), hence the missing panels.",
            "Fig. C.4: The greyscale corresponds to the 1.37 mm continuum while the blue and red contours correspond to the NOEMA intensity maps of 13CO (2 − 1) integrated over the blueshifted and redshifted wings of emission, tracing either outflows or disk winds.The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. A scale-bar is shown in the bottom right corner of each panel. Note that most of the emission is filtered out by the interferometer.Article number, page 36 of 46",
            "Fig. C.5: Intensity maps of C18O (2 − 1) emission from IRAM 30-m telescope integrated over the blueshifted and redshifted wings of emission, showing the outflow structure. The position of the strongest source in the field is depicted by a star. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. A scale-bar is shown in the bottom right corner of each panel. The map size of the IRAM 30-m observations is 1.5′ by 1.5′ with a half-power beam width of ∼11′′ at this frequency. C18O is not a good outflow tracer for all sources, hence the lack of contours in some targets.",
            "Fig. C.6: Intensity maps of SO (65 − 54) emission from IRAM 30-m telescope integrated over the blueshifted and redshifted wings of emission, showing the outflow structure. The position of the strongest source in the field is depicted by a star. The blue and red arrows correspond to the estimated directions of bipolar blueshifted and redshifted molecular outflows, respectively. A scale-bar is shown in the bottom right corner of each panel. The map size of the IRAM 30-m observations is 1.5′ by 1.5′ with a half-power beam width of ∼11′′ at this frequency.",
            "Fig. C.7: The distribution of absolute difference between the disk position angles and the assumed outflow position angles for our sample of 13 disk candidates in the CORE survey.",
            "Table 1: Positions and properties of the CORE sample, grouped in track-sharing pairs, adapted from Beuther et al. (2018).",
            "Table 2: Frequency setup of the narrow-band correlator and important lines covered.",
            "Table 3: Observational parameters for the disk candidates within the CORE survey.",
            "Table 4: Gas mass estimates.",
            "Table 5: KeplerFit parameters and dynamical mass estimates.",
            "Table 6: Fit parameters to the specific angular momentum radial profiles shown in Fig. 6 (dashed lines).",
            "Table 7: Overview of mass estimates and Toomre Q results."
        ],
        "imgs": [
            "$2305.00020v2-Figure1-1.png",
            "$2305.00020v2-Figure10-1.png",
            "$2305.00020v2-Figure11-1.png",
            "$2305.00020v2-Figure12-1.png",
            "$2305.00020v2-Figure2-1.png",
            "$2305.00020v2-Figure3-1.png",
            "$2305.00020v2-Figure4-1.png",
            "$2305.00020v2-Figure5-1.png",
            "$2305.00020v2-Figure6-1.png",
            "$2305.00020v2-Figure7-1.png",
            "$2305.00020v2-Figure8-1.png",
            "$2305.00020v2-Figure9-1.png",
            "$2305.00020v2-FigureA.1-1.png",
            "$2305.00020v2-FigureA.2-1.png",
            "$2305.00020v2-FigureB.1-1.png",
            "$2305.00020v2-FigureB.2-1.png",
            "$2305.00020v2-FigureB.3-1.png",
            "$2305.00020v2-FigureC.1-1.png",
            "$2305.00020v2-FigureC.2-1.png",
            "$2305.00020v2-FigureC.3-1.png",
            "$2305.00020v2-FigureC.4-1.png",
            "$2305.00020v2-FigureC.5-1.png",
            "$2305.00020v2-FigureC.6-1.png",
            "$2305.00020v2-FigureC.7-1.png",
            "$2305.00020v2-Table1-1.png",
            "$2305.00020v2-Table2-1.png",
            "$2305.00020v2-Table3-1.png",
            "$2305.00020v2-Table4-1.png",
            "$2305.00020v2-Table5-1.png",
            "$2305.00020v2-Table6-1.png",
            "$2305.00020v2-Table7-1.png"
        ]
    },
    {
        "id": "2305.00021",
        "abstract": "  During the last three decades the determination of the Unitarity Triangle\n(UT) was dominated by the measurements of its sides $R_b$ and $R_t$ through\ntree-level $B$ decays and the $\\Delta M_d/\\Delta M_s$ ratio, respectively, with\nsome participation of the measurements of the angle $\\beta$ through the mixing\ninduced CP-asymmetries like $S_{\\psi K_S}$ and $\\varepsilon_K$. However, as\npointed out already in 2002 by Fabrizio Parodi, Achille Stocchi and the present\nauthor, the most efficient strategy for a precise determination of the apex of\nthe UT, that is $(\\bar\\varrho,\\bar\\eta)$, is to use the measurements of the\nangles $\\beta$ and $\\gamma$. The second best strategy would be the measurements\nof $R_b$ and $\\gamma$. However, in view of the tensions between different\ndeterminations of $|V_{ub}|$ and $|V_{cb}|$, that enter $R_b$, the\n$(\\beta,\\gamma)$ strategy should be a clear winner once LHCb and Belle II will\nimprove the measurements of these two angles. In this note we recall our\nfinding of 2002 which should be finally realized in this decade through precise\nmeasurements of both angles by these collaborations. In this context we present\ntwo very simple formulae for $\\bar\\varrho$ and $\\bar\\eta$ in terms of $\\beta$\nand $\\gamma$ which could be derived by high-school students, but to my\nknowledge never appeared in the literature on the UT, not even in our 2002\npaper. We also emphasize the importance of precise measurements of both angles\nthat would allow to perform powerful tests of the SM through numerous\n$|V_{cb}|$-independent correlations between $K$ and $B$ decay branching ratios\n$R_i(\\beta,\\gamma)$ recently derived by Elena Venturini and the present author.\nThe simple findings presented here will appear in a subsection of a much longer\ncontribution to the proceedings of KM50 later this year. I exhibited them here\nso that they are not lost in the latter.\n",
        "title": "Waiting for Precise Measurements of $\\beta$ and $\\gamma$",
        "texts": [
            "Figure 1: The Unitarity Triangle.",
            "Table 1: Values of %̄ for different values of β and γ .",
            "Table 2: Values of η̄ for different values of β and γ ."
        ],
        "imgs": [
            "$2305.00021v1-Figure1-1.png",
            "$2305.00021v1-Table1-1.png",
            "$2305.00021v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00022",
        "abstract": "  Current theories of dynamical friction on galactic bars are based either on\nlinear perturbation theory, which is valid only in the fast limit where the bar\nchanges its pattern speed rapidly, or on adiabatic theory, which is applicable\nonly in the slow limit where the bar's pattern speed is near-constant. In this\npaper, we study dynamical friction on galactic bars spinning down at an\narbitrary speed, seamlessly connecting the fast and slow limits. We treat the\nbar-halo interaction as a restricted $N$-body problem and solve the\ncollisionless Boltzmann equation using the fast-angle-averaged Hamiltonian. The\nphase-space distribution and density wakes predicted by our averaged model are\nin excellent agreement with full 3D simulations. In the slow regime where\nresonant trapping occurs, we show that, in addition to the frictional torque,\nangular momentum is transferred directly due to the migration of the trapped\nphase-space: trapped orbits comoving with the resonance typically gain angular\nmomentum, while untrapped orbits leaping over the trapped island lose angular\nmomentum. Due to the negative gradient in the distribution function, gainers\ntypically outnumber the losers, resulting in a net negative torque on the\nperturber. Part of this torque due to the untrapped orbits was already\nidentified by Tremaine & Weinberg who named the phenomenon dynamical feedback.\nHere, we derive the complete formula for dynamical feedback, accounting for\nboth trapped and untrapped orbits. Using our revised formula, we show that\ndynamical feedback can account for up to $30\\%$ of the total torque on the\nMilky Way's bar.\n",
        "title": "Dynamical friction and feedback on galactic bars in the general\n  fast-slow regime",
        "texts": [
            "Figure 10. Phase-space distribution near a moving resonance predicted by linear perturbation theory (equation 58). Dotted lines mark the current position of the resonance. Linear theory qualitatively describes the near-resonant dynamics (Fig. 9) only in the fast regime (right figure) where libration is absent.",
            "Figure 11. Density wakes at the equatorial plane (𝑧 = 0) caused by (a) the corotation resonance 𝑵 = (0, 2, 2) , (b) the outer Lindblad resonance 𝑵 = (1, 2, 2) , and (c,d) the direct radial resonances 𝑵 = (1, 0, 2) and 𝑵 = (2, 0, 2) . The density is calculated from the distribution function evolved with the fast-angle averaged Hamiltonian. The bar lies on the 𝑥-axis and is rotating anti-clockwise. The black circles mark the resonant radius for circular orbits (𝐽𝑟 = 0).",
            "Figure 13. Left: model for the phase-mixed distribution function (equation 77). Middle: original distribution function (equation 52). Right: residual between the mixed model and full distribution. For all panels, the bar slowed from Ωp = 72 to 36 Gyr−1 with slowing rate 𝜂 = 0.001.",
            "Figure 14. Time evolution of the dynamical feedback (75) by the corotation resonance. The slowing rate 𝜂 increases from 0.001 (blue) to 0.01 (red) with equal spacing 0.00025.",
            "Figure 15. Dynamical feedback ?̂? from orbits with a specific 𝑱f as a function of the speed of the resonance 𝑠.",
            "Figure 16. Comparison between dynamical feedback (smooth line) and total torque (jagged line) by the corotation resonance for 𝜂 = 0.001.",
            "Figure 17. Dynamical feedback by the four strongest resonances for 𝜂 = 0.001.",
            "Figure 18. Comparison between the total dynamical feedback (smooth lines) and the total torque (jagged lines) computed from 3D test-particle simulations.",
            "Figure 3. Level curves of the averaged Hamiltonian (bottom) and its unperturbed component (top). Left column: Hamiltonian ?̄? (equation 16) in the static action coordinate 𝐽s. Right column: Hamiltonian 𝐻 (equation 25) in the comoving action coordinate Δ = 𝐽s − 𝐽s,res (𝑡 ) when 𝜂 = 0.002. 𝐽0 is the characteristic width of the resonance defined in equation (34).",
            "Figure 4. Time variation of the libration action of an orbit trapped and dragged by a moving resonance. The bar slowed from Ωp = 60 to 30 Gyr−1 in approximately 7.5 Gyr (slowing rate 𝜂 = 0.002) and the orbit was initially placed at 𝐽s = 550 kpc2 Gyr−1. The libration action calculated along the contours of the time-frozen Hamiltonian in the comoving frame 𝐻 (blue) is better preserved than that in the static frame ?̄? (black).",
            "Figure 6. Schematic diagram of the effective potential of the resonance.",
            "Figure 7. Black curve: The resonant-volume factor 𝐶 (equation 47) as a function of the dimensionless speed 𝑠 (equation 36). Blue and red curves: The local minimum 𝜃res and maximum 𝜃+sep of the resonant potential 𝑉 in the range 0 < 𝜃res < 𝜋/2 < 𝜃+sep < 𝜋. Green curve: The root 𝜃− sep of the equation 𝑉 (𝜃 ) = 𝑉 (𝜃+sep ) closest to 𝜃+sep (see Fig. 6). The difference Δ𝜃 = 𝜃+sep − 𝜃− sep is the angular width of the trapped phase-space.",
            "Figure 8. Time evolution of the phase-space distribution around a moving resonance in the slow regime (𝜂 = 0.002, 𝑠 ∼ 0.16). Left column: evolution with the 1D averaged Hamiltonian ?̄? using the CBE (equation 52). Right column: evolution with the 3D full Hamiltonian 𝐻 using a standard testparticle simulation.",
            "Figure 9. Dependence of the phase-space distribution near a resonance on the bar’s slowing rate 𝜂. Top row: the distribution after the bar has slowed from Ωp = 72 to 36 Gyr−1. Middle row: time evolution of the speed parameter 𝑠 (equation 36). The dotted lines mark the critical value 𝑠 = 1 above which trapping is absent. Bottom row: time evolution of the phase-space area of trapping represented by 𝐽ℓ,sep (equation 44). Decrease in 𝐽ℓ,sep at 𝜂 = 0.01 (third column) implies resonant escape."
        ],
        "imgs": [
            "$2305.00022v2-Figure10-1.png",
            "$2305.00022v2-Figure11-1.png",
            "$2305.00022v2-Figure13-1.png",
            "$2305.00022v2-Figure14-1.png",
            "$2305.00022v2-Figure15-1.png",
            "$2305.00022v2-Figure16-1.png",
            "$2305.00022v2-Figure17-1.png",
            "$2305.00022v2-Figure18-1.png",
            "$2305.00022v2-Figure3-1.png",
            "$2305.00022v2-Figure4-1.png",
            "$2305.00022v2-Figure6-1.png",
            "$2305.00022v2-Figure7-1.png",
            "$2305.00022v2-Figure8-1.png",
            "$2305.00022v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00023",
        "abstract": "  We assemble the largest CIV absorption line catalogue to date, leveraging\nmachine learning, specifically Gaussian processes, to remove the need for\nvisual inspection for detecting CIV absorbers. The catalogue contains\nprobabilities classifying the reliability of the absorption system within a\nquasar spectrum. Our training set was a sub-sample of DR7 spectra that had no\ndetectable CIV absorption in a large visually inspected catalogue. We used\nBayesian model selection to decide between our continuum model and our\nabsorption-line models. Using a random hold-out sample of 1301 spectra from all\nof the 26,030 investigated spectra in DR7 CIV catalogue, we validated our\npipeline and obtained an 87% classification performance score. We found good\npurity and completeness values, both ~80%, when a probability of ~95% is used\nas the threshold. Our pipeline obtained similar CIV redshifts and rest\nequivalent widths to our training set. Applying our algorithm to 185,425\nselected quasar spectra from SDSS DR12, we produce a catalogue of 113,775 CIV\ndoublets with at least 95% confidence. Our catalogue provides maximum a\nposteriori values and credible intervals for CIV redshift, column density, and\nDoppler velocity dispersion. We detect CIV absorption systems with a redshift\nrange of 1.37 $\\!-\\!$ 5.1, including 33 systems with a redshift larger than 5\nand 549 absorbers systems with a rest equivalent width greater than 2 A at more\nthan 95% confidence. Our catalogue can be used to investigate the physical\nproperties of the circumgalactic and intergalactic media.\n",
        "title": "Machine Learning Uncovers the Universe's Hidden Gems: A Comprehensive\n  Catalogue of CIV Absorption Lines in SDSS DR12",
        "texts": [
            "Figure 1. This is a flow chart for our pipeline. Training spectra from SDSS DR7 are used to train a Gaussian process kernel with which to model the quasar continuum (i.e., null model, M𝑁 ). Analytic Voigt profiles are used to construct models for absorption from a C iv doublet (M𝐷) or a generic singlet absorber (M𝑆). Conditioning on DR12 spectra produces a posterior probability estimate for each model that can be used to decide if there is a C iv absorber in the given spectrum or not. Moreover, for the absorber models, M𝐷 and M𝑆 , we have a posterior distribution for each model parameter: absorber redshift, Doppler velocity dispersion for the absorption profile, and the absorber column density.",
            "Figure 10. Purity (Equation 26) and completeness (Equation 27) of the GP catalogue compared to the PM catalogue for different C iv posterior probability (Equation 14) thresholds. The maximum allowed velocity separation between our catalogue and the PM catalogue absorbers is 350 km s−1. The intersection of the purity (dashed blue curve) and completeness (solid red curve) at a threshold of ∼ 95% gives us a balanced purity/completeness of ∼ 80%.",
            "Figure 11. The ratio of the difference between rest equivalent width from our pipeline with boxcar flux summation (WGP,flux",
            "Figure 12. Distribution of W𝑟,1548 for absorbers in four categories described in Section 4.4: detected in both the GP and PM catalogues (thick black line), in the GP uncertain (brown), in GP only (green), in the PM catalogue only (blue). The rest equivalent width distribution is similar for all categories. There are some strong absorbers with (W𝑟,1548 > 1.2Å) classified as “PM only”. Visual inspection of the spectra of these systems indicates that they are part of a triplet/complex absorber or a broad mini-BAL system.",
            "Figure 13. Example spectrum with two C iv absorbers found by GP with high confidence but not included in the PM catalogue. The QSO-ID is 51994- 0309-592 and 𝑧QSO = 2.76. Posterior probabilities for the two searches are P(M𝐷 ) = [1.00, 0.98]. The maximum a posteriori absorption redshifts are 𝑧C iv = [2.288, 2.650], and the rest equivalent widths are WGP,flux",
            "Figure 14. Example of an absorber at 𝑧PM C iv = 1.822 detected by the PM catalogue, but assigned a relatively low probability (P(M𝐷 ) = 49%) by the GP catalogue. The QSO-ID for this spectrum is 52367-0332-585, and the quasar redshift is 1.87. The vertical dashed lines show the position of PM absorbers. The posterior absorption probabilities are P(M𝐷 ) = [1.00, 1.00, 0.49, 0.15], with maximum a posterior absorber redshifts of 𝑧C iv = [1.556, 1.827, 1.822, 1.693], and the rest equivalent widths are WGP,flux",
            "Figure 15. Example spectrum containing a PM only absorber for QSO-ID: 51943-0300-475 and 𝑧QSO = 4.31 where 𝑧PM C iv = [3.5309, 3.5389] (vertical dashed lines). GP assigns P(M𝐷 ) = 1 to 𝑧𝐺𝑃 C iv = 3.540574 which is offset by only 110 km s−1from 𝑧PM C iv = 3.5389. Before the second search, we mask 350 km s−1around the first absorber and thus are unable to detect the second PM catalogue absorber.",
            "Figure 18. Column density statistics for our GP results (blue histograms) compared to the training C iv catalog from SDSS DR7 (red histograms). Each panel is showing a specific redshift bin. Y-axes show the noralized probability distribusion function (PDF). Please note that column density values should be considered as lower limits ((Cooksey et al. 2013)) because they lines are partially to completely saturated so we can only measure lower limits.",
            "Figure 2. An example learned quasar emission function (red curve) with the normalised observed smoothed flux (blue curve). The shaded red region shows 1𝜎 uncertainties. The SDSS DR7 quasar has QSO-ID: 51630-0266- 280 and redshift 2.57. Note that we search for absorbers starting 3000 km s−1 red-ward of the quasar’s redshift (shown by the solid red vertical line), so the moderate failure to match the quasar C iv emission line in this case does not lead to an artificial preference for C iv absorption. Prominent emission lines are marked by dashed vertical lines.",
            "Figure 20. Distribution of the maximum a posteriori Doppler velocity dispersion values for absorbers detected in SDSS DR12 with P(M𝐷 ) ≥ 0.95. Our prior distribution for Doppler velocity dispersion was uniform between 35 km s−1and 115 km s−1but the posterior distribution is bimodal. The larger 𝜎C iv posterior values are mostly associated with C iv absorbers found near low SNR pixels.",
            "Figure 21. The distribution of the rest equivalent width of the 1548 Å (WGP,Voigt",
            "Figure 3. Learned covariance matrix K (see Equation 8 and Equation 10) for our null (continuum) model. This matrix is built up by considering the observed flux and noise from our C iv-free training set (see Section 2). Brighter pixels show stronger correlations and darker regions weaker ones. The wavelengths of prominent emission lines are labelled. The bright diagonal implies stronger correlations between pixels at smaller wavelength separation.",
            "Figure 4. The figure shows the spectrum of QSO-ID: 51608-0267-264 with 𝑧QSO=1.89 (blue) where the singlet model (green) is preferred over the C iv doublet model (red), which is in turn preferred over the null model. If we did not have M𝑆 , our pipeline would have incorrectly detected a C iv absorber at 𝑧C iv = 1.635.",
            "Figure 5. Prior probability for a spectrum containing 𝑘 C iv absorbers as a function of quasar redshift, for 𝑘 = 1−7. We use the average number of absorbers in the PM spectrum in our wavelength search range. C iv is a priori more likely as 𝑧QSO increases but reaches a plateau at 𝑧QSO ∼ 2.5−3. This is because the C iv wavelength coverage is shorter for low 𝑧QSO as the 1548 Å emission line pushes to the blue-end of the SDSS spectral range. Note that we assume the same prior for the singlet model for 𝑘 = 1−7.",
            "Figure 6. Example SDSS DR7 spectrum with QSO-ID: 51608-0267-264 and 𝑧QSO = 1.89. Both PM and our pipeline find three absorbers between 𝑧C iv = 1.65–1.85. We also find an absorber at 𝑧C iv = 1.489 (probability 92%) that was not detected by PM, due to noise in this part of the spectrum (specifically, the 1550 line was not automatically detected with their parameters, thus the doublet was not visually inspected). The probabilities that our pipeline provides for the existence of the first, second, third, and forth C iv absorber are 𝑃 (C iv) = [1.00, 1.00, 1.00, 0.92], respectively, our maximum a posteriori absorber redshift values are 𝑧C iv = [1.829, 1.672, 1.775, 1.489], and our rest equivalent widths from Voigt profile integration (see Equation 30) are 𝑊GP 𝑟,1548 = [1.37, 0.87, 0.90, 0.79] Å. In the PM-catalogue the absorber redshifts are 𝑧PM = [1.831, 1.673, 1.777] with corresponding 𝑊PM 𝑟,1548 = [1.21 ± 0.18, 1.40 ± 0.20, 0.94 ± 0.19] Å",
            "Figure 7. Velocity difference between the detected absorbers in the GP pipeline with P(M𝐷 ) ≥ 0.95 in the validation set and the absorbers in the PM catalogue. Only absorber pairs closer than 350 km s−1are shown. The thick red line shows 𝛿vPM,GP = 0 and the dashed lines are 𝛿vPM,GP = ±150 km s−1(the SDSS spectral resolution). The median offset is 𝛿vmed PM,GP ≈-50 km s−1, which is less than an SDSS pixel (69 km s−1).",
            "Figure 8. Velocity separation (Equation 25) between GP and PM detected C iv absorption systems is shown versus the reported rest equivalent width values for 1548 Å in the PM catalogue (WPM 𝑟,1548). There is no correlation between the velocity separation and the strength of detected absorbers.",
            "Figure 9. Receiver Operator Characteristic (ROC) curve for our DR7 validation. True Positive Rate is plotted versus False Positive Rate. True positives are C iv systems in our catalogue at least 350 km s−1apart from an absorber in the PM catalogue with ranking ≥2 given any P(M𝐷 ) threshold between 0 and 1. False positives are those absorbers in our catalogue that do not have any matching absorber in the PM catalogue; though they may be real C iv absorbers (see Figure 6). Above a relatively small False Positive Rate (∼ 0.2), our algorithm procedure obtains True Positive Rate above 80% and, hence, is a successful way to identify C iv absorbers. The area under the ROC curve (AUC) is a quantitative metric for the equality of the GP algorithm; we get AUC = 0.87, a reasonable value compared to an ideal classification that gives AUC = 1.00.",
            "Table 1. For each sight-line, identified by Column 1 and 2, we report the absorber’s redshift (Column 3), column density in log(cm−2 ) (Column 4), Doppler velocity dispersion in km s−1(Column 5), rest equivalent width for 1548 Å W𝑟,1548 (Column 6), rest equivalent width for 1550 Å W𝑟,1550 (Column 7), the posterior probability of the C iv absorber P(M𝐷) (Column 8), and the posterior probability of the singlet absorber P(M𝑆) (Column 9). We show only absorbers with P(M𝐷)≠NaN. This table demonstrates a portion of the full table for the first ten rows. Note that those measurements with large errors are uncertain (i.e. low absorption model posterior probability). The full table with 445,765 rows is available at https://doi.org/10.5281/zenodo.7872725.",
            "Table 2. The number of spectra containing different numbers of C iv absorbers for various doublet model probability thresholds, P(M𝐷). The first column shows the number of C iv absorbers found within each spectrum (see Section 3.6) . The second through fourth columns show probability thresholds of > 65%, 85%, and 95% respectively. Cells show the number of quasar spectra falling in each category, together with the corresponding percentage of the 185,425 spectra in our SDSS DR12 sample."
        ],
        "imgs": [
            "$2305.00023v2-Figure1-1.png",
            "$2305.00023v2-Figure10-1.png",
            "$2305.00023v2-Figure11-1.png",
            "$2305.00023v2-Figure12-1.png",
            "$2305.00023v2-Figure13-1.png",
            "$2305.00023v2-Figure14-1.png",
            "$2305.00023v2-Figure15-1.png",
            "$2305.00023v2-Figure18-1.png",
            "$2305.00023v2-Figure2-1.png",
            "$2305.00023v2-Figure20-1.png",
            "$2305.00023v2-Figure21-1.png",
            "$2305.00023v2-Figure3-1.png",
            "$2305.00023v2-Figure4-1.png",
            "$2305.00023v2-Figure5-1.png",
            "$2305.00023v2-Figure6-1.png",
            "$2305.00023v2-Figure7-1.png",
            "$2305.00023v2-Figure8-1.png",
            "$2305.00023v2-Figure9-1.png",
            "$2305.00023v2-Table1-1.png",
            "$2305.00023v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00024",
        "abstract": "  We present new CO ($J=5-4$ and $7-6$) and [CI] ($^3P_2\\,-\\, ^3P_1$ and\n$^3P_1\\,-\\, ^3P_0$) emission line observations of the star-forming galaxy D49\nat the massive end of the Main Sequence at $z=3$. We incorporate previous CO\n($J=3-2$) and optical-to-millimetre continuum observations to fit its spectral\nenergy distribution (SED). Our results hint at high-$J$ CO luminosities\nexceeding the expected location on the empirical correlations with the infrared\nluminosity. [CI] emission fully consistent with the literature trends is found.\nWe do not retrieve any signatures of a bright active galactic nucleus that\ncould boost the $J=5-4,\\,7-6$ lines in either the infrared or X-ray bands, but\nwarm photon-dominated regions, shocks or turbulence could in principle do so.\nWe suggest that mechanical heating could be a favourable mechanism able to\nenhance the gas emission at fixed infrared luminosity in D49 and other\nmain-sequence star-forming galaxies at high redshift, but further investigation\nis necessary to confirm this explanation. We derive molecular gas masses from\ndust, CO, and [CI] that all agree within the uncertainties. Given its large\nstar formation rate (SFR) $\\sim 500~M_\\odot~{\\rm yr}^{-1}$ and stellar mass\n$>10^{11.5}~M_\\odot$, the short depletion time scale of $<0.3$ Gyr might\nindicate that D49 is experiencing its last growth spurt and will soon transit\nto quiescence.\n",
        "title": "Molecular gas content and high excitation of a massive main-sequence\n  galaxy at z = 3",
        "texts": [
            "Fig. 3. L′line/LIR [K km s−1 pc2 L−1 ] ratios as a function of LIR. Clockwise, from top left: CO (5−4), CO (7−6), [C I](3P1 − 3P0), and [C I](3P2 − 3P1). D49 is shown as a red star, BX610 as a turquoise diamond, NGC 6240 as a purple square, and MD94 as a green triangle. The blue and orange points are respectively from the local and high-redshift galaxy samples in Valentino et al. (2020), green points are the samples from Boogaard et al. (2020), and pink points are from Valentino et al. (2021). BX610 and MD94 are not shown in the CO (5 − 4)-IR plane (top left) due to lack of CO (5 − 4) observations. The black dashed and grey lines indicate the best fit in the log(LIR)-log(L′line) space and random sampling of the posterior distribution. Two galaxies in Valentino et al. (2021) are found to have high L′CO(5−4)/LIR ratios (pink down-pointing triangles in the upper left panel), both of which are also found to have strong AGN signatures ( fAGN ∼ 0.9). Three galaxies in Boogaard et al. (2020) are found to have high L′CO(7−6)/LIR ratios (green down-pointing triangles in the upper right panel, one of which is obscured by purple square). AGN signatures are detected in two of them ( fAGN ∼ 0.08), while the other one, with the highest L′CO(7−6)/LIR ratio, is labelled as a non-AGN.",
            "Table 1. Best-fit results of CO and [CI] lines of D49, obtained by fixing the redshift and FWHM for CO (5 − 4), CO (7 − 6), and [CI] (2 − 1). The upper limit on [CI] (1− 0) is computed within ±3σv, with the bestfit redshift zCO(5−4) = zCO(7−6) = z[CI](2−1) = 2.847. CO (3 − 2) is from Magdis et al. (2017).",
            "Table 2. Stardust fitting result.",
            "Table A.2. Hydrogen mass estimations by different methods."
        ],
        "imgs": [
            "$2305.00024v1-Figure3-1.png",
            "$2305.00024v1-Table1-1.png",
            "$2305.00024v1-Table2-1.png",
            "$2305.00024v1-TableA.2-1.png"
        ]
    },
    {
        "id": "2305.00026",
        "abstract": "  In order to explore the suitability of a fine-grained classification of\njournal articles by exploiting multiple sources of information, articles are\norganized in a two-layer multiplex. The first layer conveys similarities based\non the full-text of articles, and the second similarities based on cited\nreferences. The information of the two layers are only weakly associated. The\nSimilarity Network Fusion process is adopted to combine the two layers into a\nnew single-layer network. A clustering algorithm is applied to the fused\nnetwork and the classification of articles is obtained. In order to evaluate\nits coherence, this classification is compared with the ones obtained by\napplying the same algorithm to each of two layers. Moreover, the classification\nobtained for the fused network is also compared with the classifications\nobtained when the layers of information are integrated using different methods\navailable in literature. In the case of the Cambridge Journal of Economics,\nSimilarity Network Fusion appears to be the best option. Moreover, the achieved\nclassification appears to be fine-grained enough to represent the extreme\nheterogeneity characterizing the contributions published in the journal.\n",
        "title": "Fine-grained classification of journal articles by relying on multiple\n  layers of information through similarity network fusion: the case of the\n  Cambridge Journal of Economics",
        "texts": [
            "Figure 1: The workflow of exploratory analysis.",
            "Table 1: Top-10 most cited documents in the Cambridge Journal of Economics (1985-2013)",
            "Table 2: Generalized distance correlation between article similarity matrices.",
            "Table 3: Clusters of articles obtained through Louvain algorithm applied to article similarity matrices based on cited references, topics and bags of words.",
            "Table 4: Values of Cramer’s V for measuring the association between clusters obtained from article similarity matrices based on cited references, topics and bags of words.",
            "Table 5: Generalized distance correlation between fused matrices and similarity matrices based on topics and cited references.",
            "Table 6: Generalized distance correlation between fused matrices.",
            "Table 7: Partial distance correlation between the seven fused networks and the two corresponding layers. Each row reports the values of partial distance correlation between the fused networks and one of the layers, conditioned on the other layer.",
            "Table 8: Clusters of articles obtained through Louvain algorithm applied to fused networks.",
            "Table 9: Values of Cramer’s V for measuring the association between classifications of articles in the fused networks."
        ],
        "imgs": [
            "$2305.00026v1-Figure1-1.png",
            "$2305.00026v1-Table1-1.png",
            "$2305.00026v1-Table2-1.png",
            "$2305.00026v1-Table3-1.png",
            "$2305.00026v1-Table4-1.png",
            "$2305.00026v1-Table5-1.png",
            "$2305.00026v1-Table6-1.png",
            "$2305.00026v1-Table7-1.png",
            "$2305.00026v1-Table8-1.png",
            "$2305.00026v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00027",
        "abstract": "  We investigate the reach of future gravitational wave (GW) detectors in\nprobing inflaton couplings with visible sector particles that can either be\nbosonic or fermionic in nature. Assuming reheating takes place through\nperturbative quantum production from vacuum in presence of classical inflaton\nbackground field, we find that the spectral energy density of the primordial GW\ngenerated during inflation becomes sensitive to inflaton-matter coupling. We\nconclude, obeying bounds from Big Bang Nucleosysthesis and Cosmic Microwave\nBackground, that, e.g., inflaton-scalar couplings of the order of\n$\\sim\\mathcal{O}(10^{-20})$ GeV fall within the sensitivity range of several\nproposed GW detector facilities. However, this prediction is sensitive to the\nsize of the inflationary scale, nature of the inflaton-matter interaction and\nshape of the potential during reheating. Having found the time-dependent\neffective inflaton decay width, we also discuss its implications for dark\nmatter (DM) production from the thermal plasma via UV freeze-in during\nreheating. It is shown, that one can reproduce the observed DM abundance for\nits mass up to several PeVs, depending on the dimension of the operator\nconnecting DM with the thermal bath and the associated scale of the UV physics.\nThus we promote primordial GW to observables sensitive to feebly coupled\ninflaton, which is very challenging if not impossible to test in conventional\nparticle physics laboratories or astrophysical measurements.\n",
        "title": "Measuring Inflaton Couplings via Primordial Gravitational Waves",
        "texts": [
            "Figure 1. Evolution of cosmological comoving length scales with the scale factor at different epochs of the evolution of the universe. Here “RD” stands for radiation domination, “MD” implies matter domination, and “DE” indicates dark energy domination. In each case corresponding equation of state is also mentioned.",
            "Figure 2. ϕ → SS scenario. Top Left: Reheating temperature Trh as a function of n. The red part of the curve is discarded from present bound on ∆Neff due to PLANCK [61]. The grey-shaded region is in conflict with the BBN limit on Trh.Top Right: Ω (0) GW as a function of frequency, where different curves correspond to different choices of Λ for a fixed gSϕ and n.The orange-shaded regions are discarded from ∆Neff due to overproduction of GWs. Bottom Left: Same as top right, but for fixed Λ and n, with different choices of gSϕ specified below the curves. Bottom Right: Same as bottom left but for a fixed Λ and gSϕ, different curves correspond to different n values. In the bottom and upper-right panels the parameters Λ, n and gSϕ are chosen so that the BBN limit Trh > 4 MeV is satisfied [cf. Fig. 5]. Moreover, in the bottom panels, we show sensitivities of future GWs experiments.",
            "Figure 3. Same as Fig. 2, but for ϕ → ψψ scenario. In the top left panel the vertical dashed line corresponds to n = 7/2, for which βψ = (n+ 4)/(n+ 1) (see text for details).",
            "Figure 5. ϕ → SS (top left), ϕ → ψψ (top right) and ϕ → aa (bottom) scenario. In all cases the red shaded region is disallowed from BBN bound on reheating temperature Trh < 4 MeV, the cyan dashed region is forbidden from PLANCK observed ∆Neff bound on GW overproduction at f = fmax, and the “CMB bound” discards scale of inflation Λ > 1.34 × 1016 GeV from constraint on tensor to scalar ratio.",
            "Figure 7. Left: Contours satisfying relic abundance for ϕ → SS (black solid), ϕ → ψψ (black dotted) and ϕ→ aa (black dot-dashed) scenarios. Right: GW spectrum for the three cases. We fix Λ = 1015 GeV and n = 10, while choose different coupling strengths (see text).",
            "Table 1. Numerical values of the summation factors appearing in Eq. (A.21), for different values of n.",
            "Table 2. Numerical values of the inflaton field amplitude and the corresponding number of e-folds N⋆ for different values of n and fixed α = 1/6."
        ],
        "imgs": [
            "$2305.00027v2-Figure1-1.png",
            "$2305.00027v2-Figure2-1.png",
            "$2305.00027v2-Figure3-1.png",
            "$2305.00027v2-Figure5-1.png",
            "$2305.00027v2-Figure7-1.png",
            "$2305.00027v2-Table1-1.png",
            "$2305.00027v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00028",
        "abstract": "  Non-linear polynomial systems over finite fields are used to model functional\nbehavior of cryptosystems, with applications in system security, computer\ncryptography, and post-quantum cryptography. Solving polynomial systems is also\none of the most difficult problems in mathematics. In this paper, we propose an\nautomated reasoning procedure for deciding the satisfiability of a system of\nnon-linear equations over finite fields. We introduce zero decomposition\ntechniques to prove that polynomial constraints over finite fields yield finite\nbasis explanation functions. We use these explanation functions in model\nconstructing satisfiability solving, allowing us to equip a CDCL-style search\nprocedure with tailored theory reasoning in SMT solving over finite fields. We\nimplemented our approach and provide a novel and effective reasoning prototype\nfor non-linear arithmetic over finite fields.\n",
        "title": "SMT Solving over Finite Field Arithmetic",
        "texts": [
            "Figure 1: Transition Rules of MCSat",
            "Table 1: Instances solved by FFSat, GB, and GBlex, out of 25 polynomial systems per test set."
        ],
        "imgs": [
            "$2305.00028v2-Figure1-1.png",
            "$2305.00028v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00032",
        "abstract": "  Online games with modifiable virtual environments (MVEs) have become highly\npopular over the past decade. Among them, Minecraft -- supporting hundreds of\nmillions of users -- is the best-selling game of all time, and is increasingly\noffered as a service. Although Minecraft is architected as a distributed\nsystem, in production it achieves this scale by partitioning small groups of\nplayers over isolated game instances. From the approaches that can help other\nkinds of virtual worlds scale, none is designed to scale MVEs, which pose a\nunique challenge -- a mix between the count and complexity of active in-game\nconstructs, player-created in-game programs, and strict quality of service.\nServerless computing emerged recently and focuses, among others, on service\nscalability. Thus, addressing this challenge, in this work we explore using\nserverless computing to improve MVE scalability. To this end, we design,\nprototype, and evaluate experimentally Servo, a serverless backend architecture\nfor MVEs. We implement Servo as a prototype and evaluate it using real-world\nexperiments on two commercial serverless platforms, of Amazon Web Services\n(AWS) and Microsoft Azure. Results offer strong support that our serverless MVE\ncan significantly increase the number of supported players per instance without\nperformance degradation, in our key experiment by 40 to 140 players per\ninstance, which is a significant improvement over state-of-the-art commercial\nand open-source alternatives. We release Servo as open-source, on Github:\nhttps://github.com/atlarge-research/opencraft\n",
        "title": "Servo: Increasing the Scalability of Modifiable Virtual Environments\n  Using Serverless Computing -- Extended Technical Report",
        "texts": [
            "Fig. 1: The maximum number of supported players in Servo.",
            "Fig. 10: Serverless Terrain Generation Performance.",
            "Fig. 12: Performance improvement of serverless terrain generation (Servo) compared to local generation (Opencraft) for varying workloads.",
            "Fig. 13: Terrain retrieval latency for local and cloud storage.",
            "Fig. 2: An operational model of MVEs. Elements highlighted in blue indicate the components most relevant to this work.",
            "Fig. 3: Download latency (variability) from Azure Blob Storage for two types of game data.Vertical bars indicate approximate network latency thresholds for FPS (blue, left), RPG (green, middle) and RTS (red, right) games [35].",
            "Fig. 4: Servo design overview. Simulated constructs (SC) and",
            "Fig. 5: A visual representation of speculative execution in Servo. Colored areas are simulated constructs. White areas are static parts of the virtual world.",
            "Fig. 6: Example of speculative execution for simulated constructs. Servo simulates the construct locally, until it receives the results from the remote function.",
            "Fig. 7: Comparing the scalability of Servo with alternative systems. Scalability is expressed in maximum number of players while maintaining stable performance. Missing bars indicate the game could not support any players.",
            "Fig. 8: Efficiency of offloaded simulation for varying tick leads (left), and simulation lengths (right).",
            "Fig. 9: Latency (left) and number of invocations per minute (right) for varying simulations lengths in ticks.",
            "TABLE I: Overview of Experiments. Experiments focus on Simulated Constructs (SC), Terrain Generation (TG), and Remote Storage (RS). Components either run locally (L), use serverless computing (S), or combine the two (L+S). For a detailed description of parameters, workload, environment, and explanations on the notation, see Section IV-A."
        ],
        "imgs": [
            "$2305.00032v1-Figure1-1.png",
            "$2305.00032v1-Figure10-1.png",
            "$2305.00032v1-Figure12-1.png",
            "$2305.00032v1-Figure13-1.png",
            "$2305.00032v1-Figure2-1.png",
            "$2305.00032v1-Figure3-1.png",
            "$2305.00032v1-Figure4-1.png",
            "$2305.00032v1-Figure5-1.png",
            "$2305.00032v1-Figure6-1.png",
            "$2305.00032v1-Figure7-1.png",
            "$2305.00032v1-Figure8-1.png",
            "$2305.00032v1-Figure9-1.png",
            "$2305.00032v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00033",
        "abstract": "  Phylogenetic networks are increasingly being considered as better suited to\nrepresent the complexity of the evolutionary relationships between species. One\nclass of phylogenetic networks that has received a lot of attention recently is\nthe class of orchard networks, which is composed of networks that can be\nreduced to a single leaf using cherry reductions. Cherry reductions, also\ncalled cherry-picking operations, remove either a leaf of a simple cherry\n(sibling leaves sharing a parent) or a reticulate edge of a reticulate cherry\n(two leaves whose parents are connected by a reticulate edge). In this paper,\nwe present a fixed-parameter tractable algorithm to solve the problem of\nfinding a maximum agreement cherry-reduced subnetwork (MACRS) between two\nrooted binary level-1 networks. This is first exact algorithm proposed to solve\nthe MACRS problem. As proven in earlier work, there is a direct relationship\nbetween finding an MACRS and calculating a distance based on cherry operations.\nAs a result, the proposed algorithm also provides a distance that can be used\nfor the comparison of level-1 networks.\n",
        "title": "Finding agreement cherry-reduced subnetworks in level-1 networks",
        "texts": [
            "Fig. 1. In this figure, leaves are represented by open circles, tree vertices as filled circles, reticulations as filled squares, and the root of the network as a filled, inverted triangle. Network N1 is a level-1 network with |R(N )| = 2. N1 is a reticulation-trimmed subnetwork of N1 with respect to F = ∅. Network N2 = N1〈(d, e)〉, where (d, e) is a simple cherry/reduction. Network N3 = N2〈(e, f)〉 where (e, f) is a reticulated cherry/reduction. N3 is reticulation-trimmed subnetwork of N1 and of N2 with respect to F = {(x, r2)}. Network N4 = N3〈(c, e) · (f, e) · (e, b)〉 and is a reticulationtrimmed subnetwork of N1 and of N2 with respect to F = {x, r2), (v, r1)} or to F = {(w, r2), (v, r1)}. Network N5 ≃ N4, in fact, there are CSs that may head lead to leaf e being any of leaves c, d, e, or f . Each of these networks would have the same label set on that leaf, and all are weakly isomorphic with N5.",
            "Fig. 2. In this figure, leaves are represented by open circles, tree vertices as filled circles, reticulations as filled squares. A subnetwork without reticulations is represented by a large open triangle, a subnetwork that may be reticulated is represented by a large open blob. This Figure shows an example of the operation of Algorithm 3, note how R(u) ∪ R(v) \\ {v} = ∅ in this example. Subnetwork under label (1) is an example network at line 7, the dotted line represents the removed reticulation edge (u, v) by line 5 and both leaves u′ and v′ have been constructed (leaf labels are not shown). The network under label (2) shows the state of network (1) at line 8 when edges (p(u), u′) and (p(v), v′) have been added.The network under label (3) shows the state of the network under (1) at line 9 when vertices in reach(u,N ′)∪ reach(v,N ′) are removed.",
            "Fig. 3. In this figure, tree vertices as filled circles and reticulations as filled squares. A subnetwork is represented by a large open blob. vertices in red are in the same nontrivial biconnected component. Yellow edges are path π1 1 and green edges are path π1 r . Tree vertex v is a trivial biconnected component itself such that R(v) 6= ∅."
        ],
        "imgs": [
            "$2305.00033v1-Figure1-1.png",
            "$2305.00033v1-Figure2-1.png",
            "$2305.00033v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00034",
        "abstract": "  While conditional generation models can now generate natural language well\nenough to create fluent text, it is still difficult to control the generation\nprocess, leading to irrelevant, repetitive, and hallucinated content. Recent\nwork shows that planning can be a useful intermediate step to render\nconditional generation less opaque and more grounded. We present a web\nbrowser-based demonstration for query-focused summarization that uses a\nsequence of question-answer pairs, as a blueprint plan for guiding text\ngeneration (i.e., what to say and in what order). We illustrate how users may\ninteract with the generated text and associated plan visualizations, e.g., by\nediting and modifying the blueprint in order to improve or control the\ngenerated output.\n  A short video demonstrating our system is available at\nhttps://goo.gle/text-blueprint-demo.\n",
        "title": "Text-Blueprint: An Interactive Platform for Plan-based Conditional\n  Generation",
        "texts": [
            "Figure 2: a) End-to-end and b) iterative Blueprint models. The end-to-end model generates the entire blueprint plan before generating the output text, while the iterative model plans and generates one proposition at a time, conditioning on the input and the sentences generated so far. Each portion of the output is color-coded with its corresponding question-answer pair.",
            "Figure 3: Schematic representation of the different components of the web browser-based demonstration.",
            "Figure 4: Example snapshot of the results obtained with the end-to-end Blueprint model for the user query \"Why is the sky blue?\". Depending on which question-answer pairs the user selects, different summaries can be generated.",
            "Figure 5: Snapshot of the results obtained with the interactive Blueprint model for the query “What is the Titanic known for?”. Questions highlighted in red were manually added by the user, leading to a different output.",
            "Table 1: Examples of machine-generated and manually-edited plans and their corresponding summaries. We highlight in bold changes made by the user and the resulting changes to the summary.",
            "Table 2: Examples of machine-generated and manually-edited plans and their corresponding summaries (Continued). We highlight in bold changes made by the user and the resulting changes to the summary."
        ],
        "imgs": [
            "$2305.00034v1-Figure2-1.png",
            "$2305.00034v1-Figure3-1.png",
            "$2305.00034v1-Figure4-1.png",
            "$2305.00034v1-Figure5-1.png",
            "$2305.00034v1-Table1-1.png",
            "$2305.00034v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00036",
        "abstract": "  We study the linear stability of a planar interface separating two fluids in\nrelative motion, focusing on the symmetric configuration where the two fluids\nhave the same properties (density, temperature, magnetic field strength, and\ndirection). We consider the most general case with arbitrary sound speed\n$c_{\\rm s}$, Alfv\\'en speed $v_{\\rm A}$, and magnetic field orientation. For\nthe instability associated with the fast mode, we find that the lower bound of\nunstable shear velocities is set by the requirement that the projection of the\nvelocity onto the fluid-frame wavevector is larger than the projection of the\nAlfv\\'en speed onto the same direction, i.e., shear should overcome the effect\nof magnetic tension. In the frame where the two fluids move in opposite\ndirections with equal speed $v$, the upper bound of unstable velocities\ncorresponds to an effective relativistic Mach number $M_{re} \\equiv v/v_{\\rm\nf\\perp} \\sqrt{(1-v_{\\rm f\\perp}^2)/(1-v^2)} \\cos\\theta=\\sqrt{2}$, where $v_{rm\nf\\perp}=[v_A^2+c_{\\rm s}^2(1-v_A^2)]^{1/2}$ is the fast speed assuming a\nmagnetic field perpendicular to the wavevector (here, all velocities are in\nunits of the speed of light), and $\\theta$ is the laboratory-frame angle\nbetween the flow velocity and the wavevector projection onto the shear\ninterface. Our results have implications for shear flows in the magnetospheres\nof neutron stars and black holes -- both for single objects and for merging\nbinaries -- where the Alfv\\'en speed may approach the speed of light.\n",
        "title": "Linear analysis of the Kelvin-Helmholtz instability in relativistic\n  magnetized symmetric flows",
        "texts": [
            "Figure 1. Schematic diagram of the interface separating two fluids in relative motion. The interface (grey color) is located in the 𝑥 − 𝑧 plane. Above and below the interface are fluids I and II with the same Alfvén speed 𝑣A and sound speed 𝑐s. q∥ is the projection of wavevector q onto the interface. We consider the system in the laboratory frame where fluids I and II have shear velocities +𝑣?̂? and −𝑣?̂?, respectively. B0 is the magnetic field vector in the fluid rest frame. 𝜃 is the angle between q∥ and ?̂? (in the laboratory frame) while Ω is the angle between B0 and ?̂? (in the fluid frame).",
            "Figure 2. Dependence of the instability growth rate Im(𝜙) on 𝑀𝑟 andΩwhen 𝜃 = 0 (i.e., wavevector along the shear flow), for three choices of 𝑣A and 𝑐s. Panels in the first, second, and third columns represent 𝑣A = 0.1, 0.5 and 0.9. Panels in the first, second, and third rows represent 𝑐s = 0, 1/2 √ 3, 1/ √ 3. In all the panels, Im(𝜙) is then normalized to its maximum value, which is quoted in the panels themselves. The dashed cyan vertical lines represent the common upper bound 𝑀re = √ 2 across all panels. The dashed white lines in the top three panels represent the exact boundaries of the instability region when 𝑐s = 0 and cos 𝜃 = 1, see Equation 28. The dotted white lines in the middle and bottom rows represent the lower bound of the fast-mode unstable region imposed by magnetic tension, as in Equation 25.",
            "Figure 3. Dependence of the instability growth rate Im(𝜙) on 𝑀re and 𝜃 when Ω = 0 (i.e., magnetic field along the flow direction), for three choices of 𝑣A and 𝑐s. The dashed cyan vertical lines represent the common upper bound 𝑀re = √ 2 across all panels. The dashed white lines in the top three panels represent the exact boundaries of the instability region when 𝑐s = 0 and cosΩ = 1, see Equation 31. See the caption of Figure 3 for further details.",
            "Figure 4. Dependence of the instability growth rate Im(𝜙) on 𝑀re and 𝜃 when Ω = 𝜋/2 (i.e., magnetic field perpendicular to the flow direction), for three choices of 𝑣A and 𝑐s. The dashed cyan vertical lines represent the common upper bound 𝑀re = √ 2 across all panels. The dashed white lines in the top three panels represent the exact boundaries of the instability region when 𝑐s = 0 and cosΩ = 0, see Equation 34. See the caption of Figure 3 for further details."
        ],
        "imgs": [
            "$2305.00036v2-Figure1-1.png",
            "$2305.00036v2-Figure2-1.png",
            "$2305.00036v2-Figure3-1.png",
            "$2305.00036v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00037",
        "abstract": "  There is a widespread perception that dynamical evolution of integrable\nsystems should be simpler in a quantifiable sense than the evolution of generic\nsystems, though demonstrating this relation between integrability and reduced\ncomplexity in practice has remained elusive. We provide a connection of this\nsort by constructing a specific matrix in terms of the eigenvectors of a given\nquantum Hamiltonian. The null eigenvalues of this matrix are in one-to-one\ncorrespondence with conserved quantities that have simple locality properties\n(a hallmark of integrability). The typical magnitude of the eigenvalues, on the\nother hand, controls an explicit bound on Nielsen's complexity of the quantum\nevolution operator, defined in terms of the same locality specifications. We\ndemonstrate how this connection works in a few concrete examples of quantum\nspin chains that possess diverse arrays of highly structured conservation laws\nmandated by integrability.\n",
        "title": "Integrability and complexity in quantum spin chains",
        "texts": [
            "Figure 1: Left: The time evolution of the upper bound on Nielsen’s complexity for the Hamiltonian evolution of the transverse Ising model at (hx, hz) = (−1.05, 0) (blue) and the Ising model evaluated at a chaotic parameter point (hx, hz) = (−1.05, 0.5) (red). The length of the chain is L = 12. To avoid using candidate minima that are evidently sub-optimal in estimating the complexity (2.24), at every time step we compare the output of the minimization procedure to the complexity associated to the early time solution kn = 0 and the minimum of the two is chosen. Right: A zoom on the time window inside the plateau region used in the numerics.",
            "Figure 10: Histograms of the eigenvalues of the Q-matrix for Left: the chaotic Ising model (4.4) with (hx, hz) = (−1.05, 0.5) for L = 9, 10, 11 and fixed Nloc/D 2 = 0.15. For the purpose of comparing the concentration properties of the distribution at varying L, we normalize the distributions so that the area below all the staircase curves is unity. The peak of the distribution can be seen to be close to 0.85, as expected from (3.8). Right: The same histograms for the transverse Ising at (hx, hz) = (−1.05, 0), for comparison.",
            "Figure 13: Left: Saturation values of the complexity as a function of kint, with ksp = kop = ⌈kint/2⌉, for the non-integrable (4.25) and integrable (4.29) spin 1 Hamiltonians. The length of the chain is set to L = 7. Right: In order to highlight the complexity reduction of the integrable model, we display the ratio between the integrable and non-integrable curves on the left plot.",
            "Figure 2: Histograms of the eigenvalues of the Q-matrix for Left column: an integrable Ising spin chain (4.4) with (hx, hz) = (−1.05, 0) and Right column: a chaotic Ising spin chain with (hx, hz) = (−1.05, 0.5) for varying locality thresholds as Top row: ksp = kop or Bottom row: only varying kop while keeping ksp = 6 fixed. The length of the chain is set to L = 12. In the bottom left inset of each plot we zoom in on the size of the kernel of the Q-matrix. It can be seen that in the integrable case, the number of zero eigenvalues increases in steps of 2, in accordance with the form of the conserved charges (4.10)-(4.13).",
            "Figure 3: Left: The fraction of local generators to the total number of generators, as a function of kop for the two types of locality thresholds T1 and T2 we impose in the main analysis. Middle and Right: The distance between the mean of the Q-eigenvalue distribution and the right edge of the Q-histograms, for, respectively, the chaotic and integrable Ising model as a function of kop. The shape of the curves in all three plots is very similar. The results for the chaotic model qualitatively agree with the RMT prediction (3.8) up to a factor of order one.",
            "Figure 4: The saturation value of the complexity of the integrable (hx, hz) = (−1.05, 0) and chaotic (hx, hz) = (−1.05, 0.5) Ising model with L = 12 sites as a function of a locality threshold specified by k. The dashed line corresponds to ksp = 6 fixed and varying kop, while for the solid line we vary both locality degrees ksp = kop.",
            "Figure 5: Histograms of the eigenvalues of the Q-matrix for the L = 12 Left column: integrable XYZ model (4.14) and for the Right column: chaotic XYZ model with magnetic field (4.19) (right) for varying locality thresholds as Top row: ksp = kop or Bottom row: only varying kop while keeping ksp = 6 fixed. For the coupling constants we used the numbers (Jx, Jy, Jz) = (−0.35, 0.5,−0.1) and on the right plot we chose hz = 0.8. In the bottom left corner of each plot we zoom in on the zero eigenvalues. The number of zero Q-eigenvalues in the integrable case increases in accordance with the form of the conserved charges.",
            "Figure 6: The saturation values of the complexity of the integrable XYZ model (4.14) and the chaotic Hamiltonian with magnetic field (4.19) for L = 12. For the coupling constants we used the numbers (Jx, Jy, Jz) = (−0.35, 0.5,−0.1) in both cases and hz = 0.8 for the chaotic Hamiltonian.",
            "Figure 7: Histograms of the Q-eigenvalue distributions as a function of k for a set of local generators T3(k). Left: The integrable transverse Ising model at (hx, hz) = (−1.05, 0). Right: A chaotic representative of the Ising model at (hx, hz) = (−1.05, 0.5). In both cases, the length of the chain is set to L = 12.",
            "Figure 8: Left: Saturation values of the complexity as a function of k for a set of local generators T1, with and without the operators (4.20). This is displayed for chaotic and integrable instances of the Ising model at L = 12. Right: The mean of the Q-eigenvalue distributions shown in the left plot of Figure 7 and the upper left plot of Figure 2.",
            "Figure 9: Left: The distribution of eigenvalues of the Q-matrix for the integrable XXZ model at (Jx = Jy, Jz) = (−0.35,−0.1) for increasing T1(k), for L = 12. In the bottom left corner, we zoom in on the number of exact zero eigenvalues. Right: A comparison between the late-time complexity saturation values as a function of T1(k) for the integrable XYZ at (Jx, Jy, Jz) = (−0.35, 0.5,−0.1) and XXZ model at (Jx = Jy, Jz) = (−0.35,−0.1)."
        ],
        "imgs": [
            "$2305.00037v2-Figure1-1.png",
            "$2305.00037v2-Figure10-1.png",
            "$2305.00037v2-Figure13-1.png",
            "$2305.00037v2-Figure2-1.png",
            "$2305.00037v2-Figure3-1.png",
            "$2305.00037v2-Figure4-1.png",
            "$2305.00037v2-Figure5-1.png",
            "$2305.00037v2-Figure6-1.png",
            "$2305.00037v2-Figure7-1.png",
            "$2305.00037v2-Figure8-1.png",
            "$2305.00037v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00038",
        "abstract": "  The fight or flight phenomena is of evolutionary origin and responsible for\nthe type of defensive behaviours enacted, when in the face of threat. This\nreview attempts to draw the link between fear and aggression as behavioural\nmotivations for fight or flight defensive behaviours. Hence, this review\nintends to examine whether fight or flight behavioural responses are the result\nof fear and aggression. Furthermore, this review investigates whether human\nbiological motion captures the affective states associated with the fight or\nflight phenomenon. This review also aims to investigate how threat informed\nemotion and motor systems have the potential to result in empathetic appraisal\nmodulation. This is of interest to this systematic review, as empathetic\nmodulation is crucial to prosocial drive, which has the potential to increase\nthe inclination of alleviating the perceived threat of another. Hence, this\nreview investigates the role of affective computing in capturing the potential\noutcome of empathy from threat perception. To gain a comprehensive\nunderstanding of the affective states and biological motion evoked from threat\nscenarios, affective computing methods used to capture these behavioural\nresponses are discussed.\n  A systematic review using Google Scholar and Web of Science was conducted as\nof 2023, and findings were supplemented by bibliographies of key articles. A\ntotal of 22 studies were analysed from initial web searches to explore the\ntopics of empathy, threat perception, fight or flight, fear, aggression, and\nhuman motion. Relationships between affective states (fear, aggression) and\ncorresponding motor defensive behaviours (fight or flight) were examined within\nthreat scenarios, and whether existing affective computing methods are succinct\nin capturing these responses, identifying the varying consensus in the\nliterature, challenges, and limitations of existing research.\n",
        "title": "Threat Perception Modulation by Capturing Emotion, Motor and Empathetic\n  System Responses: A Systematic Review",
        "texts": [
            "Fig. 1. Overview of the systematic review process"
        ],
        "imgs": [
            "$2305.00038v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00039",
        "abstract": "  BDDs are representations of a Boolean expression in the form of a directed\nacyclic graph. BDDs are widely used in several fields, particularly in model\nchecking and hardware verification. There are several implementations for BDD\nmanipulation, where each package differs depending on the application. This\npaper presents HermesBDD: a novel multi-core and multi-platform binary decision\ndiagram package focused on high performance and usability. HermesBDD supports a\nstatic and dynamic memory management mechanism, the possibility to exploit\nlock-free hash tables, and a simple parallel implementation of the If-Then-Else\nprocedure based on a higher-level wrapper for threads and futures. HermesBDD is\ncompletely written in C++ with no need to rely on external libraries and is\ndeveloped according to software engineering principles for reliability and easy\nmaintenance over time. We provide experimental results on the n-Queens problem,\nthe de-facto SAT solver benchmark for BDDs, demonstrating a significant speedup\nof 18.73x over our non-parallel baselines, and a remarkable performance boost\nw.r.t. other state-of-the-art BDDs packages.\n",
        "title": "HermesBDD: A Multi-Core and Multi-Platform Binary Decision Diagram\n  Package",
        "texts": [
            "TABLE I HermesBDD NON-PARALLEL EXECUTION TIME BASED ON THE n-QUEENS PROBLEM COMPLEXITY. VALUES ON THE AVERAGE OF 50 SAMPLES USING THE STATIC MEMORY ALLOCATION ON A 32-CORE MACHINE."
        ],
        "imgs": [
            "$2305.00039v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00041",
        "abstract": "  Neural radiance fields (NeRF) have achieved impressive performances in view\nsynthesis by encoding neural representations of a scene. However, NeRFs require\nhundreds of images per scene to synthesize photo-realistic novel views.\nTraining them on sparse input views leads to overfitting and incorrect scene\ndepth estimation resulting in artifacts in the rendered novel views. Sparse\ninput NeRFs were recently regularized by providing dense depth estimated from\npre-trained networks as supervision, to achieve improved performance over\nsparse depth constraints. However, we find that such depth priors may be\ninaccurate due to generalization issues. Instead, we hypothesize that the\nvisibility of pixels in different input views can be more reliably estimated to\nprovide dense supervision. In this regard, we compute a visibility prior\nthrough the use of plane sweep volumes, which does not require any\npre-training. By regularizing the NeRF training with the visibility prior, we\nsuccessfully train the NeRF with few input views. We reformulate the NeRF to\nalso directly output the visibility of a 3D point from a given viewpoint to\nreduce the training time with the visibility constraint. On multiple datasets,\nour model outperforms the competing sparse input NeRF models including those\nthat use learned priors. The source code for our model can be found on our\nproject page:\nhttps://nagabhushansn95.github.io/publications/2023/ViP-NeRF.html.\n",
        "title": "ViP-NeRF: Visibility Prior for Sparse Input Neural Radiance Fields",
        "texts": [
            "Fig. 1. Overview of ViP-NeRF architecture. Given the images from primary and secondary views, we estimate a visibility prior map in the primary view and use it to supervise the visibility of pixels as predicted by the NeRF. Specifically, we cast a ray through a randomly selected pixel in the primary view and sample 3D points along the ray. For every point p𝑖 , we use the NeRF MLPs to obtain its visibility in primary and secondary views, along with volume density 𝜎𝑖 and color c𝑖 . Volume rendering outputs visibility 𝑡 ′ of the chosen pixel in the secondary view which is supervised by the visibility prior. L𝑣 constrains the visibilities𝑇𝑖 output by network and𝑇𝑖 computed using volume rendering to be consistent with each other.",
            "Fig. 13. Qualitative examples on RealEstate-10K dataset with two input views. In the first example, we see artifacts such as ghosting and blur in the frame predicted by DDP-NeRF. In the second example, we observe that DDP-NeRF infers incorrect geometry due to which the objects are placed incorrectly in the synthesized view. However, the predictions by ViP-NeRF do not suffer from such artifacts and are significantly sharper.",
            "Fig. 14. Qualitative examples on NeRF-LLFF dataset with three input views. In the first example, we find that DDP-NeRF prediction has a different global color than the ground truth. In addition, the angle of the sharp triangular object on the fortress is changed. We also observe floating blue clouds outside the fortress and blur in other regions. In the second example, we notice that DDP-NeRF is unable to infer the positions of the objects (horizontal stem and the orange leaf) correctly and instead places them at incorrect positions or breaks them into multiple parts. On the other hand, ViP-NeRF is able to synthesize the novel views reasonably well.",
            "Fig. 16. Qualitative examples on DTU dataset with two input views. DDPNeRF predictions contain significant floating clouds in all three examples, whereas ViP-NeRF produces more realistic novel views.",
            "Fig. 18. Quantitative comparison of the performance of DDP-NeRF and ViP-NeRF models with increasing distance between the training views. The x-axis denotes the frames skipped between the two training frames.",
            "Fig. 19. Loss curves of L𝑣 during training on individual scenes of both RealEstate-10K and NeRF-LLFF datasets.",
            "Fig. 2. A toy example to illustrate the computation of visibility prior. The scene contains a blue sphere and a brown box and the relative pose between the views is a translation in x direction. The secondary view image is warped to the primary view at different depth planes to create a PSV and compared with the primary view image to obtain error maps. We observe that the brown square and the blue circle are matched better in the second and third planes respectively leading to lower error (denoted as white) in the respective error maps. The minimum error across all the planes is thresholded to obtain the visibility prior map corresponding to the primary view image. The right portion of the sphere which is occluded in the secondary view image is denoted in black in the visibility map.",
            "Fig. 3. Qualitative examples on RealEstate-10K dataset with two input views. We observe that the predictions of ViP-NeRF are close to the ground truth, while those of other models suffer from various distortions. In particular, DDP-NeRF blurs regions of the frame near the left door and contains black floater artifacts.",
            "Fig. 4. Qualitative examples on RealEstate-10K and NeRF-LLFF dataset with two, three, and four input views. We observe that ViP-NeRF models specular regions better as the number of input views increases. For example, in the first row, the reflection of the chair is better reconstructed as the number of views increases.",
            "Fig. 5. Estimated depth map on RealEstate-10K dataset with two input views. We find that ViP-NeRF is better in both frame synthesis and depth estimation compared to the competing models. For example, in the first row, the depth estimated by DDP-NeRF is smooth which may be leading to a loss of sharpness in synthesizing the shrubs. In contrast, ViP-NeRF predictions are sharper. For better visualization, we show inverse depth and normalize it to set the maximum value to unity.",
            "Fig. 6. Visualization of the visibility map predicted by ViP-NeRF. White indicates the regions of the ‘Primary View’ which are visible in the ‘Secondary View’ and black indicates the occluded regions. From the primary and secondary views, we observe that the left part of the fortress and the neighboring portion of the wood are hidden in the secondary view. ViP-NeRF is able to reasonably determine the visible and occluded regions.",
            "Fig. 7. Qualitative examples on RealEstate-10K dataset with two input views. We observe sharp predictions by ViP-NeRF while predictions by other models suffer from blur and other artifacts. In particular, DDP-NeRF predictions contain blurred flowers (first row) and blurred tiles (second row).",
            "Fig. 8. Qualitative examples on RealEstate-10K dataset with three input views. We find that ViP-NeRF is able to reconstruct novel views significantly better than the competing models. DDP-NeRF extends parts of the white table and fails to reconstruct the drawer handles accurately in the first and second examples. In the third example, DDP-NeRF fails to reconstruct thin objects in the chair.",
            "Fig. 9. Qualitative examples on RealEstate-10K dataset with four input views. In the first example, DDP-NeRF fails to retain the structure of the chair while it blurs the texture of the carpet in the second example. We observe even more severe distortions among the predictions of other models.",
            "Table 1. Quantitative results on RealEstate-10K dataset.",
            "Table 10. Per-scene performance of various models with three input views on RealEstate-10K dataset. The three rows show LPIPS, SSIM, and PSNR scores, respectively.",
            "Table 11. Per-scene performance of various models with four input views on RealEstate-10K dataset. The three rows show LPIPS, SSIM, and PSNR scores, respectively.",
            "Table 12. Per-scene performance of various models with two input views on NeRF-LLFF dataset. The three rows show LPIPS, SSIM, and PSNR scores, respectively.",
            "Table 13. Per-scene performance of various models with three input views on NeRF-LLFF dataset. The three rows show LPIPS, SSIM, and PSNR scores, respectively.",
            "Table 14. Per-scene performance of various models with four input views on NeRF-LLFF dataset. The three rows show LPIPS, SSIM, and PSNR scores, respectively.",
            "Table 2. Quantitative results on NeRF-LLFF dataset.",
            "Table 3. Comparison of reliability of priors used in different models. The reference visibility is obtained using NeRF trained with dense input views.",
            "Table 4. Evaluation of depth estimated by different models with two input views. The reference depth is obtained using NeRF trained with dense input views. The depth RMSE on the two datasets are of different orders on account of different depth ranges.",
            "Table 5. Ablation experiments on both the datasets with two input views.",
            "Table 6. Original name of RealEstate-10K videos we selected for experiments and their updated names.",
            "Table 7. Quantitative results on DTU dataset. RegNeRF+ uses test camera poses during training.",
            "Table 9. Per-scene performance of various models with two input views on RealEstate-10K dataset. The three rows show LPIPS, SSIM, and PSNR scores, respectively."
        ],
        "imgs": [
            "$2305.00041v1-Figure1-1.png",
            "$2305.00041v1-Figure13-1.png",
            "$2305.00041v1-Figure14-1.png",
            "$2305.00041v1-Figure16-1.png",
            "$2305.00041v1-Figure18-1.png",
            "$2305.00041v1-Figure19-1.png",
            "$2305.00041v1-Figure2-1.png",
            "$2305.00041v1-Figure3-1.png",
            "$2305.00041v1-Figure4-1.png",
            "$2305.00041v1-Figure5-1.png",
            "$2305.00041v1-Figure6-1.png",
            "$2305.00041v1-Figure7-1.png",
            "$2305.00041v1-Figure8-1.png",
            "$2305.00041v1-Figure9-1.png",
            "$2305.00041v1-Table1-1.png",
            "$2305.00041v1-Table10-1.png",
            "$2305.00041v1-Table11-1.png",
            "$2305.00041v1-Table12-1.png",
            "$2305.00041v1-Table13-1.png",
            "$2305.00041v1-Table14-1.png",
            "$2305.00041v1-Table2-1.png",
            "$2305.00041v1-Table3-1.png",
            "$2305.00041v1-Table4-1.png",
            "$2305.00041v1-Table5-1.png",
            "$2305.00041v1-Table6-1.png",
            "$2305.00041v1-Table7-1.png",
            "$2305.00041v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00042",
        "abstract": "  This study aims to develop a novel Cycle-guided Denoising Diffusion\nProbability Model (CG-DDPM) for cross-modality MRI synthesis. The CG-DDPM\ndeploys two DDPMs that condition each other to generate synthetic images from\ntwo different MRI pulse sequences. The two DDPMs exchange random latent noise\nin the reverse processes, which helps to regularize both DDPMs and generate\nmatching images in two modalities. This improves image-to-image translation\nac-curacy. We evaluated the CG-DDPM quantitatively using mean absolute error\n(MAE), multi-scale structural similarity index measure (MSSIM), and peak\nsig-nal-to-noise ratio (PSNR), as well as the network synthesis consistency, on\nthe BraTS2020 dataset. Our proposed method showed high accuracy and reliable\nconsistency for MRI synthesis. In addition, we compared the CG-DDPM with\nseveral other state-of-the-art networks and demonstrated statistically\nsignificant improvements in the image quality of synthetic MRIs. The proposed\nmethod enhances the capability of current multimodal MRI synthesis approaches,\nwhich could contribute to more accurate diagnosis and better treatment planning\nfor patients by synthesizing additional MRI modalities.\n",
        "title": "Cycle-guided Denoising Diffusion Probability Model for 3D Cross-modality\n  MRI Synthesis",
        "texts": [
            "Figure 1: Proposed CG-DDPM: In addition to the forward and reverse diffusion in the traditional DDPM, the generation direction is controlled using a cycle-guided latent noise regularization technique. The ground truth target and source MRIs 𝑋1,…,𝑁 and 𝑌1,…,𝑁 are used to generate the deterministic latent noise 𝜖1,…,𝑁",
            "Figure 2. Ground truth MRIs and synthetic MRIs for T1→T2, T2→T1, T1→FLAIR, FLAIR→T1 synthesis. Synthetic MRIs from the proposed CG-DDPM (column #1), IDDPM (column #2), IDDIM (column #3), and MRI-cGAN (column #4) are presented column-wise. The difference maps between the truth and synthetic MRIs are shown below.",
            "Figure 3. Ground truth MRIs, synthetic MRIs from five different runs and their average of the MC-based sampling of the DDPM models are presented column-wise. We present the proposed CG-DDPM in the first row, IDDPM in the second row, and IDDIM in the third row. More examples are shown in the Appendix. C.",
            "Figure 4. Sampling stability of the DDPM-based methods from four MRI translation tasks. MC𝑛 indicates the MC-based sampling averaged result using 𝑛 runs. Notice that the N-MSSIM does not represent the absolute quantitative performance (e.g., CG-DDPM’s “1” is much higher than IDDIM’s “1”), but a trend of the performance under different numbers of runs in the MC-based sampling.",
            "Table 1. Quantitative and statistical analysis of the synthetic MRIs for CG-DDPM vs. IDDPM, IDDIM, and MRI-cGAN. MAE is calculated by the normalized images ([-1,1])."
        ],
        "imgs": [
            "$2305.00042v1-Figure1-1.png",
            "$2305.00042v1-Figure2-1.png",
            "$2305.00042v1-Figure3-1.png",
            "$2305.00042v1-Figure4-1.png",
            "$2305.00042v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00044",
        "abstract": "  Accurate, real-time measurements of price index changes using electronic\nrecords are essential for tracking inflation and productivity in today's\neconomic environment. We develop empirical hedonic models that can process\nlarge amounts of unstructured product data (text, images, prices, quantities)\nand output accurate hedonic price estimates and derived indices. To accomplish\nthis, we generate abstract product attributes, or ``features,'' from text\ndescriptions and images using deep neural networks, and then use these\nattributes to estimate the hedonic price function. Specifically, we convert\ntextual information about the product to numeric features using large language\nmodels based on transformers, trained or fine-tuned using product descriptions,\nand convert the product image to numeric features using a residual network\nmodel. To produce the estimated hedonic price function, we again use a\nmulti-task neural network trained to predict a product's price in all time\nperiods simultaneously. To demonstrate the performance of this approach, we\napply the models to Amazon's data for first-party apparel sales and estimate\nhedonic prices. The resulting models have high predictive accuracy, with $R^2$\nranging from $80\\%$ to $90\\%$. Finally, we construct the AI-based hedonic\nFisher price index, chained at the year-over-year frequency. We contrast the\nindex with the CPI and other electronic indices.\n",
        "title": "Hedonic Prices and Quality Adjusted Price Indices Powered by AI",
        "texts": [
            "FIGURE 1. An example of product characteristics for a product sold in the Amazon store",
            "FIGURE 11. ELMO Architecture. This is an ELMO network for a string of 4 words, with L = 2 hidden layers. Here, the softmax layer (multinomial logit) is a single function mapping each input in Rd to a probability distribution over the dictionary Σ.",
            "FIGURE 13. The ResNet50 operates on numerical 3-dimensional arrays representing images. It first does some early processing by applying convolutional and pooling filters, then it applies many residual block mappings, producing arrays shown in green. The penultimate layer produces a high-dimensional vector I , the image embedding, which is then used to predict the image type.",
            "FIGURE 14. SingleTask + ELMO model. Product text is mapped to W and the image is mapped to I of dimensions 256 and 2048. For illustration purposes, we only show two hidden layers with dimensions 7 and 5 respectively. In practice, we use three layers with dimensions 2048, 1024, and 256. The output is price for one time period t .",
            "FIGURE 15. MultiTask + BERT. Product text is mapped to W and image is mapped to I of dimensions 3072 and 2048 respectively. For illustration purpose, we only show two hidden layers with dimension 7 and 5 respectively, and output is of dimension 3. In practice, we use three layers with dimension 2048, 1024, and 256, and the output is a price vector over T = 72 time periods.",
            "FIGURE 16. MultiTask + Fine-tuned BERT. Product text (sentence) is tokenized and padded to X , where components represent the context-free input embedding plus a positional encoding for a token (word). Then the input is fed into a BERT model which consists of 12 layers of transformer blocks and outputs T dimensional price vector. For illustration purposes, we only show 5 tokens and two transformer blocks.",
            "FIGURE 2. Our method for generating hedonic price: The input consists of images and unstructured text data. The first step of the process creates the moderately highdimensional numerical embeddings I and W for images and text data via state-of-theart deep learning methods, such as ResNet50 and BERT. The second step of the process takes input X = (I ,W ) and creates predictions for hedonic prices Ht (X ) using deep learning methods with a multi-task structure. The models of the first step are trained on tasks unrelated to predicting prices (e.g., image classification or word prediction), where embeddings are extracted as hidden layers of the neural networks. The models of the second step are trained by price prediction tasks. Our multitask model creates an intermediate lower dimensional embedding V =V (X ), called value embedding, and then predicts the final prices in all periods {Ht (V ), t = 1, ...,T } using linear functional forms, making it easy to perform inference on the last step, using hold-out samples. Some variations of the method include fine-tuning the embeddings produced by the first step to perform well for price prediction tasks (i.e. optimizing the embedding parameters to minimize price prediction loss).",
            "FIGURE 3. Standard architecture of a Deep Neural Network. In the hedonic price prediction network, the penultimate layer is interpreted as an embedding of the product’s hedonic value and the output layer contains predicted hedonic prices in all time periods. In comparison, the networks used for text and image processing have very high-dimensional inputs and outputs, with intermediate hidden layers composed of neural sub-networks. The dense embeddings typically result from taking the last hidden layer of the network.",
            "FIGURE 4. The out-of-sample performance of the empirical hedonic price function obtained using neural network every month since March, 2013. Multi-task neural networks dominate singe-task neural networks, which dominate boosted tree models, which in turn dominate linear models.",
            "FIGURE 5. Statistical Significance of Value Embeddings via Linear Regression Model Applied to the Test Sample. The figure shows the point estimates and the pointwise 95% confidence intervals on the coefficients of the value embeddings, as estimated by the linear regression model, applied to the hold-out sample. Note that more than 90% of the coefficients are statistically significant at the 10−5 level.",
            "FIGURE 6. An example of accurate prediction of (B001GUN1N6): The neural network model predicts the price of this item at about 100. The average price on camelcamel.com is 97, with the offer price ranging from 39 to 120.",
            "FIGURE 7. An example of inaccurate prediction: The neural network model predicts the price of this item at about 300, but the recent offer prices for this product were around 2400. While this seems a miss, the price history for this item (B06XR39DJ1), that can be seen on camelcamel.com, suggests that there were periods where the offer prices for this item ranged between 206 and 2800, with an averaged price of 464.",
            "FIGURE 8. Turnover Rate for Products. The figure shows the ratio of the number of products with transactions in a given month and no transactions in the previous month.",
            "FIGURE 9. Number of Products in the Current Period over the Base Period.",
            "TABLE 1. Some properties of the CPI, BPP, ADPI, and FHPI",
            "TABLE 2. Summary of Out-of-Sample Performance of the Empirical Hedonic Price Function.",
            "TABLE 3. Examples of Construction of Confidence Intervals for Predicted Hedonic Price Hi t = V ′ i tθt and the Sale Price Pi t . Here Ĥi t = V ′ i t θ̂t is the estimated hedonic price. The term σ̂2 = V ′ i t Ĉov(θ̂t )Vi t is the square of the standard error, and [Li t ,Ui t ] = [Ĥi t ± z.95σ̂] is the 90% confidence interval for Hi t . The predictive confidence interval for Pi t is [Li t (Pi t ),Ui t (Pi t )] = [Ĥi t ± z1−α/2ν̂] with ν̂2 = σ̂2 + V̂ar(Pi t − Hi t ) . The term z.95 is .95-th quantile of the standard normal distribution.",
            "TABLE 4. Estimates of Average Annual Rate of Inflation in Apparel over four years, 2014-2017: Fisher Hedonic Index, Fisher Matched Index, Jevons Posted Price Index, Adobe DPI, and the BLS Index for Urban Areas. Adobe DPI is based on 2014-2017."
        ],
        "imgs": [
            "$2305.00044v1-Figure1-1.png",
            "$2305.00044v1-Figure11-1.png",
            "$2305.00044v1-Figure13-1.png",
            "$2305.00044v1-Figure14-1.png",
            "$2305.00044v1-Figure15-1.png",
            "$2305.00044v1-Figure16-1.png",
            "$2305.00044v1-Figure2-1.png",
            "$2305.00044v1-Figure3-1.png",
            "$2305.00044v1-Figure4-1.png",
            "$2305.00044v1-Figure5-1.png",
            "$2305.00044v1-Figure6-1.png",
            "$2305.00044v1-Figure7-1.png",
            "$2305.00044v1-Figure8-1.png",
            "$2305.00044v1-Figure9-1.png",
            "$2305.00044v1-Table1-1.png",
            "$2305.00044v1-Table2-1.png",
            "$2305.00044v1-Table3-1.png",
            "$2305.00044v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00046",
        "abstract": "  Lung cancer is a leading cause of cancer-related deaths worldwide, and early\ndetection is crucial for improving patient outcomes. Nevertheless, early\ndiagnosis of cancer is a major challenge, particularly in low-resource settings\nwhere access to medical resources and trained radiologists is limited. The\nobjective of this study is to propose an automated end-to-end deep\nlearning-based framework for the early detection and classification of lung\nnodules, specifically for low-resource settings. The proposed framework\nconsists of three stages: lung segmentation using a modified 3D U-Net named 3D\nRes-U-Net, nodule detection using YOLO-v5, and classification with a Vision\nTransformer-based architecture. We evaluated the proposed framework on a\npublicly available dataset, LUNA16. The proposed framework's performance was\nmeasured using the respective domain's evaluation matrices. The proposed\nframework achieved a 98.82% lung segmentation dice score while detecting the\nlung nodule with 0.76 mAP@50 from the segmented lung, at a low false-positive\nrate. The performance of both networks of the proposed framework was compared\nwith other studies and found to outperform them regarding segmentation and\ndetection accuracy. Additionally, our proposed Vision transformer network\nobtained an accuracy of 93.57%, which is 1.21 higher than the state-of-the-art\nnetworks. Our proposed end-to-end deep learning-based framework can effectively\nsegment lungs, and detect and classify lung nodules, specifically in\nlow-resource settings with limited access to radiologists. The proposed\nframework outperforms existing studies regarding all the respective evaluation\nmetrics. The proposed framework can potentially improve the accuracy and\nefficiency of lung cancer screening in low-resource settings, ultimately\nleading to better patient outcomes.\n",
        "title": "An automated end-to-end deep learning-based framework for lung cancer\n  diagnosis by detecting and classifying the lung nodules",
        "texts": [
            "Fig. 1. A graphical overview of the end-to-end deep learning-based framework for lung cancer detection workflow.",
            "Fig. 3. Overview of the proposed 3D Res-Unet architecture.",
            "Fig. 4. The main parts of the YOLOv5 model are the CSPDarknet backbone, the PANet neck, and the YOLO Layer head. In the CSPDarknet, features are extracted from the data, and in the PANet, the features that were extracted are combined. The final object detection results, including class, score, location, and size, are generated by the YOLO layer.",
            "Fig. 5. Overview of the proposed vision transformer architecture.",
            "Fig. 6. The visual results of lung segmentation for 3D U-Net and 3D Res-U-Net architecture. (a), (b) and (c) column represents Ground truth,3D U-Net prediction, and 3D Res-U-Net prediction.",
            "Fig. 7. Detection results of nodules on LUNA16 dataset using YOLOv5(s).",
            "TABLE I SUMMARY OF WORKS CARRIED OUT IN SEGMENTATION, NODULE DETECTION AND CLASSIFICATION DOMAIN ON LUNG CT .",
            "TABLE II DETAILS OF HYPERPARAMETERS USED FOR THE MODELS.",
            "TABLE IV COMPARISON OF THE PROPOSED FRAMEWORK WITH EXISTING NODULE DETECTION METHODS.",
            "TABLE V COMPARISON OF THE PROPOSED FRAMEWORK WITH EXISTING NODULE’S MALIGNANCY CLASSIFICATION METHODS."
        ],
        "imgs": [
            "$2305.00046v1-Figure1-1.png",
            "$2305.00046v1-Figure3-1.png",
            "$2305.00046v1-Figure4-1.png",
            "$2305.00046v1-Figure5-1.png",
            "$2305.00046v1-Figure6-1.png",
            "$2305.00046v1-Figure7-1.png",
            "$2305.00046v1-TableI-1.png",
            "$2305.00046v1-TableII-1.png",
            "$2305.00046v1-TableIV-1.png",
            "$2305.00046v1-TableV-1.png"
        ]
    },
    {
        "id": "2305.00048",
        "abstract": "  Data-driven weather prediction models (DDWPs) have made rapid strides in\nrecent years, demonstrating an ability to approximate Numerical Weather\nPrediction (NWP) models to a high degree of accuracy. The fast, accurate, and\nlow-cost DDWP forecasts make their use in operational forecasting an attractive\nproposition, however, there remains work to be done in rigorously evaluating\nDDWPs in a true operational setting. Typically trained and evaluated using ERA5\nreanalysis data, DDWPs have been tested only in a simulation, which cannot\nrepresent the real world with complete accuracy even if it is of a very high\nquality. The safe use of DDWPs in operational forecasting requires more\nthorough \"real-world\" verification, as well as a careful examination of how\nDDWPs are currently trained and evaluated. It is worth asking, for instance,\nhow well do the reanalysis datasets, used for training, simulate the real\nworld? With an eye towards climate justice and the uneven availability of\nweather data: is the simulation equally good for all regions of the world, and\nwould DDWPs exacerbate biases present in the training data? Does a good\nperformance in simulation correspond to good performance in operational\nsettings? In addition to approximating the physics of NWP models, how can ML be\nuniquely deployed to provide more accurate weather forecasts? As a first step\ntowards answering such questions, we present a robust dataset of in-situ\nobservations derived from the NOAA MADIS program to serve as a benchmark to\nvalidate DDWPs in an operational setting. By providing a large corpus of\nquality-controlled, in-situ observations, this dataset provides a meaningful\nreal-world task that all NWPs and DDWPs can be tested against. We hope that\nthis data can be used not only to rigorously and fairly compare operational\nweather models but also to spur future research in new directions.\n",
        "title": "Verification against in-situ observations for Data-Driven Weather\n  Prediction",
        "texts": [
            "Figure 1: Total number of observations for different variables in 2020, in log (base 10) scale.",
            "Figure 2: RMSE of ERA5 data vs. real-world observations for different regions.",
            "Figure 3: RMSE and ACC comparison for FourCastNet (FCN) and IFS for a 48 hour forecast. The top row shows RMSE, while the bottom row shows the ACC for each model and variable. In all cases, the FCN model outperforms IFS.",
            "Figure 4: RMSE for different variables, comparing FCN and IFS against observations for different regions of the world. Each row is one region, and the columns represent the RMSE for wind speed, temperature, and dewpoint respectively.",
            "Figure 5: Geographical extent of various regions used in evaluations.",
            "Figure 6: RMSE of ERA5, FCN, and IFS against observations for wind speeds, temperature, dewpoint, and 6-hourly precipitation accumulation. Each column represents a data source, and each row represents a variable. The x-axis represents the time of day in UTC, and the y-axis represents the RMSE in appropriate units. Note the different forecast depths for ERA5 vs. FCN and IFS.",
            "Table 1: Variables in dataset, provided at an hourly frequency for the entire year of 2020",
            "Table 2: The latitude and longitude extents of the various geographies used in the study"
        ],
        "imgs": [
            "$2305.00048v2-Figure1-1.png",
            "$2305.00048v2-Figure2-1.png",
            "$2305.00048v2-Figure3-1.png",
            "$2305.00048v2-Figure4-1.png",
            "$2305.00048v2-Figure5-1.png",
            "$2305.00048v2-Figure6-1.png",
            "$2305.00048v2-Table1-1.png",
            "$2305.00048v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00050",
        "abstract": "  The causal capabilities of large language models (LLMs) are a matter of\nsignificant debate, with critical implications for the use of LLMs in\nsocietally impactful domains such as medicine, science, law, and policy. We\nconduct a \"behavorial\" study of LLMs to benchmark their capability in\ngenerating causal arguments. Across a wide range of tasks, we find that LLMs\ncan generate text corresponding to correct causal arguments with high\nprobability, surpassing the best-performing existing methods. Algorithms based\non GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery\ntask (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain)\nand event causality (86% accuracy in determining necessary and sufficient\ncauses in vignettes). We perform robustness checks across tasks and show that\nthe capabilities cannot be explained by dataset memorization alone, especially\nsince LLMs generalize to novel datasets that were created after the training\ncutoff date.\n  That said, LLMs exhibit unpredictable failure modes, and we discuss the kinds\nof errors that may be improved and what are the fundamental limits of LLM-based\nanswers. Overall, by operating on the text metadata, LLMs bring capabilities so\nfar understood to be restricted to humans, such as using collected knowledge to\ngenerate causal graphs or identifying background causal context from natural\nlanguage. As a result, LLMs may be used by human domain experts to save effort\nin setting up a causal analysis, one of the biggest impediments to the\nwidespread adoption of causal methods. Given that LLMs ignore the actual data,\nour results also point to a fruitful research direction of developing\nalgorithms that combine LLMs with existing causal techniques. Code and datasets\nare available at https://github.com/py-why/pywhy-llm.\n",
        "title": "Causal Reasoning and Large Language Models: Opening a New Frontier for\n  Causality",
        "texts": [
            "Figure 1: When tackling real-world causal tasks, people strategically alternate between logical- and covariance-based causal reasoning as they formulate (sub-)questions, iterate, and verify their premises and implications. Now, LLMs may have the capability to automate or assist with every step of this process and seamlessly transition bteween covarianceand logic-based causality.",
            "Figure 2: Probing causal reasoning in LLMs. Two example outputs from an LLM (GPT-4). In the first dialog, the LLM discusses causal issues, such as a potential confounder and recommends an A/B experiment to correctly characterize effects and drive the requested decision-making. The second example continues the conversation and requires arguably the same kind of causal awareness of potential confounders (e.g., the population characteristics and even population sizes of the online and newspaper audience are unknown) but the LLM proceeds regardless and provides an incorrect answer.",
            "Figure 4: We probe the importance of individual words for getting a correct answer by redacting a random word from a question. Here, we show our results for experiments in gpt-3.5-turbo, averaged across 357 random redaction probes over our Tübingen experiment. We highlight words based on their importance for getting a correct result. A white background indicates that redacting the word did not reduce accuracy. A dark blue highlight indicates that redacting the word reduced accuracy the most.",
            "Figure 5: LLM completions are highlighted in yellow. Session 1: In a multi-turn interaction, GPT3.5 first gives an erroneous response to a math problem. Prompted to show its work, it correctly solves the sub-parts of the problem, but again gives the wrong final answer. Session 2: we probe for the influence of the first wrong answer on the final wrong answer by replaying an interventional-conversation and asking GPT3.5 to complete only the final answer.",
            "Table 1: Example cause-effect pairs from the Tübingen benchmark. The task is to determine whether Variable A causes Variable B, or vice-versa.",
            "Table 10: Example vignettes for evaluation of inferring necessary and sufficient causes, categorized by their type based on the different ways in which potential causes can interact to yield the final outcome. Each vignette tests two questions: “Is {Actor} a necessary cause of {Event}?” and “Is {Actor} a sufficient cause of {Event}?”.",
            "Table 11: Accuracy of gpt-3.5-turbo and gpt-4 on inferring necessary or sufficient cause on 15 standard vignettes. The vignettes are divided into eight types (e.g., Early Preemption type has three vignettes). Each (X/X) corresponds to a correct/incorrect answer on a single vignette. gpt-3.5-turbo fails at the task (worse than random chance) but gpt-4 can infer necessary and sufficient cause with high accuracy.",
            "Table 12: Testing dataset memorization issues with a novel “lab-vignettes” dataset. The average accuracy of gpt-4 stays the same as in the std vignettes, indicating that gpt4’s capabilities to infer necessary and sufficient cause can generalize to new data. Inferring necessary cause (93%) emerges as an easier task than inferring sufficient cause (78%).",
            "Table 13: Comparative assessments of normality between text-davinci-003 and GPT-4-32K. Stories taken from the BIG-Bench causal judgments task.",
            "Table 14: Two kinds of prompt templates for the Tübingen benchmark. The first asks two questions per variable pair whereas the second (“Single prompt”) asks a single question to orient each pairwise edge.",
            "Table 15: “lab-vignettes”: Examples of novel vignettes for evaluation of inferring necessary and sufficient causes. Each vignette is associated with two questions: “Is {Actor} a necessary cause of {Event}?” and “Is {Actor} a sufficient cause of {Event}?”",
            "Table 16: Our memorization test shows the Tübingen dataset is in the training dataset and has been at least partially memorized by GPT-3 and GPT-4; our experiments with the novel lab-vignettes show that the dataset has not been memorized. Results for CRASS and other benchmark datasets are forthcoming.",
            "Table 17: Perturbing the first answer from Figure 5, and observing the result shows that the first answer strongly influences the final answer",
            "Table 2: Accuracy of different versions of GPT on the Tübingen cause-effect pairs dataset. The best LLM performance outperforms the current state-of-the-art covariancebased approaches that rely on observational data of the two variables. Weighted accuracy weights individual pairs to account for overcounting due to some pairs sharing the same source dataset. The causal agent is gpt-3.5-turbo with system message set as “You are a helpful assistant for causal reasoning.”. LMPrior uses davinci-instruct-beta.",
            "Table 3: Example cause-effect pairs from the Neuropathic pain diagnosis benchmark. ‘Dir.’ refers to the ground-truth causal direction between the variables.",
            "Table 4: Accuracy of different versions of GPT on the inferring the edge directions of the Neuropathic pain diagnosis graph. As with the Tübingen dataset, LLMs like gpt-3.5turbo obtain more than 85% accuracy on determining the direction of edges. The causal agent is gpt-3.5-turbo with a system message set as “You are a helpful assistant for causal reasoning.”",
            "Table 5: Critiquing LLM output using another LLM instance. To increase robustness of an LLM’s response, we can use GPT-4 as a critic. The left panel shows an incorrect reply from gpt-3.5-turbo wherein the reasoning is correct but the LLM outputs the incorrect option (A). We create a special “critique” prompt that asks gpt-4 to evaluate the response from an AI assistant for self-consistency. gpt-4 finds the logical inconsistency and provides the correct answer.",
            "Table 6: Accuracy of different versions of GPT on the Neuropathic pain dataset.",
            "Table 7: Normalized hamming distance (NHD) for different causal discovery algorithms. Since NHD depends on the number of predicted edges, we compare the ratio of NHD and baseline NHD across algorithms. A lower NHD ratio is better. LLM-based discovery (gpt-3.5-turbo) obtains comparable NHD and the lowest NHD ratio compared to recent covariance-based discovery algorithms.",
            "Table 8: Example scenarios from the CRASS counterfactual reasoning benchmark. The task is to select the best answer choice for the counterfactual question, given a premise.",
            "Table 9: Accuracy of different LLMs on the CRASS counterfactual reasoning benchmark. gpt-4 achieves 92% accuracy, significantly higher than the previous reported accuracy on this benchmark and within six percentage points of human annotators’ accuracy."
        ],
        "imgs": [
            "$2305.00050v2-Figure1-1.png",
            "$2305.00050v2-Figure2-1.png",
            "$2305.00050v2-Figure4-1.png",
            "$2305.00050v2-Figure5-1.png",
            "$2305.00050v2-Table1-1.png",
            "$2305.00050v2-Table10-1.png",
            "$2305.00050v2-Table11-1.png",
            "$2305.00050v2-Table12-1.png",
            "$2305.00050v2-Table13-1.png",
            "$2305.00050v2-Table14-1.png",
            "$2305.00050v2-Table15-1.png",
            "$2305.00050v2-Table16-1.png",
            "$2305.00050v2-Table17-1.png",
            "$2305.00050v2-Table2-1.png",
            "$2305.00050v2-Table3-1.png",
            "$2305.00050v2-Table4-1.png",
            "$2305.00050v2-Table5-1.png",
            "$2305.00050v2-Table6-1.png",
            "$2305.00050v2-Table7-1.png",
            "$2305.00050v2-Table8-1.png",
            "$2305.00050v2-Table9-1.png"
        ]
    },
    {
        "id": "2305.00053",
        "abstract": "  TaTe$_4$ is a quasi-1D tetrachalcogenide that exhibits a CDW instability\ncaused by a periodic lattice distortion. Recently, pressure-induced\nsuperconductivity has been achieved in this compound, revealing a competition\nbetween these different ground states and making TaTe$_4$ very interesting for\nfundamental studies. Although TaTe$_4$ exhibits CDW ordering below 475 K,\ntransport experiments have reported metallic behavior with a resistivity\nplateau at temperatures lower than 10 K. In this paper, we study the electronic\nstructure of TaTe$_4$ using a combination of high-resolution angle-resolved\nphotoemission spectroscopy and density functional calculations. Our results\nreveal the existence of the long-sought metallic states. These states exhibit\nmixed dimensionality, while some of them might have potential topological\nproperties.\n",
        "title": "Experimental observation of metallic states with different\n  dimensionality in a quasi-1D charge density wave compound",
        "texts": [
            "FIG. 1. (Color online) (a) Crystal structure of TaTe4 showing the Ta linear chains and the regular octahedra formed by Ta and the Te squares. Ta and Te atoms are represented by purple and green spheres, respectively. (b) Reciprocal unit cell of TaTe4 and the corresponding high-symmetry points. The measurement plane perpendicular to the a∗-axis is highlighted. (c) Angle-integrated intensity map of TaTe4 showing the Fermi-level cutoff and the suppression of spectral intensity in an energy window of 0.2 eV. (d) ARPES energy-momentum maps of TaTe4 along Γ-X and Γ-Z, showing the dispersion perpendicular and parallel to the linear chains, respectively. (e) Energy-momentum maps along Γ-X and Γ-Z with saturated contrast over the region of reduced spectral intensity, showing electron-like metallic states (indicated by green arrows) and a hole-like metallic state (indicated by blue arrows) crossing the Fermi-level. The Brillouin zone boundaries are marked by dashed lines in all ARPES images. All measurements were carried out with a photon energy of 75 eV and linear-horizontal (LH) polarization.",
            "FIG. 2. (Color online) (a) ARPES in-plane Fermi surface maps (EB = 0) of TaTe4 obtained with photons of linear horizontal (LH, left panel) and linear vertical (LV, right panel) polarization, showing the in-plane contours of the electron-like metallic states (elliptical contours) and of the quasi-1D metallic states (indicated by arrows). (b) ARPES constant energy maps of TaTe4 at EB = −0.3 eV obtained in both polarizations (LH on the left and LV on the right), showing the contours at the band maximum of the hole-like states centered at Γ. The Brillouin zone boundaries are marked by dashed lines in all images. All measurements were carried with a photon energy of 75 eV.",
            "FIG. 3. (Color online) (a) Electronic bandstructure of TaTe4 calculated by DFT in the unmodulated phase. (b) Electronic band structure of TaTe4 calculated by DFT in the CDW phase. (c) Comparison between ARPES dispersion and DFT calculations in the unmodulated phase along Γ-X, showing the predicted hole-like state centered at Γ and the electron-like metallic states (indicated by green arrows) not predicted by the calculations. (d) Comparison between ARPES dispersions and DFT calculations in the unmodulated phase along Γ-Z for both polarizations, showing the dispersion of the hole-like state centered at Γ, visible only with horizontal polarization, and the electron-like state, visible only with vertical polarization. The quasi-1D metallic state is indicated by blue arrows. The calculated bandstructure in the non-CDW phase was shifted 0.24 eV in order to achieve a better agreement between theory and experiment. All measurements were carried out with a photon energy of 75 eV, and the energy-momentum maps were processed using the curvature method [61] to enhance the intensity of weak spectral features.",
            "FIG. 4. (Color online) (a) ARPES out-of-plane Fermi surface map (EB = 0) of TaTe4 obtained by superimposing the maps obtained using photons with both polarizations, showing the out-of-plane dispersion of the electron-like metallic states. The measurements were carried out using photon energies from 50 to 100 eV. (b) Electronic band structure of TaTe4 calculated by DFT along the M-Γ-Z direction, showing the band crossings along Γ-Z (blue) and Γ-M (yellow). The projections of the band crossings at the Fermi level are indicated by points D1 and D2, respectively. (c) Schematic of the positions of the points D1 and D2 in the reciprocal unit cell of TaTe4 and their projections on the surface Brillouin zone indicated by P1 and P2. The indices 1 and 2 refer to a single and double projection, respectively. (d) Schematic of the positions of the points P1 and P2 on the surface Brillouin zone with a qualitative description of the Fermi arcs connecting them. (e) ARPES in-plane Fermi surface maps (EB = 0) of TaTe4 maps obtained with LH and LV polarization, and the superimposed expected k-location of the Fermi arcs. This measurement was carried with a photon energy of 75 eV."
        ],
        "imgs": [
            "$2305.00053v1-Figure1-1.png",
            "$2305.00053v1-Figure2-1.png",
            "$2305.00053v1-Figure3-1.png",
            "$2305.00053v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00058",
        "abstract": "  We discuss exact regular compact object solutions in higher dimensional\nextensions of General Relativity sourced by a phantom scalar field in arbitrary\n$D$ spacetime dimensions ($D>2$), for which a central singularity is absent. We\nfollow a bottom-up approach, by means of which, by imposing the desired form of\nthe solution to the metric function, we derive the form of the self-interaction\nscalar potential, which in general appears to depend on both the scalar-hair\ncharge and the black-hole mass. We discuss in this context the validity of the\nfirst law of thermodynamics in such systems. Consistency requires the\nindependence of the potential of the mass, imposing in this way the dependence\nof the mass on the scalar charge of a type that varies with the value of $D$,\nand according to the no-hair theorem dressing the regular black hole solution\nwith secondary hair. In $D=3,4$ we demonstrate that the potential depends on\nthe ratio of the scalar charge over the mass, and thus considered as a\nparameter of the theory. This feature, however, does not characterise\nhigher-dimensional cases. Calculating the $D-$dimensional Kretschmann scalar we\nshow that it is finite at the centre point $r=0$ for arbitrary $D$, rendering\nthe solutions regular. The phantom matter content of the theory is also regular\nat $r=0$, hence the radial coordinate of our manifold is defined for $r \\ge 0$.\nWe explicitly discuss the cases of $D=3,4,5,6,10$, and demonstrate that we can\nhave regular, asymptotically flat, black holes with secondary scalar hair.\n",
        "title": "Regular Compact Objects with Scalar Hair",
        "texts": [
            "FIG. 1. The metric function b(r), the potential V (r), the square of the Riemann tensor and the mass as a function of the event horizon are ploted for l = m = 1 while varying the scalar length scale A, alongside the BTZ black hole.",
            "FIG. 2. The energy density ρ(r), the radial pressure pr(r), the equation of state w(r) and the sum of the energy density and pressure ρ(r) + pr(r) for m = l = 1, while varying the scalar length scale A for the three dimensional case.",
            "FIG. 3. Plots of the metric function b(r), the potential V (r) and the square of the Riemann tensor as functions of the radial distance r, the mass as function of the event horizon radius, the horizon radius as a function of the scalar charge A and the temperature T (rh) of the black hole as function of the horizon radius.",
            "FIG. 4. The heat capacity C(rh) = TdS/dT ∣∣∣∣ Rh→ √ r2 h +A2 as a function of the horizon radius.",
            "FIG. 5. The energy density ρ(r), the radial pressure pr(r), the equation of state w(r) and the sum of the energy density and pressure ρ(r) + pr(r) for m = 1, while varying the scalar length scale A for the four dimensional case.",
            "FIG. 6. The horizon radius as a function of A, the metric function b(r) the potential V (r) and the temperature T (rh) for c2 = −10 while changing A, for the five-dimensional black hole.",
            "FIG. 7. The energy density, the radial pressure, their sum and the equation of state are plotted while changing A for the five dimensional case.",
            "FIG. 8. The metric function b(r) for asymptotically flat black hole spacetimes from D = 6 and D = 10 while varying the mass parameter c2 and the scalar charge."
        ],
        "imgs": [
            "$2305.00058v3-Figure1-1.png",
            "$2305.00058v3-Figure2-1.png",
            "$2305.00058v3-Figure3-1.png",
            "$2305.00058v3-Figure4-1.png",
            "$2305.00058v3-Figure5-1.png",
            "$2305.00058v3-Figure6-1.png",
            "$2305.00058v3-Figure7-1.png",
            "$2305.00058v3-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00060",
        "abstract": "  A typical task for classical and quantum computing in chemistry is finding a\npotential energy surface (PES) along a reaction coordinate, which involves\nsolving the quantum chemistry problem for many points along the reaction path.\nDeveloping algorithms to accomplish this task on quantum computers has been an\nactive area of development, yet finding all the relevant eigenstates along the\nreaction coordinate remains a difficult problem, and determining PESs is thus a\ncostly proposal. In this paper, we demonstrate the use of a eigenvector\ncontinuation -- a subspace expansion that uses a few eigenstates as a basis --\nas a tool for rapidly exploring potential energy surfaces. We apply this to\ndetermining the binding PES or torsion PES for several molecules of varying\ncomplexity. In all cases, we show that the PES can be captured using relatively\nfew basis states; suggesting that a significant amount of (quantum)\ncomputational effort can be saved by making use of already calculated ground\nstates in this manner.\n",
        "title": "Quantum Eigenvector Continuation for Chemistry Applications",
        "texts": [
            "FIG. 2. Potential energy surfaces (PES) for the F2 dissociation using the cc-pvDZ basis and an (8o, 14e) active space. Solid lines show the Hartree-Fock (grey) and complete active space (CAS) FCI results, while the discontinuous lines present eigenvector continuation (EC) results with a different number of training points. The training points are shown as red, square markers and are labeled with numbers, representing the order in which they were included in the EC calculation. Results are shown for 3 types of orbital matchings: one ignoring all orbital rotations (leftmost), one ignoring the metric, but including all molecular orbital rotation factors (center), and finally one including all effects of the change in atomic orbital (AO) basis between geometries (rightmost).",
            "FIG. 3. Norm of the transformed vector used as basis in the eigenvector continuation (EC) calculation, for the three different orbital matchings (upper panel), in an F2 cc-pvDZ calculation with an (8o, 12e) active space. The original vector is the CAS-FCI solution at R = 1.5 Å (red marker in lower panel). For reference, the FCI potential energy surface is shown as a black solid curve (lower panel).",
            "FIG. 4. Bond stretching potential energy surfaces (PES) for small molecules, comparing FCI and eigenvector continuation (EC). The x-axis is the bond length rescaled with the equilibrium value for the given molecule, and the y-axis is the ground state energy rescaled by the minimum value and shifted by the large distance asymptotic (i.e. the bond energy). Symmetric bonds are shown in the upper row, while asymmetric bonds are found in the lower row.",
            "FIG. 6. Potential energy surface (PES) for hexatriene in the cc-pvDZ basis as a function of the torsion angle ϕ around the central C-C double bond. ϕ = 0◦ corresponds to the trans configuration, ϕ = 180◦ to cis. The FCI results correspond to a complete active space (6o, 6e) calculation involving only the π orbital manifold. Shown are eigenvector continuation (EC) for three different numbers of training points, always symmetrically chosen around ϕ = 180◦.",
            "FIG. 7. Two measures of the error on the potential energy surfaces (PES) for the bond stretching examples in Fig 4. The exact error with respect to FCI is shown with square markers, and the residue estimate in Eq (6) with round markers. The approximate residue follows the exact error closely.",
            "FIG. 8. Results of eigenvector continuation (EC) for excited state potential energy surfaces (PES) in F2 using the cc-pVDZ basis set. The FCI PES in the (8o, 14e) active space for the first few excited states are presented in grey. Results are shown for three different EC simulations. Left panel: EC with 3 training points using always FCI ground state vectors. Middle panel: EC with 3 training points using always FCI first excited state vectors. Right panel: EC with 6 training points in 3 different geometries, using both the ground state and 1st excited state of the FCI Hamiltonian in each point.",
            "TABLE I. Table summarizing the computational details of the molecular potential energy surfaces (PES) studied in this work.",
            "TABLE III. Equilibrium (i.e. ϕ = 0◦) geometry for trans-hexatriene, as reported in Ref. [48]."
        ],
        "imgs": [
            "$2305.00060v2-Figure2-1.png",
            "$2305.00060v2-Figure3-1.png",
            "$2305.00060v2-Figure4-1.png",
            "$2305.00060v2-Figure6-1.png",
            "$2305.00060v2-Figure7-1.png",
            "$2305.00060v2-Figure8-1.png",
            "$2305.00060v2-TableI-1.png",
            "$2305.00060v2-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00061",
        "abstract": "  Languages models have been successfully applied to a variety of reasoning\ntasks in NLP, yet the language models still suffer from compositional\ngeneralization. In this paper we present Explainable Verbal Reasoner Plus\n(EVR+), a reasoning framework that enhances language models' compositional\nreasoning ability by (1) allowing the model to explicitly generate and execute\nsymbolic operators, and (2) allowing the model to decompose a complex task into\nseveral simpler ones in a flexible manner. Compared with its predecessor\nExplainable Verbal Reasoner (EVR) and other previous approaches adopting\nsimilar ideas, our framework supports more diverse types of reasoning such as\nnested loops and different types of recursion. To evaluate our reasoning\nframework, we build a synthetic dataset with five tasks that require\ncompositional reasoning. Results show that our reasoning framework can enhance\nthe language model's compositional generalization performance on the five\ntasks, using a fine-tuned language model. We also discussed the possibility and\nthe challenges to combine our reasoning framework with a few-shot prompted\nlanguage model.\n",
        "title": "Explainable Verbal Reasoner Plus (EVR+): A Natural Language Reasoning\n  Framework that Supports Diverse Compositional Reasoning",
        "texts": [
            "Figure 1: Comparison of Different Iterative Decomposition Frameworks. Top: sequential decomposition. The next action/sub-problem is determined by all previous actions/results. For example, block 4 is generated based on blocks [1,2,3]. Middle: recursive decomposition; the generated action/sub-problem is only determined by the upper level’s state (e.g., 1.2.1 is only determined by 1.2); Bottom: hybrid decomposition, in which the hybrid reasoning framework supports both sequential decomposition and recursive decomposition. [2.1, 2.2, 2.3] are generated from [2] recursively; [3] is generated from [1, 2] sequentially.",
            "Figure 2: An EVR+ Working Cycle",
            "Figure 3: A walk-through example of EVR+ on the tree search task.",
            "Figure 4: The performance of UnifiedQA-T5-large (e2e) and EVR+ (evr, with a UnifiedQA-T5-base backbone) on the chaining, Cartesian and tree search tasks. The e2e model is trained on depth up to 2 data for chaining and tree search (i.e., data depth 0, 1, 2), and trained on depth up to 3 data for Cartesian product (i.e., depth 2, 3).",
            "Figure 5: The performance of UnifiedQA-T5-large (e2e) and EVR+ (evr, with a UnifiedQA-T5-base backbone) on the chaining-tree-search and Cartesian-treesearch tasks. For both tasks the models are trained on the data with the depth up to 2, so the data with depth 3 and 4 are OOD data.",
            "Figure 6: The program generated by GPT-3 and the target program. All lines of the program generated by GPT-3 are aligned with the target program, but with incorrect grammar.",
            "Table 1: Statistics of the SynthCompR Dataset. For the tasks except the Cartesian task we generate the du2 and du4 data. Du means depth up to (e.g., du2 means depths 0, 1, 2). For the Cartesian product task, we generate the du3 and du4 data. The number of examples of each depth are equally distributed. For example, the chaining du2 training split has 9999 examples, each depth [0, 1, 2] has 3333 training examples.",
            "Table 2: The 5 synthetic tasks that are motivated by real-world examples or previously proposed problems that require compositional reasoning.",
            "Table 3: Few-shot prompted test accuracy for each pattern.",
            "Table 6: The template to generate the training data generate_program-1, generate_program-2, generate_program-3, qa-1 of the tree search task. The generate_program data have the generate_program: prefix in the input, and the qa data have the qa: prefix in the input."
        ],
        "imgs": [
            "$2305.00061v1-Figure1-1.png",
            "$2305.00061v1-Figure2-1.png",
            "$2305.00061v1-Figure3-1.png",
            "$2305.00061v1-Figure4-1.png",
            "$2305.00061v1-Figure5-1.png",
            "$2305.00061v1-Figure6-1.png",
            "$2305.00061v1-Table1-1.png",
            "$2305.00061v1-Table2-1.png",
            "$2305.00061v1-Table3-1.png",
            "$2305.00061v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00062",
        "abstract": "  Undergraduate quantum mechanics focuses on teaching through a wavefunction\napproach in the position-space representation. This leads to a differential\nequation perspective for teaching the material. However, we know that abstract\nrepresentation-independent approaches often work better with students, by\ncomparing student reactions to learning the series solution of the harmonic\noscillator versus the abstract operator method. Because one can teach all of\nthe solvable quantum problems using a similar abstract method, it brings up the\nquestion, which is likely to lead to a better student understanding? In work at\nGeorgetown University and with edX, we have been teaching a class focused on an\noperator-forward viewpoint, which we like to call operator mechanics. It\nteaches quantum mechanics in a representation-independent fashion and allows\nfor most of the math to be algebraic, rather than based on differential\nequations. It relies on four fundamental operator identities -- (i) the Leibniz\nrule for commutators; (ii) the Hadamard lemma; (iii) the\nBaker-Campbell-Hausdorff formula; and (iv) the exponential disentangling\nidentity. These identities allow one to solve eigenvalues, eigenstates and\nwavefunctions for all analytically solvable problems (including some not often\nincluded in undergraduate curricula, such as the Morse potential or the\nPoschl-Teller potential). It also allows for more advanced concepts relevant\nfor quantum sensing, such as squeezed states, to be introduced in a simpler\nformat than is conventionally done. In this paper, we illustrate the three\napproaches of matrix mechanics, wave mechanics, and operator mechanics, we show\nhow one organizes a class in this new format, we summarize the experiences we\nhave had with teaching quantum mechanics in this fashion and we describe how it\nallows us to focus the quantum curriculum on more modern 21st century topics\nappropriate for the\n",
        "title": "Should we trade off higher-level mathematics for abstraction to improve\n  student understanding of quantum mechanics?",
        "texts": [
            "Figure 1. Images from different computer animations in the quantum-mechanics class. Top left: A nested three-SternGerlach analyzer experiment. Top right: A Bell experiment. Bottom left: A single-slit diffraction experiment (illustrating the wave properties of single-slit diffraction). Bottom right: The Hong-Ou-Mandel experiment."
        ],
        "imgs": [
            "$2305.00062v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00063",
        "abstract": "  The Clock-Drawing test is a well known and widely used neuropsychological\nmetric to assess basic cognitive function. My objective is to combine methods\nof machine learning in computer vision and image analysis to predict a\nsubject's level of cognitive impairment.\n",
        "title": "Applications of Computer Vision in Analysis of the Clock-Drawing Test as\n  a Metric of Cognitive Impairment",
        "texts": [
            "Figure 1: Process of image preprocessing and decomposition",
            "Figure 2: CNN architecture for handwritten digit extraction",
            "Table 1: CDT evaluation data"
        ],
        "imgs": [
            "$2305.00063v1-Figure1-1.png",
            "$2305.00063v1-Figure2-1.png",
            "$2305.00063v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00066",
        "abstract": "  The Kolmogorov $N$-width describes the best possible error one can achieve by\nelements of an $N$-dimensional linear space. Its decay has extensively been\nstudied in Approximation Theory and for the solution of Partial Differential\nEquations (PDEs). Particular interest has occurred within Model Order Reduction\n(MOR) of parameterized PDEs e.g.\\ by the Reduced Basis Method (RBM).\n  While it is known that the $N$-width decays exponentially fast (and thus\nadmits efficient MOR) for certain problems, there are examples of the linear\ntransport and the wave equation, where the decay rate deteriorates to\n$N^{-1/2}$. On the other hand, it is widely accepted that a smooth parameter\ndependence admits a fast decay of the $N$-width. However, a detailed analysis\nof the influence of properties of the data (such as regularity or slope) on the\nrate of the $N$-width seems to lack.\n  In this paper, we use techniques from Fourier Analysis to derive exact\nrepresentations of the $N$-width in terms of initial and boundary conditions of\nthe linear transport equation modeled by some function $g$ for half-wave\nsymmetric data. For arbitrary functions $g$, we derive bounds and prove that\nthese bounds are sharp. In particular, we prove that the $N$-width decays as\n${c_r N^{-r}}$ for functions {with Sobolev regularity} $g\\in\nH^{r{-\\varepsilon}}$ for all $\\varepsilon>0$ even if $g\\not\\in H^{r}$. Our\ntheoretical investigations are complemented by numerical experiments which\nconfirm the sharpness of our bounds and give additional quantitative insight.\n",
        "title": "The Kolmogorov N-width for linear transport: Exact representation and\n  the influence of the data",
        "texts": [
            "Fig. 1: Kolmorogov N -width dN (P) width for a discontinuous function – comparison of POD, exact form of dN (P) and known asymptotic rate.",
            "Fig. 2: Construction of an odd HWS initial condition from a smooth ramp.",
            "Fig. 3: Ramp functions with varying smoothness Ck.",
            "Fig. 4: N -width for ramps with varying regularity.",
            "Fig. 5: N -width depending on the slope of a continuous, piecewise linear function.",
            "Fig. 6: δN (P) for random functions of different smoothness.",
            "Fig. 7: 2D-transport problem: δN -width for initial- and boundary conditions of different regularity Ck(ΩP), k = 0, ..., 4.",
            "Table 1: Values for 2ε for each gk"
        ],
        "imgs": [
            "$2305.00066v1-Figure1-1.png",
            "$2305.00066v1-Figure2-1.png",
            "$2305.00066v1-Figure3-1.png",
            "$2305.00066v1-Figure4-1.png",
            "$2305.00066v1-Figure5-1.png",
            "$2305.00066v1-Figure6-1.png",
            "$2305.00066v1-Figure7-1.png",
            "$2305.00066v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00069",
        "abstract": "  The Standard Model does not constrain the form of the Yukawa matrices and\nthus the origin of fermion mass hierarchies and mixing pattern remains\npuzzling. On the other hand, there are intriguing relations between fermion\nmasses and mixing angles which may point towards specific textures of Yukawa\nmatrices. One of the classic hypothesis is the zero texture proposed by\nFritzsch which is, however, excluded by present precision tests since it\npredicts a too large value of $|V_{cb}|$ as well as a too small value of the\nratio $|V_{ub}/V_{cb}|$. In this paper we discuss a minimal modification which\nstill maintains the six zero entries as in the original Fritzsch ansatz. This\nmodification consists in introducing an asymmetry between the 23 and 32 entries\nin the down-quark Yukawa matrix. We show that this flavour structure can\nnaturally emerge in the context of models with inter-family $SU(3)_H$ symmetry.\nWe present a detailed analysis of this Fritzsch-like texture by testing its\npredictions and showing that it is perfectly compatible with the present\nprecision data on quark masses and CKM mixing matrix.\n",
        "title": "Minimally modified Fritzsch texture for quark masses and CKM mixing",
        "texts": [
            "Figure 1: Seesaw diagrams inducing the Yukawa couplings of upper quarks via exchange of vector-like quarks U,U c and Q,Qc. Analogous diagrams with U,U c → D,Dc and φ→ φ̃ will work for down quarks.",
            "Figure 3: Symmetric Fritzsch textures for quark Yukawa matrices do not predict the correct value of Vcb and of the ratio Vub/Vcb.",
            "Figure 4: Predictions of the asymmetric Fritzsch-like textures (see eq. (3.2)) with xd = 3.3, xu = 1, confronted with experimental data.",
            "Figure 7: Parameter space in the scenario with xu = 1 (symmetric Fritzsch texture for up-type quarks, asymmetric 23 entries for down-type quarks, see eq. (3.2)) in the xd-β̃, δ̃-β̃ and xd-β̃ planes, marginalizing over the other variable. 1σ, 2σ and 3σ preferred regions of the parameters are indicated (χ2 min + 1, χ2 min + 4, χ2 min + 9), assuming Yukawa matrices of Fritzsch-like form at 103 GeV (left), 106 TeV (centre), 1016 TeV (right).",
            "Table 1: Determinations of quark mass ratios used in this work. In the first line, mud = (mu +md)/2. ∗ Value adopted by Particle Data Group (PDG), averaging Nf = 2+1+1 and Nf = 2+1+1 flavours lattice results [71].",
            "Table 2: Magnitudes and phases of CKM elements as quoted by Particle Data Group [3].",
            "Table 3: Result of global fit for CKM parameters, including constraints implied by the unitarity of the three generation CKM matrix, as reported by Particle Data Group [3]."
        ],
        "imgs": [
            "$2305.00069v1-Figure1-1.png",
            "$2305.00069v1-Figure3-1.png",
            "$2305.00069v1-Figure4-1.png",
            "$2305.00069v1-Figure7-1.png",
            "$2305.00069v1-Table1-1.png",
            "$2305.00069v1-Table2-1.png",
            "$2305.00069v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00070",
        "abstract": "  We present an online post-hoc calibration method, called Online Platt Scaling\n(OPS), which combines the Platt scaling technique with online logistic\nregression. We demonstrate that OPS smoothly adapts between i.i.d. and\nnon-i.i.d. settings with distribution drift. Further, in scenarios where the\nbest Platt scaling model is itself miscalibrated, we enhance OPS by\nincorporating a recently developed technique called calibeating to make it more\nrobust. Theoretically, our resulting OPS+calibeating method is guaranteed to be\ncalibrated for adversarial outcome sequences. Empirically, it is effective on a\nrange of synthetic and real-world datasets, with and without distribution\ndrifts, achieving superior performance without hyperparameter tuning. Finally,\nwe extend all OPS ideas to the beta scaling method.\n",
        "title": "Online Platt Scaling with Calibeating",
        "texts": [
            "Figure 1: The combination of Platt scaling and online logistic regression yields Online Platt Scaling (OPS). Calibeating is applied on top of OPS to achieve further empirical improvements and theoretical validity.",
            "Figure 11: The adaptive behavior of OPS for the simulated regression-function drift scenario described in Section 1.2.",
            "Figure 12: Results for the same experimental setup as Figures 5 and 6, but with ϵ “ 0.05.",
            "Figure 13: Results for the same experimental setup as Figures 5 and 6, but with ϵ “ 0.2.",
            "Figure 14: Performance of online beta scaling (OBS) and its calibeating variants on real datasets with and without distribution drift. OBS further improves upon OPS in most cases. In each plot, TOBS is the best-performing method.",
            "Figure 15: Comparing the performance of windowed histogram binning (WHB), online Platt scaling (OPS), online beta scaling (OBS), and their tracking variants on real datasets with and without distribution drifts. Among non-tracking methods (dotted lines), WHB performs well with i.i.d. data, while OBS performs well for drifting data. Among tracking methods (solid lines), TOBS and TOPS are the best-performing methods in every plot. Tracking typically does not improve WHB much since WHB is already a binning method (so tracking is implicit).",
            "Figure 16: Foster (1999)’s ϵ-calibrated forecaster on Pittsburgh’s hourly rain data (2008-2012). The forecaster makes predictions on the grid p0.05, 0.15, . . . , 0.95q. In the long run, the forecaster starts predicting 0.35 for every instance, closely matching the average number of instances on which it rained (« 0.37).",
            "Figure 2: Online adversarial post-hoc calibration.",
            "Figure 3: The adaptive behavior of Online Platt scaling (OPS) for the covariate drift dataset described in Section 1.2. The title of each panel indicates the time-window that panel corresponds to. The histogram of Xt values in the corresponding time window is plotted with maximum height normalized to 1. Also plotted is the true curve for PrpY “ 1 | X “ xq and two predictive curves: a base model trained on t “ 1 to t “ 1000, and OPS-calibrated models with parameter values fixed at the start of the time window. The base model is accurate for the training data which is mostly in r´5, 10s, but becomes inaccurate and miscalibrated with the covariate-shifted values for larger t (bottom two subplots). OPS adapts well, agreeing with the base model in the top-right subplot, but flipping the base model predictions in the bottom-right subplot.",
            "Figure 4: The adaptive behavior of OPS for the simulated label shift and regression-function drift datasets described in Section 1.2. For more details on the contents of the figure, please refer to Figure 3. The improvement in calibration and accuracy of OPS over the base model is visually apparent, but for completeness, {Acc, CE} values are reported in the Appendix as part of Figures 10 and 11.",
            "Figure 5: Drifting data. CE (calibration error) values over time of considered models on four datasets with synthetically induced drifts. The plots have invisible error bars since variation across the 100 runs was small. OPS consistently performs better than BM, FPS, and WPS, while TOPS is the best-performing among all methods across datasets and time. All methods had roughly the same SHP values at a given time-step, so the SHP plots are delayed to Appendix A (Figure 8).",
            "Figure 6: IID data. CE values over time of considered models with four randomly shuffled (ie, nearly i.i.d.) datasets. The plots have invisible error bars since variation across runs was small. TOPS achieves the smallest values of CE throughout.",
            "Figure 7: Experiments with synthetic data. In all cases, TOPS has the lowest CE across time.",
            "Figure 8: Sharpness results with drifting data. SHP values over time of considered models on four datasets with synthetically induced drifts (Section 4.1). The plots have invisible error bars since variation across the 100 runs was small. The drop in expected sharpness is below 0.005 at all times except on the Fetal Health Dataset.",
            "Table 1: Asymptotic regret and running times of online logistic regression (OLR) algorithms for OPS as functions of the radius of reference class B and time-horizon T . For general OLR, regret and running times also depend on the dimension of X . However, OPS effectively reduces the dimensionality of X to 2, so that a second-order method like ONS runs almost as fast as a first-order method like OGD. Also note that B “ ? a2 ` b2 is small if the base model f is not highly miscalibrated. ONS with fixed hyperparameters was chosen for all OPS experiments; see Section 2.2 for implementation details.",
            "Table 2: Metadata for datasets used in Section 4.1. The sort-by column indicates which covariate was used to order data points. All datasets are under the Creative Commons CC0 license."
        ],
        "imgs": [
            "$2305.00070v2-Figure1-1.png",
            "$2305.00070v2-Figure11-1.png",
            "$2305.00070v2-Figure12-1.png",
            "$2305.00070v2-Figure13-1.png",
            "$2305.00070v2-Figure14-1.png",
            "$2305.00070v2-Figure15-1.png",
            "$2305.00070v2-Figure16-1.png",
            "$2305.00070v2-Figure2-1.png",
            "$2305.00070v2-Figure3-1.png",
            "$2305.00070v2-Figure4-1.png",
            "$2305.00070v2-Figure5-1.png",
            "$2305.00070v2-Figure6-1.png",
            "$2305.00070v2-Figure7-1.png",
            "$2305.00070v2-Figure8-1.png",
            "$2305.00070v2-Table1-1.png",
            "$2305.00070v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00071",
        "abstract": "  Recent gravitational-wave transient catalogs have used \\pastro{}, the\nprobability that a gravitational-wave candidate is astrophysical, to select\ninteresting candidates for further analysis. Unlike false alarm rates, which\nexclusively capture the statistics of the instrumental noise triggers,\n\\pastro{} incorporates the rate at which triggers are generated by both\nastrophysical signals and instrumental noise in estimating the probability that\na candidate is astrophysical. Multiple search pipelines can independently\ncalculate \\pastro{}, each employing a specific data reduction. While the range\nof \\pastro{} results can help indicate the range of uncertainties in its\ncalculation, it complicates interpretation and subsequent analyses. We develop\na statistical formalism to calculate a \\emph{unified} \\pastro{} for\ngravitational-wave candidates, consistently accounting for triggers from all\npipelines, thereby incorporating extra information about a signal that is not\navailable with any one single pipeline. We demonstrate the properties of this\nmethod using a toy model and by application to the publicly available list of\ngravitational-wave candidates from the first half of the third LIGO-Virgo-KAGRA\nobserving run. Adopting a unified \\pastro{} for future catalogs would provide a\nsimple and easy-to-interpret selection criterion that incorporates a more\ncomplete understanding of the strengths of the different search pipelines\n",
        "title": "A Unified $p_\\mathrm{astro}$ for Gravitational Waves: Consistently\n  Combining Information from Multiple Search Pipelines",
        "texts": [
            "FIG. 1: A schematic of the toy model data. Each row is a segment, consisting of four data point indicated by the rounded rectangles. The noise in the segments is drawn from a standard normal distribution, with its value indicated by the color scale of the rounded rectangle. Segments 2 and 4 from the top in this example contain a signal, added randomly to one of the four data points indicated by the vermilion colored star.",
            "FIG. 2: Toy-model exploration of the unified pastro formalism. In both figures, the dashed lines indicate the real number of segments with (and without) a signal. The shaded regions are 90% uncertainty levels.",
            "FIG. 3: Joint likelihood distributions for the signal and noise hypothesis. The spans of the signal and noise distributions span are dissimilar. The signal distribution extends to much larger β values than the noise distribution.",
            "FIG. 4: The distribution of triggers that were found by one pipeline only. The top plot shows the noise and signal distribution of GstLAL, while the bottom plot shows the PyCBC distribution of triggers. The black stars are again the on-source O3a triggers from GWTC-2.1 that have only been found by the corresponding pipeline [19].",
            "FIG. 5: The posterior for the signal and noise counts in the joint analysis. The shaded region in the one-dimensional posterior corresponds to 90% uncertainty levels, while the contours in the two-dimensional posteriors are the 50% and 90% levels. We recover a median value Λs = 53+10",
            "TABLE I: Triggers with a unified pastro ≥ 0.5 from our illustrative analysis. The triggers that have pastro ≥ 0.5 in at least one pipeline in GWTC-2.1 [19] are shown in the second column. Also listed are the FARs of the triggers from the GstLAL and PyCBCpipelines. These results illustrate the properties of the unified pastro method, but a larger number of noise triggers, and more accurate population models, would be needed to obtain reliable quantitative results."
        ],
        "imgs": [
            "$2305.00071v1-Figure1-1.png",
            "$2305.00071v1-Figure2-1.png",
            "$2305.00071v1-Figure3-1.png",
            "$2305.00071v1-Figure4-1.png",
            "$2305.00071v1-Figure5-1.png",
            "$2305.00071v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00072",
        "abstract": "  We present discontinuous Galerkin (DG) methods for solving a first-order\nsemi-linear hyperbolic system, which was originally proposed as a continuum\nmodel for a one-dimensional dimer lattice of topological resonators. We examine\nthe energy-conserving or energy-dissipating property in relation to the choices\nof simple, mesh-independent numerical fluxes. We demonstrate that, with certain\nnumerical flux choices, our DG method achieves optimal convergence in the $L^2$\nnorm. We provide numerical experiments that validate and illustrate the\neffectiveness of our proposed numerical methods.\n",
        "title": "Discontinuous Galerkin methods for a first-order semi-linear hyperbolic\n  continuum model of a topological resonator dimer array",
        "texts": [
            "Figure 2: From the left to the right, we plot the errors |w1−wh 1 | and |w2−wh 2 | over the spatial location x for the problem (6.5) using P3 polynomial on a uniform mesh of N = 20, 40, 80; from the top to the bottom are the results by using the upwind fluxes (6.1), the central fluxes (6.2), the mixed central fluxes (6.4), and the mixed upwind fluxes (6.3), respectively.",
            "Figure 4: Plots of both the numerical solutions wh 1 , w h 2 , and the exact solutions w1, w2 of problem (6.8) with the degree of approximation space q = 3. The upwind fluxes (6.1) is used in the simulation. The numerical and exact solutions at t = 0, 30, 75, 100 are plotted from top to bottom. On the left, we present the results for w1, while on the right, we display the results for w2.",
            "Figure 7: Space-time plots of wh 2 (x, t). On the left panel, from top to bottom, are the plots for the kink soliton with q = 0, q = 1, q = 2, and q = 3, respectively; On the right panel are the zoom-in plots of the transition region, x ∈ (88, 103), of the kink soliton.",
            "Figure 8: Comparison between the kink solitons with different degrees of approximation space q at the final time t = 100. On the left presents the results for wh 1 , and the right shows the results for wh 2 .",
            "Figure 9: we present the energy difference, |Eh(t)−Eh(0)| on the left and Eh(t)−Eh(0) on the right, of kink solitons with different degrees q of approximation space in a moving box until the final time T = 100. The box is initially put at the region of x ∈ [60, 140] and then moves to the right with the same speed as the kink solitons.",
            "Table 1: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.6) using Pq polynomials and the upwind flux (6.1). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 2: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.6) using Pq polynomials and the central flux (6.2). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 3: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.6) using Pq polynomials and the mixed central flux (6.4). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 4: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.6) using Pq polynomials and the mixed upwind flux (6.3). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 5: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.8) using Pq polynomials and the upwind flux (6.1). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 6: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.8) using Pq polynomials and the central flux (6.2). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 7: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.8) using Pq polynomials and the mixed central flux (6.4). The interval is divided into N uniform cells, and the terminal computational time is T = 1.",
            "Table 8: L2 errors and the corresponding convergence rates for w1, w2, b1, b2 of problem (6.8) using Pq polynomials and the mixed upwind flux (6.3). The interval is divided into N uniform cells, and the terminal computational time is T = 1."
        ],
        "imgs": [
            "$2305.00072v2-Figure2-1.png",
            "$2305.00072v2-Figure4-1.png",
            "$2305.00072v2-Figure7-1.png",
            "$2305.00072v2-Figure8-1.png",
            "$2305.00072v2-Figure9-1.png",
            "$2305.00072v2-Table1-1.png",
            "$2305.00072v2-Table2-1.png",
            "$2305.00072v2-Table3-1.png",
            "$2305.00072v2-Table4-1.png",
            "$2305.00072v2-Table5-1.png",
            "$2305.00072v2-Table6-1.png",
            "$2305.00072v2-Table7-1.png",
            "$2305.00072v2-Table8-1.png"
        ]
    },
    {
        "id": "2305.00073",
        "abstract": "  We go through several previous corrections and contributions to the muon\n$g-2$, starting from the dark photon hypothesis to the dark Z. We explore the\ninputs from a dark Z boson virtual mediator in a first order loop. We consider\nnot only the QED like contributions in the theory but also weak interactions.\nWe obtain a new factor that adds corrections to the form factor associated with\nthe anomalous magnetic moment. We show our result is favorable in new\nunexplored windows in the mass-coupling parameter space.\n",
        "title": "Corrections of $Z'$ to the Magnetic Moment of the Muon",
        "texts": [
            "FIG. 2: In green, our analytic expression in Equation (9) for the numerical results previously outlined by Pospelov et al. (see [40]) marked in black dashed lines. This is the case of a U(1) sector coupled to photons. For comparison we show known restricted zones from Babar [42, 43] and NA64 experiments [44], along with SM results for the exclusion in parameter space to the electron and muon anomalous magnetic moment. Constraints adapted from [44].",
            "FIG. 3: Our analytic expression in 9 is shown in black dashed lines, this is the U(1) coupling to SM. Constraints on the Dark Boson mass and kinetic mixing from [45] can be seen as shaded regions, plus their result for the muon g − 2 using this symmetry, again (as in fig. 2) our result explains in a complete and legible expression the previous result fitted to the anomaly. Babar excluded region comes from searches of Z ′ or Dark Z from the productions of µ−µ+Z ′ at colliders [46]. CCFR comes from measurement of the neutrino trident cross section [47] and Borexino from neutrino electron scattering [48]. In Figure 4 we use these constraints, but there we include a mass mixing and a hypercharge coupling to the SM. Figure adapted from [45].",
            "FIG. 4: Constraints for the Dark Z boson (DZ) in the kinetic mixing versus boson mass parameter space in two regimes of the mass mixing parameter, δ, from eq. (26). We set δ to be 10−3 and 10−1, shown as the brown and red contours, respectively. In a dotted line, we represent the exact comparison between our result and the anomaly, eq. (1). The straight lines by the sides of the dotted one represent the 2σ allowed region. Left: In fuchsia, constraints outlined by Croon et al.[56] on supernova muons coupled to Z’ and Borexino, from Figure 3. Right: In pink, exclusion zone from previous work in dark photon-QED like approach to a DZ [45] as shown in fig. 3 and coming from simply setting the masses for the boson in eq. (9), plus the constraints from Babar, Borexino and CCFR as described before."
        ],
        "imgs": [
            "$2305.00073v2-Figure2-1.png",
            "$2305.00073v2-Figure3-1.png",
            "$2305.00073v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00074",
        "abstract": "  For a cosmological first-order phase transition in the early Universe, the\nassociated stochastic gravitational wave background is usually dominated by\nsound waves from plasma fluid motions, which have been analytically modeled as\na random superposition of freely propagating sound shells but with the force by\nthe scalar field that produces the self-similar profile removed. In this\nLetter, we propose a new analytic sound shell model by focusing on the forced\npropagating contribution from the initial collision stage of sound shells when\ntheir self-similar profiles are still maintained by the moving bubble walls. We\nreproduce the causal $k^3$ scaling in the infrared consistent with numerical\nsimulations, and also recover the broad dome in the power spectrum first\nobserved in numerical simulations. The total sound waves should contain both\ncontributions from forced collisions and free propagation of sound shells at\nearly and late stages of the phase transition, respectively.\n",
        "title": "Hydrodynamic sound shell model",
        "texts": [
            "FIG. 4. A schematic illustration for the single-shell and double-shell contributions to the energy-momentum tensor with their two-point correlation functions coming from x⃗ and y⃗ in the same sound shell (blue shell) or in different sound shells (cyan and red shells).",
            "FIG. 5. Schematic illustration for the two-point correlator of the energy-momentum tensor from three different configurations shown in 1 + 1 dimensions (top row) and 2 + 1 dimensions (bottom row). For the single-shell case, there should be only one bubble nucleated in the region shaded in yellow.",
            "FIG. 6. A typical 2-dimensional view for the 3-dimensional region of an equal-time hypersurface. The single-shell contribution comes from a bubble nucleated in the region Uxy shaded in yellow, while the double-shell contribution comes from two bubbles nucleated separately in U ′ x and U ′ y shaded in blue and red. The system has a SO(2) symmetry and is invariant under rotations around r⃗ direction.",
            "FIG. 7. The single-shell (left) and double-shell (right) power spectra for α = 0.1. The discrete points are the numerical results and solid lines are their interpolating functions. The curves correspond to different vw from 0.80 to 1.00 with interval ∆vw = 0.02 from the top one to the bottom one, respectively. The blue and red dashed lines are the asymptotic behaviors of the power spectra with vw = 0.8 and vw = 1, respectively. All these power spectra scale as k3 at low frequencies.",
            "FIG. 8. The full shapes of power spectra from the single-shell (blue) and double-shell (orange) contributions to the total power spectrum (green) for different vw with fixed α = 0.1."
        ],
        "imgs": [
            "$2305.00074v2-Figure4-1.png",
            "$2305.00074v2-Figure5-1.png",
            "$2305.00074v2-Figure6-1.png",
            "$2305.00074v2-Figure7-1.png",
            "$2305.00074v2-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00076",
        "abstract": "  We present the findings of our participation in the SemEval-2023 Task 10:\nExplainable Detection of Online Sexism (EDOS) task, a shared task on offensive\nlanguage (sexism) detection on English Gab and Reddit dataset. We investigated\nthe effects of transferring two language models: XLM-T (sentiment\nclassification) and HateBERT (same domain -- Reddit) for multi-level\nclassification into Sexist or not Sexist, and other subsequent\nsub-classifications of the sexist data. We also use synthetic classification of\nunlabelled dataset and intermediary class information to maximize the\nperformance of our models. We submitted a system in Task A, and it ranked 49th\nwith F1-score of 0.82. This result showed to be competitive as it only\nunder-performed the best system by 0.052% F1-score.\n",
        "title": "HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and\n  Side-Information for Multi-Level Sexism Classification",
        "texts": [
            "Figure 1: Different level of classification as provided in the shared task",
            "Figure 2: Task B. Using authentic and synthetic training datasets.",
            "Figure 3: Task C. Each input sentence is paired with its parent class [\"Threats\", \"Derogation\", \"Animosity\", \"Prejudiced Discussion\"] before tokenization.",
            "Table 1: Dataset Description and Distribution of Sentiment Labels",
            "Table 3: Result of the different tasks."
        ],
        "imgs": [
            "$2305.00076v1-Figure1-1.png",
            "$2305.00076v1-Figure2-1.png",
            "$2305.00076v1-Figure3-1.png",
            "$2305.00076v1-Table1-1.png",
            "$2305.00076v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00077",
        "abstract": "  Requirements elicitation interviews are a widely adopted technique, where the\ninterview success heavily depends on the interviewer's preparedness and\ncommunication skills. Students can enhance these skills through practice\ninterviews. However, organizing practice interviews for many students presents\nscalability challenges, given the time and effort required to involve\nstakeholders in each session. To address this, we propose REIT, an extensible\narchitecture for Requirements Elicitation Interview Training system based on\nemerging educational technologies. REIT has components to support both the\ninterview phase, wherein students act as interviewers while the system assumes\nthe role of an interviewee, and the feedback phase, during which the system\nassesses students' performance and offers contextual and behavioral feedback to\nenhance their interviewing skills. We demonstrate the applicability of REIT\nthrough two implementations: RoREIT with a physical robotic agent and VoREIT\nwith a virtual voice-only agent. We empirically evaluated both instances with a\ngroup of graduate students. The participants appreciated both systems. They\ndemonstrated higher learning gain when trained with RoREIT, but they found\nVoREIT more engaging and easier to use. These findings indicate that each\nsystem has distinct benefits and drawbacks, suggesting that REIT can be\nrealized for various educational settings based on preferences and available\nresources.\n",
        "title": "Exploring Emerging Technologies for Requirements Elicitation Interview\n  Training: Empirical Assessment of Robotic and Virtual Tutors",
        "texts": [
            "Figure 1: The architecture REIT for requirements elicitation interview training system. The dashed lines indicate optional",
            "Figure 10: Experimental setup for the user study.",
            "Figure 2: Visual presentation of the overall contextual performance analysis of a sample user at the end of the session.",
            "Figure 6: The interaction flow between the user and REIT.",
            "Figure 7: Samples of the interview training system’s dialogue displayer states during the interview session.",
            "Figure 8: Samples of the interview training system’s dialogue displayer states during the feedback session.",
            "Figure 9: The experimental design of the user study."
        ],
        "imgs": [
            "$2305.00077v3-Figure1-1.png",
            "$2305.00077v3-Figure10-1.png",
            "$2305.00077v3-Figure2-1.png",
            "$2305.00077v3-Figure6-1.png",
            "$2305.00077v3-Figure7-1.png",
            "$2305.00077v3-Figure8-1.png",
            "$2305.00077v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00081",
        "abstract": "  The paper considers the problem of modeling a univariate random variable.\nMain contributions: (i) Suggested a new family of distributions with quantile\ndefined by a linear combination of some basis quantiles. This family of\ndistributions has a high shape flexibility and covers commonly used\ndistributions. (ii) Proposed an efficient estimation method by constrained\nlinear regression (linearity with respect to the parameters). Various types of\nconstraints and regularizations are readily available to reduce model\nflexibility and improve out-of-sample performance for small datasets . (iii)\nProved that the estimator is asymptotically a minimum Wasserstein distance\nestimator and is asymptotically normal. The estimation method can also be\nviewed as the best fit in quantile-quantile plot. (iv) Case study demonstrated\nnumerical efficiency of the approach (estimated distribution of historical\ndrawdowns of SP500 Index).\n",
        "title": "Mixture Quantiles Estimated by Constrained Linear Regression",
        "texts": [
            "Figure 1: Convergence of error and weighted 2-Wasserstein distance obtained by weighted least squares regression. Black line = objective (error) of the optimization problem of weighted least squares regression. Red line = Wasserstein distance between the estimated quantile function and the true quantile function. Grey band = 90% confidence band of the error obtained by 100 repeated experiments. Red band = 90% confidence band of the distance obtained by 100 repeated experiments. The horizontal axis = sample size in log scale.",
            "Figure 2: Convergence of error and 1-Wasserstein distance obtained by least absolute deviation regression. Black line = objective (error) of the optimization problem of weighted least squares regression. Red line = Wasserstein distance between the estimated quantile function and the true quantile function. Grey band = 90% confidence band of the error obtained by 100 repeated experiments. Red band = 90% confidence band of the distance obtained by 100 repeated experiments. The horizontal axis = sample size in log scale",
            "Figure 3: Q-Q plots of models fitted by least squares regression with cardinality constraint C = 1, 2 and coefficient λ = 0.6, 12 of L1 penalty. MLE is included as a benchmark. {(xn, yn)}N n=1 = black points, xn = n-th sample order statistics, yn = quantile with confidence level n N+1 of the model.",
            "Figure 4: Q-Q plots of models fitted by least absolute deviation regression with cardinality constraint C = 1, 2 and coefficient λ = 1.1, 1.9 of L1 penalty. MLE is included as a benchmark. {(xn, yn)}N n=1 = black points, xn = n-th sample order statistics, yn = quantile with confidence level n N+1 of the model.",
            "Figure 5: Scaled quantile functions of the fitted models and sample points {(− log(1− pn), yn)}N n=1, where pn = n N+1 and yn are the standardized drawdowns. The y-axis is the standardized drawdown. The x-axis is -log(1-probability). The models are fitted with least squares regression with cardinality constraint C = 1, 2 and coefficient λ = 1.1, 1.9 of L1 penalty. The following three estimates almost overlap: least squares, least squares with cardinality constraint C = 2, and least squares with penalty coefficient λ = 0.6. Compared to MLE, all models have better fit to the tail observations, except for least squares regression with C = 1.",
            "Figure 6: Scaled quantile functions of the fitted models and sample points {(− log(1− pn), yn)}N n=1, where pn = n N+1 and yn are the standardized drawdowns. The y-axis is the standardized drawdown. The x-axis is -log(1-probability). The models are fitted with least least absolute deviation (LAD) regression with cardinality constraint C = 1, 2 and coefficient λ = 1.1, 1.9 of L1 penalty. The two scaled quantile functions obtained by the following estimators almost overlap: LAD regression and LAD regression with cardinality constraint C = 2. Compared to MLE, all models have better fit to the tail observations.",
            "Table 1: The table presents the measures of goodness-of-fit for models with different errors, constraints and penalties. MLE is included for comparison. C = value of cardinality constraint, λ = coefficient of L1 penalty in LASSO regression, WMSE = weighted mean squared error, MAE = mean absolute error, KS = Kolmogorov–Smirnov distance, LLK = log likelihood."
        ],
        "imgs": [
            "$2305.00081v1-Figure1-1.png",
            "$2305.00081v1-Figure2-1.png",
            "$2305.00081v1-Figure3-1.png",
            "$2305.00081v1-Figure4-1.png",
            "$2305.00081v1-Figure5-1.png",
            "$2305.00081v1-Figure6-1.png",
            "$2305.00081v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00083",
        "abstract": "  Surrogate-assisted search-based testing (SA-SBT) aims to reduce the\ncomputational time for testing compute-intensive systems. Surrogates enhance\ntesting techniques by improving test case generation focusing the testing\nbudget on the most critical portions of the input domain. In addition, they can\nserve as approximations of the system under test (SUT) to predict tests'\nresults instead of executing the tests on compute-intensive SUTs. This article\nreflects on the existing SA-SBT techniques, particularly those applied to\nsystem-level testing and often facilitated using simulators or complex test\nbeds. Our objective is to synthesize different heuristic algorithms and\nevaluation methods employed in existing SA-SBT techniques and present a\ncomprehensive view of SA-SBT solutions. In addition, by critically reviewing\nour previous work on SA-SBT, we aim to identify the limitations in our proposed\nalgorithms and evaluation methods and to propose potential improvements. We\npresent a taxonomy that categorizes and contrasts existing SA-SBT solutions and\nhighlights key research gaps. To identify the evaluation challenges, we conduct\ntwo replication studies of our past SA-SBT solutions: One study uses industrial\nadvanced driver assistance system (ADAS) and the other relies on a Simulink\nmodel benchmark. We compare our results with those of the original studies and\nidentify the difficulties in evaluating SA-SBT techniques, including the impact\nof different contextual factors on results generalization and the validity of\nour evaluation metrics. Based on our taxonomy and replication studies, we\npropose future research directions, including re-considerations in the current\nevaluation metrics used for SA-SBT solutions, utilizing surrogates for fault\nlocalization and repair in addition to testing, and creating frameworks for\nlarge-scale experiments by applying SA-SBT to multiple SUTs and simulators.\n",
        "title": "Reflections on Surrogate-Assisted Search-Based Testing: A Taxonomy and\n  Two Replication Studies based on Industrial ADAS and Simulink Models",
        "texts": [
            "Figure 1: Experiential learning cycle.",
            "Figure 2: A Taxonomy for Surrogate-Assisted Search-Based Testing (SA-SBT).",
            "Figure 3: SUT of the original study Abdessalem et al. (2018a): a pedestrian crosses the lane of the ego car equipped with the AEB system.",
            "Figure 4: AVP testing scenario from the replication study: a pedestrian occluded by a parking car is crossing the lane of the ego car, which is approaching a free parking spot.",
            "Figure 5: The comparison of HV, GD and Spread (∆) values obtained by NSGAII and NSGAII-DT from the original study Abdessalem et al. (2018a).",
            "Figure 6: The comparison of HV, GD and Spread values obtained by NSGAII and NSGAIIDT from the replication study.",
            "Table 1: Classifying the SA-SBT techniques based on our taxonomy",
            "Table 2: Experimental setup for replication study vs. the study in original paper Abdessalem et al. (2018a)",
            "Table 3: The number of distinct critical scenarios obtained by NSGAII and NSGAII-DT from the replication and original study.",
            "Table 4: Results for piecewise continuous input signals.",
            "Table 5: Results for constrained input signals."
        ],
        "imgs": [
            "$2305.00083v1-Figure1-1.png",
            "$2305.00083v1-Figure2-1.png",
            "$2305.00083v1-Figure3-1.png",
            "$2305.00083v1-Figure4-1.png",
            "$2305.00083v1-Figure5-1.png",
            "$2305.00083v1-Figure6-1.png",
            "$2305.00083v1-Table1-1.png",
            "$2305.00083v1-Table2-1.png",
            "$2305.00083v1-Table3-1.png",
            "$2305.00083v1-Table4-1.png",
            "$2305.00083v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00084",
        "abstract": "  In this paper, we present CarGameAR: An Integrated AR Car Game Authoring\nInterface for Custom-Built Car Programed on Arduino Board. The car consists of\nan Arduino board, an H-bridge, and motors. The objective of the project is to\ncreate a system that can move a car in different directions using a computer\napplication. The system uses Unity software to create a virtual environment\nwhere the user can control the car using keyboard commands. The car's motion is\nachieved by sending signals from the computer to the Arduino board, which then\ndrives the motors through the H-bridge. The project provides a cost-effective\nand efficient way to build a car, which can be used for educational purposes,\nsuch as teaching programming. Moreover, this project is not limited to the\ncontrol of the car through keyboard commands in a virtual environment. The\nsystem can be adapted to support augmented reality (AR) technology, providing\nan even more immersive and engaging user experience. By integrating the car\nwith AR, the user can control the car's motion using physical gestures and\nmovements, adding an extra layer of interactivity to the system. This makes the\ncar an ideal platform for game development in AR, allowing the user to create\ndriving games that blend the physical and virtual worlds seamlessly.\nAdditionally, the car's affordability and ease of construction make it an\naccessible and valuable tool for teaching programming and principles in a fun\nand interactive way. Overall, this project demonstrates the versatility and\npotential of the car system, highlighting the various applications and\npossibilities it offers for both education and entertainment.\n",
        "title": "CarGameAR: An Integrated AR Car Game Authoring Interface for\n  Custom-Built Car Programed on Arduino Board",
        "texts": [
            "Figure 5: Screenshot of experiment results that tests AR Arduino car on the game authoring interface."
        ],
        "imgs": [
            "$2305.00084v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00086",
        "abstract": "  COVID-19 resulted in some of the largest supply chain disruptions in recent\nhistory. To mitigate the impact of future disruptions, we propose an integrated\nhybrid simulation framework to couple nonstationary demand signals from an\nevent like COVID-19 with a model of an end-to-end supply chain. We first create\na system dynamics susceptible-infected-recovered (SIR) model, augmenting a\nclassic epidemiological model to create a realistic portrayal of demand\npatterns for oxygen concentrators (OC). Informed by this granular demand\nsignal, we then create a supply chain discrete event simulation model of OC\nsourcing, manufacturing, and distribution to test production augmentation\npolicies to satisfy this increased demand. This model utilizes publicly\navailable data, engineering teardowns of OCs, and a supply chain illumination\nto identify suppliers. Our findings indicate that this coupled approach can use\nrealistic demand during a disruptive event to enable rapid recommendations of\npolicies for increased supply chain resilience with controlled cost.\n",
        "title": "An Integrated System Dynamics and Discrete Event Supply Chain Simulation\n  Framework for Supply Chain Resilience with Non-Stationary Pandemic Demand",
        "texts": [
            "Figure 1: Comparisons of the active cases between the SIR model and actual in Georgia (GA)",
            "Figure 10: Fulfillment time statistics of customer orders.",
            "Figure 11: Daily demand at distributors vs. manufacturer backlog (increased contact rate scenario).",
            "Figure 2: Comparisons of the active cases between the SIR model and actual in Massachusetts (MA)",
            "Figure 3: Macroscale view of the OC supply chain in this study.",
            "Figure 4: Comparison of infectious values per state between the baseline and increased contact rate scenarios.",
            "Figure 5: OC orders in AZ in the baseline experiment over time in days (x-axis).",
            "Figure 6: OC orders in AZ in the increased contact rate experiment over time in days (x-axis).",
            "Figure 7: OC availability in CA in the baseline experiment over time in days (x-axis).",
            "Figure 8: OC availability in CA in the increased OC usage rate experiment over time in days (x-axis).",
            "Table 1: SIR Model Parameter Details in the Baseline Scenario",
            "Table 2: Fulfillment time summary of customer and distributor replenishment orders."
        ],
        "imgs": [
            "$2305.00086v2-Figure1-1.png",
            "$2305.00086v2-Figure10-1.png",
            "$2305.00086v2-Figure11-1.png",
            "$2305.00086v2-Figure2-1.png",
            "$2305.00086v2-Figure3-1.png",
            "$2305.00086v2-Figure4-1.png",
            "$2305.00086v2-Figure5-1.png",
            "$2305.00086v2-Figure6-1.png",
            "$2305.00086v2-Figure7-1.png",
            "$2305.00086v2-Figure8-1.png",
            "$2305.00086v2-Table1-1.png",
            "$2305.00086v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00088",
        "abstract": "  Magnetic resonance imaging (MRI) is widely employed for diagnostic tests in\nneurology. However, the utility of MRI is largely limited by its long\nacquisition time. Acquiring fewer k-space data in a sparse manner is a\npotential solution to reducing the acquisition time, but it can lead to severe\naliasing reconstruction artifacts. In this paper, we present a novel\nDual-Domain Cross-Iteration Squeeze and Excitation Network (DD-CISENet) for\naccelerated sparse MRI reconstruction. The information of k-spaces and MRI\nimages can be iteratively fused and maintained using the Cross-Iteration\nResidual connection (CIR) structures. This study included 720 multi-coil brain\nMRI cases adopted from the open-source fastMRI Dataset. Results showed that the\naverage reconstruction error by DD-CISENet was 2.28 $\\pm$ 0.57%, which\noutperformed existing deep learning methods including image-domain prediction\n(6.03 $\\pm$ 1.31, p < 0.001), k-space synthesis (6.12 $\\pm$ 1.66, p < 0.001),\nand dual-domain feature fusion approaches (4.05 $\\pm$ 0.88, p < 0.001).\n",
        "title": "DD-CISENet: Dual-Domain Cross-Iteration Squeeze and Excitation Network\n  for Accelerated MRI Reconstruction",
        "texts": [
            "Figure 1: The architecture of DD-CISENet. I-Net or K-Net modules are end-to-end connected for dual-domain feature fusion. Cross-Iteration Residual (CIR) connections enable the retention of image or k-space features across iterations.",
            "Figure 2: Visualizations of the reconstructed MRI images using predicted k-space. Difference maps are placed at the bottom side for comparison.",
            "Table 1: Quantification of the generated k-space data and reconstructed images."
        ],
        "imgs": [
            "$2305.00088v1-Figure1-1.png",
            "$2305.00088v1-Figure2-1.png",
            "$2305.00088v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00089",
        "abstract": "  We introduce and analyse a simple probabilistic model of article production\nand citation behavior that explicitly assumes that there is no decline in\ncitability of a given article over time. It makes predictions about the number\nand age of items appearing in the reference list of an article. The latter\ntopics have been studied before, but only in the context of data, and to our\nknowledge no models have been presented. We then perform large-scale analyses\nof reference list length for a variety of academic disciplines. The results\nshow that our simple model cannot be rejected, and indeed fits the aggregated\ndata on reference lists rather well. Over the last few decades, the\nrelationship between total publications and mean reference list length is\nlinear to a high level of accuracy. Although our model is clearly an\noversimplification, it will likely prove useful for further modeling of the\nscholarly literature. Finally, we connect our work to the large literature on\n\"aging\" or \"obsolescence\" of scholarly publications, and argue that the\nimportance of that area of research is no longer clear, while much of the\nexisting literature is confused and confusing.\n",
        "title": "A model for reference list length of scholarly articles",
        "texts": [
            "Figure 1. Relationships between t, P (t) and L(t).",
            "Figure 3. Linear relationship between P (t) and L(t) from dataset of [2], 1985–2004.",
            "Figure 5. Binomial fitting of mean reference list length of documents published in 2016.",
            "Figure 6. Median reference list length, by year",
            "Figure 7. Linear relationship between P (t) and L(t) (Median).",
            "Table 2. Fit of linear model for L(t) versus P (t) from dataset of [2], 1985–2004.",
            "Table 3. Predictions versus sample statistics for age of references conditional on article being published in 2016 and references being published no earlier than 2006.",
            "Table 4. Fit of linear model for L(t) versus P (t) - Median"
        ],
        "imgs": [
            "$2305.00089v1-Figure1-1.png",
            "$2305.00089v1-Figure3-1.png",
            "$2305.00089v1-Figure5-1.png",
            "$2305.00089v1-Figure6-1.png",
            "$2305.00089v1-Figure7-1.png",
            "$2305.00089v1-Table2-1.png",
            "$2305.00089v1-Table3-1.png",
            "$2305.00089v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00091",
        "abstract": "  The NEPv approach has been increasingly used lately for optimization on the\nStiefel manifold arising from machine learning. General speaking, the approach\nfirst turns the first order optimality condition, also known as the KKT\ncondition, into a nonlinear eigenvalue problem with eigenvector dependency\n(NEPv) or a nonlinear polar decomposition with orthogonal factor dependency\n(NPDo) and then solve the nonlinear problem via some variations of the\nself-consistent-field (SCF) iteration. The difficulty, however, lies in\ndesigning a proper SCF iteration so that a maximizer is found at the end.\nCurrently, each use of the approach is very much individualized, especially in\nits convergence analysis to show that the approach does work or otherwise. In\nthis paper, a unifying framework is established. The framework is built upon\nsome basic assumptions. If the basic assumptions are satisfied, globally\nconvergence is guaranteed to a stationary point and during the SCF iterative\nprocess that leads to the stationary point, the objective function increases\nmonotonically. Also a notion of atomic functions is proposed, which include\ncommonly used matrix traces of linear and quadratic forms as special ones. It\nis shown that the basic assumptions are satisfied by atomic functions and by\nconvex compositions of atomic functions. Together they provide a large\ncollection of objectives for which the NEPv/NPDo approach is guaranteed to\nwork.\n",
        "title": "A Theory of the NEPv Approach for Optimization On the Stiefel Manifold",
        "texts": [
            "Table 1: Objective functions in the literature",
            "Table 2: The NPDo Ansatz on objective functions in Table 1",
            "Table 3: Condition on φi and choice of Qi at Line 4 of Algorithm 3.1",
            "Table 4: The NEPv Ansatz on objective functions in Table 1"
        ],
        "imgs": [
            "$2305.00091v1-Table1-1.png",
            "$2305.00091v1-Table2-1.png",
            "$2305.00091v1-Table3-1.png",
            "$2305.00091v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00092",
        "abstract": "  Differentiable simulation enables gradients to be back-propagated through\nphysics simulations. In this way, one can learn the dynamics and properties of\na physics system by gradient-based optimization or embed the whole\ndifferentiable simulation as a layer in a deep learning model for downstream\ntasks, such as planning and control. However, differentiable simulation at its\ncurrent stage is not perfect and might provide wrong gradients that deteriorate\nits performance in learning tasks. In this paper, we study differentiable\nrigid-body simulation with contacts. We find that existing differentiable\nsimulation methods provide inaccurate gradients when the contact normal\ndirection is not fixed - a general situation when the contacts are between two\nmoving objects. We propose to improve gradient computation by continuous\ncollision detection and leverage the time-of-impact (TOI) to calculate the\npost-collision velocities. We demonstrate our proposed method, referred to as\nTOI-Velocity, on two optimal control problems. We show that with TOI-Velocity,\nwe are able to learn an optimal control sequence that matches the analytical\nsolution, while without TOI-Velocity, existing differentiable simulation\nmethods fail to do so.\n",
        "title": "Improving Gradient Computation for Differentiable Physics Simulation\n  with Contacts",
        "texts": [
            "Figure 10: Multiple-collision: learning curves of different existing differentiable simulation methods. Left: Methods based on velocity impulses. Right: Compliant models and PBD.",
            "Figure 13: Multiple-collision: learned control of our proposed method.",
            "Figure 3: Motivating problem: Learning curve initialized from the analytical optimal solution.",
            "Figure 4: (a) ball positions in iteration i ; (b) ball positions in iteration i+1 ; (c) Difference between penetration direction n̂ and collision direction n̄ in an arbitrary iteration.",
            "Figure 5: Single-collision: learning curves of different existing differentiable simulation methods. Left: Methods based on velocity impulses. Right: Compliant models and PBD.",
            "Figure 6: Single-collision: learned control from existing differentiable simulation methods.",
            "Figure 9: Multiple-collision: (a) Trajectory before optimization; (b) Analytical optimal trajectory."
        ],
        "imgs": [
            "$2305.00092v1-Figure10-1.png",
            "$2305.00092v1-Figure13-1.png",
            "$2305.00092v1-Figure3-1.png",
            "$2305.00092v1-Figure4-1.png",
            "$2305.00092v1-Figure5-1.png",
            "$2305.00092v1-Figure6-1.png",
            "$2305.00092v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00094",
        "abstract": "  Predicting the evolution of systems that exhibit spatio-temporal dynamics in\nresponse to external stimuli is a key enabling technology fostering scientific\ninnovation. Traditional equations-based approaches leverage first principles to\nyield predictions through the numerical approximation of high-dimensional\nsystems of differential equations, thus calling for large-scale parallel\ncomputing platforms and requiring large computational costs. Data-driven\napproaches, instead, enable the description of systems evolution in\nlow-dimensional latent spaces, by leveraging dimensionality reduction and deep\nlearning algorithms. We propose a novel architecture, named Latent Dynamics\nNetwork (LDNet), which is able to discover low-dimensional intrinsic dynamics\nof possibly non-Markovian dynamical systems, thus predicting the time evolution\nof space-dependent fields in response to external inputs. Unlike popular\napproaches, in which the latent representation of the solution manifold is\nlearned by means of auto-encoders that map a high-dimensional discretization of\nthe system state into itself, LDNets automatically discover a low-dimensional\nmanifold while learning the latent dynamics, without ever operating in the\nhigh-dimensional space. Furthermore, LDNets are meshless algorithms that do not\nreconstruct the output on a predetermined grid of points, but rather at any\npoint of the domain, thus enabling weight-sharing across query-points. These\nfeatures make LDNets lightweight and easy-to-train, with excellent accuracy and\ngeneralization properties, even in time-extrapolation regimes. We validate our\nmethod on several test cases and we show that, for a challenging\nhighly-nonlinear problem, LDNets outperform state-of-the-art methods in terms\nof accuracy (normalized error 5 times smaller), by employing a dramatically\nsmaller number of trainable parameters (more than 10 times fewer).\n",
        "title": "Latent Dynamics Networks (LDNets): learning the intrinsic dynamics of\n  spatio-temporal processes",
        "texts": [
            "Figure 1: LDNet architecture. The network NN dyn receives the input u(t) and the latent state s(t) and returns the time derivative of the latent state, thus defining its dynamics. The network NN rec, instead, is evaluated only when an estimate of the output field y is sought. More precisely, an approximation of y(x, t) is recovered by giving as an input to NN rec the latent state at time t and the query space coordinate x ∈ Ω. In general, the reconstruction network NN rec might take as an input u(t) as well (see e.g. Sec. 3, Test Case 2); for simplicity, in the figure we represent the special case when NN rec does not depend on u(t).",
            "Figure 10: We compare the results obtained with the POD-DEIM method, for an increasing number of considered modes (reported in the titles), against the results obtained with our proposed method. The figure shows the predictions obtained for a sample belonging to the test dataset. The left-most column reports the FOM solution of the AP model (the abscissa denotes time, the ordinate denotes space). (a) the space-time solution; (b) the space-time error with respect to the FOM solution; (c)-(d)-(e) three snapshots of the space-dependent output field at t = 250, 300 and 350, in which we compare the predicted solution (red solid line) with the FOM solution (black dashed line).",
            "Figure 11: We compare the results obtained with the POD-DEIM method, for an increasing number of considered modes, against the results obtained with our proposed method. Specifically, we report boxplots of the distribution of the testing (blue) and training (light blue) errors obtained with each method. The red diamonds represent the average error on each dataset.",
            "Figure 2: Test Case 1b. 100 testing samples, comparing the reference outputs y (left) with the LDNet predictions ỹ (right). For each sample, the horizontal axis refers to space, and the vertical axis refers to time.",
            "Figure 3: Results of Test Case 1. (a)-(b): Testing accuracy of Test Case 1b, as a function of the number of training samples (with ∆t = 0.05) and of ∆t (with 100 training samples). For each setting we run 5 training runs with random weights initialization. Each dot corresponds to a training run, while the solid line is the geometric mean. (c): FOM against LDNet predictions on 8 testing samples for Test Case 1b. The abscissa corresponds to space and the ordinate to time. (d): Mapping from the latent space trajectories and the Fourier space coefficients of the FOM solution for the testing samples of Test Case 1b. (e): Testing accuracy of Test Case 1c as a function of the number of latent states and of the maximum input frequency fmax. (f): FOM against LDNet predictions on 2 testing samples for Test Case 1c, obtained by employing 5 latent states, for different maximum input frequencies (reported above the figure).",
            "Figure 4: Test Case 1b. Trajectories in the latent space (s1, s2) of 24 testing samples obtained with four different LDNets, by starting from as many different initial guesses for the trainable parameters (each of them corresponding to different columns). In the first (respectively, second) row, each point in the latent space is colored according to the corresponding value of Re(ẑ(0.5)) (respectively, Im(ẑ(0.5))).",
            "Figure 5: Test Case 1c. 80 testing samples for each fmax value considered in this work (namely 0.5, 1 and 2), comparing the reference outputs y (left) with the LDNet predictions ỹ (right), for ds = 5. For each sample, the horizontal axis refers to space, and the vertical axis refers to time.",
            "Figure 6: Test Case 2. (a): Computational domain and equations of the FOM. (b): Error metrics (NRMSE and Pearson dissimilarity) of LDNets for different number of latent variables (1, 5 and 10). The training dataset consists of 80 simulations with T = 20, while the test dataset comprises 200 simulations with T = 40. The blue lines refer to the testing error obtained in the interval t ∈ [0, 20] (that is the same interval seen during training), while orange lines refer to the testing error in the interval t ∈ [0, 40]. (c): A snapshot of the velocity field within the interval t ∈ [0, 20] (interpolation interval) of a testing sample. (d): A snapshot of the velocity field within the interval t ∈ [20, 40] (extrapolation interval) of a testing sample.",
            "Figure 7: Test Case 2. (a): Streamlines of the velocity field v for one testing sample over time (t ∈ [0, 40]). Horizontal and vertical axis refer to space in the domain Ω = (0, 1)2. For each subplot, the left one represents the FOM while the right one represents the LDNet approximation for ds = 10. (b): Input signal u(t) over time applied to the top portion of the boundary Γtop.",
            "Figure 8: Test Case 3: Methods comparison. We compare the results obtained with different methods for a sample belonging to the test dataset. The left-most column reports the FOM solution of the AP model (the abscissa denotes time, the ordinate denotes space). For each method we report: (a) the space-time solution; (b) the space-time error with respect to the FOM solution; (c) the time-evolution of the 12 latent variables; (d)-(e)-(f) three snapshots of the space-dependent output field at t = 250, 300 and 350, in which we compare the predicted solution (red solid line) with the FOM solution (black dashed line).",
            "Figure 9: Results of Test Case 3. (a): Boxplots of the distribution of the testing (blue) and training (light blue) errors obtained with each method. The red diamonds represent the average error on each dataset. (b): Number of trainable parameters of each method. The bin encoder is present only for auto-encoderbased methods, but not for LDNets. The bin dynamics refers to the NN that evolves the latent states. The POD-DEIM method is not included, as it does not envisage a training stage.",
            "Table 2: Test Case 1a: training and test accuracy metrics for LDNets trained with an increasing number of BFGS training epochs (500, 5000 and 50000). Training time refer to a single-CPU standard laptop.",
            "Table 4: Test Case 2: test accuracy metrics for LDNets trained with an increasing number of latent states (1, 5 and 10).",
            "Table 5: Test Case 3: hyperparameters ranges and selected values for the AE/ODE and AE/LSTM models. For the encoder (respectively, the decoder) the number of neurons refers to the first (respectively, last) hidden layer. In the other layers, the number of neurons is linearly varied to connect the first (respectively, last) hidden layer to the layer of latent variables.",
            "Table 6: Test Case 3: hyperparameters ranges and selected values for the LDNet.",
            "Table 7: Test Case 3: Training and testing errors obtained with the different methods and number of trainable parameters."
        ],
        "imgs": [
            "$2305.00094v1-Figure1-1.png",
            "$2305.00094v1-Figure10-1.png",
            "$2305.00094v1-Figure11-1.png",
            "$2305.00094v1-Figure2-1.png",
            "$2305.00094v1-Figure3-1.png",
            "$2305.00094v1-Figure4-1.png",
            "$2305.00094v1-Figure5-1.png",
            "$2305.00094v1-Figure6-1.png",
            "$2305.00094v1-Figure7-1.png",
            "$2305.00094v1-Figure8-1.png",
            "$2305.00094v1-Figure9-1.png",
            "$2305.00094v1-Table2-1.png",
            "$2305.00094v1-Table4-1.png",
            "$2305.00094v1-Table5-1.png",
            "$2305.00094v1-Table6-1.png",
            "$2305.00094v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00095",
        "abstract": "  The quadratic convection term in the incompressible Navier-Stokes equations\nis considered as a non-linear forcing to the linear operator, and it is studied\nin the Fourier domain through the analysis of interactions between triadically\ncompatible wavenumber-frequency triplets. Interaction coefficients are proposed\nto quantify the contribution to the forcing by each pair of triplets and are\ncomputed using data from direct numerical simulations of a turbulent channel at\n$Re_{\\tau} \\approx 550$. The coefficients show the importance of interactions\ninvolving streamwise large scales. The regions of non-linear interactions\npermitted under the quasi-linear (QL) and generalized quasi-linear (GQL)\nassumptions are shown to be significant contributors to the forcing and\nincreasing the number of GQL-large scales is shown to monotonically increase\nthe total forcing captured, providing a possible reason for the success of QL\nand GQL simulations. The tools presented are expected to be useful for\nimproving modeling of the nonlinearity, especially in QL, GQL, and resolvent\nanalyses, and understanding the amplitude modulation mechanism relating\nlarge-scale fluctuations to the modulation of near-wall structures.\n",
        "title": "Spatio-temporal characterization of non-linear forcing in turbulence",
        "texts": [
            "Figure 1: Contour plots of streamwise power spectra as a function of :G , H, and the wavespeed 2 = l/:G . Figures (a)-(b) are the large scales with :G = 0.5, 1, and (c) is the small scale with :G = 20. The black dash lines are the 1D mean streamwise velocity profile and are also the critical layer locations.",
            "Figure 2: Heatmaps of the magnitude of the streamwise and temporal interaction coefficients with logarithmically-scaled colorbars. The inserts in (a,b) correspond to a",
            "Figure 3: The regions of triadic interactions included in QL/GQL in (a) tabular form and (b) graphical form for comparison with figure 2. The color for the table cells and figure are green for triadic interactions resolved in both QL and GQL; blue for additional triadic interactions included in GQL but not in QL; and red for triadic interactions modeled or neglected in both QL and GQL. Hashed cells in the table indicate prohibited interactions.",
            "Figure 4: Fraction of total DNS forcing captured by interactions obeying GQL assumptions for various values of Λ. Temporal averaging performed over 1024 (solid black line) and 32 time snapshots (red dashed line)."
        ],
        "imgs": [
            "$2305.00095v1-Figure1-1.png",
            "$2305.00095v1-Figure2-1.png",
            "$2305.00095v1-Figure3-1.png",
            "$2305.00095v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00097",
        "abstract": "  As a type of valuable intellectual property (IP), deep neural network (DNN)\nmodels have been protected by techniques like watermarking. However, such\npassive model protection cannot fully prevent model abuse. In this work, we\npropose an active model IP protection scheme, namely NNSplitter, which actively\nprotects the model by splitting it into two parts: the obfuscated model that\nperforms poorly due to weight obfuscation, and the model secrets consisting of\nthe indexes and original values of the obfuscated weights, which can only be\naccessed by authorized users with the support of the trusted execution\nenvironment. Experimental results demonstrate the effectiveness of NNSplitter,\ne.g., by only modifying 275 out of over 11 million (i.e., 0.002%) weights, the\naccuracy of the obfuscated ResNet-18 model on CIFAR-10 can drop to 10%.\nMoreover, NNSplitter is stealthy and resilient against norm clipping and\nfine-tuning attacks, making it an appealing solution for DNN model protection.\nThe code is available at: https://github.com/Tongzhou0101/NNSplitter.\n",
        "title": "NNSplitter: An Active Defense Solution for DNN Model via Automated\n  Weight Obfuscation",
        "texts": [
            "Figure 1. An overview of NNSplitter. (a) Offline model obfuscation: NNSplitter splits the pre-trained model into two parts once the reward is converged, i.e., the obfuscated model and the model secrets (including the indexes and the original weight values). (b) Online secured inference: an attacker can only extract the obfuscated model stored in the normal world, which exhibits poor performance. However, the original model accuracy can be preserved by integrating the model secrets stored in the secure world of the victim’s device.",
            "Figure 2. The obfuscated weights spread across all layers, illustrated in a VGG-11 model trained on CIFAR-10 as an example.",
            "Figure 4. Apply norm clipping to improve the accuracy of obfuscated models on CIFAR-10/100.",
            "Figure 5. Apply fine-tuning to improve the accuracy of obfuscated VGG-11 models on different datasets. For each ratio, the average (solid line) and the error band (shadow region) are taken from 5 trials, with baseline accuracy as comparisons (dotted line).",
            "Figure 6. The performance comparison between the obfuscated model generated by NNSplitter and obfuscating a single layer (either the first or the last layer). Figure (a) displays the accuracy of the obfuscated model, while (b) shows the improved accuracy achieved through fine-tuning.",
            "Table 2. The settings of mask hyper-parameters.",
            "Table 3. NNSplitter applied to multiple DNN models on three datasets. The number of obfuscated weights is the median value when the obfuscated (Obfu.) accuracy degraded to random guess (<11% for Fashion-MNIST/CIFAR-10, and <2% for CIFAR-100). The obfuscated accuracy of random is reported as mean±std with the same number of obfuscated weights.",
            "Table 4. The increment ratio of the obfuscated weights for BaseNNSplitter compared to NNSplitter when both cause the randomguessing accuracy.",
            "Table 5. Comparison of different obfuscation strategies."
        ],
        "imgs": [
            "$2305.00097v2-Figure1-1.png",
            "$2305.00097v2-Figure2-1.png",
            "$2305.00097v2-Figure4-1.png",
            "$2305.00097v2-Figure5-1.png",
            "$2305.00097v2-Figure6-1.png",
            "$2305.00097v2-Table2-1.png",
            "$2305.00097v2-Table3-1.png",
            "$2305.00097v2-Table4-1.png",
            "$2305.00097v2-Table5-1.png"
        ]
    },
    {
        "id": "2305.00100",
        "abstract": "  The immense computational cost of traditional numerical weather and climate\nmodels has sparked the development of machine learning (ML) based emulators.\nBecause ML methods benefit from long records of training data, it is common to\nuse datasets that are temporally subsampled relative to the time steps required\nfor the numerical integration of differential equations. Here, we investigate\nhow this often overlooked processing step affects the quality of an emulator's\npredictions. We implement two ML architectures from a class of methods called\nreservoir computing: (1) a form of Nonlinear Vector Autoregression (NVAR), and\n(2) an Echo State Network (ESN). Despite their simplicity, it is well\ndocumented that these architectures excel at predicting low dimensional chaotic\ndynamics. We are therefore motivated to test these architectures in an\nidealized setting of predicting high dimensional geophysical turbulence as\nrepresented by Surface Quasi-Geostrophic dynamics. In all cases, subsampling\nthe training data consistently leads to an increased bias at small spatial\nscales that resembles numerical diffusion. Interestingly, the NVAR architecture\nbecomes unstable when the temporal resolution is increased, indicating that the\npolynomial based interactions are insufficient at capturing the detailed\nnonlinearities of the turbulent flow. The ESN architecture is found to be more\nrobust, suggesting a benefit to the more expensive but more general structure.\nSpectral errors are reduced by including a penalty on the kinetic energy\ndensity spectrum during training, although the subsampling related errors\npersist. Future work is warranted to understand how the temporal resolution of\ntraining data affects other ML architectures.\n",
        "title": "Temporal Subsampling Diminishes Small Spatial Scales in Recurrent Neural\n  Network Emulators of Geophysical Turbulence",
        "texts": [
            "Figure 1. A sample prediction of sea surface temperatures in the Gulf of Mexico at 1/25◦",
            "Figure 11. Quantitative comparison of ESN predictions, showing NRMSE (left), KE NRMSE (middle), and KE relative error (right), exactly as in Figure 9, except here γ = 10−1 is fixed,",
            "Figure 13. The impact of doubling the hidden layer dimension from Nr = 6,000 to Nr = 12,000 on NRMSE (left), KE NRMSE (middle), and KE relative error (right). Increasing the hidden layer dimension is relatively proportional to reducing the temporal subsampling",
            "Figure 14. Subsampling related spectral errors persist even when the number of training samples is fixed. Here, the number of samples is fixed to 9.72× 104 for all cases, and yet the temporal subsampling related spectral errors remain. Here, γ = 10−1 and the solid gray line indicates the",
            "Figure 3. An illustration of the ESN architecture used, as it is applied to each local group",
            "Figure 4. One sample NVAR prediction from the test dataset for Nsub = 1, 4, 16; shown in the second, third, and fourth panels at a lead time of 4 hours. The corresponding truth is shown",
            "Figure 5. NRMSE (Equation (8); left) and KE density relative error (Equation (9); right)",
            "Figure 6. NRMSE computed using NVAR at various temporal resolutions (Nsub; columns) and with variable memory capacities (Nlag; colors). Decreasing the subsampling factor shows a similar effect as adding memory: error is at first reduced, but tends to produce more unstable",
            "Figure 7. Kinetic energy density relative error with Nsub = 16 at various timesteps (columns) and memory capacity (Nlag; colors). Increasing memory at first reduces error at all spatial scales, but later on the error propagates more readily into the large scale.",
            "Figure 8. One sample prediction from the test dataset, where each panel shows potential",
            "Figure 9. Quantitative comparison of ESN predictions at Nsub = 1 with macro-scale parameters chosen using different values of γ in Equation (12). NRMSE (Equation (10); left),"
        ],
        "imgs": [
            "$2305.00100v2-Figure1-1.png",
            "$2305.00100v2-Figure11-1.png",
            "$2305.00100v2-Figure13-1.png",
            "$2305.00100v2-Figure14-1.png",
            "$2305.00100v2-Figure3-1.png",
            "$2305.00100v2-Figure4-1.png",
            "$2305.00100v2-Figure5-1.png",
            "$2305.00100v2-Figure6-1.png",
            "$2305.00100v2-Figure7-1.png",
            "$2305.00100v2-Figure8-1.png",
            "$2305.00100v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00101",
        "abstract": "  We study the nature of the chiral symmetry restoration within the Yukawa\nmodel with spontaneous symmetry breaking. We work with scalar and fermion\nfields which are subject to the effects of a rotating system. In this work, we\nshow the derivation of the scalar field propagator in a rotating medium using\nthe Fock-Schwinger proper-time method. We compute analytically the effective\npotential in the high-temperature approximations, including the contribution of\nthe ring diagrams to account for the plasma screening properties. We study the\nchiral transition as we vary the angular velocity $\\Omega$, the boson\nself-coupling $\\lambda$ and the fermion-boson coupling $g$. We show that the\ncritical temperature for the restoration of chiral symmetry always starts with\ndecreasing behaviour, until it reaches a minimum and from there when increasing\n$\\Omega$, we observe $T_c$ increases monotonically. In all the phase transition\nlines in the $T-\\Omega$ plane reported, we obtain that the rotating effects are\nable to change the order of the phase transition.\n",
        "title": "Chiral symmetry restoration in a rotating medium",
        "texts": [
            "FIG. 1. Tree-level potential V tree and vacuum effective potential V vac are shown, in order to compare the position and curvature of minimum in both cases. We use λ = 0.5 and g = 0.4 and for V vac, two different values of the renormalization scale are used, µ = 1 and 10 GeV.",
            "FIG. 5. Critical temperature Tc as a function of Ω, using λ = 1, g = 0.4, 0.6 and 0.8. The vertical grey band highlights the region where first order phase transition is found. Outside of the highlighted region the phase transition is of second order."
        ],
        "imgs": [
            "$2305.00101v2-Figure1-1.png",
            "$2305.00101v2-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00102",
        "abstract": "  Motivated by a problem in graph theory, this article introduces an algebra\ncalled the balanced algebra. This algebra is defined by generators and\nrelations, and the main goal is to find a minimal set of relations for it.\n",
        "title": "Minimal relations for the balanced algebra",
        "texts": [
            "Figure 1: The cube graph Q3.",
            "Figure 10: Illustration of the swaps in the proof of Lemma 5.1, for p = 2 and q = 1. First LR is moved past Q1, then the Q1 is moved past both P2 and P1 (this is where induction is used), and finally LR is moved back to the center.",
            "Figure 11: Illustration of UD = (RRRLLRLL)(LLRLRLRR). The dashed line represents elevation zero. Elevation is positive inside U , negative inside D, and zero for exactly three indices; the zero elevation locations are marked with a black dot.",
            "Figure 12: An example of Lemma 6.3. The black circles indicate the locations i = 3 and j = 5, and the horizontal lines the elevations e3(W ) = 3 and e5(W ) = 1. Graphically, the statement of the lemma says that it is possible to draw a horizontal line between the two given horizontal lines which intersects the graph both left from i and right from j; here the line can be drawn at elevation 1 or 2.",
            "Figure 13: Illustration of Proposition 6.4 (i) =⇒ (ii), with the example word RRRRRLLLLRRLLL which has a subword RL4R. In this example i = 4 and j = 10, and the subword RL4R is drawn in bold. The black circles indicate the locations i′ = 3 and j′ = 11, which are the starting and ending points for UD = (RRLL)(LLRR). (Note that the choices e = 2, i′ = 2, and j′ = 10 would be valid as well.)",
            "Figure 14: Illustration on how the elevation multiset of the word W = LL(RL)3R(RL)2R(RL)RRLL can be written as in Lemma 6.5. For this word, a = b = 2, m = 4, and (k1, k2, k3, k4) = (3, 2, 1, 0). The three different parts of E(W ) are separated with vertical dashed lines. The horizontal dashed lines illustrate how the elevations i− 2 for 1 ≤ i ≤ 3 appear ki + 1+ ki+1 times: first ki times “at the peaks” of (RL)ki (black dots), then once more and finally ki+1 times “after the peaks” of (RL)ki+1 (white circles). Note that there are no white circles along elevation 1 (topmost horizontal line), because k4 = 0.",
            "Figure 17: Illustration on how the words of the equivalence class are related by swaps. There is an edge (directed or undirected) between words if and only if the words are related by a swap. The directed edges indicate the swaps that occur when the reduction algorithm is applied.",
            "Figure 2: The graph Q3 with base vertex α. The dashed lines are used to separate the subconstituents.",
            "Figure 3: The word RRLRLL. An ascending line segment represents the letter R and a descending line segment represents the letter L. (Words are drawn from left to right.) As the word is balanced, the word begins and ends at the same vertical level; in this picture, a dashed line is drawn at that level.",
            "Figure 4: The words RRLLRL and RLRRLL can be obtained from each other by switching the places of the “peak” RL and “valley” LR. The higher dashed line indicates the level where the product of these words starts and ends. Alternatively, they can be obtained from each other by switching the places of the “high peak” RRLL and the “low peak” RL. The lower dashed line indicates the level where the product of these words starts and ends.",
            "Figure 5: Illustration of the word RRLLRLRLLLRLRR = (RRLL)(RL)(RL)(LLRLRR). Each prime in the product starts and ends at the dotted line.",
            "Figure 6: Illustration of the word W = RRRLLRLLLLRRRL. The dashed lines indicate the different elevations.",
            "Figure 7: The two words are related by a swap of type (RL,LR). The dashed line is at elevation 2, where the subword (RL)(LR) (in the first word) and (LR)(RL) (in the second word) begins and ends.",
            "Figure 8: Illustration of the upper prime RRLRRLRRLLLL, and the lower prime LLRLRLRLRR.",
            "Figure 9: Visualization of the upper prime P = RRLRRLLL, and how it can be written as RZL, where Z = (RL)(RRLL). The words RL and RRLL are upper primes."
        ],
        "imgs": [
            "$2305.00102v1-Figure1-1.png",
            "$2305.00102v1-Figure10-1.png",
            "$2305.00102v1-Figure11-1.png",
            "$2305.00102v1-Figure12-1.png",
            "$2305.00102v1-Figure13-1.png",
            "$2305.00102v1-Figure14-1.png",
            "$2305.00102v1-Figure17-1.png",
            "$2305.00102v1-Figure2-1.png",
            "$2305.00102v1-Figure3-1.png",
            "$2305.00102v1-Figure4-1.png",
            "$2305.00102v1-Figure5-1.png",
            "$2305.00102v1-Figure6-1.png",
            "$2305.00102v1-Figure7-1.png",
            "$2305.00102v1-Figure8-1.png",
            "$2305.00102v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00103",
        "abstract": "  In this paper, we prove the existence of two positive $T$-periodic solutions\nof an electrostatic actuator modeled by the time-delayed Duffing equation\n$$\\ddot{x}(t)+f_{D}(x(t),\\dot{x}(t))+ x(t)=1- \\dfrac{e\n\\mathcal{V}^{2}(t,x(t),x_{d}(t),\\dot{x}(t),\\dot{x}_{d}(t))}{x^2(t)}, \\qquad\nx(t)\\in\\,]0,\\infty[ $$ where $x_{d}(t)=x(t-d)$ and\n$\\dot{x}_{d}(t)=\\dot{x}(t-d),$ denote position and velocity feedback\nrespectively, and $$\n\\mathcal{V}(t,x(t),x_{d}(t),\\dot{x}(t),\\dot{x}_{d}(t))=V(t)+g_{1}(x(t)-x_{d}(t))+g_{2}(\\dot{x}(t)-\\dot{x}_{d}(t)),$$\nis the feedback voltage with positive input voltage $V(t)\\in\nC(\\mathbb{R}/T\\mathbb{Z})$ for $e\\in \\mathbb{R}^{+}, g_{1},g_{2}\\in\n\\mathbb{R}$, $d\\in [0,T[$. The damping force $f_{D}(x,\\dot{x})$ can be linear,\ni.e., $f_{D}(x,\\dot{x}) = c\\dot{x}$, $c\\in\\mathbb{R}^+$ or squeeze film type,\ni.e., $f_{D}(x,\\dot{x}) = \\gamma\\dot{x}/x^{3}$, $\\gamma\\in\\mathbb{R}^+$. The\nfundamental tool to prove our result is a local continuation method of periodic\nsolutions from the non-delayed case $(d=0)$. Our approach provides new insights\ninto the delay phenomenon on microelectromechanical systems and can be used to\nstudy the dynamics of a large class of delayed Li\\'enard equations that govern\nthe motion of several actuators, including the comb-drive finger actuator and\nthe torsional actuator. Some numerical examples are provided to illustrate our\nresults.\n",
        "title": "Periodic oscillations in electrostatic actuators under time delayed\n  feedback controller",
        "texts": [
            "Figure 1. Schematic diagram of a parallel plate capacitor with one movable plate, under electrostatic, restoring and damping forces.",
            "Figure 10. Phase portrait for two solutions of equation (7) with delay d = 80 and positive gain at the velocity G2 = 40. The asymptotically stable periodic trajectory persists under the influence of these constants.",
            "Figure 11. Phase portrait for two solutions of equation (7) with delay d = 1 and negative gain at the velocity G2 = −8. The asymptotically stable periodic trajectory persists under the influence of these constants.",
            "Figure 5. With gain G1 = 0 and fixed delay on speed, there is a positive gain value of G2 for which the system changes from having an asymptotically stable equilibrium point to one for which only stability can be assured.",
            "Figure 8. Behavior of two solutions of equation (5) for gain G1 = 0 and fixed delay d = 300 on speed. In the graph at the top it is observed the case G2 = −100 and in the graph at the bottom it is observed the case G2 = −123.",
            "Figure 9. Phase portrait for two solutions of equation (7) without delay. The asymptotically stable periodic trajectory established in Theorem 10 holds.",
            "Table 1. Values of the parameters for equation (27).",
            "Table 2. Values of the dimensionless parameters for equation (5) based on the data in Table 1."
        ],
        "imgs": [
            "$2305.00103v2-Figure1-1.png",
            "$2305.00103v2-Figure10-1.png",
            "$2305.00103v2-Figure11-1.png",
            "$2305.00103v2-Figure5-1.png",
            "$2305.00103v2-Figure8-1.png",
            "$2305.00103v2-Figure9-1.png",
            "$2305.00103v2-Table1-1.png",
            "$2305.00103v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00104",
        "abstract": "  We present Multiscale Multiview Vision Transformers (MMViT), which introduces\nmultiscale feature maps and multiview encodings to transformer models. Our\nmodel encodes different views of the input signal and builds several\nchannel-resolution feature stages to process the multiple views of the input at\ndifferent resolutions in parallel. At each scale stage, we use a\ncross-attention block to fuse information across different views. This enables\nthe MMViT model to acquire complex high-dimensional representations of the\ninput at different resolutions. The proposed model can serve as a backbone\nmodel in multiple domains. We demonstrate the effectiveness of MMViT on audio\nand image classification tasks, achieving state-of-the-art results.\n",
        "title": "MMViT: Multiscale Multiview Vision Transformers",
        "texts": [
            "Figure 1: An overview of the 16-block MMViT model. The input spectrogram is first patchified into two views with different resolutions. Both views are then encoded with a learnable spatio-temporal positional encoding layer. The embedded features pass through four scale stages, each with multiple transformer blocks. The second-to-last block of each stage except the last stage is used to fuses the information from both views using cross-attention, while the last block uses scaled self-attention to reduce spatio-temporal resolution and increase feature channels. The other blocks use regular self-attention.",
            "Figure 2: MMViT blocks structure for a) cross attention block which fuses information between two views at the same stage; b) self-attention layer for two views with multi-head pooling attention equivalent to a MViT block [13].",
            "Table 1: Audio classification results.",
            "Table 2: Image Classification results."
        ],
        "imgs": [
            "$2305.00104v1-Figure1-1.png",
            "$2305.00104v1-Figure2-1.png",
            "$2305.00104v1-Table1-1.png",
            "$2305.00104v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00105",
        "abstract": "  Hydraulic stimulation is a critical process for increasing the permeability\nof fractured geothermal reservoirs. This technique relies on coupled\nhydromechanical processes induced by reservoir stimulation through pressurized\nfluid injection into the rock formation. The injection of fluids causes\nporomechanical stress changes that can lead to the dilation of fractures due to\nfracture slip and to tensile fracture opening and propagation, so-called\nmixed-mechanism stimulation. The effective permeability of the rock is\nparticularly enhanced when new fractures connect with pre-existing fractures.\nMixed-mechanism stimulation can significantly improve the productivity of\ngeothermal reservoirs, and the technique is especially important in reservoirs\nwhere the natural permeability of the rock is insufficient to allow for\ncommercial flow rates. This paper presents a modeling approach for simulating\nthe deformation and expansion of fracture networks in porous media under the\ninfluence of anisotropic stress and fluid injection. It utilizes a coupled\nhydromechanical model for poroelastic, fractured media. Fractures are governed\nby contact mechanics and allowed to grow and connect through a fracture\npropagation model. To conduct numerical simulations, we employ a twolevel\napproach, combining a finite volume method for poroelasticity with a finite\nelement method for fracture propagation. The study investigates the impact of\ninjection rate, matrix permeability, and stress anisotropy on stimulation\noutcomes. By analyzing these factors, we can better understand the behavior of\nfractured geothermal reservoirs under mixedmechanism stimulation.\n",
        "title": "Modeling of mixed-mechanism stimulation for the enhancement of\n  geothermal reservoirs",
        "texts": [
            "Figure 1. Illustration of a host medium 𝛺𝑀, fractures 𝛺𝐹, intersection 𝛺𝐼, and interfaces between higher- and lower-dimensional domains, denoted by 𝛤 and 𝛬, respectively. In the detailed images to the right of the general figure on the left, the different domains and interfaces are separated for illustration purposes.",
            "Figure 10. Effect of fluid injection rate on pressure at the injection point and total fracture growth.",
            "Figure 13. Fracture propagation and pressure evolution in a 2D porous medium during fluid injection, 𝑄0 = 2 × 10−7 𝑚2 𝑠⁄ , into a pre-existing fracture. The solid white lines indicate open fractures, while the solid red lines indicate closed fractures. The color bar represents pore pressure in MPa.",
            "Figure 2. Illustration of projection operators between subdomains.",
            "Figure 3. Illustration of a fracture, ΩF, and a fine-level domain 𝜔, adapted from Hau et al. (2022).10",
            "Figure 4. The T-type intersection between fractures or a fracture and boundary. The fracture is widened for illustration purposes.",
            "Figure 5. The geometry of model 1.",
            "Figure 6. Fracture propagation and pressure evolution in a 2D porous media during fluid injection at rate 𝑄0 = 1 × 10−7 𝑚2 𝑠⁄ into a pre-existing fracture. The solid white lines indicate opening fractures, while the solid red lines indicate closed fractures. The color bar represents pore pressure in MPa.",
            "Figure 7. The geometry of model 2.",
            "Figure 9. The geometry of model 3.",
            "Table 1. The parameters used in the governing equations."
        ],
        "imgs": [
            "$2305.00105v1-Figure1-1.png",
            "$2305.00105v1-Figure10-1.png",
            "$2305.00105v1-Figure13-1.png",
            "$2305.00105v1-Figure2-1.png",
            "$2305.00105v1-Figure3-1.png",
            "$2305.00105v1-Figure4-1.png",
            "$2305.00105v1-Figure5-1.png",
            "$2305.00105v1-Figure6-1.png",
            "$2305.00105v1-Figure7-1.png",
            "$2305.00105v1-Figure9-1.png",
            "$2305.00105v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00108",
        "abstract": "  SkyPortal is an open-source software package designed to efficiently discover\ninteresting transients, manage follow-up, perform characterization, and\nvisualize the results. By enabling fast access to archival and catalog data,\ncross-matching heterogeneous data streams, and the triggering and monitoring of\non-demand observations for further characterization, a SkyPortal-based platform\nhas been operating at scale for 2 yr for the Zwicky Transient Facility Phase II\ncommunity, with hundreds of users, containing tens of millions of time-domain\nsources, interacting with dozens of telescopes, and enabling community\nreporting. While SkyPortal emphasizes rich user experiences (UX) across common\nfrontend workflows, recognizing that scientific inquiry is increasingly\nperformed programmatically, SkyPortal also surfaces an extensive and\nwell-documented API system. From backend and frontend software to data science\nanalysis tools and visualization frameworks, the SkyPortal design emphasizes\nthe re-use and leveraging of best-in-class approaches, with a strong\nextensibility ethos. For instance, SkyPortal now leverages ChatGPT\nlarge-language models (LLMs) to automatically generate and surface source-level\nhuman-readable summaries. With the imminent re-start of the next-generation of\ngravitational wave detectors, SkyPortal now also includes dedicated\nmulti-messenger features addressing the requirements of rapid multi-messenger\nfollow-up: multi-telescope management, team/group organizing interfaces, and\ncross-matching of multi-messenger data streams with time-domain optical\nsurveys, with interfaces sufficiently intuitive for the newcomers to the field.\n(abridged)\n",
        "title": "A data science platform to enable time-domain astronomy",
        "texts": [
            "Figure 1. Flowchart for the multi-messenger, technical ecosystem envisioned in this platform.",
            "Figure 10. Analysis section from the GCN event page of GRB221110A. The GBM region is uploaded after correcting for Earth occultation, which produces a cut on the shape of the original map. The sources detected in the region covered by ZTF are shown as red dots, with their names. The Sources menu allows for in-depth scanning of the candidates, showing cutouts of ZTF, and other surveys, as well as the photometry of the candidate. For this event, all the sources were unrelated to the GRB.",
            "Figure 2. An example of the multi-resolution HEALPix sampling scheme for tiling localizations. The left panel shows an example heat map image representing the localization probabilities; darker, deeper colors represent higher probability density. The middle panel shows the boundaries of the multi-resolution HEALPix tiles on which the sky map was sampled. The right panel shows potential telescope field of views covering that skymap with the skymap confidence level contours included.",
            "Figure 4. GCN Page - Analysis Section: here, users can visualize the localizations associated with an event, and query the sources, galaxies, instrument tiles (for a given allocation on an instrument), and observations contained in the different localizations, while restraining their searches based on several parameters: cumulative probability, number of detections, distance in Mpc, and first and last detection dates. Other features accessible in this section allow to query catalogs of candidates from different alert brokers, run simulations with simsurvey, and generate text-based summaries similar to GCN circulars with added version control. It is also possible to submit the executed observations to treasuremap.space (Wyatt et al. 2020). Side panels can be opened that contain the properties of the event and localizations, lightcurves, GCN notices and circulars, as well as a comment section for users to communicate their results.",
            "Figure 5. GCN Page - Observation planning: here, users select an allocation, the fields of the instrument of the allocation that overlap with a localization, as well as pick the parameters to use from the MMA API class of the instrument. Multiple observation plans can be created simultaneously and combined if necessary. Moreover, buttons allow users to download observability and airmass charts, as well as recompute airmass in real time to show which tiles of the skymap are observable. It is also possible to submit the proposed observations to treasuremap.space (Wyatt et al. 2020). Once created, all observation plans will be listed by instrument, where they can be updated, sent, or deleted to/from an instrument queue.",
            "Figure 8. Analysis posterior for a fit to ZTF22abykahf with the Type Ia supernova analysis service.",
            "Figure 9. Source page visualization of the AI-generated summary of using the ChatGPT 3.5 completion service on ZTF21abqhkjd (Yao et al. 2021)."
        ],
        "imgs": [
            "$2305.00108v2-Figure1-1.png",
            "$2305.00108v2-Figure10-1.png",
            "$2305.00108v2-Figure2-1.png",
            "$2305.00108v2-Figure4-1.png",
            "$2305.00108v2-Figure5-1.png",
            "$2305.00108v2-Figure8-1.png",
            "$2305.00108v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00109",
        "abstract": "  Segmentation in medical imaging is a critical component for the diagnosis,\nmonitoring, and treatment of various diseases and medical conditions.\nPresently, the medical segmentation landscape is dominated by numerous\nspecialized deep learning models, each fine-tuned for specific segmentation\ntasks and image modalities. The recently-introduced Segment Anything Model\n(SAM) employs the ViT neural architecture and harnesses a massive training\ndataset to segment nearly any object; however, its suitability to the medical\ndomain has not yet been investigated. In this study, we explore the zero-shot\nperformance of SAM in medical imaging by implementing eight distinct prompt\nstrategies across six datasets from four imaging modalities, including X-ray,\nultrasound, dermatoscopy, and colonoscopy. Our findings reveal that SAM's\nzero-shot performance is not only comparable to, but in certain cases,\nsurpasses the current state-of-the-art. Based on these results, we propose\npractical guidelines that require minimal interaction while consistently\nyielding robust outcomes across all assessed contexts. The source code, along\nwith a demonstration of the recommended guidelines, can be accessed at\nhttps://github.com/Malta-Lab/SAM-zero-shot-in-Medical-Imaging.\n",
        "title": "Zero-shot performance of the Segment Anything Model (SAM) in 2D medical\n  imaging: A comprehensive evaluation and practical guidelines",
        "texts": [
            "Fig. 1. Samples from each of the six datasets used in this study. A: ISIC, B: HAM, C: CXR, D: HJXR, E: CVC, F: BUSI.",
            "Fig. 10. Image from the ISIC dataset with bounding box and point inputs accompanied by SAM’s predictions. The point prompts guide the model to remove these areas. The 2nd prediction reached an adequate segmentation.",
            "Fig. 2. Example of all prompt strategies on a skin lesion image and mask. (A): original image, (B): CP, (C): RP, (D): RP3, (E): RP5, (F): BB in green, BBS5 in red, BBS10 in blue, and BBS20 in yellow. The size and position shown are their max variation for BBS methods.",
            "Fig. 3. Three returning predictions from SAM using RP5 (A, B, C) and BBS10 (D, E, F) input methods for the CXR dataset. A physician may choose the one that best fits the corresponding region to be segmented.",
            "Fig. 4. Comparison of using always the 1st, 2nd, or 3rd prediction versus choosing the best one per image (max) with the BB strategy for all datasets.",
            "Fig. 5. Example of inconsistencies within the ground-truth region in the CXR dataset.",
            "Fig. 6. Example of inconsistencies in the ground-truth region in the ISIC dataset.",
            "Fig. 7. Image from the BUSI dataset with bounding box input accompanied by SAM’s predictions. Both the 2nd and 3rd predictions exhibit accurate segmentation of the intended region.",
            "Fig. 8. Image from the CVC dataset with bounding box input accompanied by SAM’s predictions. Both the 2nd and 3rd predictions exhibit accurate segmentation of the intended region.",
            "Fig. 9. Image from the ISIC dataset with bounding box input accompanied by SAM’s predictions. None of them are adequate and require further prompt points.",
            "Table 1. Summary of SAM’s ViT architecture variations.",
            "Table 2. DSC of predictions for the ViT-H model for six datasets using the eight proposed prompt strategies considering the 1st, 2nd, and 3rd prediction.",
            "Table 3. DSC of predictions for all variations of SAM for six datasets using the eight proposed prompt strategies. For each set of predictions, only the one with the highest DSC was considered.",
            "Table 4. Comparison of the results of the BBS5 strategy using the ViT-L model with the current state-of-the-art DL models.",
            "Table 5: DSC of predictions for six datasets using the eight proposed prompt strategies for the three SAM ViT sizes."
        ],
        "imgs": [
            "$2305.00109v2-Figure1-1.png",
            "$2305.00109v2-Figure10-1.png",
            "$2305.00109v2-Figure2-1.png",
            "$2305.00109v2-Figure3-1.png",
            "$2305.00109v2-Figure4-1.png",
            "$2305.00109v2-Figure5-1.png",
            "$2305.00109v2-Figure6-1.png",
            "$2305.00109v2-Figure7-1.png",
            "$2305.00109v2-Figure8-1.png",
            "$2305.00109v2-Figure9-1.png",
            "$2305.00109v2-Table1-1.png",
            "$2305.00109v2-Table2-1.png",
            "$2305.00109v2-Table3-1.png",
            "$2305.00109v2-Table4-1.png",
            "$2305.00109v2-Table5-1.png"
        ]
    },
    {
        "id": "2305.00111",
        "abstract": "  Most existing sensor-based monitoring frameworks presume that a large\navailable labeled dataset is processed to train accurate detection models.\nHowever, in settings where personalization is necessary at deployment time to\nfine-tune the model, a person-specific dataset needs to be collected online by\ninteracting with the users. Optimizing the collection of labels in such phase\nis instrumental to impose a tolerable burden on the users while maximizing\npersonal improvement. In this paper, we consider a fine-grain stress detection\nproblem based on wearable sensors targeting everyday settings, and propose a\nnovel context-aware active learning strategy capable of jointly maximizing the\nmeaningfulness of the signal samples we request the user to label and the\nresponse rate. We develop a multilayered sensor-edge-cloud platform to\nperiodically capture physiological signals and process them in real-time, as\nwell as to collect labels and retrain the detection model. We collect a large\ndataset and show that the context-aware active learning technique we propose\nachieves a desirable detection performance using 88\\% and 32\\% fewer queries\nfrom users compared to a randomized strategy and a traditional active learning\nstrategy, respectively.\n",
        "title": "Active Reinforcement Learning for Personalized Stress Monitoring in\n  Everyday Settings",
        "texts": [
            "Figure 1: BPM for two subjects.",
            "Figure 3: Average processing pipeline time as a function of the number of users.",
            "Figure 5: Architecture of the proposed Deep Q-Network.",
            "Figure 6: After training, distribution of the state variables for the instances that are selected to be labeled (blue), and the instances that are not selected (gray). Vertical axis are the number count.",
            "Figure 7: Personalizing the model using different instance selection methods.",
            "Figure 8: Number of queries needed to reach a certain performance level during personalization.",
            "Figure 9: Response rate behavior for different query methods",
            "Table 1: Distribution of stress labels from different subjects.",
            "Table 2: Personalization for different number of subjective instances used. The metric is recall on the minority class.",
            "Table 3: Comparison of our study vs other studies",
            "Table 5: Average Recall (on class stressed) on the two classes, using leave-subject-out Cross-Validation method. Stress labels are five levels: not at all (0), a little bit (1), some (2), a lot (3), extremely (4) which are mapped to binary classes.",
            "Table 6: components of the state space"
        ],
        "imgs": [
            "$2305.00111v1-Figure1-1.png",
            "$2305.00111v1-Figure3-1.png",
            "$2305.00111v1-Figure5-1.png",
            "$2305.00111v1-Figure6-1.png",
            "$2305.00111v1-Figure7-1.png",
            "$2305.00111v1-Figure8-1.png",
            "$2305.00111v1-Figure9-1.png",
            "$2305.00111v1-Table1-1.png",
            "$2305.00111v1-Table2-1.png",
            "$2305.00111v1-Table3-1.png",
            "$2305.00111v1-Table5-1.png",
            "$2305.00111v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00112",
        "abstract": "  We present a study of a directional search for Dark Matter boosted forward\nwhen scattered by cosmic-ray nuclei, using a module of the NEWSdm experiment.\nThe boosted Dark Matter flux at the edge of the Earth's atmosphere is expected\nto be pointing to the Galactic Center, with a flux 15 to 20 times larger than\nin the transverse direction.\n  The module of the NEWSdm experiment consists of a 10 kg stack of Nano Imaging\nTrackers, i.e.~newly developed nuclear emulsions with AgBr crystal sizes down\nto a few tens of nanometers. The module is installed on an equatorial\ntelescope. The relatively long recoil tracks induced by boosted Dark Matter,\ncombined with the nanometric granularity of the emulsion, result in an\nextremely low background. This makes an installation at the INFN Gran Sasso\nlaboratory, both on the surface and underground, viable. A comparison between\nthe two locations is made. The angular distribution of nuclear recoils induced\nby boosted Dark Matter in the emulsion films at the surface laboratory is\nexpected to show an excess with a factor of 3.5 in the direction of the\nGalactic Center. This excess allows for a Dark Matter search with directional\nsensitivity. The surface laboratory configuration prevents the deterioration of\nthe signal in the rock overburden and it emerges as the most powerful approach\nfor a directional observation of boosted Dark Matter with high sensitivity. We\nshow that, with this approach, a 10 kg module of the NEWSdm experiment exposed\nfor one year at the Gran Sasso surface laboratory can probe Dark Matter masses\nbetween 1 keV/c$^2$ and 1 GeV/c$^2$ and cross-section values down to\n$10^{-30}$~cm$^2$ with a directional sensitive search.\n",
        "title": "Directional Sensitivity of the NEWSdm Experiment to Cosmic Ray Boosted\n  Dark Matter",
        "texts": [
            "Figure 1. Galactic Cosmic-Ray (by GALPROP v.57) and Dark-Matter (NFW) distributions in arbitrary units. The region within ±5 degrees from the direction of the Galactic Center is also shown. r denotes the distance from the Galactic Center in the galactic plane, z corresponds to the direction perpendicular to the Galactic plane.",
            "Figure 13. The directional signal evaluation scheme. The solid angle indicated by the blue marker corresponds to the Galactic Center direction, the yellow marker denotes an equal solid angle in the perpendicular direction.",
            "Figure 14. CNO nuclear-recoil angular distributions from boosted DM particles with mχ = 1 keV/c2 (left), mχ = 1 MeV/c2 (center) and mχ = 1 GeV/c2 (right) coming from GC to the perpendicular direction. Colored lines stand for selected angular distributions of the CNO recoils from DM with 0, 30, 60, 90 degree cone directions. Black histograms represent the total CNO angular distributions. σχp = 10−28 cm2.",
            "Figure 2. The averaging of boosted DM particle flux.",
            "Figure 3. CRDM spectra for σχp = 10−30 cm2 from Center, Anti Center of the Galaxy and from the Lateral direction. Three DM masses (1 keV/c2, 1 MeV/c2, 1 GeV/c2) are considered here as an example.",
            "Figure 5. Scatter plot of energy versus cos θ for C recoils at the surface level for σχp = 10−28 cm2. The numbers in the figures denote the amounts of DM particles crossing the observational surface level for the first time, provided that the number of DM particles starting from the top of the atmosphere is set to 105.",
            "Figure 6. Scatter plot of energy versus cos θ for C recoils at the underground level for σχp = 10−28 cm2. The numbers in the figures denote the amounts of DM particles crossing the observational underground level for the first time, provided that the number of DM particles starting from the top of the atmosphere is set to 105.",
            "Figure 7. C (left) and H(right) recoil track length R distributions at the surface level. For σχp = 10−28 cm2, mχ = 1 keV/c2, 1 MeV/c2, 1 GeV/c2 and for 105 DM at the edge of the atmosphere. The vertical lines indicate the limits on the track lengths of 70 and 1000 nm.",
            "Figure 8. Angular distributions of C recoil events in sr−1kg−1year−1 with track lengths > 70 nm at the surface and underground levels for mχ = 1 keV/c2, 1 MeV/c2 and 1 GeV/c2 as examples. Vertical lines denote the angular ranges [0, 30] — 2 and [60, 90] — 1."
        ],
        "imgs": [
            "$2305.00112v4-Figure1-1.png",
            "$2305.00112v4-Figure13-1.png",
            "$2305.00112v4-Figure14-1.png",
            "$2305.00112v4-Figure2-1.png",
            "$2305.00112v4-Figure3-1.png",
            "$2305.00112v4-Figure5-1.png",
            "$2305.00112v4-Figure6-1.png",
            "$2305.00112v4-Figure7-1.png",
            "$2305.00112v4-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00116",
        "abstract": "  This paper presents a new technique for the virtual reality (VR)\nvisu-alization of complex volume images obtained from computer tomography (CT)\nand Magnetic Resonance Imaging (MRI) by combining three-dimensional (3D) mesh\nprocessing and software coding within the gaming engine. The method operates on\nreal representations of human organs avoiding any structural ap-proximations of\nthe real physiological shape. In order to obtain realistic repre-sentation of\nthe mesh model, geometrical and topological corrections are per-formed on the\nmesh surface with preserving real shape and geometric structure. Using\nmathematical intervention on the 3D model and mesh triangulation the second\npart of our algorithm ensures an automatic construction of new two-dimensional\n(2D) shapes that represent vector slices along any user chosen di-rection. The\nfinal result of our algorithm is developed software application that allows to\nuser complete visual experience and perceptual exploration of real human organs\nthrough spatial manipulation of their 3D models. Thus our pro-posed method\nachieves a threefold effect: i) high definition VR representation of real\nmodels of human organs, ii) the real time generated slices of such a model\nalong any directions, and iii) almost unlimited amount of training data for\nmachine learning that is very useful in process of diagnosis. In addition, our\ndeveloped application also offers significant benefits to educational process\nby ensuring interactive features and quality perceptual user experience.\n",
        "title": "A New Technique of the Virtual Reality Visualization of Complex Volume\n  Images from the Computer Tomography and Magnetic Resonance Imaging",
        "texts": [
            "Fig. 1. VR visualization process flow",
            "Fig. 2. DICOM slice images of the heart across coronal, sagittal and transverse planes",
            "Fig. 3. 3D heart model: a) entire mesh, b) topological errors",
            "Fig. 4. The flow chart of our algorithm",
            "Fig. 5. Mesh face fj intersected by the plane α",
            "Fig. 6. 3D heart model: a) source model from CT scanner, b) refined and texturized VR model",
            "Fig. 7. Application preview: a) display when one of the annotation numbers is selected, b) display of the quiz mode",
            "Fig. 8. 2D shapes of the aorta 3D model obtained from: a) the standard transverse slicing plane; b) Our method - 300 rotated transverse slicing plane.",
            "Fig. 9. Our algorithm in action: renderings and slicing results (red lines)",
            "Table 1. The aorta mean diameter values (in mm)",
            "Table 2. Comparative results of the mesh slicing procces over different 3D models: DC – Coordinate of a slicing plane, T– The slicing computation time"
        ],
        "imgs": [
            "$2305.00116v1-Figure1-1.png",
            "$2305.00116v1-Figure2-1.png",
            "$2305.00116v1-Figure3-1.png",
            "$2305.00116v1-Figure4-1.png",
            "$2305.00116v1-Figure5-1.png",
            "$2305.00116v1-Figure6-1.png",
            "$2305.00116v1-Figure7-1.png",
            "$2305.00116v1-Figure8-1.png",
            "$2305.00116v1-Figure9-1.png",
            "$2305.00116v1-Table1-1.png",
            "$2305.00116v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00124",
        "abstract": "  Aerobreakup of drops is a fundamental two-phase flow problem that is\nessential to many spray applications. A parametric numerical study was\nperformed by varying the gas stream velocity, focusing on the regime of\nmoderate Weber numbers, in which the drop deforms to a forward bag. When the\nbag is unstable, it inflates and disintegrates into small droplets. Detailed\nnumerical simulations were conducted using the volume-of-fluid method on an\nadaptive octree mesh to investigate the aerobreakup dynamics. Grid-refinement\nstudies show that converged 3D simulation results for drop deformation and bag\nformation are achieved by the refinement level equivalent to 512 cells across\nthe initial drop diameter. To resolve the thin liquid sheet when the bag\ninflates, the mesh is further refined to 2048 cells across the initial drop\ndiameter. The simulation results for the drop length and radius were validated\nagainst previous experiments, and a good agreement was achieved. The\nhigh-resolution results of drop morphological evolution were used to identify\nthe different phases in the aerobreakup process, characterize the distinct flow\nfeatures and dominant mechanisms in each phase. In the early time, the drop\ndeformation and velocity are independent of the Weber number, and a new\ninternal-flow deformation model, which respects this asymptotic limit, has been\ndeveloped. The pressure and velocity fields around the drop were shown to\nbetter understand the internal flow and interfacial instability that dictate\nthe drop deformation. Finally, the impact of drop deformation on the drop\ndynamics was discussed.\n",
        "title": "Detailed numerical investigation of the drop aerobreakup in the bag\n  breakup regime",
        "texts": [
            "Figure 1. Schematics of the computational domains for (a) 2D-axisymmetric and (b) 3D simulations.",
            "Figure 10. (a) Comparison of Laplace pressure (Eq. (5.14)) with liquid inertia (Eq. (5.15)) and gas-pressure differences estimated by the VB (Eqs. (5.16)) and present models ((5.17)) as a function of We when the rim is formed. (b) Comparison of the drop lateral radius when the rim is formed, R̂∗, measured from the present simulation and the model prediction (Eq. (5.18)).",
            "Figure 11. Time evolutions of (a) the drop radius R̂, (b) the drop length L̂, (c) the rate of change of R̂, (d) the bag length Lfb, and (e) the bag sheet thickness along x axis, for different We.",
            "Figure 12. Temporal evolution of the y-velocity (uy) on the central x-y plane inside the drop for different We. The points C and D marked in (d) and (e) indicates the concave locations on the perturbed windward surface due to drop deformation. Different deformation phases for We = 12.0 are indicated in (c).",
            "Figure 14. Time evolutions of (a) sheet thickness ĥa and (b) bag length L̂fb for the cases We = 12.0 and 15.3. (c) L̂fb as a function of ĥa.",
            "Figure 15. Time evolution of the drop surface from t̂ = t/τd = 2.51-2.58 for We = 12.0, showing the breakupof the bag due to appearance and merging of holes. The color on the interfaces represents the velocity magnitude. The three different views are shown for each time.",
            "Figure 16. Effect of mesh resolution on the bag bursting for We = 12.0. (a) Time evolution of the drop surface area. (b)-(d) Drop surfaces when the holes are just formed for different mesh resolutions N = 512, 1024, 2048, respectively.",
            "Figure 17. Rayleigh-Taylor instability due to centripetal acceleration of the rim, forming fingers at the rim, which later detach to form children droplet. The results are for We = 12.0 and t̂ = 2.534-2.589 with an increment of 0.008. The color on the interfaces represents the velocity magnitude, see figure 15 for the color scale.",
            "Figure 18. Interaction between rims of different holes when the hole-merging occurs. The results are for We = 12.0 and t̂ = t/τd = 2.544-2.562 with an increment of 0.004. The color on the interfaces represents the velocity magnitude, see figure 15 for the color scale.",
            "Figure 19. Time evolutions of (a) streamwise velocity of the drop uc, (b) drop Reynold number Red, (c) drag coefficient CD, and (d, e) lift coefficients in the lateral y and z directions, for drops at different We.",
            "Figure 2. (a) Representative snapshot of the drop surface and velocity magnitude on the central x-y plane, with annotations showing the characteristic length scales for the drop shape. (b) Time evolution of ha = xmax,a − xmin,a for We = 15.3, indicating the time ranges resolved by different mesh resolutions. The horizontal lines indicate the minimum cell size for each mesh. The dimensionless variables are denoted by ,̂ defined in Eqs.(3.10) and (3.11).",
            "Figure 3. Time evolutions of (a) the drop length L̂ and (b) the drop radius R̂ for We=15.3 obtained from the 3D simulations. The experimental results by Opfer et al. (2014), Flock et al. (2012), and Jackiw & Ashgriz (2021) are shown for comparison.",
            "Figure 4. Time evolutions (a) drag coefficient CD and (b) gas enstrophy Ω̂g = Ωgd0/U 2 0 for We = 15.3. The 3D simulation results for two different mesh resolutions N = 256 and 512 are shown. In (b) the results for N = 256 were obtained by the mesh refinement L = 14 without further increase as in other cases.",
            "Figure 5. Comparison between 2D-axisymmetric and 3D simulation results for We=15.3, including (a) drop length L̂, (b) drop radius R̂, (c) drop velocity ud, and (d) drag coefficient CD. The experimental results by Opfer et al. (2014), Flock et al. (2012), and Jackiw & Ashgriz (2021) are shown in (a) and (b) for comparison.",
            "Figure 6. Time evolutions of the pressure field on the x-y plane using (a) 2D-axisymmetric and (b) 3D simulations, and (c) the vortical structures using 3D simulations. The results are for the case We = 15.3. The color on the drop surface in (c) represents the velocity magnitude.",
            "Figure 7. Temporal evolutions of (a) pressure p and (b) y-velocity in the drop on the central x-y plane, (c) drop surface colored with velocity magnitude, (d) the drop lateral radius R̂ and its rate of change dR̂/dt̂ for We = 12.0. Different phases of deformation are defined and indicated.",
            "Figure 8. Early-time evolution of (a) rate of change of drop radius dR̂/dt̂ and (b) drop velocity ûd for different We. The inviscid compressible flow simulation results for shock-droplet interaction by Meng & Colonius (2018) are shown in (b) for comparison.",
            "Figure 9. Comparison between the present simulation and model results for dR̂/dt̂ and R̂ with predictions of other models for (a,c) We = 12.0 and (b,d) We = 15.3. The results for other models are shown as well: VB, KS, TAB, Rimbert represent the models of Villermaux & Bossa (2009), Kulkarni & Sojka (2014), O’Rourke & Amsden (1987), Rimbert et al. (2020), while JA and JA2 represent the two models of Jackiw & Ashgriz (2021) (Eqs. (5.9) and (5.10)).",
            "Table 1. Fluid properties for simulation cases.",
            "Table 2. Simulation cases and key parameters."
        ],
        "imgs": [
            "$2305.00124v1-Figure1-1.png",
            "$2305.00124v1-Figure10-1.png",
            "$2305.00124v1-Figure11-1.png",
            "$2305.00124v1-Figure12-1.png",
            "$2305.00124v1-Figure14-1.png",
            "$2305.00124v1-Figure15-1.png",
            "$2305.00124v1-Figure16-1.png",
            "$2305.00124v1-Figure17-1.png",
            "$2305.00124v1-Figure18-1.png",
            "$2305.00124v1-Figure19-1.png",
            "$2305.00124v1-Figure2-1.png",
            "$2305.00124v1-Figure3-1.png",
            "$2305.00124v1-Figure4-1.png",
            "$2305.00124v1-Figure5-1.png",
            "$2305.00124v1-Figure6-1.png",
            "$2305.00124v1-Figure7-1.png",
            "$2305.00124v1-Figure8-1.png",
            "$2305.00124v1-Figure9-1.png",
            "$2305.00124v1-Table1-1.png",
            "$2305.00124v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00126",
        "abstract": "  Moving object segmentation (MOS) in dynamic scenes is an important,\nchallenging, but under-explored research topic for autonomous driving,\nespecially for sequences obtained from moving ego vehicles. Most segmentation\nmethods leverage motion cues obtained from optical flow maps. However, since\nthese methods are often based on optical flows that are pre-computed from\nsuccessive RGB frames, this neglects the temporal consideration of events\noccurring within the inter-frame, consequently constraining its ability to\ndiscern objects exhibiting relative staticity but genuinely in motion. To\naddress these limitations, we propose to exploit event cameras for better video\nunderstanding, which provide rich motion cues without relying on optical flow.\nTo foster research in this area, we first introduce a novel large-scale dataset\ncalled DSEC-MOS for moving object segmentation from moving ego vehicles, which\nis the first of its kind. For benchmarking, we select various mainstream\nmethods and rigorously evaluate them on our dataset. Subsequently, we devise\nEmoFormer, a novel network able to exploit the event data. For this purpose, we\nfuse the event temporal prior with spatial semantic maps to distinguish\ngenuinely moving objects from the static background, adding another level of\ndense supervision around our object of interest. Our proposed network relies\nonly on event data for training but does not require event input during\ninference, making it directly comparable to frame-only methods in terms of\nefficiency and more widely usable in many application cases. The exhaustive\ncomparison highlights a significant performance improvement of our method over\nall other methods. The source code and dataset are publicly available at:\nhttps://github.com/ZZY-Zhou/DSEC-MOS.\n",
        "title": "Event-Free Moving Object Segmentation from Moving Ego Vehicle",
        "texts": [
            "Figure 1: DSEC-MOS examples. The figure shows: (a) Calibrated-to-Event RGB frames; (b) Example Event frames; (c) Disparity maps; (d) Our DSEC-MOS Ground Truth Segmentation Masks; (e) Ground Truth Masks visualized on calibrated RGB frames. Best zoomed in.",
            "Figure 2: Comparison of SAM [15] w/o or w/ Prompts. The figure shows: (a) RGB frames; (b) SAM without Prompts on RGB; (c) SAM with Bounding Boxes Prompts; (d) Our DSEC-MOS Ground Truth Segmentation Masks visualized on RGB frames. Best zoomed in.",
            "Figure 3: Comparison of Masks before and after Revision. The figure shows: (a) RGB frames; (b) Masks before Revision; (c) Masks after revision as our MOS Ground Truth. Zoomed in comparisons are also provided.",
            "Table 1: DSEC-MOS Training-Testing Split and Illumination Conditions Split"
        ],
        "imgs": [
            "$2305.00126v1-Figure1-1.png",
            "$2305.00126v1-Figure2-1.png",
            "$2305.00126v1-Figure3-1.png",
            "$2305.00126v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00127",
        "abstract": "  In this paper, we investigate the scheduling issue of diesel generators (DGs)\nin an Internet of Things (IoT)-Driven isolated microgrid (MG) by deep\nreinforcement learning (DRL). The renewable energy is fully exploited under the\nuncertainty of renewable generation and load demand. The DRL agent learns an\noptimal policy from history renewable and load data of previous days, where the\npolicy can generate real-time decisions based on observations of past renewable\nand load data of previous hours collected by connected sensors. The goal is to\nreduce operating cost on the premise of ensuring supply-demand balance. In\nspecific, a novel finite-horizon partial observable Markov decision process\n(POMDP) model is conceived considering the spinning reserve. In order to\novercome the challenge of discrete-continuous hybrid action space due to the\nbinary DG switching decision and continuous energy dispatch (ED) decision, a\nDRL algorithm, namely the hybrid action finite-horizon RDPG (HAFH-RDPG), is\nproposed. HAFH-RDPG seamlessly integrates two classical DRL algorithms, i.e.,\ndeep Q-network (DQN) and recurrent deterministic policy gradient (RDPG), based\non a finite-horizon dynamic programming (DP) framework. Extensive experiments\nare performed with real-world data in an IoT-driven MG to evaluate the\ncapability of the proposed algorithm in handling the uncertainty due to\ninter-hour and inter-day power fluctuation and to compare its performance with\nthose of the benchmark algorithms.\n",
        "title": "Optimal Scheduling in IoT-Driven Smart Isolated Microgrids Based on Deep\n  Reinforcement Learning",
        "texts": [
            "Fig. 1: The schematic diagram of the IoT-driven smart isolated MG system.",
            "Fig. 2: The schematic description of the learning process of the DRL agent.",
            "Fig. 3: The neural network framework of HAFH-RDPG.",
            "Fig. 4: The trajectories of the PV power, load power, and equivalent load power of one typical day in the experimental data.",
            "Fig. 5: The average performance curves of three DRL algorithms across five runs in the training process. The ordinate corresponds to the performance, i.e., the average cumulative reward over 10 test episodes. The shaded areas indicate the standard errors of the three algorithms.",
            "Fig. 6: The equivalent load, generation power, battery and sum cost trajectories of various algorithms for a specific test episode on run 1. The charge or discharge power of the battery, the power generated by each of the three DGs, and the individual costs are shown through the bar chart.",
            "Fig. 7: The sum cost trajectories for a specific test episode to compare the performance of different algorithms.",
            "TABLE II: Hyper-parameters of the DRL algorithms.",
            "TABLE III: The individual, average, maximum performance, as well as the standard error of the proposed and benchmark algorithms across five runs. In each run, we executed 100 episodes of 24 time steps. The individual performance is the average cumulative reward over 100 test episodes."
        ],
        "imgs": [
            "$2305.00127v1-Figure1-1.png",
            "$2305.00127v1-Figure2-1.png",
            "$2305.00127v1-Figure3-1.png",
            "$2305.00127v1-Figure4-1.png",
            "$2305.00127v1-Figure5-1.png",
            "$2305.00127v1-Figure6-1.png",
            "$2305.00127v1-Figure7-1.png",
            "$2305.00127v1-TableII-1.png",
            "$2305.00127v1-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00128",
        "abstract": "  We study the Schwinger model with $N_{\\rm f} \\geq 2$ degenerate fermion\nflavors, by means of lattice simulations. We use dynamical Wilson fermions for\n$N_{\\rm f} = 2$, and re-weighted quenched configurations for overlap-hypercube\nfermions with $N_{\\rm f} \\leq 6$. In this framework, we explore an analogue of\nthe QCD pion decay constant $F_{\\pi}$, which is dimensionless in $d=2$, and\nwhich has hardly been considered in the literature. We determine $F_{\\pi}$ by\nthree independent methods, with numerical and analytical ingredients. First, we\nconsider the 2-dimensional version of the Gell-Mann--Oakes--Renner relation,\nwhere we insert both theoretical and numerical values for the quantities\ninvolved. Next we refer to the $\\delta$-regime, {\\it i.e.\\ a small spatial\nvolume, where we assume formulae from Chiral Perturbation Theory to apply even\nin the absence of Nambu-Goldstone bosons. We further postulate an effective\nrelation between $N_{\\rm f}$ and the number of relevant, light bosons, which we\ndenote as \"pions\". Thus $F_{\\pi}$ is obtained from the residual \"pion\" mass in\nthe chiral limit, which is a finite-size effect. Finally, we address to the\n2-dimensional Witten--Veneziano formula: it yields a value for $F_{\\eta}$,\nwhich we identify with $F_{\\pi}$, as in large-$N_{\\rm c}$ QCD. All three\napproaches consistently lead to $F_{\\pi} \\simeq 1/\\sqrt{2 \\pi}$ at fermion mass\n$m=0$, which implies that this quantity is meaningful.\n",
        "title": "An analogue to the pion decay constant in the multi-flavor Schwinger\n  model",
        "texts": [
            "Figure 1: Values for Fπ obtained from the Gell-Mann–Oakes–Renner relation (2.3) for Nf = 2, . . . , 6 flavors, at fermion masses 0.05 ≤ m ≤ 0.4. The data are obtained from quenched simulations at β = 4 (above) and at β = 6 (below) with overlap-hypercube re-weighting, which works well, but for fermion mass m ≲ 0.05 the results are affected by finite-size effects on Mπ. We see convincing agreement for different Nf , and hardly any difference for the different gauge couplings, hence the continuum limit seems smooth. In all cases, the extrapolations to the chiral limit are compatible with Fπ ≃ 0.4.",
            "Figure 10: The percentage of our Σ-value as a function of the number of dominant contributions, out of a total of 104 configurations at β = 4 (left) and 3× 104 configurations at β = 6 (right), at m = 0.05 on a 24× 24 lattice. We see that even more flavors than 6 would be troublesome.",
            "Figure 11: Illustration of the “pion” mass measured with σ1 (Mσ1 π ) and with σ3 (Mσ3 π ), for Nf = 2, at β = 5 on a 24 × 24 lattice. The upper plot shows that there is good agreement at fermion mass m ≥ 0.1, but at m ≤ 0.05 they differ drastically: Mσ3 π attains a residual value, which is the expected ϵ-regime behavior, whereas Mσ1 π drops to 0 with an approximately linear dependence on m <∼ 0.02. The lower plot zooms into the small-m region, and compares the data to eq. (36) of Ref. [7], where Mη = g √ 2/π is the “η-mass” in the chiral limit, cf. eq. (4.4), and γ is Euler’s constant. For m >∼ 0.05, Mσ1 π and Mσ3 π are close to each other, and to the prediction in the third regime of Ref. [7].",
            "Figure 2: The chiral condensate, measured for Nf = 2, at β = 5 on a 24× 24 lattice, based on the Dirac spectrum according to eq. (2.5). It is compared to an asymptotic formula for small m given in Ref. [7], where Mη represents the “η-meson” mass in the chiral limit, see eq. (4.4). We see that re-weighting works very well even for fermion masses down to m = 0.001 (cf. Appendix A), but the Gell-Mann–Oakes–Renner relation for Fπ, eq. (2.3), also involves Mπ, which is amplified by finite-size effects.",
            "Figure 3: Simulation results for the “pion” mass Mπ in the δ-regime, L≪ Lt (with Lt = 64), using dynamical Wilson fermions. For a small fermion mass m (determined by the PCAC relation) and a small spatial extent L, significant errors occur, as expected for Wilson fermions. Still, the full range of fermion masses enables sensible extrapolations to the residual “pion” mass MR π in the chiral limit m→ 0.",
            "Figure 4: The residual “pion” masses MR π in the δ-regime, obtained from simulations of two flavors of dynamical Wilson fermions and extrapolated to the chiral limit according to Figure 3, in spatial volumes L = 6, . . . , 12. The data follow well a fit proportional to 1/L, and the coefficient corresponds to Fπ = 0.3923(6).",
            "Figure 5: Like Figure 3, but here the “pion” mass Mπ is measured with overlap-hypercube fermions, using quenched, re-weighted gauge configurations, generated at β = 4. In contrast to Figure 3, this yields small errors and smooth chiral extrapolations for all spatial sizes L = 4, . . . , 12 under consideration.",
            "Figure 6: Like Figure 4, but now with data obtained from the extrapolation of overlap-hypercube fermions results, see Figure 5. Again the fit to the conjectured behavior MR π ∝ 1/L works very well for L < 12, and we extract Fπ = 0.3988(1). This value is well compatible with further results that we obtained for Fπ by employing different methods, and in perfect agreement with formula (1.2).",
            "Figure 7: Residual “pion” masses MR π in the δ-regime (Lt = 32) for a variety of spatial sizes L ≪ Lt, and Nf = 2, . . . , 6 flavors. We show chiral extrapolations of quenched, re-weighted results with overlap-hypercube fermions, at β = 4. The fits were performed in the range where they are successful, i.e. in the full range for Nf = 2, and for L ≤ 6 for Nf > 2. They lead to highly consistent values for Fπ, if we apply the effective formula (3.4).",
            "Figure 8: The quenched topological susceptibility χq t , for two different lattice formulations of the topological charge density (standard plaquette term θP and sin(θP)). In the latter case, the topological charge QS = ∑ P sin(θP)/2π can be computed analytically [39], while in case of QT = ∑ P θP/2π the sum over the plaquettes can be computed numerically [38]. In both cases, the values are in excellent agreement with our simulation results. Both formulations consistently lead to the continuum limit with χq t/g 2 = 1/4π2, which was derived in Ref. [37].",
            "Table 1: Results for Fπ, obtained by fits to eqs. (3.3) and (3.4), with Nf = 2, at three values of β."
        ],
        "imgs": [
            "$2305.00128v2-Figure1-1.png",
            "$2305.00128v2-Figure10-1.png",
            "$2305.00128v2-Figure11-1.png",
            "$2305.00128v2-Figure2-1.png",
            "$2305.00128v2-Figure3-1.png",
            "$2305.00128v2-Figure4-1.png",
            "$2305.00128v2-Figure5-1.png",
            "$2305.00128v2-Figure6-1.png",
            "$2305.00128v2-Figure7-1.png",
            "$2305.00128v2-Figure8-1.png",
            "$2305.00128v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00133",
        "abstract": "  The instabilities of the nontrivial phase elliptic solutions in a repulsive\nBose-Einstein condensate (BEC) with a periodic potential are investigated.\nBased on the defocusing nonlinear Schr\\\"{o}dinger (NLS) equation with an\nelliptic function potential, the well-known modulational instability (MI), the\nmore recently identified high-frequency instability, and an unprecedented -- to\nour knowledge -- variant of the MI, the so-called isola instability are\nidentified numerically. Upon varying parameters of the solutions, instability\ntransitions occur through the suitable bifurcations, such as the Hamiltonian\nHope one. Specifically, (i) increasing the elliptic modulus $k$ of the\nsolutions, we find that MI switches to the isola instability and the dominant\ndisturbance has twice the elliptic wave's period, corresponding to a Floquet\nexponent $\\mu=\\frac{\\pi}{2K(k)}$. The isola instability arises from the\ncollision of spectral elements at the origin of the spectral plane. (ii) Upon\nvarying $V_{0}$, the transition between MI and the high-frequency instability\noccurs. Differently from the MI and isola instability where the collisions of\neigenvalues happen at the origin, high-frequency instability arises from\npairwise collisions of nonzero, imaginary elements of the stability spectrum;\n(iii) In the limit of sinusoidal potential, we show that MI occurs from a\ncollision of eigenvalues with $\\mu=\\frac{\\pi}{2K(k)}$ at the origin; (iv) we\nalso examine the dynamic byproducts of the instability in chaotic fields\ngenerated by its manifestation. An interesting observation is that, in addition\nto MI, the isola instability could also lead to dark localized events in the\nscalar defocusing NLS equation.\n",
        "title": "The instabilities beyond modulational type in a repulsive Bose-Einstein\n  condensate with a periodic potential",
        "texts": [
            "FIG. 11: Numerical evolution of the MI resulting in pattern distortion and collisional events (highlighted by boxes on the left panel and zoomed-in at the middle and right panels). The initial condition is solution (3) perturbed by 5% random noise with k = 0.6, B = 0.25 and V0 = 1. The amplitude evolution (upper-left); the (solid-line)zoomed-in evolution of the box on the upper-left is shown on the middle panel; the (dotted-line) zoomed-in evolution of the box on the left is shown on the rightmost panel.",
            "FIG. 2: Left panel shows the maximal instability growth rate γ as a function of k with B = 0.25 and V0 = 1. When k < kc, the modulation instability appears [one example can be seen in (a) (with k = 0.55) of the right panel]. At k = kc, the ellipse-like curve appears. From kc to ke, the dominant instability switches to the ellipse-like instability [one example can be seen in (d) (with k = 0.64) of the right panel]. At k = ke, MI disappears and only the ellipse-like eigenvalues exist. From ke to kg , the ellipse-like curve is compressed vertically [as shown in (f) (with k = 0.69) of the right panel]. An infinity symbol forms at kg (as shown in (g) of the right panel). When k > kg , the infinity symbol splits into two isolas drifting away along the real axis [as shown in (h) (with k = 0.8) of the right panel]. For the right panel, the red dots correspond to µ = 0 and the green dots correspond to µ = π",
            "FIG. 3: Real part of growth rates as a function of the Floquet parameter µ, where (b) (MI with k = 0.6) and (h) (isola instability with k = 0.8) similarly to the left panel of FIG. 2",
            "FIG. 4: Eigenfunctions of the isola instability branch for µ = π 2K(k) , where (h) is labeled in FIG. 2.",
            "FIG. 5: The maximal instability growth rate γ as a function of k and V0 with B = 0.3.",
            "FIG. 6: (Left panel) The maximal instability growth rate γ as a function of V0. When V0 = V0f , the elliptic solutions are stable. When −0.19 < V0 < V0b = −0.18431, the first bubble dominates the instability (see (a) (with V0 = −0.19) of the right panel). From V0 to V0b, the two bubbles approach and collision (see (b) of the right panel). When V0 > V0b, the two bubbles pass through each other (see (c) (with V0 = −0.18) of the right panel) and then they fuse together (see (d) (with V0 = −0.01456) of the right panel) and move toward the origin (see (e) (with V0 = −0.005) of the right panel). When 0 < V0 < V0j = 0.06063, a transition between different stability spectra caused by the collision of eigenvalues with µ = 0 at the origin happens (see (g, h, i) (with V0 = 0.032, 0.04009, 0.052) of the right panel). The red dots in (g, h, i) of the right panel correspond to µ = 0. When V0 > V0j , we show three different stability spectra (see (k, l,m) (with V0 = 0.1, 0.28, 0.8) of the right panel).",
            "FIG. 7: Real part of growth rates as a function of the Floquet parameter µ, where (c) (high-frequency instability) is labeled in the left panel of FIG. 6",
            "FIG. 9: The maximal instability growth rate γ as a function of B and V0 with k = 0."
        ],
        "imgs": [
            "$2305.00133v1-Figure11-1.png",
            "$2305.00133v1-Figure2-1.png",
            "$2305.00133v1-Figure3-1.png",
            "$2305.00133v1-Figure4-1.png",
            "$2305.00133v1-Figure5-1.png",
            "$2305.00133v1-Figure6-1.png",
            "$2305.00133v1-Figure7-1.png",
            "$2305.00133v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00134",
        "abstract": "  We report the discovery of 2M0056-08 as an equal-mass eclipsing binary (EB),\ncomprising two red straggler stars (RSSs) with an orbital period of 33.9 d.\nBoth stars have masses of 1.419 Msun, identical to within 0.2%. Both stars\nappear to be in the early red-giant phase of evolution; however, they are far\ndisplaced to cooler temperatures and lower luminosities compared to standard\nstellar models. The broadband spectral energy distribution shows NUV excess and\nX-ray emission, consistent with chromospheric and coronal emission from\nmagnetically active stars; indeed, the stars rotate more rapidly than typical\nred giants and they evince light curve modulations due to spots. These\nmodulations also reveal the stars to be rotating synchronously with one\nanother. There is evidence for excess FUV emission and long-term modulations in\nradial-velocities; it is not clear whether these are also attributable to\nmagnetic activity or if they reveal a tertiary companion. Stellar evolution\nmodels modified to account for the effects of spots can reproduce the observed\nradii and temperatures of the RSSs. If the system possesses a white dwarf\ntertiary, then mass-transfer scenarios could explain the manner by which the\nstars came to possess such remarkably identical masses and by which they came\nto be sychronized. However, if the stars are presumed to have been formed as\nidentical twins, and they managed to become tidally synchronized as they\nevolved toward the red giant branch, then all of the features of the system can\nbe explained via activity effects, without requiring a complex dynamical\nhistory.\n",
        "title": "An Eclipsing Binary Comprising Two Active Red Stragglers of Identical\n  Mass and Synchronized Rotation: A Post-Mass-Transfer System or Just Born That\n  Way?",
        "texts": [
            "Figure 1. Gaia color-magnitude diagram of RS CVn systems identified by Leiner et al. (2022). The 2M0056−08 system is represented by the large symbol; its position can only be accommodated by a normal subgiant if simultaneously extremely old and metal-rich, as indicated by the model isochrone (black curve).",
            "Figure 11. Long-term trends in the variability of 2M0056−08, excluding the eclipses, and removing the rotation signatures from Figure 9. The thick line shows the smoothed median of the data in each band. The circles show the times of the spectroscopic observations. The yellow line shows the sinusoid with the period of ∼210 days approximating the light curve.",
            "Figure 12. Comparison of the radii and temperatures of the eclipsing components in the 2M0056−08 system against a MIST theoretical evolutionary track for the nearly identical masses of the components. As expected for RSSs, the stars appear far displaced to cooler Teff compared to normal subgiant or red giant stars of the same mass and metallicity.",
            "Figure 13. Same as Figure 12, but comparing radius versus mass (top) and luminosity versus mass (bottom), for a range of ages consistent with the measured radii.",
            "Figure 14. The components of simulated binaries in the HR diagram, selected to have the same total mass and orbital period as 2M0056−08, but for different choices of the mass ratio, q, and requiring the stars’ radii to remain detached. Each pair of component stars is represented by filled symbols of the same color on a standard stellar evolution model, which has been manually shifted in Teff and L to crudely simulate the suppressed temperatures and luminosities observed (dotted curve); the resulting combined-light position for that pair is represented by the open symbol of the same color. In all cases, the combined light of the synthetic binaries falls in the RSS region of the diagram (i.e., to the right of the standard model track; solid curve). For the 2M0056−08 system to have been selected as an RSS EB candidate implicitly required q & 0.95; see the text.",
            "Figure 15. Alternative evolutionary models incorporating the effects of reduced convective efficiency due to a large starspot covering fraction. The solid black track shows standard MIST evolutionary tracks for a 1.419 M star, which use a standard solar calibrated mixing length α = 1.82 (Choi et al. 2016). Colored tracks are MESA evolutionary tracks of varying metallicity that use adjusted α values as indicated.",
            "Figure 2. TESS light curve extraction pixel masks and flagged light curve data for Sector 3 (top) and Sector 30 (bottom). The pink and red dashed boxes in the upper panels represent the pixel masks for the sky background and the aperture mask used for photometric extraction with the NEMESIS pipeline. The red and yellow Xs represent the location of the target star and the photocenter of the aperture mask. The cyan colored points are other stellar sources within 42′′ of 2M0056−08, sized by the difference in magnitude from 2M0056−08. The lower panels display the light curves with Barycentric TESS Julian Day (BTJD) timestamps in noramlized relative flux units. The photometric measurements are colored by the TESS quality flag bit values for each timestamp. In Sector 30, about half of the deeper eclipse have quality flag bit values of 2048.",
            "Figure 3. Broadening function of a representative spectroscopic observation of 2M0056−08, showing the two eclipsing components to be of comparable brightness in visible light. Note also the lack of any clear signature of a tertiary companion; its contribution is constrained to be less than a few percent of the total system light in the visible.",
            "Figure 4. Radial-velocity measurements for 2M0056−08 together with our binary model described below. Residuals are shown at the bottom. The errorbars correspond to the final uncertainties, after folding in the jitter values reported in Table 2, added in quadrature.",
            "Figure 5. Comparison of the observed Coudé spectrum of 2M0056−08 (blue) with synthetic binary spectra at a range of metallicities.",
            "Figure 6. Spectral energy distribution of 2M0056−08. Red symbols represent the observed broadband photometry from ROSAT, GALEX, SDSS, Pan-STARRS, 2MASS, and WISE; horizontal bars represent the effective bandpass widths. Red and cyan curves represent PHOENIX stellar atmosphere models representing the cooler and hotter EB component stars, respectively, and the green curve represents a hot blackbody (T = 11 000 K) with R = 0.03 R , chosen to match the (activity-corrected; downward arrow) GALEX fluxes; see the text. The dark blue curve represents the sum of all three components, providing an excellent fit to the broadband photometry as well as to the Gaia spectrum (gray swath, inset), which also constrains the metallicity via the absorption feature in the g band (vertical dotted lines). The magenta curve represents a blackbody with best-fit T = 5× 106 K to the X-ray fluxes, consistent with coronal emission from the active eclipsing stars; see the text.",
            "Figure 7. Eclipse model shown with the TESS photometry for sectors 3 and 30 (top) and the ASAS-SN V - and g-band measurements (bottom). Sector 3 and the g band are displaced vertically for clarity. Residuals are shown below each panel. They display systematic deviations that may be due to a combination of spots on one or both stars, stray light affecting the TESS photometry, and possible errors in our detrending.",
            "Table 2. Joint Photometric-Spectroscopic Orbital Solution for 2M0056−08",
            "Table 3. Derived Parameters from our Joint PhotometricSpectroscopic Solution for 2M0056−08"
        ],
        "imgs": [
            "$2305.00134v1-Figure1-1.png",
            "$2305.00134v1-Figure11-1.png",
            "$2305.00134v1-Figure12-1.png",
            "$2305.00134v1-Figure13-1.png",
            "$2305.00134v1-Figure14-1.png",
            "$2305.00134v1-Figure15-1.png",
            "$2305.00134v1-Figure2-1.png",
            "$2305.00134v1-Figure3-1.png",
            "$2305.00134v1-Figure4-1.png",
            "$2305.00134v1-Figure5-1.png",
            "$2305.00134v1-Figure6-1.png",
            "$2305.00134v1-Figure7-1.png",
            "$2305.00134v1-Table2-1.png",
            "$2305.00134v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00136",
        "abstract": "  The purpose of this study is to investigate the development process for\nArtificial inelegance (AI) and machine learning (ML) applications in order to\nprovide the best support environment. The main stages of ML are problem\nunderstanding, data management, model building, model deployment and\nmaintenance. This project focuses on investigating the data management stage of\nML development and its obstacles as it is the most important stage of machine\nlearning development because the accuracy of the end model is relying on the\nkind of data fed into the model. The biggest obstacle found on this stage was\nthe lack of sufficient data for model learning, especially in the fields where\ndata is confidential. This project aimed to build and develop a framework for\nresearchers and developers that can help solve the lack of sufficient data\nduring data management stage. The framework utilizes several data augmentation\ntechniques that can be used to generate new data from the original dataset\nwhich can improve the overall performance of the ML applications by increasing\nthe quantity and quality of available data to feed the model with the best\npossible data. The framework was built using python language to perform data\naugmentation using deep learning advancements.\n",
        "title": "Optimizing the AI Development Process by Providing the Best Support\n  Environment",
        "texts": [
            "Figure 1 The machine learning lifecycle",
            "Figure 3 The Benefits of Data Augmentation",
            "Figure 31 After performing rotate",
            "Figure 4 As the training rate decreases, the left plot indicates an infection point where the validation error begins to grow. Overfitting to the training data has resulted in a model that performs badly on the testing data.",
            "Figure 7 Sample Pairing augmentation strategy"
        ],
        "imgs": [
            "$2305.00136v1-Figure1-1.png",
            "$2305.00136v1-Figure3-1.png",
            "$2305.00136v1-Figure31-1.png",
            "$2305.00136v1-Figure4-1.png",
            "$2305.00136v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00137",
        "abstract": "  Spatially-coupled (SC) codes is a class of convolutional LDPC codes that has\nbeen well investigated in classical coding theory thanks to their high\nperformance and compatibility with low-latency decoders. We describe toric\ncodes as quantum counterparts of classical two-dimensional spatially-coupled\n(2D-SC) codes, and introduce spatially-coupled quantum LDPC (SC-QLDPC) codes as\na generalization. We use the convolutional structure to represent the parity\ncheck matrix of a 2D-SC code as a polynomial in two indeterminates, and derive\nan algebraic condition that is both necessary and sufficient for a 2D-SC code\nto be a stabilizer code. This algebraic framework facilitates the construction\nof new code families. While not the focus of this paper, we note that small\nmemory facilitates physical connectivity of qubits, and it enables local\nencoding and low-latency windowed decoding. In this paper, we use the algebraic\nframework to optimize short cycles in the Tanner graph of 2D-SC hypergraph\nproduct (HGP) codes that arise from short cycles in either component code.\nWhile prior work focuses on QLDPC codes with rate less than 1/10, we construct\n2D-SC HGP codes with small memories, higher rates (about 1/3), and superior\nthresholds.\n",
        "title": "Spatially-Coupled QLDPC Codes",
        "texts": [
            "Fig. 1. A toric code defines on a 3 × 3 grid. Vertices are indicated by circles and faces are indicated by squares. Vertices/edges with the same index are glued together to create a torus with 18 edges, 9 vertices, and 9 faces. Vertex 5 specifies the generator Z2 ⊗ Z3 ⊗ Z4 ⊗ Z7 and face 8 specifies generator X10 ⊗X13 ⊗X14 ⊗X15.",
            "Fig. 3. Examples show how flexible cycle candidates of SC-HGP codes can be decomposed into two different components from Pa and Pb. The matrices in the bottom panels of (a) and (b) are Pa and Pb, and those in the top panels are P. Nodes from copies of A and B are highlighted by red nodes and blue nodes, respectively. The number at each node is the value in its partitioning matrix Pa or Pb. The red and blue cycles in (a) shows two flexible cycles-8 candidates where each of them is resulting from a pair of cycles-4 candidates from Pa and Pb. Let sa = a1 − a2 + a4 − a3, sb = b1 − b2 + b4 − b3, the alternating sums associated with the blue and red cycle candidates are sa−sb and sa+sb, respectively. The orange and green cycles in (a) shows two flexible cycles-6 candidates where each of them is resulting from a cycle-4 candidate from Pa and node b3 from Pb. The alternating sums of both of them are sa. (b) shows three flexible cycles-8 candidates where each of them is resulting from a cycle-6 candidate from Pa and an entry b from Pb. The alternating sums of all three cases are a1 − a2 + a3 − a4 + a5 − a6.",
            "Fig. 4. Different partitioning patterns of cycle-8 candidates resulting from a pair of cycle-4 candidates in Pa and Pb. The partitioning pattern is represented by {{a, b}, {c, d}}, where each one of a, b, c, d corresponds to the number of nodes in each group of {a1, a2, a3, a4} that form a cycle-4 candidate. The outer bracket separates those correspond to nodes in the top left panel (i.e., In2×n2 ⊗A) and those correspond to nodes in the bottom right panel (i.e., within Ir2×r2 ⊗ AT). For example, in (a), all the nodes associated with ai, i = 1, . . . , 4, are in the top left panel, while each group of {a1, a2, a3, a4} in this panel contains 2 nodes of the cycle-8 candidate. Therefore, the partitioning pattern is {{2, 2}, {0, 0}}. Similarly, the partitioning pattern of cycles in Fig. 3(a) is {{2, 0}, {2, 0}}. The green cycle in (a) is also a cycle-8 candidate, but the alternating sum is not dependent on bi, i = 1, . . . , 4, thus these cycles can be easily removed by removing cycle-4 candidates in Pa with an zero alternating sum.",
            "Fig. 6. Frame Error Rate (FER) for [[7300, 2500]] SC-QLDPC codes with BP decoder.",
            "Fig. 7. Frame Error Rate (FER) for [[5800, 1600]] SC-QLDPC codes with BP decoder.",
            "TABLE I NUMBER OF FLEXIBLE CYCLES IN [[7300, 2500]] CODES"
        ],
        "imgs": [
            "$2305.00137v3-Figure1-1.png",
            "$2305.00137v3-Figure3-1.png",
            "$2305.00137v3-Figure4-1.png",
            "$2305.00137v3-Figure6-1.png",
            "$2305.00137v3-Figure7-1.png",
            "$2305.00137v3-TableI-1.png"
        ]
    },
    {
        "id": "2305.00139",
        "abstract": "  In node classification using graph neural networks (GNNs), a typical model\ngenerates logits for different class labels at each node. A softmax layer often\noutputs a label prediction based on the largest logit. We demonstrate that it\nis possible to infer hidden graph structural information from the dataset using\nthese logits. We introduce the key notion of label non-uniformity, which is\nderived from the Wasserstein distance between the softmax distribution of the\nlogits and the uniform distribution. We demonstrate that nodes with small label\nnon-uniformity are harder to classify correctly. We theoretically analyze how\nthe label non-uniformity varies across the graph, which provides insights into\nboosting the model performance: increasing training samples with high\nnon-uniformity or dropping edges to reduce the maximal cut size of the node set\nof small non-uniformity. These mechanisms can be easily added to a base GNN\nmodel. Experimental results demonstrate that our approach improves the\nperformance of many benchmark base models.\n",
        "title": "Leveraging Label Non-Uniformity for Node Classification in Graph Neural\n  Networks",
        "texts": [
            "Figure 1. Accuracy for M1, M2 respectively on the Cora dataset.",
            "Figure 11. Illustration of Theorem 3 with Venn diagrams.",
            "Figure 2. The Venn diagrams illustrate Theorem 1 and Corollary 1. In (a), the arrows are paths along which f̃ increases. In (b), if we color the graph according to f̃ value, then it should be layered as shown.",
            "Figure 3. The Venn diagram illustrates that to differentiate nodes using f̃ value along the boundary, we may either increase the size of O0 and O1 as in (b) or create a bottleneck as in (c).",
            "Figure 5. The figure is the scheme of the proposed model. We see that there are two separate modules (in the dashed blue boxes corresponding to the two algorithms. They can be applied either separately or jointly to the base model.",
            "Figure 7. Performance against parameter choices.",
            "Figure 8. Performance for model mismatch between Algorithm 1 and Algorithm 2.",
            "Figure 9. Performance based on GAT with L = 2 to 8 layers.",
            "Table 4. List of notations",
            "Table 6. Comparisons with Renode, Self-train and PTDNet"
        ],
        "imgs": [
            "$2305.00139v1-Figure1-1.png",
            "$2305.00139v1-Figure11-1.png",
            "$2305.00139v1-Figure2-1.png",
            "$2305.00139v1-Figure3-1.png",
            "$2305.00139v1-Figure5-1.png",
            "$2305.00139v1-Figure7-1.png",
            "$2305.00139v1-Figure8-1.png",
            "$2305.00139v1-Figure9-1.png",
            "$2305.00139v1-Table4-1.png",
            "$2305.00139v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00141",
        "abstract": "  Cardiovascular diseases (CVDs) can be effectively treated when detected\nearly, reducing mortality rates significantly. Traditionally, phonocardiogram\n(PCG) signals have been utilized for detecting cardiovascular disease due to\ntheir cost-effectiveness and simplicity. Nevertheless, various environmental\nand physiological noises frequently affect the PCG signals, compromising their\nessential distinctive characteristics. The prevalence of this issue in\novercrowded and resource-constrained hospitals can compromise the accuracy of\nmedical diagnoses. Therefore, this study aims to discover the optimal\ntransformation method for detecting CVDs using noisy heart sound signals and\npropose a noise robust network to improve the CVDs classification\nperformance.For the identification of the optimal transformation method for\nnoisy heart sound data mel-frequency cepstral coefficients (MFCCs), short-time\nFourier transform (STFT), constant-Q nonstationary Gabor transform (CQT) and\ncontinuous wavelet transform (CWT) has been used with VGG16. Furthermore, we\npropose a novel convolutional recurrent neural network (CRNN) architecture\ncalled noise robust cardio net (NRC-Net), which is a lightweight model to\nclassify mitral regurgitation, aortic stenosis, mitral stenosis, mitral valve\nprolapse, and normal heart sounds using PCG signals contaminated with\nrespiratory and random noises. An attention block is included to extract\nimportant temporal and spatial features from the noisy corrupted heart\nsound.The results of this study indicate that,CWT is the optimal transformation\nmethod for noisy heart sound signals. When evaluated on the GitHub heart sound\ndataset, CWT demonstrates an accuracy of 95.69% for VGG16, which is 1.95%\nbetter than the second-best CQT transformation technique. Moreover, our\nproposed NRC-Net with CWT obtained an accuracy of 97.4%, which is 1.71% higher\nthan the VGG16.\n",
        "title": "NRC-Net: Automated noise robust cardio net for detecting valvular\n  cardiac diseases using optimum transformation method with heart sound signals",
        "texts": [
            "Figure 1: A graphical representation of the classification workflow of noisy heart sound (HS). After several preprocessing steps, HS and lung sound (LS) have been acquired framing at 3.5sec and are mixed at specific SNRs to yield noisy HS datasets. Next, in the transformation phase, 2D input images are generated using four transformation techniques (CQT, CWT, STFT and MFCC). Finally, in the classification phase, the 2D images for each category have been successively passed to the proposed architecture. An overview of the NRC-Net architecture consisting of four stages, i.e., Spatial Feature Extractor Block (SFEB), Holistic Attention Block (HAB), Temporal Feature Extractor Block (TFEB), and Terminal Classification Block (TCB) is also demonstrated.",
            "Figure 10: Accuracy vs. epoch curves obtained for: (a) proposed network, (b) VGG16, and (c) MobileNet V2 during training and testing.",
            "Figure 11: Performance comparison of different models with CWT on AWGN.",
            "Figure 3: Architecture of spatial feature extractor block (SFEB).",
            "Figure 4: Architecture of holistic attention block (HAB).",
            "Figure 5: Architecture of temporal feature extractor block (TFEB).",
            "Figure 6: Architecture of terminal classification block (TCB).",
            "Figure 7: A schematic representation of K-fold CV when K = 10. The initial training dataset contains 4000 samples and is randomly divided into K separate sets. In each iteration of the process, K-1 of these sets is used to train a model (highlighted in light orange), while the remaining set is employed for validation (highlighted in pink). This process is repeated K times, covering all possible combinations of validation sets. The final evaluation of the model is conducted on 1000 samples at each SNR level, as represented by the blue gradient.",
            "Figure 9: Performance comparison with different transformation methods: (a) CWT, (b) CQT, (c) Spectogram, and (d) MFCC.",
            "Table 1: Summary of works carried out on automated detection of heart sounds using GitHub PCG dataset [9].",
            "Table 2: Details of hyperparameters used for the models.",
            "Table 3: Comparison of accuracy(%) for VGG16 model with different transformation techniques.",
            "Table 4: Ten-fold CV scores obtained for the proposed model.",
            "Table 5: Comparison of NRC-Net with existing works using GitHub PCG dataset [9].",
            "Table 6: Number of parameters used in different models."
        ],
        "imgs": [
            "$2305.00141v1-Figure1-1.png",
            "$2305.00141v1-Figure10-1.png",
            "$2305.00141v1-Figure11-1.png",
            "$2305.00141v1-Figure3-1.png",
            "$2305.00141v1-Figure4-1.png",
            "$2305.00141v1-Figure5-1.png",
            "$2305.00141v1-Figure6-1.png",
            "$2305.00141v1-Figure7-1.png",
            "$2305.00141v1-Figure9-1.png",
            "$2305.00141v1-Table1-1.png",
            "$2305.00141v1-Table2-1.png",
            "$2305.00141v1-Table3-1.png",
            "$2305.00141v1-Table4-1.png",
            "$2305.00141v1-Table5-1.png",
            "$2305.00141v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00142",
        "abstract": "  We deduce a non-linear commutator higher-spin (HS) symmetry algebra which\nencodes unitary irreducible representations of the AdS group -- subject to a\nYoung tableaux $Y(s_1,\\ldots ,s_k)$ with $k\\geq 2$ rows -- in a $d$-dimensional\nanti-de-Sitter space. Auxiliary representations for a deformed non-linear HS\nsymmetry algebra in terms of a generalized Verma module, as applied to\nadditively convert a subsystem of second-class constraints in the HS symmetry\nalgebra into one with first-class constraints, are found explicitly in the case\nof a $k=2$ Young tableaux. An oscillator realization over the Heisenberg\nalgebra for the Verma module is constructed. The results generalize the method\nof constructing auxiliary representations for the symplectic $sp(2k)$ algebra\nused for mixed-symmetry HS fields in flat spaces \\cite{BRbos}. Polynomial\ndeformations of the $su(1,1)$ algebra related to the Bethe ansatz are studied\nas a by-product. A nilpotent BRST operator for a non-linear HS symmetry algebra\nof the converted constraints for $Y(s_1, s_2)$ is found, with non-vanishing\nterms (resolving the Jacobi identities) of third order in powers of ghost\ncoordinates. A gauge-invariant unconstrained reducible Lagrangian formulation\nfor a free bosonic HS field of generalized spin $(s_1,s_2)$ is deduced.\nFollowing the results of \\cite{BuchbinderReshetnyak, BRmasscub}, we develop a\nBRST approach to constructing general off-shell local cubic interaction\nvertices for irreducible massive higher-spin fields (being candidates for\nmassive particles in the Dark Matter problem). A new reducible gauge-invariant\nLagrangian formulation for an antisymmetric massive tensor field of spin\n$(1,1)$ is obtained.\n",
        "title": "Gauge Invariant Lagrangian Formulations for Mixed Symmetry Higher Spin\n  Bosonic Fields in AdS Spaces",
        "texts": [
            "Table 1: HS symmetry non-linear algebra Am(Y (k), AdSd).",
            "Table 2: The non-linear part of the algebra A′(Y (k), AdSd)."
        ],
        "imgs": [
            "$2305.00142v3-Table1-1.png",
            "$2305.00142v3-Table2-1.png"
        ]
    },
    {
        "id": "2305.00145",
        "abstract": "  The $^3$He(n,p) process is excellent for neutron detection between thermal\nand $\\sim$4\\,MeV because of the high cross section and near-complete energy\ntransfer from the neutron to the proton. This process is typically used in\ngaseous forms with ionization readout detectors. Here we study the response of\na liquid $^3$He neutron detector with a scintillation readout. We anticipate an\nefficiency boost of around a factor of 64 compared to 10\\,atm gaseous\ndetectors, given similar detector volumes.\n",
        "title": "Response of a Liquid $^3$He Neutron Detector",
        "texts": [
            "FIGURE 2. The parameters of the response function mapped to a 1.5 MeV signal peak. A2 is related to calibration and is not present in the equation. There is no A10 [3].",
            "FIGURE 3. The experimental data is example data taken from [6], corresponding to 142 keV nuclear recoils. The horizontal axis represents the signal size in number of photoelectrons (phe), and the vertical represents counts per bin.",
            "FIGURE 4. (Top) From left to right, the plots of a2 and a3 for nuclear recoils. (Bottom) From right to left, the plots of a2 and a3 for electronic recoils. Energy uncertainties are scaled by ×3, and phe uncertainties are scaled by ×20. For each figure, the energy uncertainties are obtained from [6] and the phe uncertainties are obtained from the covariance matrix of the fits. The red points correspond to the individual photon yield/width data and uncertainties from the Berkeley publication the red dashed lines are fits to those points. The blue points represent the yield/widths from our Gaussian fits and their uncertainties. The blue dashed lines are a fit to those points.",
            "FIGURE 5. Neutron flux as a function of energy for the SNOLAB environment. The red and purple curves are smoothings of the high-energy neutrons computed from the SuperCDMS sensitivity projection paper [15]. The orange portion of the curve is an interpolation in the region below 10 keV down to the Maxwell-Boltzmann portion for the thermal neutron flux. The integral of the thermal flux region (from 10−4 eV to about 1 eV) is normalized to the measured underground SNOLAB thermal neutron flux: 4144.8±49.8±105.3 n/m2/day.",
            "FIGURE 6. Schematic depicting how the flux is converted into an expected event rate. (Left) Shows situations where the (n,p) cross section is small enough (mean free path of neutrons much larger than detector size) that the flux can be treated as uniform throughout the detector and equal to the external neutron flux. (Right) Shows situations–taken to be En<1 keV–where any incoming neutron is nearly guaranteed to produce an (n,p) reaction in the detector. The black region near the edge depicts the region where thermal neutrons (En ∼0.025 eV) are likely to interact. The tan region shows where neutrons of energies somewhat higher–up to around 1 keV–are likely to interact.",
            "FIGURE 7. The expected spectrum of a 2×2×2 cm3 detector operated at SNOLAB for 1 yr (black points) compared to the expected total neutron distribution (black line) with (n,p) (blue shaded) and elastic (orange shaded) contributions. The uncertainties for zero-count bins were scaled so they did not obscure the plot.",
            "TABLE I. (Top) A table of fit parameters which quantify how the Gaussian parameters a2 and a3 behave with deposited energy according to our fits. (Bottom) A table of fit parameters which quantify how the Gaussian parameters a2 and a3 behave with deposited energy according to the fits from [6]."
        ],
        "imgs": [
            "$2305.00145v1-Figure2-1.png",
            "$2305.00145v1-Figure3-1.png",
            "$2305.00145v1-Figure4-1.png",
            "$2305.00145v1-Figure5-1.png",
            "$2305.00145v1-Figure6-1.png",
            "$2305.00145v1-Figure7-1.png",
            "$2305.00145v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00147",
        "abstract": "  Recent work demonstrates that images from various chest X-ray datasets\ncontain visual features that are strongly correlated with protected demographic\nattributes like race and gender. This finding raises issues of fairness, since\nsome of these factors may be used by downstream algorithms for clinical\npredictions. In this work, we propose a framework, using generative adversarial\nnetworks (GANs), to visualize what features are most different between X-rays\nbelonging to two demographic subgroups.\n",
        "title": "Visualizing chest X-ray dataset biases using GANs",
        "texts": [
            "Figure 1: Framework of our proposed method. (a) We train a GAN on an image dataset, and a binary classifier on the images and labels for a demographic prediction task (e.g., White vs. Black race). (b) We project a subset of images onto the trained GAN’s latent space. To ensure the projected images are reasonably reconstructed, we only keep projected images whose labels (predicted by the attribute classifier trained in (a)) agree with their original labels. We also fit an SVM hyperplane to separate the two classes in the latent space. Finally, we visualize the differences between the classes by starting at a latent code corresponding to a random image, and traversing along the normal direction of the SVM hyperplane, to generate a sequence of images showing a transformation.",
            "Figure 2: Sample visualization results. The left column corresponds to the projected initial image and the last three columns show images generated at different traversal distances in the latent space. The red text indicates the output probabilities predicted by the attribute classifier for each class. For example, the top left [0.98, 0.01] indicate the CXR has a 98% possibility of being white and 1% possibility of being black. We also use red boxes to highlight the areas that visually vary the most. For White/Black, the shoulder bone and right lung structures change shape, and the lungs become more opaque. For Asian/White, the entire chest shape changes and grows larger. These visualizations also explain why the Reading Race study (Gichoya et al., 2022) did not find race prediction to significantly change when blocking local regions. The proposed applied to Cardiomegaly enlarges the heart, in agreement with the known effect of that disease."
        ],
        "imgs": [
            "$2305.00147v2-Figure1-1.png",
            "$2305.00147v2-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00149",
        "abstract": "  Recent research demonstrates that deep learning models are capable of\nprecisely extracting bio-information (e.g. race, gender and age) from patients'\nChest X-Rays (CXRs). In this paper, we further show that deep learning models\nare also surprisingly accurate at recognition, i.e., distinguishing CXRs\nbelonging to the same patient from those belonging to different patients. These\nfindings suggest potential privacy considerations that the medical imaging\ncommunity should consider with the proliferation of large public CXR databases.\n",
        "title": "X-ray Recognition: Patient identification from X-rays using a\n  contrastive objective",
        "texts": [
            "Figure 1: Example CXRs from Chexpert. We show four CXRs for two random patients taken over multiple visits. Various changes, related to health condition and other factors make it hard to visually determine whether a pair of CXRs belong to the same person or not.",
            "Figure 2: (a) True Positive Rate(TPR) vs. False Positive Rate(FPR) and AUROC scores for recognition models on different test dataset settings. We considered two models: 1. The proposed X-Ray recognition model (red), 2. DenseNet-121 trained for bio-information classification (baseline, black). We trained the second model for its respective tasks, and use its feature .. We consider the following test set settings: 1. randomly selected positive/negative pairs (solid line), 2. negative pairs with the same gender (dashed line), and 3. OOD test set from NIH dataset (dotted line). Results show that recognition model is able to distinguish IDs under all settings with a much higher accuracy. (b) Results of transfer learning on bio-information prediction. Results show that one can make prediction with high accuracy only based on information captured by the recognition model."
        ],
        "imgs": [
            "$2305.00149v1-Figure1-1.png",
            "$2305.00149v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00150",
        "abstract": "  In this paper, we develop an arbitrary-order locking-free enriched Galerkin\nmethod for the linear elasticity problem using the stress-displacement\nformulation in both two and three dimensions. The method is based on the mixed\ndiscontinuous Galerkin method in [30], but with a different stress\napproximation space that enriches the arbitrary order continuous Galerkin space\nwith some piecewise symmetric-matrix valued polynomials. We prove that the\nmethod is well-posed and provide a parameter-robust error estimate, which\nconfirms the locking-free property of the EG method. We present some numerical\nexamples in two and three dimensions to demonstrate the effectiveness of the\nproposed method.\n",
        "title": "A locking-free mixed enriched Galerkin method of arbitrary order for\n  linear elasticity using the stress-displacement formulation",
        "texts": [
            "Fig. 1. Errors of ‖u − uh‖ and ‖σ − σh‖div = √ ‖σ − σh‖2 + ‖div(σ − σh)‖2 for Example 7.2 with λ = 1, 104, 108, k = 1, 2 and η = 0.1.",
            "Fig. 2 shows the robustness of the mixed EG method for different values of λ.",
            "Table 3 Errors and convergence orders for Example 7.1 with different k."
        ],
        "imgs": [
            "$2305.00150v1-Figure1-1.png",
            "$2305.00150v1-Figure2-1.png",
            "$2305.00150v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00151",
        "abstract": "  We model the boundary-layer flashback (BLF) of CH$_4$/H$_2$/air swirling\nflames via large-eddy simulations with the flame-surface-density method\n(LES-FSD), in particular, at high pressures. A local displacement speed model\ntabulating the stretched flame speed is employed to account for the\nthermo-diffusive effects, flame surface curvature, and heat loss in LES-FSD.\nThe LES-FSD well captures the propagation characteristics during the BLF of\nswirling flames. In the LES-FSD for lean CH$_4$/H$_2$/air flames at 2.5 bar,\nthe critical equivalence ratio for flashback decreases with the increasing\nhydrogen volume fraction, consistent with the experiments. This is due to the\nimproved modeling of effects of the flame stretch and heat loss on the local\ndisplacement speed. We also develop a simple model to predict the BLF limits of\nswirling flames. The model estimates the critical bulk velocity for given\nreactants and swirl number, via the balance between the flame-induced pressure\nrise and adverse pressure for boundary-layer separation. We validate the model\nagainst 14 datasets of CH$_4$/H$_2$/air swirling flame experiments, with the\nhydrogen volume fractions in fuel from 50% to 100%. The present model well\nestimates the flashback limits in various operating conditions.\n",
        "title": "Modeling the boundary-layer flashback of premixed hydrogen-enriched\n  swirling flames at high pressures",
        "texts": [
            "Figure 1: Schematic of the computational domain for LES-FSD, where the blue arrows denote the swirling inflow direction.",
            "Figure 10: Contours of I0 and s0LI0 in terms of K and h in cases A1 (upper row) and A3 (lower row) at the BLF limit φ = φcr. The point with error bars presents averaged values with one standard deviations of K and h on the leading edge of the flame front.",
            "Figure 11: Schematics of (a) propagation modes of the flame tongue in the mixing tube and (b) the velocity decomposition along the direction of the bulk flow.",
            "Figure 12: Schematics on the modes of flame stabilization and BLF in the mixing tube.",
            "Figure 13: Comparisons on the BLF limit between the experiment [17] and the simple model in Eqs. (12) and (13). (a) Contour of Uudx,cr in terms of XH2 and φ is calculated by the model, and symbols denote experimental results with values of Ux provided in legends in (b). (b) Comparison between experimental and modeling results of Uudx,cr.",
            "Figure 2: Instantaneous contours of c̃ in LES-FSD at different times in case E1 with XH2 = 80%, φ = 0.558, p = 2.5 bar, Tub = 473 K, and Ux = 15 m/s.",
            "Figure 5: Time-averaged flame front and velocity vectors over a period from t = 100 ms to 200 ms in case E1. The arrows denote 〈ũs〉t.",
            "Figure 6: Radial profiles of 〈ũx〉t, 〈ũθ〉t, and 〈c̃〉t crossing the flame base in case E1.",
            "Figure 7: Time-averaged pressure from 100 to 200 ms on the x-r plane crossing the flame base in case E1.",
            "Figure 8: Comparisons of the BLF limits obtained in LES-FSD (lines) and experiments [17] (symbols) in cases A1, A2, and A3 with Ux = 15 m/s and different XH2 . The red solid and black dotted lines represent LES-FSD results using models of 〈sd〉A with and without flame stretch effects, respectively. The upper and lower bounds of the error bar with the width ∆φ = 0.025 denotes the values of φ in flashback and flame stabilization, respectively.",
            "Figure A.2: The angle α obtained by Eq. (10), LES, and experiments [15] in nonreacting swirling flows of cases (a) F1 and (b) F2.",
            "Figure A.3: Comparisons of the absolute axial velocities of the flame tongue during BLF obtained via experiments (blue dashed lines) and LES-FSD with 〈sd〉A models in Eq. (A.1) based on unstretched flames (black squares) and Eq. (7) based on stretched flames (red circles) in cases (a) F1 and (b) F2.",
            "Table 1: Operating conditions in the LES-FSD for the BLF of CH4/H2/air swirling flames.",
            "Table 2: Comparisons of experimental results and model predictions of Uudx,cr in CH4/H2/air swirling flames."
        ],
        "imgs": [
            "$2305.00151v1-Figure1-1.png",
            "$2305.00151v1-Figure10-1.png",
            "$2305.00151v1-Figure11-1.png",
            "$2305.00151v1-Figure12-1.png",
            "$2305.00151v1-Figure13-1.png",
            "$2305.00151v1-Figure2-1.png",
            "$2305.00151v1-Figure5-1.png",
            "$2305.00151v1-Figure6-1.png",
            "$2305.00151v1-Figure7-1.png",
            "$2305.00151v1-Figure8-1.png",
            "$2305.00151v1-FigureA.2-1.png",
            "$2305.00151v1-FigureA.3-1.png",
            "$2305.00151v1-Table1-1.png",
            "$2305.00151v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00152",
        "abstract": "  Theoretical studies on transfer learning or domain adaptation have so far\nfocused on situations with a known hypothesis class or model; however in\npractice, some amount of model selection is usually involved, often appearing\nunder the umbrella term of hyperparameter-tuning: for example, one may think of\nthe problem of tuning for the right neural network architecture towards a\ntarget task, while leveraging data from a related source task.\n  Now, in addition to the usual tradeoffs on approximation vs estimation errors\ninvolved in model selection, this problem brings in a new complexity term,\nnamely, the transfer distance between source and target distributions, which is\nknown to vary with the choice of hypothesis class.\n  We present a first study of this problem, focusing on classification; in\nparticular, the analysis reveals some remarkable phenomena: adaptive rates,\ni.e., those achievable with no distributional information, can be arbitrarily\nslower than oracle rates, i.e., when given knowledge on distances.\n",
        "title": "Limits of Model Selection under Transfer Learning",
        "texts": [
            "Figure 1: A simple example, following up on NN Examples 1 and 2, where i♯ . = argmini ϕ ♯(i) is different from i∗P . Here, decision boundaries under P are depicted in black, whereby each h∗P,i, i = 1, 2, 3, corresponds to the i boundaries on the left of it, including those of h∗P,i−1 (level Hi allows up to i boundaries). Now decision boundaries under Q (as depicted in gray) are shifted to the right of boundaries under P : as a consequence all h∗Pi ’s have similar excess Q-error EQ, so that i♯ is determined by ρi’s. Now for this hierarchy, ρi may decrease (better transferability) for smaller levels i simply by virtue of P assigning more mass to corresponding decision boundaries as i decreases, as suggested by the density dPX/dQX which is depicted in dashed lines."
        ],
        "imgs": [
            "$2305.00152v4-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00156",
        "abstract": "  We introduce in this paper the mechanism of graph random features (GRFs).\nGRFs can be used to construct unbiased randomized estimators of several\nimportant kernels defined on graphs' nodes, in particular the regularized\nLaplacian kernel. As regular RFs for non-graph kernels, they provide means to\nscale up kernel methods defined on graphs to larger networks. Importantly, they\ngive substantial computational gains also for smaller graphs, while applied in\ndownstream applications. Consequently, GRFs address the notoriously difficult\nproblem of cubic (in the number of the nodes of the graph) time complexity of\ngraph kernels algorithms. We provide a detailed theoretical analysis of GRFs\nand an extensive empirical evaluation: from speed tests, through Frobenius\nrelative error analysis to kmeans graph-clustering with graph kernels. We show\nthat the computation of GRFs admits an embarrassingly simple distributed\nalgorithm that can be applied if the graph under consideration needs to be\nsplit across several machines. We also introduce a (still unbiased) quasi Monte\nCarlo variant of GRFs, q-GRFs, relying on the so-called reinforced random\nwalks, that might be used to optimize the variance of GRFs. As a byproduct, we\nobtain a novel approach to solve certain classes of linear equations with\npositive and symmetric matrices.\n",
        "title": "Taming graph kernels with random features",
        "texts": [
            "Figure 1. The pictorial representation of signature vectors. The contibutions to the dot-product between two signature vectors come from the vertices that were visited by both vectors.",
            "Figure 2. Relative Frobenius norm error for the setting described in Sec. 5.2. First two rows correspond to d = 1 and last two to d = 2. We considered the following graphs (from upper-left to lower-right): Erdos-Renyi graph with edge prob. 0.4 (ER-0.4, N = 1000), ER-0.1 (N = 1000), dolphins (N = 62), eurosis (N = 1272), Networking (N = 1249), Databases (N = 1046), Encryption-and-Compression (N = 864), Hardware-and-Architecture (N = 763).",
            "Table 1. The comparison of the number of FLOPS for the setting from Sec. 5.1 for different linear systems solvers and GRFs. Different rows correspond to: N = 800, N = 1000 and N = 3000.",
            "Table 2. Clustering errors for the experiments from Sec. 5.3 (for the d-regularized Laplacian kernel). Different tested methods: (1) regular GRFs (reg, no compression), (2) GRFs with the more accurate among: JLT (jlt), and anchor points (anc) techniques.",
            "Table 3. Standard deviations for the experiments from Sec. 5.2 (for the d-regularized Laplacian kernel)."
        ],
        "imgs": [
            "$2305.00156v1-Figure1-1.png",
            "$2305.00156v1-Figure2-1.png",
            "$2305.00156v1-Table1-1.png",
            "$2305.00156v1-Table2-1.png",
            "$2305.00156v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00157",
        "abstract": "  We study the extended thermodynamics of the hyperbolic black hole with scalar\nhair and obtain the extended holographic R\\'{e}nyi entropy of holographic\nconformal field theories with scalar hair. We analyze the behaviors of the\nextended holographic R\\'{e}nyi entropy in terms of holographic calculations.\nMoreover, we generalize the capacity of entanglement from the extended\nR\\'{e}nyi entropy and show that it maps to the heat capacity of the thermal\nconformal field theories on the hyperbolic space.\n",
        "title": "Extended Holographic R\\'{e}nyi Entropy and hyperbolic black hole with\n  scalar hair",
        "texts": [
            "Figure 1. Isotherms in the P -V diagrams of the hairy hyperbolic AdS black hole. We set GN = VΣ = T = 1. Left: the solid curve is the hairy hyperbolic black hole with α = 0.5, while the dashed curve is the hyperbolic black hole with α = 0 (without scalar hair). Right: the solid curve is the hairy hyperbolic black hole with α = 0.6, while the dashed curve is the hyperbolic black hole with α = 0(without scalar hair).",
            "Figure 2. The Gibbs free energy as a function of temperature at fixed p = GN = VΣ = 1 for different values of α. The solid curve is the hairy black hole where blue one is for r+, and orange one is for r−, while the dashed curve is the hyperbolic black hole without scalar hair. The relation between the temperature and horizon radius of black hole is described in the subfigure."
        ],
        "imgs": [
            "$2305.00157v1-Figure1-1.png",
            "$2305.00157v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00160",
        "abstract": "  We study the universal dynamical relaxation behaviors of a quantum XY chain\nfollowing a quench, paying special attention to the case that the prequenched\nHamiltonian, or the postquenched Hamiltonian, or both of them are at critical\npoints of equilibrium quantum phase transitions. In such ``critical quench\", we\nfind very interesting real-time dynamical scaling behaviors and the crossover\nphenomena between them. For a quench from a noncritical point to a critical\npoint, we find that, compared to the noncritical quench, the universal\npower-law scaling behavior does not change; however, there may be a crossover\nbetween the exponential decaying behavior and the power-law scaling. For a\nquench from a critical point to a noncritical point, the power-law scaling\nbehaviors $t^{-3/2}$ and $t^{-3/4}$ in the noncritical quenches may be changed\nto $t^{-1}$ and $t^{-1/2}$, respectively. If the prequenched Hamiltonian is set\nto be a point that is close to but not exactly at a critical point, we find\ninteresting crossover phenomena between different power-law scaling behaviors.\nWe also study the quench from the vicinity of a multicritical point, we find\ncrossover behaviors that are induced by a different mechanism, and new\ncrossover exponent is found. All the results are related to the gap-closing\nproperties of the energy spectrum of the critical points.\n",
        "title": "Dynamical relaxation behaviors of a critical quench",
        "texts": [
            "FIG. 1. Equilibrium phase diagram of the XY model (1): for |h| < 1, the system is in the ferromagnetic or antiferromagnetic ordered phase; for |h| > 1, the system is in the paramagnetic disordered phase; A, B, and E are incommensurate phases; C, D, and F are commensurate phases; the dashed lines are the boundaries between the incommensurate and commensurate phases.",
            "FIG. 3. Crossover of a qench from (h, χ)=(1.5, 2) to (1, 0.2); the subset is a quasi-logarithmic plot of the early time region.",
            "FIG. 8. (a) crossover behavior of a quench from (1+ δh, χ) = (1.02, 1) to (0.75, 1/ √ 2); (b) crossover time τc versus δh.",
            "FIG. 9. (a) crossover behavior of a quench from (1+ δh, χ) = (1.1, 0.5) to (0.5, 1/ √ 2); (b) crossover time τc versus δh."
        ],
        "imgs": [
            "$2305.00160v2-Figure1-1.png",
            "$2305.00160v2-Figure3-1.png",
            "$2305.00160v2-Figure8-1.png",
            "$2305.00160v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00161",
        "abstract": "  This paper presents ViewFormer, a simple yet effective model for multi-view\n3d shape recognition and retrieval. We systematically investigate the existing\nmethods for aggregating multi-view information and propose a novel ``view set\"\nperspective, which minimizes the relation assumption about the views and\nreleases the representation flexibility. We devise an adaptive attention model\nto capture pairwise and higher-order correlations of the elements in the view\nset. The learned multi-view correlations are aggregated into an expressive view\nset descriptor for recognition and retrieval. Experiments show the proposed\nmethod unleashes surprising capabilities across different tasks and datasets.\nFor instance, with only 2 attention blocks and 4.8M learnable parameters,\nViewFormer reaches 98.8% recognition accuracy on ModelNet40 for the first time,\nexceeding previous best method by 1.1% . On the challenging RGBD dataset, our\nmethod achieves 98.4% recognition accuracy, which is a 4.1% absolute\nimprovement over the strongest baseline. ViewFormer also sets new records in\nseveral evaluation dimensions of 3D shape retrieval defined on the SHREC'17\nbenchmark.\n",
        "title": "ViewFormer: View Set Attention for Multi-view 3D Shape Understanding",
        "texts": [
            "Figure 1: A division for multi-view 3D shape analysis methods based on how they organize views and aggregate multiview information. View Set is the proposed perspective that the views of a 3D shape are organized in a set.",
            "Figure 2: Visualization of the attention scores for 8 views of a 3D airplane.",
            "Figure 3: Visualization of 3D shape feature distribution on ModelNet10 (MN10), ModelNet40 (MN40) and RGBD.",
            "Figure 4: Visualization of the top 10 retrieved results for each query shape.",
            "Figure 5: Comparison of instance accuracy on ModelNet40 when using 1-stage and 2-stage optimization.",
            "Figure 6: The learning rate curve for optimizing ViewFormer.",
            "Figure 7: Learning efficiency of ViewFormer.",
            "Figure 8: Visualization of multi-view attention of 8 views of a nightstand in colored lines.",
            "Figure 9: Visualization of multi-view attention for all view pairs of a range hood in colorful lines.",
            "Table 1: Comparison of 3D shape recognition on ModelNet40. The best score is in bold black and the second best is in blue. The convention is kept in the following tables.",
            "Table 12: Ablation study: the number of views.",
            "Table 13: Ablation study: different methods using a same Initializer.",
            "Table 14: Ablation Study: the architecture of Encoder.",
            "Table 15: Ablation study: the performance gains brought by the devised encoder over Initializer.",
            "Table 16: Ablation study: effect of the patch-level correlations.",
            "Table 2: Comparison of 3D shape recognition on ModelNet10.",
            "Table 3: Comparison of 3D shape recognition on RGBD.",
            "Table 4: Comparison of 3D shape retrieval on ShapeNet Core55.",
            "Table 5: Ablation study: choices for Initializer.",
            "Table 6: Ablation study: position encoding and class token.",
            "Table 7: Ablation study: number of attention blocks.",
            "Table 8: Ablation study: choices for Transition.",
            "Table 9: Ablation study: choices for Decoder."
        ],
        "imgs": [
            "$2305.00161v1-Figure1-1.png",
            "$2305.00161v1-Figure2-1.png",
            "$2305.00161v1-Figure3-1.png",
            "$2305.00161v1-Figure4-1.png",
            "$2305.00161v1-Figure5-1.png",
            "$2305.00161v1-Figure6-1.png",
            "$2305.00161v1-Figure7-1.png",
            "$2305.00161v1-Figure8-1.png",
            "$2305.00161v1-Figure9-1.png",
            "$2305.00161v1-Table1-1.png",
            "$2305.00161v1-Table12-1.png",
            "$2305.00161v1-Table13-1.png",
            "$2305.00161v1-Table14-1.png",
            "$2305.00161v1-Table15-1.png",
            "$2305.00161v1-Table16-1.png",
            "$2305.00161v1-Table2-1.png",
            "$2305.00161v1-Table3-1.png",
            "$2305.00161v1-Table4-1.png",
            "$2305.00161v1-Table5-1.png",
            "$2305.00161v1-Table6-1.png",
            "$2305.00161v1-Table7-1.png",
            "$2305.00161v1-Table8-1.png",
            "$2305.00161v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00162",
        "abstract": "  To provide real-time parking information, existing studies focus on\npredicting parking availability, which seems an indirect approach to saving\ndrivers' cruising time. In this paper, we first time propose an on-street\nparking recommendation (OPR) task to directly recommend a parking space for a\ndriver. To this end, a learn-to-rank (LTR) based OPR model called OPR-LTR is\nbuilt. Specifically, parking recommendation is closely related to the \"turnover\nevents\" (state switching between occupied and vacant) of each parking space,\nand hence we design a highly efficient heterogeneous graph called ESGraph to\nrepresent historical and real-time meters' turnover events as well as\ngeographical relations; afterward, a convolution-based event-then-graph network\nis used to aggregate and update representations of the heterogeneous graph. A\nranking model is further utilized to learn a score function that helps\nrecommend a list of ranked parking spots for a specific on-street parking\nquery. The method is verified using the on-street parking meter data in Hong\nKong and San Francisco. By comparing with the other two types of methods:\nprediction-only and prediction-then-recommendation, the proposed\ndirect-recommendation method achieves satisfactory performance in different\nmetrics. Extensive experiments also demonstrate that the proposed ESGraph and\nthe recommendation model are more efficient in terms of computational\nefficiency as well as saving drivers' on-street parking time.\n",
        "title": "Beyond Prediction: On-street Parking Recommendation using Heterogeneous\n  Graph-based List-wise Ranking",
        "texts": [
            "Fig. 1. An OPR example. A driver sends a parking request at destination D at 10:01, then receives a recommended list from an OPR model with ranked results of the destination.",
            "Fig. 2. Converting a STGraph to an ESGraph. (A) A sequence of spatial graphs from a previous time tn to a present time t0 with fixed time interval. (B) Edge-contraction in one temporal path of STGraph. (C). The resulting event-spatial heterogeneous graph with 1 turn-over event. (D) One spatial vertex with its 1-D spatial adjacent and 3 turn-over events.",
            "Fig. 3. Overview of the model architecture of proposed OPR-LTR. The mode mainly included three parts: ESGraph input, event-then-graph Convolutional Layer, and Readout layer. Gated 1D Conv is the component of the graph convolutional layer and Inter query-item & inter-item dependency learning is the component of the readout layer.",
            "Fig. 4. Study of ESGraph Representation.",
            "Fig. 5. Study of Practical Effectiveness. Compared models are AppNDCG (AN), Prediction-Only models (PO), T-GCN (TG), DCRNN (DC), GAMCN (GA), STPGCN (ST), and the Proposed OPR-LTR (OL).",
            "Fig. 6. Comparison of the space and time complexity.",
            "TABLE I METRICS PERFORMANCE IN HONG KONG AND SAN FRANCISCO.",
            "TABLE II COMPARISON OF DIFFERENT MODEL SIZES.",
            "TABLE III DIFFERENT DEPENDENCIES’ CONTRIBUTION STUDY."
        ],
        "imgs": [
            "$2305.00162v1-Figure1-1.png",
            "$2305.00162v1-Figure2-1.png",
            "$2305.00162v1-Figure3-1.png",
            "$2305.00162v1-Figure4-1.png",
            "$2305.00162v1-Figure5-1.png",
            "$2305.00162v1-Figure6-1.png",
            "$2305.00162v1-TableI-1.png",
            "$2305.00162v1-TableII-1.png",
            "$2305.00162v1-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00163",
        "abstract": "  In video super-resolution, it is common to use a frame-wise alignment to\nsupport the propagation of information over time. The role of alignment is\nwell-studied for low-level enhancement in video, but existing works overlook a\ncritical step -- resampling. We show through extensive experiments that for\nalignment to be effective, the resampling should preserve the reference\nfrequency spectrum while minimizing spatial distortions. However, most existing\nworks simply use a default choice of bilinear interpolation for resampling even\nthough bilinear interpolation has a smoothing effect and hinders\nsuper-resolution. From these observations, we propose an implicit\nresampling-based alignment. The sampling positions are encoded by a sinusoidal\npositional encoding, while the value is estimated with a coordinate network and\na window-based cross-attention. We show that bilinear interpolation inherently\nattenuates high-frequency information while an MLP-based coordinate network can\napproximate more frequencies. Experiments on synthetic and real-world datasets\nshow that alignment with our proposed implicit resampling enhances the\nperformance of state-of-the-art frameworks with minimal impact on both compute\nand parameters.\n",
        "title": "Enhancing Video Super-Resolution via Implicit Resampling-based Alignment",
        "texts": [
            "Figure 2: A comparison diagram between bilinear interpolation and our implicit alignment. Bilinear interpolation fixes aggregation weight Wbi. Implicit alignment learns affinity through the cross-attention module to calculate the final result. Red grids denote the source frame, purple grids denote the target frame, and blue grids denote the aligned frame.",
            "Figure 3: Qualitative comparison on REDS4 dataset. We highlight the detail regions with yellow boxes. Compared with BasicVSR, IA-CNN provides more details on the wall and more uniform patterns on the window.",
            "Figure 4: Qualitative comparison on VideoLQ dataset. Our proposed IA method recovers the building details and the brick textures, which ReadlBasicVSR does not recover. We highlight the detail regions with yellow boxes.",
            "Table 1: PSNR/SSIM Comparison of VSR transformers on Sintel datasets with optical flow of different accuracies for alignment. The best score is marked in bold.",
            "Table 2: Quantitative comparison on the REDS4 [22] dataset, Vid4 [20], Vimeo-90K-T [31] dataset for 4× VSR task. The best score is marked in bold.",
            "Table 3: Ablations on positional encodings. The positional encoding improves the alignment effectiveness compared to the naive window-based cross-attention.",
            "Table 4: PSNR/SSIM for different window sizes."
        ],
        "imgs": [
            "$2305.00163v1-Figure2-1.png",
            "$2305.00163v1-Figure3-1.png",
            "$2305.00163v1-Figure4-1.png",
            "$2305.00163v1-Table1-1.png",
            "$2305.00163v1-Table2-1.png",
            "$2305.00163v1-Table3-1.png",
            "$2305.00163v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00164",
        "abstract": "  Optimal estimation and inference for both the minimizer and minimum of a\nconvex regression function under the white noise and nonparametric regression\nmodels are studied in a nonasymptotic local minimax framework, where the\nperformance of a procedure is evaluated at individual functions. Fully adaptive\nand computationally efficient algorithms are proposed and sharp minimax lower\nbounds are given for both the estimation accuracy and expected length of\nconfidence intervals for the minimizer and minimum.\n  The nonasymptotic local minimax framework brings out new phenomena in\nsimultaneous estimation and inference for the minimizer and minimum. We\nestablish a novel uncertainty principle that provides a fundamental limit on\nhow well the minimizer and minimum can be estimated simultaneously for any\nconvex regression function. A similar result holds for the expected length of\nthe confidence intervals for the minimizer and minimum.\n",
        "title": "Estimation and inference for minimizer and minimum of convex functions:\n  optimality, adaptivity and uncertainty principles",
        "texts": [
            "Fig 1: Water filling process.",
            "Fig 2: Illustration of the localization step. At level j, the middle two intervals are the two subintervals of the selected interval at level j − 1. One adjacent interval of the same length on each side is added and the interval at level j is selected among these four intervals.",
            "Fig 3: Illustration of the stopping rule."
        ],
        "imgs": [
            "$2305.00164v1-Figure1-1.png",
            "$2305.00164v1-Figure2-1.png",
            "$2305.00164v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00165",
        "abstract": "  The rapidly expanding market for regenerative medicines and cell therapies\nhighlights the need to advance the understanding of cellular metabolisms and\nimprove the prediction of cultivation production process for human induced\npluripotent stem cells (iPSCs). In this paper, a metabolic kinetic model was\ndeveloped to characterize underlying mechanisms of iPSC culture process, which\ncan predict cell response to environmental perturbation and support process\ncontrol. This model focuses on the central carbon metabolic network, including\nglycolysis, pentose phosphate pathway (PPP), tricarboxylic acid (TCA) cycle,\nand amino acid metabolism, which plays a crucial role to support iPSC\nproliferation. Heterogeneous measures of extracellular metabolites and multiple\nisotopic tracers collected under multiple conditions were used to learn\nmetabolic regulatory mechanisms. Systematic cross-validation confirmed the\nmodel's performance in terms of providing reliable predictions on cellular\nmetabolism and culture process dynamics under various culture conditions. Thus,\nthe developed mechanistic kinetic model can support process control strategies\nto strategically select optimal cell culture conditions at different times,\nensure cell product functionality, and facilitate large-scale manufacturing of\nregenerative medicines and cell therapies.\n",
        "title": "Metabolic Regulatory Network Kinetic Modeling with Multiple Isotopic\n  Tracers for iPSCs",
        "texts": [
            "Figure 1: A schematic of the time-course extracellular concen-",
            "Figure 10: Cell characteristic predictions for the low glucose and high lactate cultures using the dynamic model trained on different",
            "Figure 11: Cell characteristic predictions for the high glucose and high lactate cultures using the dynamic model trained on the",
            "Figure 12: Cell characteristic predictions for the low glucose and low lactate cultures using the dynamic model trained on the",
            "Figure 13: Cell characteristic predictions for the low glucose and high lactate cultures using the dynamic model trained on the",
            "Figure 14: Metabolic flux maps for K3 iPSC for the high glucose and high lactate cultures at 24-h and 48-h. Predicted fluxes are given in nmol/106 cells⋅h. The line thicknesses represent the relative fluxes.",
            "Figure 15: Metabolic flux maps for K3 iPSC for the low glucose and low lactate cultures at 24-h and 48-h. Predicted fluxes are given in nmol/106 cells⋅h. The line thicknesses represent the relative fluxes.",
            "Figure 16: Metabolic flux maps for K3 iPSC for the low glucose and high lactate cultures at 24-h and 48-h. Predicted fluxes are given in nmol/106 cells⋅h. The line thicknesses represent the relative fluxes.",
            "Figure 2: The iPSC regulatory metabolic network. Glycolysis,",
            "Figure 3: Cell characteristic predictions for the high glucose and low lactate cultures using the dynamic model trained on different",
            "Figure 4: Cell characteristic predictions for the high glucose and low lactate cultures using the dynamic model trained on the",
            "Figure 7: Metabolic flux maps for K3 iPSC for the high glucose and low lactate cultures at 24-h and 48-h. Predicted fluxes are given in nmol/106 cells⋅h. The line thicknesses represent the relative fluxes.",
            "Figure 8: Cell characteristic predictions for the high glucose and high lactate cultures using the dynamic model trained on different",
            "Figure 9: Cell characteristic predictions for the low glucose and low lactate cultures using the dynamic model trained on different",
            "Table 1 Dynamic model prediction for biomass-specific uptake and production rates for key extracellular metabolite (nmol/106 cells⋅h)."
        ],
        "imgs": [
            "$2305.00165v1-Figure1-1.png",
            "$2305.00165v1-Figure10-1.png",
            "$2305.00165v1-Figure11-1.png",
            "$2305.00165v1-Figure12-1.png",
            "$2305.00165v1-Figure13-1.png",
            "$2305.00165v1-Figure14-1.png",
            "$2305.00165v1-Figure15-1.png",
            "$2305.00165v1-Figure16-1.png",
            "$2305.00165v1-Figure2-1.png",
            "$2305.00165v1-Figure3-1.png",
            "$2305.00165v1-Figure4-1.png",
            "$2305.00165v1-Figure7-1.png",
            "$2305.00165v1-Figure8-1.png",
            "$2305.00165v1-Figure9-1.png",
            "$2305.00165v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00168",
        "abstract": "  Two-dimensional chromium ditelluride (CrTe2) is a promising ferromagnetic\nlayered material that exhibits long-range ferromagnetic ordering in the\nmonolayer limit. The formation energies of the different possible structural\nphases (1T, 1H, 2H) calculated from density functional theory (DFT) show that\nthe 1T phase is the ground state, and the energetic transition barriers between\nthe phases, calculated by the nudged elastic band method, are large, on the\norder of 0.5 eV. The self-consistent Hubbard $U$ correction parameters are\ncalculated for all the phases of CrTe$_2$. The calculated magnetic moment of\n1T-CrTe$_2$ with $\\geq 2$ layers lies in the plane, whereas the magnetic moment\nof a monolayer is out-of-plane. Band filling and tensile bi-axial strain cause\nthe magnetic moment of a monolayer to switch from out-of-plane to in-plane, and\ncompressive bi-axial strain in a bilayer causes the magnetic moment to switch\nfrom in-plane to out-of-plane. The magnetic anisotropy is shown to originate\nfrom the large spin orbit coupling (SOC) of the Te atoms and the anisotropy of\nthe exchange coupling constants $J_{xy}$ and $J_z$ in an XXZ type Hamiltonian.\nRenormalized spin wave theory using experimental values for the magnetic\nanisotropy energy and Curie temperatures provides a range of values for the\nnearest neighbor exchange coupling.\n",
        "title": "Structural, electronic, and magnetic properties of CrTe2",
        "texts": [
            "FIG. 1. Top and lateral views of 1T, 1H, and 2H phases of CrTe2. The unit cells are shown by the thin lines. Blue and golden balls represent Cr and Te atoms, respectively. The 1T phase contains one formula unit (f.u.) per unit cell in a hexagonal lattice belonging to the P 3̄m1 space group with each Cr atom surrounded by Te atoms in octahedral coordination. The 1H and 2H phases are hexagonal, trigonal prismatic, and the difference between the two phases is in their interlayer stacking. In the 1H structure, layers are stacked directly on top of each other so that the 1H structure contains 1 f.u. / unit cell and belongs to the P 6̄m2 space group. The 2H structure contains 2 f.u. / unit cell and belongs to the P63/mmc space group.",
            "TABLE I. U parameters of the Cr atom in CrTe2 calculated from linear response method.",
            "TABLE II. Formation Energies Eform (eV) and relaxed lattice constants for different phases of CrTe2 in bulk, monolayer (1L) and bilayer (2L) geometries. For the bilayer structure, c corresponds to the interlayer Cr-Cr distance."
        ],
        "imgs": [
            "$2305.00168v1-Figure1-1.png",
            "$2305.00168v1-TableI-1.png",
            "$2305.00168v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00172",
        "abstract": "  Portfolio selection involves optimizing simultaneously financial goals such\nas risk, return and Sharpe ratio. This problem holds considerable importance in\neconomics. However, little has been studied related to the nonconvexity of the\nobjectives. This paper proposes a novel generalized approach to solve the\nchallenging Portfolio Selection problem in an intuitionistic fuzzy environment\nwhere the objectives are soft pseudoconvex functions, and the constraint set is\nconvex. Specifically, we utilize intuitionistic fuzzy theory and flexible\noptimization to transform the fuzzy pseudoconvex multicriteria vector into a\npseudoconvex programming problem that can be solved by recent gradient descent\nmethods. We demonstrate that our method can be applied broadly without special\nforms on membership and nonmembership functions as in previous works.\nComputational experiments on real-world scenarios are reported to show the\neffectiveness of our method.\n",
        "title": "Multicriteria Portfolio Selection with Intuitionistic Fuzzy Goals as a\n  Pseudoconvex Vector Optimization",
        "texts": [
            "Table 2. Covariance matrix of chosen stocks",
            "Table 4. E(x),V(x) and Sr(x) values of the solution"
        ],
        "imgs": [
            "$2305.00172v1-Table2-1.png",
            "$2305.00172v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00175",
        "abstract": "  Constrained clustering problems generalize classical clustering formulations,\ne.g., $k$-median, $k$-means, by imposing additional constraints on the\nfeasibility of clustering. There has been significant recent progress in\nobtaining approximation algorithms for these problems, both in the metric and\nthe Euclidean settings. However, the outlier version of these problems, where\nthe solution is allowed to leave out $m$ points from the clustering, is not\nwell understood. In this work, we give a general framework for reducing the\noutlier version of a constrained $k$-median or $k$-means problem to the\ncorresponding outlier-free version with only $(1+\\varepsilon)$-loss in the\napproximation ratio. The reduction is obtained by mapping the original instance\nof the problem to $f(k,m, \\varepsilon)$ instances of the outlier-free version,\nwhere $f(k, m, \\varepsilon) = \\left( \\frac{k+m}{\\varepsilon}\\right)^{O(m)}$. As\nspecific applications, we get the following results:\n  - First FPT (in the parameters $k$ and $m$) $(1+\\varepsilon)$-approximation\nalgorithm for the outlier version of capacitated $k$-median and $k$-means in\nEuclidean spaces with hard capacities.\n  - First FPT (in the parameters $k$ and $m$) $(3+\\varepsilon)$ and\n$(9+\\varepsilon)$ approximation algorithms for the outlier version of\ncapacitated $k$-median and $k$-means, respectively, in general metric spaces\nwith hard capacities.\n  - First FPT (in the parameters $k$ and $m$) $(2-\\delta)$-approximation\nalgorithm for the outlier version of the $k$-median problem under the Ulam\nmetric. Our work generalizes the known results to a larger class of constrained\nclustering problems. Further, our reduction works for arbitrary metric spaces\nand so can extend clustering algorithms for outlier-free versions in both\nEuclidean and arbitrary metric spaces.\n",
        "title": "Clustering What Matters in Constrained Settings",
        "texts": [
            "Table 1. The table defines various outlier-free versions of the constrained k-median problem. The k-means versions are defined similarly using D2 instead of D. We include a few references. The problems are categorized based on the type of constraints. There are three main types of constraints (i) size (constraints on the cluster size), (ii) center (constraints on the points a center can service), and (iii) label (constraints on the label of points in clusters). A constrained problem can have a combination of these constraint types.",
            "Table 2. A × means that the techniques are not known to apply to the problem. The new results that do not follow"
        ],
        "imgs": [
            "$2305.00175v1-Table1-1.png",
            "$2305.00175v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00179",
        "abstract": "  It is anticipated that integrated sensing and communications (ISAC) would be\none of the key enablers of next-generation wireless networks (such as beyond 5G\n(B5G) and 6G) for supporting a variety of emerging applications. In this paper,\nwe provide a comprehensive review of the recent advances in ISAC systems, with\na particular focus on their foundations, system design, networking aspects and\nISAC applications. Furthermore, we discuss the corresponding open questions of\nthe above that emerged in each issue. Hence, we commence with the information\ntheory of sensing and communications (S$\\&$C), followed by the\ninformation-theoretic limits of ISAC systems by shedding light on the\nfundamental performance metrics. Next, we discuss their clock synchronization\nand phase offset problems, the associated Pareto-optimal signaling strategies,\nas well as the associated super-resolution ISAC system design. Moreover, we\nenvision that ISAC ushers in a paradigm shift for the future cellular networks\nrelying on network sensing, transforming the classic cellular architecture,\ncross-layer resource management methods, and transmission protocols. In ISAC\napplications, we further highlight the security and privacy issues of wireless\nsensing. Finally, we close by studying the recent advances in a representative\nISAC use case, namely the multi-object multi-task (MOMT) recognition problem\nusing wireless signals.\n",
        "title": "Integrated Sensing and Communications: Recent Advances and Ten Open\n  Challenges",
        "texts": [
            "Fig. 1. The topology of monostatic/bistatic deployments and single-cell/cooperative scenarios.",
            "Fig. 10. Range bias caused by TMO.",
            "Fig. 11. Different compensation techniques in ISAC systems.",
            "Fig. 12. Illustration of the Pareto boundary of achievable performance region.",
            "Fig. 14. Array geometry of the 6-antenna nested array and coprime array.",
            "Fig. 15. Potential cellular architecture in ISAC systems.",
            "Fig. 16. Sensing security and privacy scenarios.",
            "Fig. 17. Radio signal processing pipeline for human sensing.",
            "Fig. 18. Sensing measurements that contain different information. (a) 3D time-Range-Doppler map, (b) 2-dimensional (2D) time-Doppler map, (c) 2D time-range map, and (d) 2D range-Doppler map.",
            "Fig. 19. Time-Doppler frequency maps from a WiFi system and a 5G NR system, respectively.",
            "Fig. 20. Design guidelines and future research directions for ISAC systems.",
            "Fig. 21. Stylized factors affecting the Pareto-optimal design of ISAC systems.",
            "Fig. 4. CRB and BCRB versus SNR.",
            "Fig. 5. The pentagon inner bound of the CRB-rate region.",
            "Fig. 6. Three categories of S&C environment with typical scenarios.",
            "Fig. 7. Channel parameters between S&C with the corresponding factor graph.",
            "Fig. 9. Graphical illustration of various integration and coordination scenarios."
        ],
        "imgs": [
            "$2305.00179v1-Figure1-1.png",
            "$2305.00179v1-Figure10-1.png",
            "$2305.00179v1-Figure11-1.png",
            "$2305.00179v1-Figure12-1.png",
            "$2305.00179v1-Figure14-1.png",
            "$2305.00179v1-Figure15-1.png",
            "$2305.00179v1-Figure16-1.png",
            "$2305.00179v1-Figure17-1.png",
            "$2305.00179v1-Figure18-1.png",
            "$2305.00179v1-Figure19-1.png",
            "$2305.00179v1-Figure20-1.png",
            "$2305.00179v1-Figure21-1.png",
            "$2305.00179v1-Figure4-1.png",
            "$2305.00179v1-Figure5-1.png",
            "$2305.00179v1-Figure6-1.png",
            "$2305.00179v1-Figure7-1.png",
            "$2305.00179v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00187",
        "abstract": "  We consider a stochastic matching model with a general compatibility graph,\nas introduced in \\cite{MaiMoy16}. We prove that most common matching policies\n(including FCFM, priorities and random) satisfy a particular sub-additive\nproperty, which we exploit to show in many cases, the coupling-from-the-past to\nthe steady state, using a backwards scheme {\\em \\`a la} Loynes. We then use\nthese results to explicitly construct perfect bi-infinite matchings, and to\nbuild a perfect simulation algorithm in the case where the buffer of the system\nis finite.\n",
        "title": "On the sub-additivity of stochastic matching",
        "texts": [
            "Figure 1: The ‘paw’ graph.",
            "Figure 10: The two perfect matchings Mfcfm(ijy1y2) and Mfcfm(y1y2), for an even p and an odd q.",
            "Figure 2: ’Match the Shortest’ is not sub-additive.",
            "Figure 4: Construction of the increasing sequence ( M {Y,0} n (φ) ) n∈N for a given sample ω, Y (ω) = 13, φ = lcfm and G the compatibility graph of Figure 1.",
            "Figure 5: Backwards construction of the sequence ( M {∅,m} ∞ (φ) ) m∈Z for φ = lcfm and G, the compatibility graph of Figure 1. Adding nodes on the left of the matching may break the matches performed at the previous step.",
            "Figure 7: Two perfect bi-infinite fcfm- (or ml-) matchings corresponding to the graph of Figure 1 and the same input.",
            "Figure 8: Top: Two blocks matched in fcfm. Bottom: completion of the exchanges by matchings."
        ],
        "imgs": [
            "$2305.00187v2-Figure1-1.png",
            "$2305.00187v2-Figure10-1.png",
            "$2305.00187v2-Figure2-1.png",
            "$2305.00187v2-Figure4-1.png",
            "$2305.00187v2-Figure5-1.png",
            "$2305.00187v2-Figure7-1.png",
            "$2305.00187v2-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00189",
        "abstract": "  Circulatory system abnormalities might be an indicator of diseases or tissue\ndamage. Early detection of vascular abnormalities might have an important role\nduring treatment and also raise the patient's awarenes. Current detection\nmethods for vascular imaging are high-cost, invasive, and mostly\nradiation-based. In this study, a low-cost and portable microcomputer-based\ntool has been developed as a near-infrared (NIR) superficial vascular imaging\ndevice. The device uses NIR light-emitting diode (LED) light at 850 nm along\nwith other electronic and optical components. It operates as a non-contact and\nsafe infrared (IR) imaging method in real-time. Image and video analysis are\ncarried out using OpenCV (Open-Source Computer Vision), a library of\nprogramming functions mainly used in computer vision. Various tests were\ncarried out to optimize the imaging system and set up a suitable external\nenvironment. To test the performance of the device, the images taken from three\ndiabetic volunteers, who are expected to have abnormalities in the vascular\nstructure due to the possibility of deformation caused by high glucose levels\nin the blood, were compared with the images taken from two non-diabetic\nvolunteers. As a result, tortuosity was observed successfully in the\nsuperficial vascular structures, where the results need to be interpreted by\nthe medical experts in the field to understand the underlying reasons. Although\nthis study is an engineering study and does not have an intention to diagnose\nany diseases, the developed system here might assist healthcare personnel in\nearly diagnosis and treatment follow-up for vascular structures and may enable\nfurther opportunities.\n",
        "title": "Real-Time Superficial Vein Imaging System for Observing Abnormalities on\n  Vascular Structures",
        "texts": [
            "Figure 1: NIR Imaging Module. (A) Transmission of light. (B) Reflection of light.",
            "Figure 10: Adjusting the lighting of the system. (A, B) Images taken by changing the angles of the LEDs to test for decreasing the glare effect. (C, D) Images captured by changing the distance of the target to the camera to select the optimal distance between the device and the target with less glare and data loss.",
            "Figure 11: Demonstrating the effectiveness of the device for superficial vein images of the arm and hand. (A, D) Raw images. (B, E) Images with removed background. (C, F) CLAHE applied.",
            "Figure 12: Frangi filtering application to the superficial veins of the foot to detect vessel-like or tube-like structures. (A) Raw image with background removed. (B) Raw image with CLAHE applied. (C) Frangi filtering followed by CLAHE.",
            "Figure 13: Vascular structure images of the lower leg and foot taken from diabetic volunteers (Volunteers I, II, III) , who are expected to have abnormal vascular structure because of deformations caused by high blood sugar in the blood. Raw images and output superficial vein images after all processing are represented for each diabetic volunteer, respectively: (A, D) elderly diabetic person “Volunteer I” with toe amputation due to diabetic foot, (B, E) a middle-aged person (Volunteer II) with diabetes using insulin, (C, F) an elderly volunteer with newly diagnosed diabetes uses only medicine, not insulin (Volunteer III).",
            "Figure 14: Vascular structure images of the lower leg and foot taken from non-diabetic volunteers (Volunteers IV, V) who are expected to have healthier vascular structure compared to volunteers with diabetes. (A, B, C) Raw images. (D, E, F) Output superficial vein images after all processing are applied. (A, B, D, E) Images belong to Volunteer IV and (C, F) images belong to Volunteer V.",
            "Figure 2: Block diagram of the system containing hardware and software components.",
            "Figure 4: Operating structure of the system. (A) Illustration of the hardware system and a real result with the process applied on the screen. (B) Real-time image acquisition from one of the volunteers. (C) A display screenshot of the real-time video processing result.",
            "Figure 5: The neighborhood structure of inner regions in the CLAHE. (A) A given IR region with its all-neighboring regions. (B) The first quarter of (i,j) region and its relations with the closest four regions [42]",
            "Figure 6: The neighborhood structure of a corner region in the CLAHE [42].",
            "Figure 7: The effect of diffusers on the images with a top view of the animation of the imaging system. 2 LEDs and camera are aligned at the same axes to select the best condition during the capturing process with less shadows and glares with and without diffusers. (A) Images captured without diffusers. The glare (yellow arrow) that occurs after the process is clearly visible. (B) Images with the same process applied with diffusers where glare effect is eliminated.",
            "Figure 8: The effect of NIR light intensity on the images. The process on the images captured using 1 and 2 NIR LEDs to select the quantity of the used NIR LEDs to achieve minimal data loss. (A, D) Raw images. (B, E) Grayscale conversion. (C, F) CLAHE applied.",
            "Figure 9: Comparison of the images taken during daylight and at night to observe the effect of environment illumination and the quality of the pictures taken. LEDs and camera are aligned at the same axes, night and daylight images captured with 2 NIR LEDs to observe diffusing of the light. (A, D) Raw images. (B, E) Grayscale conversion. (C, F) CLAHE applied."
        ],
        "imgs": [
            "$2305.00189v1-Figure1-1.png",
            "$2305.00189v1-Figure10-1.png",
            "$2305.00189v1-Figure11-1.png",
            "$2305.00189v1-Figure12-1.png",
            "$2305.00189v1-Figure13-1.png",
            "$2305.00189v1-Figure14-1.png",
            "$2305.00189v1-Figure2-1.png",
            "$2305.00189v1-Figure4-1.png",
            "$2305.00189v1-Figure5-1.png",
            "$2305.00189v1-Figure6-1.png",
            "$2305.00189v1-Figure7-1.png",
            "$2305.00189v1-Figure8-1.png",
            "$2305.00189v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00190",
        "abstract": "  Distributed sensor networks often include a multitude of sensors, each\nmeasuring parts of a process state space or observing the operations of a\nsystem. Communication of measurements between the sensor nodes and estimator(s)\ncannot realistically be considered delay-free due to communication errors and\ntransmission latency in the channels. We propose a novel stability-based method\nthat mitigates the influence of sensor network delays in distributed state\nestimation for linear time-varying systems. Our proposed algorithm efficiently\nselects a subset of sensors from the entire sensor nodes in the network based\non the desired stability margins of the distributed Kalman filter estimates,\nafter which, the state estimates are computed only using the measurements of\nthe selected sensors. We provide comparisons between the estimation performance\nof our proposed algorithm and a greedy algorithm that exhaustively selects an\noptimal subset of nodes. We then apply our method to a simulative scenario for\nestimating the states of a linear time-varying system using a sensor network\nincluding 2000 sensor nodes. Simulation results demonstrate the performance\nefficiency of our algorithm and show that it closely follows the achieved\nperformance by the optimal greedy search algorithm.\n",
        "title": "Distributed State Estimation for Linear Time-Varying Systems with Sensor\n  Network Delays",
        "texts": [
            "Fig. 2: Estimates of state variable x1(k) with and without delays. Notice an MD higher than 100% around 0.5 seconds compared to the ideal response.",
            "Fig. 3: Implementing the greedy sensor subset selection (Algorithm 1): (a) Variation of MSE and (b) variation of MD on reducing the threshold. The values are ensemble means.",
            "Fig. 5: State estimates (Algorithm 2) with n = 2000, 192 nodes selected, returning an MSE = 2.3871, MD = 0.2593.",
            "Fig. 6: State estimates of x1(k) and x2(k) with n = 2000 in the presence of stochastic delays. Algorithm 2, selected 20 nodes returns MSE = 1.92 and MD = 0.11."
        ],
        "imgs": [
            "$2305.00190v1-Figure2-1.png",
            "$2305.00190v1-Figure3-1.png",
            "$2305.00190v1-Figure5-1.png",
            "$2305.00190v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00191",
        "abstract": "  We consider a network with multiple sources and a base station that send\ntime-sensitive information to remote clients. The Age of Incorrect Information\n(AoII) captures the freshness of the informative pieces of status update\npackets at the destinations. We derive the closed-form Whittle Index\nformulation for a push-based multi-user network over unreliable channels with\nAoII-dependent cost functions. We also propose a new semantic performance\nmetric for pull-based systems, named the Age of Incorrect Information at Query\n(QAoII), that quantifies AoII at particular instants when clients generate\nqueries. Simulation results demonstrate that the proposed Whittle Index-based\nscheduling policies for both AoII and QAoII-dependent cost functions are\nsuperior to benchmark policies, and adopting query-aware scheduling can\nsignificantly improve the timeliness for scenarios where a single user or\nmultiple users are scheduled at a time.\n",
        "title": "Optimization of AoII and QAoII in Multi-User Links",
        "texts": [
            "Fig. 1. The structure of the system model.",
            "Fig. 2. Average AoII values for the Round Robin (RR), Greedy (GP), AoIWhittle Index (AoI-WI), and AoII-Whittle Index (AoII-WI) scheduling for the system with 2 to 9 users each time a single user is scheduled.",
            "Fig. 3. Average AoII values for the Round Robin (RR), Greedy (GP), AoIWhittle Index (AoI-WI), and AoII-Whittle Index (AoII-WI) scheduling for a system with 37 users, each time the number of scheduled users is increased.",
            "Fig. 5. Average QAoII values for the Round Robin (RR), Greedy (GP), QAoIWhittle Index (QAoI-WI), and QAoII-Whittle Index (QAoII-WI) scheduling for a system with 37 users, each time the number of scheduled users is increased.",
            "TABLE I AVERAGE AOII & QAOII VALUES FOR DIFFERENT SCHEDULING POLICIES FOR A SYSTEM WITH 3 USERS WHEN A SINGLE USER IS SCHEDULED."
        ],
        "imgs": [
            "$2305.00191v1-Figure1-1.png",
            "$2305.00191v1-Figure2-1.png",
            "$2305.00191v1-Figure3-1.png",
            "$2305.00191v1-Figure5-1.png",
            "$2305.00191v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00192",
        "abstract": "  A fast and accurate grid impedance measurement of three-phase power systems\nis crucial for online assessment of power system stability and adaptive control\nof grid-connected converters. Existing grid impedance measurement approaches\ntypically rely on pointwise sinusoidal injections or sequential wideband\nperturbations to identify a nonparametric grid impedance curve via fast Fourier\ncomputations in the frequency domain. This is not only time-consuming, but also\ninaccurate during time-varying grid conditions, while on top of that, the\nidentified nonparametric model cannot be immediately used for stability\nanalysis or control design. To tackle these problems, we propose to use\nparametric system identification techniques (e.g., prediction error or subspace\nmethods) to obtain a parametric impedance model directly from time-domain\ncurrent and voltage data. Our approach relies on injecting wideband excitation\nsignals in the converter's controller and allows to accurately identify the\ngrid impedance in closed loop within one injection and measurement cycle. Even\nthough the underlying parametric system identification techniques are\nwell-studied in general, their utilization in a grid impedance identification\nsetup poses specific challenges, is vastly underexplored, and has not gained\nadequate attention in urgent and timely power systems applications. To this\nend, we demonstrate in numerical experiments how the proposed parametric\napproach can accomplish a significant improvement compared to prevalent\nnonparametric methods.\n",
        "title": "MIMO Grid Impedance Identification of Three-Phase Power Systems:\n  Parametric vs. Nonparametric Approaches",
        "texts": [
            "Fig. 1: Sketch of the proposed grid impedance identification setup.",
            "Fig. 2: Overview of existing approaches for MIMO grid impedance identification/measurement of three-phase power systems.",
            "Fig. 3: One-line diagram of three-phase grid-connected power converter system used for wideband excitation and grid impedance identification. The proposed approach can be also applied to other type of converter controls.",
            "Fig. 4: Small-signal block diagram of grid impedance identification problem.",
            "Fig. 5: One-line diagram of the power converter connected to the three-phase power grid used for simulation-based studies of grid impedance identification.",
            "Fig. 6: Three phase voltage and current signals at the PCC, both in the absence and in the presence of RBS wideband excitation.",
            "Fig. 7: Bode diagrams of the identified 2×2 grid impedance Zg(s) in Fig. 5 using different parametric and nonparametric identification methods. The black dashed line indicates the analytically computed true grid impedance.",
            "TABLE I: Electrical Parameters of the Numerical Experiment",
            "TABLE II: Comparison of Grid Impedance Identification Methods"
        ],
        "imgs": [
            "$2305.00192v1-Figure1-1.png",
            "$2305.00192v1-Figure2-1.png",
            "$2305.00192v1-Figure3-1.png",
            "$2305.00192v1-Figure4-1.png",
            "$2305.00192v1-Figure5-1.png",
            "$2305.00192v1-Figure6-1.png",
            "$2305.00192v1-Figure7-1.png",
            "$2305.00192v1-TableI-1.png",
            "$2305.00192v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00194",
        "abstract": "  Feature matching is a crucial technique in computer vision. A unified\nperspective for this task is to treat it as a searching problem, aiming at an\nefficient search strategy to narrow the search space to point matches between\nimages. One of the key aspects of search strategy is the search space, which in\ncurrent approaches is not carefully defined, resulting in limited matching\naccuracy. This paper, thus, pays attention to the search space and proposes to\nset the initial search space for point matching as the matched image areas\ncontaining prominent semantic, named semantic area matches. This search space\nfavors point matching by salient features and alleviates the accuracy\nlimitation in recent Transformer-based matching methods. To achieve this search\nspace, we introduce a hierarchical feature matching framework: Area to Point\nMatching (A2PM), to first find semantic area matches between images and later\nperform point matching on area matches. We further propose Semantic and\nGeometry Area Matching (SGAM) method to realize this framework, which utilizes\nsemantic prior and geometry consistency to establish accurate area matches\nbetween images. By integrating SGAM with off-the-shelf state-of-the-art\nmatchers, our method, adopting the A2PM framework, achieves encouraging\nprecision improvements in massive point matching and pose estimation\nexperiments.\n",
        "title": "Searching from Area to Point: A Hierarchical Framework for\n  Semantic-Geometric Combined Feature Matching",
        "texts": [
            "Fig. 1. Overview of the proposed feature matching framework and area matching method. (i) Top: The proposed Area to Point Matching (A2PM) framework first finds semantic area matches between images and then performs point matching on matched areas. (ii) Bottom: For area matching, we propose Semantic and Geometry Area Matching (SGAM) method including Semantic Area Matching (SAM, the green part) and Geometry Area Matching (GAM, the blue part). The SAM takes semantic segmentation to to detect and match semantic object area (SOA) and semantic intersection area (SIA) between images. Integrating with a Point Matcher (PM), the GAM consists of a Predictor (GP) to determine true matches from doubtful areas and a Rejector (GR) to screen out false and bad area matches.",
            "Fig. 2. Semantic Area Matching (SAM). SAM divides image areas into two types to process. For both types of areas, area detection and description are performed first, and then area matching is based on specially-designed descriptor distance minimization.",
            "Fig. 3. The image of MMA. Our SGAM methods in this figure are implemented with their best parameter settings and significantly increases the matching accuracy for all direct matchers.",
            "Fig. 4. Ablation study of GR parameter φ. The point matching and pose estimation performance of SGAM COTR/LoFTR with different φ settings under three difficulties on ScanNet are reported. The blue lines are pose estimation accuracy and yellow lines correspond to point matching accuracy. The different values of φ are on the x-axis where∞ represents SGAM w/o GR, permitting all area matches (zoom in for details).",
            "TABLE I VALUE RESULTS (%) OF MMA. WE REPORT MMAS WITH DIFFERENT THRESHOLDS UNDER VARIOUS MATCHING DIFFICULTIES. THE OVERALL BEST RESULTS ARE BOLD. WE IMPLEMENT DIFFERENT VARIANTS OF SGAM ( φ = 1 ∼ 4.5) FOR DIFFERENT POINT MATCHERS AND REPORT THE BEST RESULTS, WHICH ACQUIRE NOTEWORTHY PRECISION IMPROVEMENT.",
            "TABLE II RELATIVE POSE ESTIMATION RESULTS (%). THE POSE ESTIMATION AUC ON SCANNET (FD@5/10) AND MATTERPORT3D WITH THRESHOLDS 5◦, 10◦, 20◦, 30◦ ARE REPORTED. THE OVERALL BEST RESULTS ARE BOLD. THE IMPRESSIVE RESULTS MANIFESTS THE EFFECTIVENESS OF A2PM FRAMEWORK AND SGAM METHOD IN POSE ESTIMATION.",
            "TABLE III AREA MATCHING PERFORMANCE ON SCANNET. THE AREA MATCHING RESULTS (%) OF SAM AND SGAM COMBINED WITH DIFFERENT POINT MATCHERS UNDER THREE MATCHING DIFFICULTIES IN SCANNET ARE REPORTED. THE OVERALL BEST RESULTS ARE BOLD. THE AREA MATCHING RESULTS MANIFEST THE EFFECTIVENESS OF SAM AND GAM. THE ACCURACY OF PM ALSO AFFECTS THE PERFORMANCE OF SGAM.",
            "TABLE IV AREA MATCHING PERFORMANCE ON SCANNET OF TWO SAM AREAS AND GP. WE CONSTRUCT AREA MATCHING EXPERIMENTS FOR TWO AREAS IN SAM AND GP INTEGRATED WITH TWO POINT MATCHERS. AOR AND AMP@0.7 UNDER DIFFERENT MATCHING DIFFICULTIES (EACH WITH 1500 IMAGE PAIRS) ARE REPORTED ALONG WITH THE AREA NUMBER PER IMAGE."
        ],
        "imgs": [
            "$2305.00194v3-Figure1-1.png",
            "$2305.00194v3-Figure2-1.png",
            "$2305.00194v3-Figure3-1.png",
            "$2305.00194v3-Figure4-1.png",
            "$2305.00194v3-TableI-1.png",
            "$2305.00194v3-TableII-1.png",
            "$2305.00194v3-TableIII-1.png",
            "$2305.00194v3-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00195",
        "abstract": "  Medical studies frequently require to extract the relationship between each\ncovariate and the outcome with statistical confidence measures. To do this,\nsimple parametric models are frequently used (e.g. coefficients of linear\nregression) but usually fitted on the whole dataset. However, it is common that\nthe covariates may not have a uniform effect over the whole population and thus\na unified simple model can miss the heterogeneous signal. For example, a linear\nmodel may be able to explain a subset of the data but fail on the rest due to\nthe nonlinearity and heterogeneity in the data. In this paper, we propose\nDDGroup (data-driven group discovery), a data-driven method to effectively\nidentify subgroups in the data with a uniform linear relationship between the\nfeatures and the label. DDGroup outputs an interpretable region in which the\nlinear model is expected to hold. It is simple to implement and computationally\ntractable for use. We show theoretically that, given a large enough sample,\nDDGroup recovers a region where a single linear model with low variance is\nwell-specified (if one exists), and experiments on real-world medical datasets\nconfirm that it can discover regions where a local linear model has improved\nperformance. Our experiments also show that DDGroup can uncover subgroups with\nqualitatively different relationships which are missed by simply applying\nparametric approaches to the whole dataset.\n",
        "title": "Data-Driven Subgroup Identification for Linear Regression",
        "texts": [
            "Figure 1. Demonstration on synthetic dataset. (a-c) The region selected by (a) DDGroup, (b) k-means clustering and (c) linear model tree. The grey shaded area denotes the correct subgroup and the green box corresponds to the learned boundary. For k-means clustering, the number of clusters is searched from 2 to 10, and the bounding box for the cluster with smallest MSE is reported in (b). The depth of LMT is searched from 1 to 10, and the best performance is reported in (c). (d) Robustness of DDGroup to core group misspecification. The shaded region shows standard error of the mean over 50 trials. The black dashed line denotes the point at which “bad” points are included in the core region. The red dashed line denotes the point at which the center of the supplied core set is outside of R. The y-axis records precision, recall, and F1 score (higher is better).",
            "Figure 2. MSE vs. subgroup size selected by DDGroup. The x-axis shows the fraction of test points included in the selected region. The y-axis shows the MSE of the model on the test points in the selected region, normalized by the test MSE of the base model on the whole dataset. (Lower is better.) Different colored points correspond to different random training/validation/test splits on the same dataset. There are 10 random splits in total for each dataset.",
            "Table 1. Performance on single subgroup identification for k-means clustering, linear model tree, and DDGroup on synthetic datasets of varying sizes. We report the average F1 score plus or minus the standard error of the mean over 20 trials. DDGroup outperforms the comparison methods for all sample sizes and finds accurate results even with few samples.",
            "Table 2. Performance on single subgroup identification for baseline (linear regression model on the whole data), k-means clustering, linear model tree, and DDGroup on the real-world datasets. Here d denotes the dimension of the features, and subgroup size denotes the fraction of the data included in the selected subgroup. We report the average results (± the standard error of the mean) for 10 runs of different random splits.",
            "Table 3. Performance on multiple subgroups identification for baseline (linear regression model on the whole data), k-means clustering, linear model tree, and DDGroup on the real-world datasets. Here we select three subgroups (rather than a single subgroup as in Table 2) and report the average results for the selected groups. Here d denotes the dimension of the features, and subgroup size denotes the fraction of the data included in the selected subgroups. We report the average results for 10 runs of different random splits (± the standard error of the mean)."
        ],
        "imgs": [
            "$2305.00195v1-Figure1-1.png",
            "$2305.00195v1-Figure2-1.png",
            "$2305.00195v1-Table1-1.png",
            "$2305.00195v1-Table2-1.png",
            "$2305.00195v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00197",
        "abstract": "  We study numerically the curvature tensor in a three-dimensional discrete\nspace. Starting from the continuous metric of a three-sphere, we transformed it\ninto a discrete space using three integers $n_1, n_2$, and $n_3$. The numerical\nresults are compared with the expected values in the continuous limit. We show\nthat as the number of cells in the lattice increases, the continuous limit is\nrecovered.\n",
        "title": "Curvature Tensor in Discrete Gravity",
        "texts": [
            "Figure 14. The Root-mean-squared error of R1213−R1312, R1223−R2312 and R1323−R2313 versus N is shown.",
            "Figure 2. The mean value of the curvature R̄ for different values of N."
        ],
        "imgs": [
            "$2305.00197v1-Figure14-1.png",
            "$2305.00197v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00199",
        "abstract": "  The outbreak of the COVID-19 pandemic has had an unprecedented impact on\nChina's labour market, and has largely changed the structure of labour supply\nand demand in different regions. It becomes critical for policy makers to\nunderstand the emerging dynamics of the post-pandemic labour market and provide\nthe right policies for supporting the sustainable development of regional\neconomies. To this end, in this paper, we provide a data-driven approach to\nassess and understand the evolving dynamics in regions' labour markets with\nlarge-scale online job search queries and job postings. In particular, we model\nthe spatial-temporal patterns of labour flow and labour demand which reflect\nthe attractiveness of regional labour markets. Our analysis shows that regional\nlabour markets suffered from dramatic changes and demonstrated unusual signs of\nrecovery during the pandemic. Specifically, the intention of labour flow\nquickly recovered with a trend of migrating from large to small cities and from\nnorthern to southern regions, respectively. Meanwhile, due to the pandemic, the\ndemand of blue-collar workers has been substantially reduced compared to that\nof white-collar workers. In addition, the demand structure of blue-collar jobs\nalso changed from manufacturing to service industries. Our findings reveal that\nthe pandemic can cause varied impacts on regions with different structures of\nlabour demand and control policies. This analysis provides timely information\nfor both individuals and organizations in confronting the dynamic change in job\nmarkets during the extreme events, such as pandemics. Also, the governments can\nbe better assisted for providing the right policies on job markets in\nfacilitating the sustainable development of regions' economies.\n",
        "title": "Large-Scale Assessment of Labour Market Dynamics in China during the\n  COVID-19 Pandemic",
        "texts": [
            "Figure 1: Labour flow intention graph during 2019Q4 to 2021Q2. The node size shows Authority score. We show edges (and their connected cities) whose frequency larger than 5,000. Also, we show flow intention inside major urban agglomerations in China. Since urban agglomerations have active flow intentions, we show edges (and their connected cities) with frequency larger than 15,000 for better presentation.",
            "Figure 2: Spatial distribution of labour flow intention during 2019Q4 to 2021Q2. (a) The distribution of Authority and Hub scores of different cities, where each point indicates a city and the two green lines indicate the score medians of all cities. Here we only show the names of some cities with large Authority or Hub scores. (b) The detected communities of labour flow intention with clustering resolution set to be 0.8. (c) The Black holes and Volcanoes of labour flow intention in China, where red color means positive net Outflow (i.e., Volcanoes); blue color means positive net Inflow (i.e., Black holes); and darker color means higher absolute value.",
            "Figure 3: The quarterly change of labour flow intention among different tiers. (a) The sum of Authority/Hub scores in different tiers of city. (b) The comparison of Authority/Hub scores between same quarters in different years, where Q4means the increase ratio of 2020Q4 to 2019Q4; Q1 means the increase ratio of 2020Q1 to 2021Q1; Q2 means the increase ratio of 2020Q2 to 2021Q2. (c) The change ratio of cross-tier labour flow intention in 2020Q4 to 2019Q4. Each row shows the change of the distribution of flow-out intention to different tiers (x-axis) for each tier (y-axis). (d) The change ratio of cross-tier labour flow intention in 2020Q2 to 2021Q2.",
            "Figure 4: The spatial distribution of Authority and Hub change. (a) The increase ratio of Authority and Hub scores by comparing 2019Q4 with 2020Q4. (b) The increase ratio of Authority and Hub scores by comparing 2020Q2 with 2021Q2. Note that, the red color means positive value; the blue color means negative value; the darker color means higher absolute value and white means 0. Cities with very small values (< 0.0005) are labeled in white.",
            "Figure 5: The distribution of labour demand over different time periods. X-axis represents time periods and y-axis represents the number of relevant job postings.",
            "Figure 6: The spatial visualization of labour demand increase from 2019Q4 to 2020Q4. (a) The increase ratio of number. (b) The increase ratio of normalized labour demand"
        ],
        "imgs": [
            "$2305.00199v1-Figure1-1.png",
            "$2305.00199v1-Figure2-1.png",
            "$2305.00199v1-Figure3-1.png",
            "$2305.00199v1-Figure4-1.png",
            "$2305.00199v1-Figure5-1.png",
            "$2305.00199v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00203",
        "abstract": "  Mean-reverting portfolios with volatility and sparsity constraints are of\nprime interest to practitioners in finance since they are both profitable and\nwell-diversified, while also managing risk and minimizing transaction costs.\nThree main measures that serve as statistical proxies to capture the\nmean-reversion property are predictability, portmanteau criterion, and crossing\nstatistics. If in addition, reasonable volatility and sparsity for the\nportfolio are desired, a convex quadratic or quartic objective function,\nsubject to nonconvex quadratic and cardinality constraints needs to be\nminimized. In this paper, we introduce and investigate a comprehensive modeling\nframework that incorporates all the previous proxies proposed in the literature\nand develop an effective unifying algorithm that is enabled to obtain a\nKarush-Kuhn-Tucker (KKT) point under mild regularity conditions. Specifically,\nwe present a tailored penalty decomposition method that approximately solves a\nsequence of penalized subproblems by a block coordinate descent algorithm. To\nthe best of our knowledge, our proposed algorithm is the first for finding\nvolatile, sparse, and mean-reverting portfolios based on the portmanteau\ncriterion and crossing statistics proxies. Further, we establish that the\nconvergence analysis can be extended to a nonconvex objective function case if\nthe starting penalty parameter is larger than a finite bound and the objective\nfunction has a bounded level set. Numerical experiments on the S&P 500 data set\ndemonstrate the efficiency of the proposed algorithm in comparison to a\nsemidefinite relaxation-based approach and suggest that the crossing statistics\nproxy yields more desirable portfolios.\n",
        "title": "Statistical Proxy based Mean-Reverting Portfolios with Sparsity and\n  Volatility Constraints",
        "texts": [
            "Fig. 1: Statistical proxy-and SDP-based portfolios for k = 5.",
            "Fig. 2: Statistical proxy-and SDP-based portfolios for k = 10. Fig. 3: Statistical proxy-and SDP-based portfolios for k = 17.",
            "Fig. 4: Statistical proxy-based portfolios for k = 5, 10, 17."
        ],
        "imgs": [
            "$2305.00203v1-Figure1-1.png",
            "$2305.00203v1-Figure2-1.png",
            "$2305.00203v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00204",
        "abstract": "  We present a sample dataset featuring pedestrians generated using the ARCANE\nframework, a new framework for generating datasets in CARLA (0.9.13). We\nprovide use cases for pedestrian detection, autoencoding, pose estimation, and\npose lifting. We also showcase baseline results. For more information, visit\nhttps://project-arcane.eu/.\n",
        "title": "CARLA-BSP: a simulated dataset with pedestrians",
        "texts": [
            "Figure 1: Coordinate system used by CARLA.",
            "Figure 10: PCK@0.05 metrics during training for simple transformer-based autoencoder and noisy CARLA-BSP and AMASS data contrasted with JAAD@1.0 and PIE@1.0 runs.",
            "Figure 11: PCKhn@0.1 metrics during training for simple transformer-based autoencoder and noisy CARLA-BSP and AMASS data contrasted with JAAD@1.0 and PIE@1.0 runs.",
            "Figure 12: Example PIE@0.1 rendering results. From left: fragment of a source video with original pose data (red) and model output (green), normalized input pose data as dots, model output as dots.",
            "Figure 13: Example JAAD@0.1 rendering results. From left: fragment of a source video with original pose data (red) and model output (green), normalized input pose data as dots, model output as dots.",
            "Figure 14: Example rendering results for JAAD@1.0 test set. Order (from the top) follows rows in Tab. 3. Follow QR codes to see videos for each pedestrian. 21",
            "Figure 15: Visualization of pose estimation results. It can be seen that the model learned the average skeleton.",
            "Figure 16: Change in MPJPE calculated on validation subset during the training.",
            "Figure 17: Example outputs frompose liftingmodels. In visualization videos, all model outputs are vertically flipped. Follow QR codes to see more examples.",
            "Figure 3: Partial structure of the main repository and its relation to Docker images. All mentioned repositories are hosted on GitHub.",
            "Figure 5: The same frame as in Fig. 4, but captured by the semantic segmentation camera and rendered using the Cityscapes palette.",
            "Figure 6: (Above) The same frame as in Fig. 4, but with additional info (including skeleton overlay) rendered using dataset_advanced_preview.ipynb notebook from pedestrian_scenarios. (Below) Different frame from the same video.",
            "Figure 7: Classification results in terms of F1-score when using perfect CARLA-BSP data.",
            "Figure 8: Classification results for short experiments with PedestrianGraph model.",
            "Figure 9: Classification results for short experiments with LSTM model.",
            "Table 1: Basic dataset stats including the number of annotated frames.",
            "Table 2: Example data from a single row in data.csv (continued).",
            "Table 3: Setup and results for the tests of models trained using various datasets.",
            "Table 4: Quality measures in pose lifting task calculated using a test set of CARLA-BSP."
        ],
        "imgs": [
            "$2305.00204v1-Figure1-1.png",
            "$2305.00204v1-Figure10-1.png",
            "$2305.00204v1-Figure11-1.png",
            "$2305.00204v1-Figure12-1.png",
            "$2305.00204v1-Figure13-1.png",
            "$2305.00204v1-Figure14-1.png",
            "$2305.00204v1-Figure15-1.png",
            "$2305.00204v1-Figure16-1.png",
            "$2305.00204v1-Figure17-1.png",
            "$2305.00204v1-Figure3-1.png",
            "$2305.00204v1-Figure5-1.png",
            "$2305.00204v1-Figure6-1.png",
            "$2305.00204v1-Figure7-1.png",
            "$2305.00204v1-Figure8-1.png",
            "$2305.00204v1-Figure9-1.png",
            "$2305.00204v1-Table1-1.png",
            "$2305.00204v1-Table2-1.png",
            "$2305.00204v1-Table3-1.png",
            "$2305.00204v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00206",
        "abstract": "  The apparent shape of galaxy clustering depends on the adopted cosmology used\nto convert observed redshift to comoving distance, the $r(z)$ relation, as it\nchanges the line elements along and across the line of sight differently. The\nAlcock-Paczy\\'nski (AP) test exploits this property to constrain the expansion\nhistory of the universe. We present an extensive review of past studies on the\nAP test. We adopt an extended AP test method introduced by Park et al. (2019),\nwhich uses the full shape of redshift-space two-point correlation function (CF)\nas the standard shape, and apply it to the SDSS DR7, BOSS, and eBOSS LRG\nsamples covering the redshift range up to $z=0.8$.We calibrate the test against\nthe nonlinear cosmology-dependent systematic evolution of the CF shape using\nthe Multiverse simulations. We focus on examining whether or not the flat\n$\\Lambda$CDM `concordance' model is consistent with observation. We constrain\nthe flat $w$CDM model to have $w=-0.892_{-0.050}^{+0.045}$ and\n$\\Omega_m=0.282_{-0.023}^{+0.024}$ from our AP test alone, which is\nsignificantly tighter than the constraints from the BAO or SNe I$a$ methods by\na factor of 3 - 6. When the AP test result is combined with the recent BAO and\nSNe I$a$ results, we obtain $w=-0.903_{-0.023}^{+0.023}$ and\n$\\Omega_m=0.285_{-0.009}^{+0.014}$. This puts a strong tension with the flat\n$\\Lambda$CDM model with $w=-1$ at $4.2\\sigma$ level. Consistency with $w=-1$ is\nobtained only when the Planck CMB observation is combined. It remains to see if\nthis tension between observations of galaxy distribution at low redshifts and\nCMB anisotropy at the decoupling epoch becomes greater in the future studies\nand leads us to a new paradigm of cosmology.\n",
        "title": "Tomographic Alcock-Paczynski Test with Redshift-Space Correlation\n  Function: Evidence for the Dark Energy Equation of State Parameter w>-1",
        "texts": [
            "Figure 1. Distribution of galaxy number density in the SDSS samples used in this study. A ΛCDM cosmology with",
            "Figure 10. Angular selection functions for the LRG clutering data samples in the north and south Galactic maps. The color bar on the right encodes the completeness of the LRG sample as a function of position on the sky.",
            "Figure 11. Likelihood map in the Ωm − w plane. The contours in each panel has the same meaning as the one shown in Fig. 6, but it is derived by considering the redshift evolution of CF between all adjacent redshift slices.",
            "Figure 2. Upper panel: stellar mass function of the LOWZ sample. The solid line presents the observed stellar mass functions of the LOWZ sample in various redshift bins. Mass selection is clearly incomplete at the low-mass end, which is more pronounced at higher redshifts. We adopt the complete stellar mass function reconstructed by G18 (dashed lines for three redshift intervals) for performing the subhalo abundance-matching in simulation. We can obtain the massselection function at each redshift bin by comparing the observed function to the dashed line. Lower panel: galaxy number density distribution of the LOWZ sample in redshift (red solid line). The dashed lines are those for eight HR4 mocks by adopting the mass-selection function. The black solid line shows the mean of all mocks, which well restores the observational data.",
            "Figure 3. Normalized two-point correlation functions of seven observational samples in increasing order of redshift from z1 to z7 (solid lines). The dotted lines in grey are the measurements from HR4 mocks. All the observed correlation functions are superposed on one another in the last panel. Agreement between all the seven samples is excellent on the scales s⊥ > 3h−1Mpc. A cosmology with Ωm = 0.26 and w = −1 is used for the plots.",
            "Figure 4. Intrinsic shape moments of the normalized redshift-space CF obtained for 10 different Multiverse simulation cosmologies in the second redshift slice z2. Top: ξ̂0(s), middle: ξ̂2(s), bottom: ξ̂4(s). Models with the same Ωm nearly overlaps with one another. The shaded areas attached to the fiducial model show the 1σ uncertainties, which are estimated from the MultiDark mock simulations (see the text).",
            "Figure 5. Likelihood function maps L(Ωm, w) from our extended AP test analysis using the baseline mock samples. The contours in different colors correspond to the cases when the slice at zi is chosen as the reference for measuring the relative CF shape evolution across redshift slices. Cosmologydependent systematic corrections to the shape evolution are made (∆ξ̂sys(Ωm, w)). We average over all choices of the reference slice for the final constraint (pink color). For comparison, the constraint assuming fixed amount of systematics obtained for the fiducial cosmology (∆ξ̂sys = ∆ξ̂fid(Ωm, w)) is shown with grey color contours, which is more stretched in the plane. The diamond symbols denote the ten cosmologies with varying Ωm and w covered by the Multiverse simulations given in Table 2. The sub-panels present marginalized constraints for each parameter with curves enclosing the 1σ and 2σ regions.",
            "Figure 6. Likelihood function maps in the w − Ωm plane from our extended AP test using the baseline SDSS data. We also show constraints from BAO/SN/CMB probes for comparison. The contours in gold shows the likelihood function of our AP test combined with two other low-redshift probes. The sub-panels show the marginalized probability distribution function of each cosmological parameter. The likelihood functions of other cosmological probes are borrowed from literature Alam et al. (2021); the SDSS BAO-only measurements (Howlett et al. 2015; Alam et al. 2017; Raichoor et al. 2021; de Mattia et al. 2021), Pantheon SNe Ia-only measurements (Scolnic et al. 2018) and Planck CMB-only measurements (Planck Collaboration et al. 2020).",
            "Figure 7. The sensitivity of DAH to Ωm and w, quantified by ∂ln(DAH)/∂Ωm (left panel) and ∂ln(DAH)/∂w (right panel). Sensitivity to w decreases at high redshifts and crosses zero at z ∼ 1.3. The results for H(z), DL and DV are plotted for comparison. A cosmology of Ωm = 0.3 and w = −1 is used.",
            "Figure 8. Improvement in wCDM constraints by including the AP measurement. Results are shown for each data set combination presented in the text and Table 3. Squares are the “peak” values, which are the parameter values at the highest probability in maximum likelihood estimate, and crosses are the“mean” values referring to the average value of the parameter. The improvement factor in parameter uncertainty is 3-7.",
            "Figure 9. The parameter β(z) = f/b for the galaxies in the seven SDSS samples used in this study (blue dots). Note that β is almost independent of redshift. The HR4 cosmology is used to calculate the growth rate function f , and the snapshots of HR4 are used to measure the matter fluctuation at various redshifts and to estimate the galaxy bias factors. For comparison, the function β(z) for the galaxies with a fixed bias factor of b = 1.5 (dashed line) or 2.0 (solid line) is plotted for the HR4 cosmology.",
            "Table 1. Summary of the key AP test papers. PS, CF, and LSS stand for power spectrum, correlation function, and large-scale structures in the universe, respectively. DA is the angular diameter distance, and H is the Hubble parameter.",
            "Table 2. Matter density parameter at the present epoch and constant dark energy equation of state parameter of the Multiverse simulations.",
            "Table 3. Marginalized best-fit value, Ωm and w, average value, 〈Ωm〉 and 〈w〉, and 68% confidence limits, σ(Ωm) and σ(w), estimated from various cosmological probes and their combined likelihood analyses. The baseline samples include the six low redshift SDSS slices while all samples include the eBOSS LRG sample as well. The ‘joint’ constraint considers the crosscorrelations between different radial modes (see the text). Our main result is from combination of baseline AP+BAO+SN."
        ],
        "imgs": [
            "$2305.00206v1-Figure1-1.png",
            "$2305.00206v1-Figure10-1.png",
            "$2305.00206v1-Figure11-1.png",
            "$2305.00206v1-Figure2-1.png",
            "$2305.00206v1-Figure3-1.png",
            "$2305.00206v1-Figure4-1.png",
            "$2305.00206v1-Figure5-1.png",
            "$2305.00206v1-Figure6-1.png",
            "$2305.00206v1-Figure7-1.png",
            "$2305.00206v1-Figure8-1.png",
            "$2305.00206v1-Figure9-1.png",
            "$2305.00206v1-Table1-1.png",
            "$2305.00206v1-Table2-1.png",
            "$2305.00206v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00210",
        "abstract": "  In this work, we introduce ShipHullGAN, a generic parametric modeller built\nusing deep convolutional generative adversarial networks (GANs) for the\nversatile representation and generation of ship hulls. At a high level, the new\nmodel intends to address the current conservatism in the parametric ship design\nparadigm, where parametric modellers can only handle a particular ship type. We\ntrained ShipHullGAN on a large dataset of 52,591 \\textit{physically validated}\ndesigns from a wide range of existing ship types, including container ships,\ntankers, bulk carriers, tugboats, and crew supply vessels. We developed a new\nshape extraction and representation strategy to convert all training designs\ninto a common geometric representation of the same resolution, as typically\nGANs can only accept vectors of fixed dimension as input. A space-filling layer\nis placed right after the generator component to ensure that the trained\ngenerator can cover all design classes. During training, designs are provided\nin the form of a shape-signature tensor (SST) which harnesses the compact\ngeometric representation using geometric moments that further enable the\ninexpensive incorporation of physics-informed elements in ship design. We have\nshown through extensive comparative studies and optimisation cases that\nShipHullGAN can generate designs with augmented features resulting in versatile\ndesign spaces that produce traditional and novel designs with geometrically\nvalid and practically feasible shapes.\n",
        "title": "ShipHullGAN: A generic parametric modeller for ship hull design using\n  deep convolutional generative model",
        "texts": [
            "Figure 10: Reconstruction of designs in Fig. 8 using the proposed shape encoding approach. It is evident that all three designs now possess a consistent underlying geometric representation.",
            "Figure 11: Comparison between the original KCS hull and its surface reconstruction from the grid points of the proposed body-plan-based approach. (a) Surface representations of the original and reconstructed hulls, (b) their geometric representation, comparisons in terms of (c) the one-sided Hausdorff distance [44], and (d) Gaussian curvature.",
            "Figure 12: Illustration of transformation of grid points into training set’s 3-tuples of input matrices.",
            "Figure 13: Structure of a matrix containing coordinates of the grid points and GMIs of a design in the training dataset.",
            "Figure 14: Convolutional architecture of the generator used in ShipHullGAN.",
            "Figure 16: Plots depicting the value of (a) SC, (b) MMD and (c) novelty metrics evaluated using Eqs. (15), (13) and (16), respectively, versus the number of employed latent features.",
            "Figure 17: (a) Interpolation of points of CSs using cubic NURBS curves. (b) Construction of NURBS surfaces interpolating the curves with a loft operation. (c) Inspection of hull surface fairness using isophotes mapping analysis.",
            "Figure 18: Design variations created with ShipHullGAN. Randomly sampled designs from Z and design variations resulting from changing each of the variables in z can be visualised at https://youtu.be/ZIfmAs5-qFw and https: //youtu.be/avlq0FxZP-s, respectively.",
            "Figure 19: Examples of newly generated designs using ShipHullGAN adopting features from parent designs in Fig. 5.",
            "Figure 2: The parameterisation proposed by [6] for container ship hulls. Is it applicable to a naval ship design such as the DTMB hull?",
            "Figure 21: t-SEN plot of some design in the training data and newly generated designs from the ShipHullGAN model.",
            "Figure 22: (a) Diversity and (b) novelty of designs created with the generator of GAN and ShipHullGAN.",
            "Figure 23: Examples of invalid (self-intersecting) designs resulted from the GAN model. The red curve indicates the regions of intersection.",
            "Figure 26: (a) Convergence plots of Cw during the first 100 optimisation iterations performed in Zcs. (b) 3D surfaces of zcs and its optimised variant found in Zcs.",
            "Figure 3: Transformation of KCS hull into DTMB hull achieved using the ShipHullGAN parametric modeller. Training on synthetic variations of both hulls makes it possible to generate unique designs featuring a blend of KCS and DTMB attributes, exemplified in designs 5-7 along the sequence of arrows.",
            "Figure 4: The ShipHullGAN architecture incorporates shapes and their geometric moments in the form of SST to improve design validity and incorporate physics into the latent variables. It also includes a space-filling layer that aims to create a uniform distribution of designs from the generator. Once trained, the generator can then be linked with the performance evaluation code and optimiser to perform shape optimisation for optimised design alternatives satisfying given design constraints.",
            "Figure 5: Main ship hull types used in training of ShipHullGAN model.",
            "Figure 6: Indicative instances from the synthetic design variation of Bulker, DTMB, Global-S, KCS, KVLCC2, and Megayacht hulls in Fig. 5 created for training ShipHullGAN.",
            "Figure 7: Distribution of (a) wave resistance coefficient (Cw) and (b) ship-hull volume (5) in the training dataset.",
            "Figure 8: Example of three ship hulls with different structures of the surface parameterisation: the DTMB hull is constructed with a single NURBS surface, whereas the KCS and S-175 are composed of several NURBS surface patches with a significantly different number of control points.",
            "Figure 9: Steps of the proposed body-plan-based approach for extracting geometric information from ship-hull shapes.",
            "Table 2: Main particulars and Cw of KCS, KVLCC and Crew Supply vessel hulls and the optimised designs in the Figs. 24, 25 and 26."
        ],
        "imgs": [
            "$2305.00210v1-Figure10-1.png",
            "$2305.00210v1-Figure11-1.png",
            "$2305.00210v1-Figure12-1.png",
            "$2305.00210v1-Figure13-1.png",
            "$2305.00210v1-Figure14-1.png",
            "$2305.00210v1-Figure16-1.png",
            "$2305.00210v1-Figure17-1.png",
            "$2305.00210v1-Figure18-1.png",
            "$2305.00210v1-Figure19-1.png",
            "$2305.00210v1-Figure2-1.png",
            "$2305.00210v1-Figure21-1.png",
            "$2305.00210v1-Figure22-1.png",
            "$2305.00210v1-Figure23-1.png",
            "$2305.00210v1-Figure26-1.png",
            "$2305.00210v1-Figure3-1.png",
            "$2305.00210v1-Figure4-1.png",
            "$2305.00210v1-Figure5-1.png",
            "$2305.00210v1-Figure6-1.png",
            "$2305.00210v1-Figure7-1.png",
            "$2305.00210v1-Figure8-1.png",
            "$2305.00210v1-Figure9-1.png",
            "$2305.00210v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00212",
        "abstract": "  Heavy-ion collisions are a unique tool for testing the behaviour of matter\nunder extreme conditions. The momentum correlations of charm and bottom hadrons\nhave been considered for testing heavy quarks' thermalization in the hot, dense\nmedium produced by the collisions. In this respect, two effects have been\nconsidered: the decrease of the initial back-to-back correlations and the\nincrease of correlations due to heavy-quark interactions with collectively\nflowing medium.\n  Here, we show that, in the case of a single charm and anti-charm hadron pair\nproduction, the collective flow allows for testing heavy-quark production\nlocality and spatial diffusion. Using an example of central Pb+Pb collisions at\nthe CERN SPS energies, we demonstrate that the azimuthal correlations of charm\nand anti-charm hadrons are particularly sensitive to their spatial\ncorrelations. We argue that the existing experimental technology and beam\nintensities at the CERN SPS should allow for the corresponding measurements\nsoon. The correlation measurements in collisions with a single heavy-quark pair\nproduced will provide a unique input constraining the diffusion of charm quarks\nand verifying assumptions concerning production locality of a charm and\nanti-charm quark pair.\n",
        "title": "Production locality and spatial diffusion of heavy flavour at high\n  energy densities",
        "texts": [
            "Figure 1. The distribution of c-c̄ pairs in the difference of azimuthal angles ∆φ (left) and transverse momenta ∆pT (right) for local, independent and correlated (σ = 2 fm emission).",
            "Figure 2. The projection for statistical precision of measurement of the azimuthal correlation ∆φ assuming the experiment registered N = 1000 D0D̄0 pairs. The local, independent, and correlated emission is assumed.",
            "Table I. Estimate of the duration of a data-taking period needed to collect 1000 D0D̄0-pairs (first three rows). In the calculations, the duty cycle of 30% was assumed. The last row shows the ratio of the produced pairs of cc̄ quarks to all combinations of them."
        ],
        "imgs": [
            "$2305.00212v1-Figure1-1.png",
            "$2305.00212v1-Figure2-1.png",
            "$2305.00212v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00214",
        "abstract": "  We show that the energy required by a turbulent flow to displace a given\namount of fluid through a straight duct in a given time interval can be reduced\nby modulating in time the pumping power. The control strategy is hybrid: it is\npassive, as it requires neither a control system nor control energy, but it\nmanipulates how pumping energy is delivered to the system (as in active\ntechniques) to increase the pumping efficiency. Our control employs a\ntemporally periodic pumping pattern, where a short and intense acceleration (in\nwhich the pumping system is on) followed by a longer deceleration (in which the\npumping system is off) makes the flow alternately visit a quasi-laminar and a\nturbulent state. The computational study is for a plane channel flow, and\nemploys direct numerical simulations, which present specific computational\nchallenges, for example the highly varying instantaneous value of the Reynolds\nnumber, and the importance of discretisation effects. Particular care is\ndevoted to a meaningful definition of drag reduction in the present context.\nThe ability of the forcing to yield significant savings is demonstrated. Since\nonly a small portion of the parameter space is investigated, the best\nperformance of the control technique remains to be assessed.\n",
        "title": "On-off pumping for drag reduction in a turbulent channel flow",
        "texts": [
            "Figure 1: Left: temporal variation of the function Π(𝑡) employed in the present work, with period 𝑇 and duty cycle b. The cycle-averaged value Π is kept constant across the numerical experiments, as the maximum intensity is Π/b. Right: sketch of the money-time plane, with the energy 𝐸 (money) needed to move the fluid through the duct on the vertical axis, and the inverse of the required time on the horizontal axis. The continuous line is the turbulent friction law, which describes all the uncontrolled flow states; the dashed line corresponds to the laminar regime. The black dot on the turbulent line represents a generic uncontrolled flow state, while the red dot, below the turbulent line, is a successfully controlled flow state, more efficient than the natural turbulent flow. The four grey dots on the turbulent and laminar lines are flow states used to quantify control performance (see text).",
            "Figure 2: DNS results (filled colour symbols) compared to the reference uncontrolled flow (continuous line), the laminar flow (dashed line) and relevant results taken from literature. The colour of the filled symbols encodes the forcing period, and their shape refers to the value of the duty-cycle. The results from Iwamoto et al. (2007), Kobayashi et al. (2021) and opposition control data reported by Frohnapfel et al. (2012) are represented as blue, red and yellow crosses, respectively. The black dot on the reference line corresponds to 𝑅𝑒𝜏 = 180.",
            "Figure 3: Time evolution of the forcing term Π (a), the corresponding flow rate (b), the friction-based Reynolds number 𝑅𝑒𝜏 (c) and the cross-plane turbulent kinetic energy 𝐾⊥ (d), during one representative cycle, for 𝑇+ = 14400 and b = 0.1. The bottom panel (e) shows the flow rate over the first 20 cycles, with the inset zooming in on the last peak."
        ],
        "imgs": [
            "$2305.00214v1-Figure1-1.png",
            "$2305.00214v1-Figure2-1.png",
            "$2305.00214v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00215",
        "abstract": "  Cu$_3$TeO$_6$, a three-dimensional antiferromagnet forming a unique spin-web\nlattice of spin-1/2 Cu2+ ions below the Neel temperature T$_N$ = 62 K, has\nrecently been found to exhibit topological Dirac or nodal magnon dispersion. In\nthis study, we report the discovery of the linear magnetoelectric (ME) effects\nin Cu$_3$TeO$_6$ below TN. Our pyroelectric current measurements at a constant\nmagnetic field (H) reveal a linear increase of electric polarization (P) with H\nfor both P // H and P $\\perp$ H configurations; a maximum P // [110] = 20\n$\\mu$C/m$^2$ is obtained at u0H // [1-10] = 14 T, corresponding to a linear ME\ncoefficient 1.8 ps/m. Magnetic point group analysis and Monte-Carlo simulations\nconfirm that finite linear ME coefficients are allowed in the off-diagonal and\ndiagonal ME tensor components, consistent with the magnetic point group of\n$\\bar{3}'$. As the parity-time symmetry can be broken in the presence of H or\nelectric field E in the linear ME materials, we envisage that Cu$_3$TeO$_6$\nshould exhibit a H- or E-induced transformation in the topological magnon\ndispersion from a Dirac point/nodal line type into two Weyl point types.\n",
        "title": "Observation of linear magnetoelectric effect in a Dirac magnon\n  antiferromagnet Cu$_3$TeO$_6$",
        "texts": [
            "Figure 1 (a) The crystal structure of Cu3TeO6 including the eight Cu hexagons surrounding TeO6 octahedra. (b) First (solid line), second (bold dash line), and nineth (weak dash line) nearest neighbor (NN) exchange interactions are drawn as J1, J2 , and J9, respectively. The plus (+) and minus (-) signs indicate Cu ions of neighbouring Cu hexagon at equal distance above and below the shown Cu hexagon of solid line and J9 is exchange interactions between these two Cu ions. The 1st NN forms a hexagon and the 1st with the 2nd NN forms a hyper kagome structure. (c) XRD data taken along the [100] crystallographic direction with the inset picture of the Cu3TeO6 single crystal.",
            "Figure 2 Temperature and magnetic dependence of magnetic properties of Cu3TeO6. (a) Magnetic susceptibility and (b) inverse susceptibility as a function of temperature and (c,d) magnetic field dependence of magnetization with two field ranges along each direction in the Cu3TeO6 single crystals .",
            "Figure 4 Temperature dependence of electric polarization at selected magnetic fields in the Cu3TeO6 single crystals for various P and H directions as represented by schematic inset figures for each data. The polarization becomes significantly large in the transverse configurations, supporting the presence of the dominant off-diagonal ME tensors in Cu3TeO6."
        ],
        "imgs": [
            "$2305.00215v1-Figure1-1.png",
            "$2305.00215v1-Figure2-1.png",
            "$2305.00215v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00216",
        "abstract": "  The increasing scale of alternating current and direct current (AC/DC) hybrid\nsystems necessitates a faster power flow analysis tool than ever. This letter\nthus proposes a specific physics-guided graph neural network (PG-GNN). The\ntailored graph modelling of AC and DC grids is firstly advanced to enhance the\ntopology adaptability of the PG-GNN. To eschew unreliable experience emulation\nfrom data, AC/DC physics are embedded in the PG-GNN using duality. Augmented\nLagrangian method-based learning scheme is then presented to help the PG-GNN\nbetter learn nonconvex patterns in an unsupervised label-free manner.\nMulti-PG-GNN is finally conducted to master varied DC control modes. Case study\nshows that, relative to the other 7 data-driven rivals, only the proposed\nmethod matches the performance of the model-based benchmark, also beats it in\ncomputational efficiency beyond 10 times.\n",
        "title": "Physics-Guided Graph Neural Networks for Real-time AC/DC Power Flow\n  Analysis",
        "texts": [
            "Fig. 2. The voltage amplitude and phase angle errors.",
            "Fig. 3. The voltage amplitude and phase angle errors under branch switch-off."
        ],
        "imgs": [
            "$2305.00216v1-Figure2-1.png",
            "$2305.00216v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00217",
        "abstract": "  In a recent paper published in the Journal of Language Evolution, Kauhanen,\nEinhaus & Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the\nresults presented in one of my papers (Koplenig, Royal Society Open Science, 6,\n181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show\nthrough a series of statistical analyses that large numbers of L2 (second\nlanguage) speakers do not seem to affect the (grammatical or statistical)\ncomplexity of a language. To this end, I focus on the way in which the\nEthnologue assesses language status: a language is characterised as vehicular\nif, in addition to being used by L1 (first language) speakers, it should also\nhave a significant number of L2 users. KEW criticise both the use of\nvehicularity as a (binary) indicator of whether a language has a significant\nnumber of L2 users and the idea of imputing a zero proportion of L2 speakers to\nnon-vehicular languages whenever a direct estimate of that proportion is\nunavailable. While I recognise the importance of post-publication commentary on\npublished research, I show in this rejoinder that both points of criticism are\nexplicitly mentioned and analysed in my paper. In addition, I also comment on\nother points raised by KEW and demonstrate that both alternative analyses\noffered by KEW do not stand up to closer scrutiny.\n",
        "title": "Still no evidence for an effect of the proportion of non-native speakers\n  on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023)",
        "texts": [
            "Figure 1: Results of the Bayesian multilevel models, each row visualizes the results for one of the three outcome specifications, while each column plots the kernel density of the simulated marginal posterior distributions for each estimated parameter. In each case, the small plots on the bottom visualize the 95% equal-tailed credible interval. The Gelman–Rubin convergence diagnostic (Gelman & Rubin 1992; Brooks & Gelman 1998), Rc, is given in parentheses for each model and for each estimated parameter. While most values are below 1.2 indicating convergence, the overall Rc-value for the model with morphological complexity as the outcome for the subset of languages with available information for at least six WALS features is a bit high. However, for all three models, each Rc value is below 1.2 for all estimated fixed effects.",
            "Figure 3: Percentage of languages that have an L2 proportion of (i) more than 0, (ii) more than 0.10, (iii) more than 0.25 and (iv) more than 0.50 per type of complexity (information-theoretic or morphological)",
            "Figure 4: Median L2 proportion for non-vehicular and vehicular languages per type of complexity (information-theoretic or morphological) each across 100 completed samples from KEW’s multiple imputation analysis.",
            "Table 1 – Overview of the results of the complete case linear mixed effects model analyses for each outcome. βlogPop – estimated coefficient for the log of speaker population size; βL2prop – estimated coefficient for the L2 proportion; βinteraction – estimated coefficient for the interaction between the L2 proportion and the log of speaker population size."
        ],
        "imgs": [
            "$2305.00217v6-Figure1-1.png",
            "$2305.00217v6-Figure3-1.png",
            "$2305.00217v6-Figure4-1.png",
            "$2305.00217v6-Table1-1.png"
        ]
    },
    {
        "id": "2305.00218",
        "abstract": "  In the big data era researchers face a series of problems. Even standard\napproaches/methodologies, like linear regression, can be difficult or\nproblematic with huge volumes of data. Traditional approaches for regression in\nbig datasets may suffer due to the large sample size, since they involve\ninverting huge data matrices or even because the data cannot fit to the memory.\nProposed approaches are based on selecting representative subdata to run the\nregression. Existing approaches select the subdata using information criteria\nand/or properties from orthogonal arrays. In the present paper we improve\nexisting algorithms providing a new algorithm that is based on D-optimality\napproach. We provide simulation evidence for its performance. Evidence about\nthe parameters of the proposed algorithm is also provided in order to clarify\nthe trade-offs between execution time and information gain. Real data\napplications are also provided.\n",
        "title": "Subdata selection for big data regression: an improved approach",
        "texts": [
            "Figure 1: An example for the different approaches. Data with two covariates and full data size of 50 data points were generated. The different approaches were used to select 8 data points. The full data can be seen in the first panel and then the IBOSS approach, the OSS approach and our new approach.",
            "Figure 2: The MSEs, D- and A-efficiencies for the subdata selected by different approaches, when the full data size is n = 5 × 103, 104 and 105, the subdata size is k = 100, and the number of candidate data points is K = 25. Alg1 is executed with 5 iterations, and VAlg1 is executed once.",
            "Figure 3: The mean execution time (in seconds) of Alg1 in the cases of 1, 3, 5, 7, 10, 12, 15, 18 and 20 iteration(s), when the subdata size is k = 28, 42, 56, and the number of candidate data points is K = 20, 40, 60.",
            "Figure 4: The mean percent increase in the generalized variance by Alg1 in the cases of 1, 3, 5, 7, 10, 12, 15, 18 and 20 iteration(s), when the subdata size is k = 28, 42, 56, and the number of candidate data points is K = 20, 40, 60.",
            "Figure 5: The bootstrap MSEs for the subdata selected by different approaches, when the subdata size is k = 6p, 10p, 16p, 32p, and the number of candidate data points is K = 20. Alg1 is executed with 5 iterations, and VAlg1 is executed once.",
            "Figure 6: D-efficiency, A-efficiency and execution time (in seconds) for the subdata selected by different approaches, when the subdata size is k = 12p, 18p, 28p, 56p, the number of candidate data points is K = 20, Alg1 is executed with 5 iterations and VAlg1 is executed once.",
            "Figure 7: The convex hulls between the 9th and the 3rd sensor, as well as between the 14th and the 8th sensor, for the subdata selected by different approaches, when the subdata seize is k = 140 and the number of candidate data points is K = 10. Alg1 is executed with 5 iterations, and VAlg1 is executed once.",
            "Table 1: The mean execution time (in seconds) of VAlg1 which is executed once, when the subdata size is k = 28, 42, 56, and the number of candidate data points is K = 20, 40, 60."
        ],
        "imgs": [
            "$2305.00218v1-Figure1-1.png",
            "$2305.00218v1-Figure2-1.png",
            "$2305.00218v1-Figure3-1.png",
            "$2305.00218v1-Figure4-1.png",
            "$2305.00218v1-Figure5-1.png",
            "$2305.00218v1-Figure6-1.png",
            "$2305.00218v1-Figure7-1.png",
            "$2305.00218v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00219",
        "abstract": "  We provide a theoretical description of dynamical heterogeneities in\nglass-forming liquids, based on the premise that relaxation occurs via local\nrearrangements coupled by elasticity. In our framework, the growth of the\ndynamical correlation length $\\xi$ and of the correlation volume $\\chi_4$ are\ncontrolled by a zero-temperature fixed point. We connect this critical behavior\nto the properties of the distribution of local energy barriers at zero\ntemperature. Our description makes a direct connection between dynamical\nheterogeneities and avalanche-type relaxation associated to dynamic\nfacilitation, allowing us to relate the size distribution of heterogeneities to\ntheir time evolution. Within an avalanche, a local region relaxes multiple\ntimes, the more the larger is the avalanche. This property, related to the\nnature of the zero-temperature fixed point, directly leads to decoupling of\nparticle diffusion and relaxation time (the so-called Stokes-Einstein\nviolation). Our most salient predictions are tested and confirmed by numerical\nsimulations of scalar and tensorial thermal elasto-plastic models.\n",
        "title": "Scaling Description of Dynamical Heterogeneity and Avalanches of\n  Relaxation in Glass-Forming Liquids",
        "texts": [
            "FIG. 10. A schematic plot of the yield surface for the tensorial model. The blue dot shows the state of a site in the shear stress space. The yield surface is described by two parallel lines separated by 2σY and each line makes an angle of θY with σ̃xx axis. The distance from the yield surface is shown by x.",
            "FIG. 11. The four-point correlation function χ4 for the scalar model. (a): The peak value χ∗ 4 versus T for several L in a Log-Log plot. The dashed line follows χ∗ 4 ∼ T−γ . (d): Scaling collapse of χ∗ 4(L, T ), which determines ν.",
            "FIG. 12. The four-point structure factor S4(q, t) and the associated correlation length ξ4 for the scalar model. (a): S4(q, τ∗) for several temperatures for L = 128. (b): The corresponding plot for the Ornstein-Zernike form in Eq. (B5). The dashed-line defines a slope corresponding to the exponent a. (c): The extracted ξ4 versus T . The dashed line follows ξ4 ∼ T−ν . (b): χ∗ 4 versus ξ4. The dashed line follows χ∗ 4 ∼ ξ d̃f 4 .",
            "FIG. 14. Diffusion of tracer particles for the tensorial model with L = 128. (a): The y component of typical trajectory of a tracer particle with T = 0.015 (τα = 4.14×1012). (b): Meansquared displacement ∆2(t) of tracer particles are shown with points. The solid lines follow ∆2(t) = Dt, from which we extract the diffusion coefficient D.",
            "FIG. 16. Avalanche distributions P (S) (a) and P (S̃) (b) for several x0 approaching the critical point xc = x0 = 0.281 for the scalar model with L = 256. The dashed lines in (a) and (b) follow P (S) ∼ S−τ and P (S̃) ∼ S−τ̃ , respectively.",
            "FIG. 19. (a): Distribution P (x) for the scalar model with L = 256, obtained from the finite temperature simulations and the extremal dynamics. The vertical arrow locates the critical threshold xc. (b): 〈Esecond − Emin〉, where the average is taken over configurations right before (or after) each avalanche formation, i.e., for which xmin > x0 = xc. The dashed line follows 〈Esecond − Emin〉 ∼ N−δ.",
            "FIG. 5. Statistical properties of avalanches during the extremal dynamics at T = 0+ for the tensorial model. (a, b): Scaling collapse for the cutoff size Sc = 〈S3〉/〈S2〉 based on Eq. (3), for various L for the event-based (a) and site-based (b) avalanche sizes, which determines the critical threshold xc and critical exponents, 1/σ, 1/σ̃, df , and d̃f . (c, d): Sc versus xc−x0. The red dashed line corresponds to Sc ∼ (xc−x0)−1/σ in (c) and S̃c ∼ (xc − x0)−1/σ̃d in (d).",
            "FIG. 7. (a): P (x) from finite T simulations and extremal dynamics at T = 0+ for the tensorial model with L = 256. The red arrow indicates xc. (b): Average of Esecond − Emin obtained from the extremal dynamics for various N = Ld. The red dashed line corresponds to 〈Esecond − Emin〉 ∼ N−δ.",
            "TABLE I. Critical exponents (γ, ν) obtained from finite T simulations in the scalar and tensorial elastoplastic models in two-dimensions, compared with their predicted values proposed in Section V.",
            "TABLE II. Critical exponents obtained from extremal dynamics simulations at T = 0+ for the scalar and tensorial elastoplastic models in two-dimensions. The reported error for the measured exponents corresponds to the range of parameters over which the power law behaviour successfully collapses the data."
        ],
        "imgs": [
            "$2305.00219v1-Figure10-1.png",
            "$2305.00219v1-Figure11-1.png",
            "$2305.00219v1-Figure12-1.png",
            "$2305.00219v1-Figure14-1.png",
            "$2305.00219v1-Figure16-1.png",
            "$2305.00219v1-Figure19-1.png",
            "$2305.00219v1-Figure5-1.png",
            "$2305.00219v1-Figure7-1.png",
            "$2305.00219v1-TableI-1.png",
            "$2305.00219v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00222",
        "abstract": "  We reformulate in Hamiltonian language the recent proposal by Hohm and\nZwiebach of an action yielding the most general $O(d,d)$-symmetric string\ncosmology equations, at tree-level in the string-loop expansion, but to all\norders in the $\\alpha'$ expansion. This allows us to give a simple\ncharacterization of a large class of non-singular, non-perturbative, pre-big\nbang scenarios smoothly interpolating between a low-energy initial accelerated\n(string frame) expansion and a phase of final (string and Einstein frame)\ndecelerated expansion. Interestingly, these solutions must necessarily include,\njust around the bounce, a very short phase of (string-frame) contraction.\n",
        "title": "Non-singular pre-big bang scenarios from all-order $\\alpha'$ corrections",
        "texts": [
            "Figure 1. The red curve represents the parametric plot of the solution (1.1) with d = 3. The low-energy expanding pre-big bang and post big bang branches, corresponding to the asymptotic limits t → ±∞ of the solution (1.1), are represented by the dashed half lines ϕ̇ = √ dH > 0 and −ϕ̇ = √ dH > 0. Their connection implemented by the full solution (1.1) describes a continuous path turning “anticlockwise\" in the plane of the figure.",
            "Figure 2. Parametric plot of the regular bouncing solution of Eq. (2.1), with α′ = 2 and d = 3. It describes a continuous, heart-like path turning clockwise in the plane of the figure.",
            "Figure 3. Qualitative behaviour of a simple function H(f) satisfying the two conditions (2.2) and (2.3). The plotted curve H(f) = −f + f3 is characterised by f0 = 1, f1 = 1/ √ 3, f2 = √ 2, and physically corresponds to the particular solutions presented in [24] for appropriate values of the parameters.",
            "Figure 4. The time behaviour of the solution (2.8), (2.10) is represented by the solid red curves, plotted for d = 3 and α′ = 2 (for graphical reasons, we have expressed time in units of 5 √ α′). The dashed black curves describe the behaviour of the (singular) low-energy pre- and post-big bang branches, corresponding to the asymptotic limits t → ∓∞. The smooth transition between the initial accelerated to the final decelerated expansion is triggered by a high-curvature phase of accelerated/decelerated contraction.",
            "Figure 5. Parametric plot of the new solution (2.8), (2.10) (for d = 3, in units α′ = 2). We stress that the direction of the arrow along the curve cannot be reversed.",
            "Figure 6. The green shaded region, satisfying the condition H < −ϕ̇, is the allowed region for solutions describing an expanding metric in the E-frame. The sky-blue shaded region, satisfying the condition H > −ϕ̇/d, is the allowed region for solutions describing a growing string coupling. The superposition of the two allowed regions, in the upper-left quadrant of the figure, contains the final, expanding post-big bang regime of the bouncing solutions presented in this paper.",
            "Figure 7. The “deformed-heart\" curve representing the parametric plot of the solution (2.8), (2.10) (for d = 3, in units α′ = 2), in the plane spanned by the kinetic energy of the “physical\" dilaton field ϕ and by the Hubble parameter HE of the Einstein-frame geometry.",
            "Figure 8. Parametric plot of the two Hubble parameters corresponding to the case of Eq. (3.8) in which, out of a total of nine Hi, d = 3 are equal to H1 (red curve) and n = 6 are equal to H2 (black curve). We use units in which α′ = 2 as well as c2 = c3 = 2. We took, as initial conditions,",
            "Figure 9. Time evolution of the dilaton’s growth rate according to the solution (3.8), for the particular anisotropic initial configuration described in the text. Quite late after the bounce epoch the dilaton tends to become time-independent (the apparent divergence at t = 0 is due to the vanishing of ϕ̇ at the bounce, see e.g. Fig. 8)."
        ],
        "imgs": [
            "$2305.00222v3-Figure1-1.png",
            "$2305.00222v3-Figure2-1.png",
            "$2305.00222v3-Figure3-1.png",
            "$2305.00222v3-Figure4-1.png",
            "$2305.00222v3-Figure5-1.png",
            "$2305.00222v3-Figure6-1.png",
            "$2305.00222v3-Figure7-1.png",
            "$2305.00222v3-Figure8-1.png",
            "$2305.00222v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00223",
        "abstract": "  In this paper, we introduce PathRTM, a novel deep neural network detector\nbased on RTMDet, for automated KI-67 proliferation and tumor-infiltrated\nlymphocyte estimation. KI-67 proliferation and tumor-infiltrated lymphocyte\nestimation play a crucial role in cancer diagnosis and treatment. PathRTM is an\nextension of the PathoNet work, which uses single pixel keypoints for within\neach cell. We demonstrate that PathRTM, with higher-level supervision in the\nform of bounding box labels generated automatically from the keypoints using\nNuClick, can significantly improve KI-67 proliferation and tumorinfiltrated\nlymphocyte estimation. Experiments on our custom dataset show that PathRTM\nachieves state-of-the-art performance in KI-67 immunopositive, immunonegative,\nand lymphocyte detection, with an average precision (AP) of 41.3%. Our results\nsuggest that PathRTM is a promising approach for accurate KI-67 proliferation\nand tumor-infiltrated lymphocyte estimation, offering annotation efficiency,\naccurate predictive capabilities, and improved runtime. The method also enables\nestimation of cell sizes of interest, which was previously unavailable, through\nthe bounding box predictions.\n",
        "title": "PathRTM: Real-time prediction of KI-67 and tumor-infiltrated lymphocytes",
        "texts": [
            "Fig. 1: Extracted tiles (1a) are annotated by domain expert with keypoints (1b) as ground truth. Once the cells of interest are labeled, the pre-trained NuClick neural network is applied to produce bounding box annotations to train an object detector (1c).",
            "Fig. 2: Visualization of PathRTM’s predicted bounding boxes and GradCAM [19] on a sample tile after training where the model displays its ability to detect the entire cell of interest apposed to a single keypoint within the cell.",
            "Fig. 3: A diagram depicting the deployment of the PathRTM method. Step (a) the annotation of keypoints and automatic NuClick bounding box labels are generated, followed by training RTMDet detector. Step (b) the trained detector is deployed on a per-tile bases, the predicted bounding boxes over the tiles are grouped by patient identifiers, followed by cell level histograms over each patients predictions are generated.",
            "Fig. 4: A confusion matrix with categories immunonegative, immunopositive, tumor-infiltrated lymphocytes, and background.",
            "Fig. 5: A histogram across all cells",
            "Table 1: PathRTM Overall AP results",
            "Table 2: PathRTM class AP results"
        ],
        "imgs": [
            "$2305.00223v1-Figure1-1.png",
            "$2305.00223v1-Figure2-1.png",
            "$2305.00223v1-Figure3-1.png",
            "$2305.00223v1-Figure4-1.png",
            "$2305.00223v1-Figure5-1.png",
            "$2305.00223v1-Table1-1.png",
            "$2305.00223v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00224",
        "abstract": "  VQA have attracted a lot of attention from the quantum computing community\nfor the last few years. Their hybrid quantum-classical nature with relatively\nshallow quantum circuits makes them a promising platform for demonstrating the\ncapabilities of NISQ devices. Although the classical machine learning community\nfocuses on gradient-based parameter optimization, finding near-exact gradients\nfor VQC with the parameter-shift rule introduces a large sampling overhead.\nTherefore, gradient-free optimizers have gained popularity in quantum machine\nlearning circles. Among the most promising candidates is the SPSA algorithm,\ndue to its low computational cost and inherent noise resilience. We introduce a\nnovel approach that uses the approximated gradient from SPSA in combination\nwith state-of-the-art gradient-based classical optimizers. We demonstrate\nnumerically that this outperforms both standard SPSA and the parameter-shift\nrule in terms of convergence rate and absolute error in simple regression\ntasks. The improvement of our novel approach over SPSA with stochastic gradient\ndecent is even amplified when shot- and hardware-noise are taken into account.\nWe also demonstrate that error mitigation does not significantly affect our\nresults.\n",
        "title": "An Empirical Comparison of Optimizers for Quantum Machine Learning with\n  SPSA-based Gradients",
        "texts": [
            "Figure 2. Validation results after every epoch during training on an ideal simulator using SPSA-based gradient estimation",
            "Table II SPSA RESULTS. FOR EACH INDIVIDUAL DATASET THE REPORTED LOSS IS THE AVERAGE COMPUTED OVER 5 TRIALS. THE NORMALIZED AVERAGE ERROR WITH RESPECT TO STANDARD SPSA (NORM. AVG.), COMPUTED OVER ALL TRIALS FOR ALL DATASETS, IS GIVEN AT THE BOTTOM OF EACH METHOD.",
            "Table III PARAMETER-SHIFT RULE RESULTS. FOR EACH INDIVIDUAL DATASET THE REPORTED LOSS IS THE AVERAGE COMPUTED OVER 5 TRIALS. THE NORMALIZED AVERAGE ERROR WITH RESPECT TO STANDARD SPSA (NORM. AVG.), COMPUTED OVER ALL TRIALS FOR ALL DATASETS, IS GIVEN AT THE BOTTOM OF EACH METHOD.",
            "Table IV PERORMANCE OF AMSGRAD AND SPSA ON CIRCUITS WITH DIFFERENT EXPRESSIVITY"
        ],
        "imgs": [
            "$2305.00224v1-Figure2-1.png",
            "$2305.00224v1-TableII-1.png",
            "$2305.00224v1-TableIII-1.png",
            "$2305.00224v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00228",
        "abstract": "  Since the seminal work of Idelsohn, O\\~nate and Del-Pin (2004), the Particle\nFinite Element Method (PFEM) has relied on a Delaunay triangulation and the\nAlpha--Shape (AS) algorithm in the remeshing process. This approach guarantees\na good quality of the Lagrangian mesh, but introduces a list of shortcomings\nthat demand geometrical treatments tailored to each problem. In order to\nimprove the remeshing process in PFEM, this work proposes the use of a\nLevel--Set (LS) function instead of the Alpha--Shape algorithm. Since the\nLevel--Set considers the boundary of the fluid and its interior, and not only a\ngeometric criterion as does the Alpha--Shape, the proposed strategy (PFEM--LS)\nshows more robustness than the classical approach (PFEM--AS) owing to three\nmain improvements. First, the LS function allows for a better control over the\nelements that are created during the fluid/fluid contact, which helps to reduce\nmass creation. Second, it helps to preserve the smoothness of the free surface\nand to reduce mass loss. Third, it allows the meshing of solitary particles\nthat are detached from the free surface, which improves the representation of\ndrops in PFEM. The methodology is presented and validated using free surface\nflow problems in 2D.\n",
        "title": "A Particle Finite Element Method based on Level Set functions",
        "texts": [
            "Figure 1: Illustration of the classic Particle Finite Element Method based on the Alpha–Shape (PFEM–AS), and the proposed scheme based on Level–Set functions (PFEM–LS). (a) A known state of the fluid at time tn. (b) Delaunay triangulation of the updated configuration at tn+1. (c) The α of each element is computed. (d) Triangulation after filtering elements using AS. (e) Solution obtained at the next time tn+2. (f) Level–Set function built according to the boundaries and interior of the fluid. (g) Triangulation after filtering elements using LS. (h) Solution obtained at the next time step tn+2.",
            "Figure 10: Level–Set function in the gap between two bodies. (a–c) The points used to build φ(x), where w and hu represent the gap and element size, respectively. (d–f) The LS functions around the gap. These functions are built for different gap distances, which are given in the legend of subfigure (d).",
            "Figure 11: Time required to (a) build, (b) evaluate, and (c) build and evaluate the Level–Set function for different discretisations of the Zalesak’s disc. NFEM denotes the number of particles discretising the model and NLS the number of particles used to build φ. The time is normalised with respect to the time required to solve the governing equations (1) for one time step.",
            "Figure 13: Illustration of a fluid layer that cannot be split due to the addition of particles on the free surface.",
            "Figure 14: A disc of fluid in free fall that impacts (a) a rigid surface, (c) another fluid at rest. (b) and (d) show the instant of the contact between the bodies for different values of ε. The distance at which contact is established is defined by dc.",
            "Figure 15: Comparison of filtered triangulations using Alpha–Shape (AS) and Level–Set (LS). (a) The nodal discretisation of the fluid domain, where boundary nodes are shown in red and interior nodes in black. (b) The LS function, where the interior is shown in blue and the exterior in yellow. (c) The filtered triangulation using LS and φ(x) ≥ −0.001 hu. (d) The filtered triangulation using AS and αmax = 1.2. In (c) and (d), the yellow elements are those that do not belong to the initial domain, but are incorporated during the meshing process and are required to model the contact in PFEM.",
            "Figure 16: Illustration of element removal in PFEM–LS. (a) A small perturbation of the free surface modelled by one element, (b) the LS function around the element, and (c) the largest element allowed by LS criterion using ε = −0.001. (d) A fluid spike, (e) the LS function, and (f) the mesh obtained by the LS criterion with ε = −0.001. (g) A small body detached from the bulk body and its LS function. (h) A tiny body modelled by a highly distorted element. (i) The element is rearranged as an equilateral triangle.",
            "Figure 17: (a) Illustration of the detachment of a particle from the free surface and the generation of a triangular drop. (b) Concave free surface that shows an element from the Delaunay triangulations that is allowed by the LS function but removed by AS.",
            "Figure 18: Summary of the remeshing process in PFEM–LS. The steps in yellow are not present in PFEM–AS.",
            "Figure 2: Workflow of the Particle Finite Element Method (PFEM) based on the Alpha–Shape (AS) algorithm during the remeshing process. The workflow is denoted as PFEM–AS in this work.",
            "Figure 20: Volume variation of the dam break problem. (a) Comparison of results againts those obtained by Franci and Cremonesi [9] (abbreviated as F&C (2017)). Here, hFS is expressed in mm and “This work” means PFEM–AS and no–slip. (b) Analytical volume variation for different discretisations. For a better perception of the discretisation, the initial number of particles in a PFEM simulation is indicated in the right hand side of the legend.",
            "Figure 21: Two snapshots of the dam-break using PFEM–AS with (a) no–slip and (b) free–slip boundary condition. Close-up views in circular sections illustrate the loss of volume due to a stretching of the free–surface and the use of AS. The hatched elements in the rectangular close-up view illustrate the volume addition during remeshings due to the no-slip model.",
            "Figure 22: Volume variation of the dam break problem using (a) PFEM–AS and (b) PFEM–LS. Each graph compares results with no–slip and free–slip boundary conditions.",
            "Figure 23: Fluid boundaries at time 0.148 s for the 12 simulations of the dam break problem. Animations of these simulations can be found in [31].",
            "Figure 24: Fall of a triangular water drop. (a) Geometry and illustration of the two triangular drops that are analysed, and (b) space discretisation.",
            "Figure 27: Illustration of mechanisms generating surfing particles. Generation due to (a) free–surface degradation and (b) impact of a non-meshed drop. Red elements represent those attached to a surfing particle. Animations of these snapshots can be found in [31].",
            "Figure 29: In (a-c), volume variation during simulation of a disk of fluid falling in fluid using PFEM–AS (above) and PFEM–LS (below). Results of Franci and Cremonesi [9] are also displayed for comparison (F&C (2017)). In (d), snapshots of simulation using PFEM–AS and hFS = 5.0mm, at times labelled in (a).",
            "Figure 3: Remeshing process using the Alpha–Shape algorithm and the obtained discretisations using different values of αmax.",
            "Figure 30: Snapshots of simulations of a disk of viscous fluid falling on fluid. Simulations using (a-c) PFEM–AS and (d-f) PFEM–LS. Simulation videos are provided in [31].",
            "Figure 33: Four stages of a fluid discharged from two nozzles impacting on fluid. The time of the snapshot is shown above each picture and is given in s. Snapshots are obtained from the simulation using PFEM–LS and hFS = 0.1 m.",
            "Figure 34: Volume variation for the viscous fluid passing two nozzles problem, (a) using PFEM–AS and (b) using PFEM–LS. The blue coloured zone represents the area between the curve with hFS = 0.05 m and the curve Σ∆V = 0.",
            "Figure 35: Simulation snapshots of a fluid discharged from two nozzles impacting on a fluid at rest. Each subfigure compares simulations obtained with PFEM–AS and hFS = 0.1 m (left), PFEM–LS and hFS = 0.1 m (middle), and PFEM–AS and hFS = 0.05 m (right). The snapshot time and total volume variation due to remeshing are detailed below the pictures. Components of the volume variation vector refer to the snapshot in the [left , middle , right]. The reader is referred to [31] for simulation videos.",
            "Figure 4: (a) Illustration of a mass creation mechanism when particles are added at the centroid of elements lying on the free–surface. (b) Particle removal when they are too close, and mass loss mechanism when a particle is removed from the free surface. (c) A snapshot of the dam break with free-slip condition and two facets that must be refined for correct use of Alpha–Shape.",
            "Figure 6: Element size (h) in terms of the distance to the free–surface.",
            "Figure 8: (a) Zalesak’s disk [26] to be discretized for building the Level–Set function φ(x). (b) Triangulation is used to define the inner points for the φ(x) function. (c) Only a set of internal points are chosen based on a criteria dictated by the triangulation. (d) Only half of the internal points of subfigure c are chosen. (e) All points discretising the domain are used to build φ(x). (f-h) Contour plots of φ(x) obtained from the set of points indicated by the black arrows.",
            "Figure 9: Comparison of two Level–Set functions that are built using (a) several and (b) few external points. The legend of the black, red and green dots is given in Fig. 8.",
            "Table 1: Impact of a drop using PFEM–AS and PFEM–LS. Two discretisations are considered for the drop: a triangular element and a single node. The first row shows the instant at which the contact is captured during remeshing. The second and third rows show the crater produced by the impact from two release heights. The reader is referred to [31] for simulation videos.",
            "Table 2: Average volume variation in the impact of a viscous fluid disk, computed as the ratio between the blue area of Fig. 31 and the simulation span. All values are computed over 3 seconds of simulation."
        ],
        "imgs": [
            "$2305.00228v1-Figure1-1.png",
            "$2305.00228v1-Figure10-1.png",
            "$2305.00228v1-Figure11-1.png",
            "$2305.00228v1-Figure13-1.png",
            "$2305.00228v1-Figure14-1.png",
            "$2305.00228v1-Figure15-1.png",
            "$2305.00228v1-Figure16-1.png",
            "$2305.00228v1-Figure17-1.png",
            "$2305.00228v1-Figure18-1.png",
            "$2305.00228v1-Figure2-1.png",
            "$2305.00228v1-Figure20-1.png",
            "$2305.00228v1-Figure21-1.png",
            "$2305.00228v1-Figure22-1.png",
            "$2305.00228v1-Figure23-1.png",
            "$2305.00228v1-Figure24-1.png",
            "$2305.00228v1-Figure27-1.png",
            "$2305.00228v1-Figure29-1.png",
            "$2305.00228v1-Figure3-1.png",
            "$2305.00228v1-Figure30-1.png",
            "$2305.00228v1-Figure33-1.png",
            "$2305.00228v1-Figure34-1.png",
            "$2305.00228v1-Figure35-1.png",
            "$2305.00228v1-Figure4-1.png",
            "$2305.00228v1-Figure6-1.png",
            "$2305.00228v1-Figure8-1.png",
            "$2305.00228v1-Figure9-1.png",
            "$2305.00228v1-Table1-1.png",
            "$2305.00228v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00229",
        "abstract": "  Machine Learning (ML) is of increasing interest for modeling parametric\neffects in manufacturing processes. But this approach is limited to established\nprocesses for which a deep physics-based understanding has been developed over\ntime, since state-of-the-art approaches focus on reducing the experimental\nand/or computational costs of generating the training data but ignore the\ninherent and significant cost of developing qualitatively accurate\nphysics-based models for new processes . This paper proposes a transfer\nlearning based approach to address this issue, in which a ML model is trained\non a large amount of computationally inexpensive data from a physics-based\nprocess model (source) and then fine-tuned on a smaller amount of costly\nexperimental data (target). The novelty lies in pushing the boundaries of the\nqualitative accuracy demanded of the source model, which is assumed to be high\nin the literature, and is the root of the high model development cost. Our\napproach is evaluated for modeling the printed line width in Fused Filament\nFabrication. Despite extreme functional and quantitative inaccuracies in the\nsource our approach reduces the model development cost by years, experimental\ncost by 56-76%, computational cost by orders of magnitude, and prediction error\nby 16-24%.\n",
        "title": "Accelerated and Inexpensive Machine Learning for Manufacturing Processes\n  with Incomplete Mechanistic Knowledge",
        "texts": [
            "Figure 1: Comparison of source and target for h = (a) 0.7 mm (b) 0.85 mm (c) 1.2 mm. Feed rate F and stage speed S are in mm/min.",
            "Figure 2: RMSE from direct learning as a function of the number of training points for for h = (a) 0.7 mm (b) 0.85 mm (c) 1.2 mm. Comparison of RMSEdirect to the error obtained from transfer learning using different amounts of experimental F and S and for h = (d) 0.7 mm (e) 0.85 mm (f) 1.2 mm. Feed rate F and stage speed S are in mm/min.",
            "Figure 3: Comparison of transfer learnt model and target for h = (a-d) 0.7 mm (e-h) 0.85 mm (i-l) 1.2 mm.",
            "Table 1. Comparison of smallest RMSE and corresponding number of training samples for direct learning and transfer learning"
        ],
        "imgs": [
            "$2305.00229v1-Figure1-1.png",
            "$2305.00229v1-Figure2-1.png",
            "$2305.00229v1-Figure3-1.png",
            "$2305.00229v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00230",
        "abstract": "  In the present paper, we perform a sub-Planckian quantum mode analysis of\nlinear cosmological perturbation in the inflaton field over a classical quasi\nde-Siter metric background by dynamical horizon exit (DHE) method. In this way,\nwe probe the inflationary regime of a quintessential $\\alpha$-attractor model\nby analysing the COBE/Planck normalized power spectra, spectral indices, tensor\nto scalar ratio, number of e-folds, running of the spectral index and\ninflationary Hubble parameter in $k$-space. We compare our results with\nordinary $\\alpha$-attractor $E$ and $T$ models and with that of Planck-2018\nresults. Our estimated values of $n_s$ and $r$ lie within $68\\%$ CL with\nrespect to Planck data for $k=0.001 - 0.009$ Mpc$^{-1}$ for all values of\n$\\alpha$. The $\\alpha$ values, obtained in our calculations satisfy various\npost inflationary constraints regarding preheating and reheating, reported in\ncurrent literature. We observe that quintessence sets an upper bound of\n$\\alpha=4.3$ and thereby restricts the model from becoming of the power law\ntype, making it more efficacious than ordinary $\\alpha$-attractors in\nexplaining both inflation and dark energy. A striking observation in our\nanalyses is that, unlike in our previous study, we find a continuous values of\n$\\alpha$ within $\\frac{1}{10}\\leq \\alpha\\leq 4.3$ for the specified $k$ range.\nAt the end, we have shown that the model parameters constrained in this work\ngive a very small vacuum density $\\sim 10^{-117}-10^{-115} M_P^4$ which is an\nessential criterion for current and future dark energy observations of the\nuniverse.\n",
        "title": "Constraining the quintessential $\\alpha$-attractor inflation through\n  dynamical horizon exit method",
        "texts": [
            "Figure 1. Schematic diagram of the quintessential inflaton potential for α = 1 10 and n = 2 (as for example; exact values will be illustrated in section 4.) normalised byM4 plotted against ψ in the unit ofMP . ψ > 0 and ψ < 0 regions correspond to the inflationary slow-roll plateau and quintessential flat tail respectively. The inflaton field (the red ball) rolls over the potential from the regimes of inflation to quintessence smoothly through the period of kination, where the field is allowed to free-fall. At the bottom of the potential the inflaton field is non-oscillatory and survives until today to become dark energy. Standard model particles are produced at the potential minima in the thermal bath of the hot big bang by non-standard ways.",
            "Figure 10. Tensor power spectra for four values of α for a given value of n. The values of ∆t(k) increase on increase in α for a particular value of k.",
            "Figure 11. Number of e-folds for four values of α for a given value of n. The values of N(k) remain almost same for α = 1 10 , 1 6 and α = 1, 4.3 for a particular value of k.",
            "Figure 12. Scalar spectral indices for four values of α for a given value of n. The values of ns(k) remain almost fixed for all values of α.",
            "Figure 13. Tensor spectral indices for four values of α for a given value of n. The values of |nt(k)| increase on increase in α for a particular value of k.",
            "Figure 14. Tensor to scalar ratios for four values of α for a given value of n. The values of r(k) increase on increase in α for a particular value of k.",
            "Figure 15. Running of the spectral index for four values of α for a given value of n. Very small variation is observed in αs(k) on increase in α.",
            "Figure 16. Inflationary Hubble parameters for four values of α for a given value of n. The values of Hinf(k) increase on increase in α for a particular value of k.",
            "Figure 17. Comparisons of power spectra, number of e-folds and the inflationary Hubble parameters of quintessential α-attractor (QI model) with that of ordinary α-attractor E and T models for n = 122 and α = 1. The results for QI model are smaller than that of E and T models. But the values coincide (or the differences are too small to be detected in the scale shown here) for the two α-attractors, which is quite expected. However the N(k) values are very close for all the models described here.",
            "Figure 18. Comparisons of spectral indices, tensor to scalar ratios and the running of the spectral index of quintessential α-attractor (QI model) with that of ordinary α-attractor E and T models for n = 122 and α = 1. The results for QI model are smaller than that of E and T models except for the tensor to scalar ratios, which is obvious. Here also, the values coincide (or the differences are too small to be detected in the scale shown here) for the two α-attractors, which is quite expected. However the values of spectral indices and tensor to scalar ratios are very close for all the models described here.",
            "Figure 19. Comparison of our calculations for ns and r with that of Planck-2018 data for increasing values of α for a given value of n. All our results lie within the 68% CL. The yellow dots of equal size at the ends represent the data are obtained for a fixed initial condition corresponding to the number of e-folds N = 63.49.",
            "Figure 2. Changes in shape and energy scale of the potential with the variations of n and α. Figure (2a) shows that the amplitude of the potential towards inflation remains almost fixed whereas that in the quintessential tail part varies with the increase in n for a fixed value of α (here α = 1 6 ). Figure (2b) shows that, as α increases for a fixed value of n (here n = 2) the potential loses its plateau form and starts to become polynomial type. This aspect will be more clear in the next figure.",
            "Figure 20. Combined results of figure 19 show an elevation of the ns − r parameteric line with increased values of α from 1 10 through 4.3, which is a signature of the potential distortion explained in the context of figures 2b and 3 in section 2. The white line represents that all values of α are permitted between 1 10 and 4.3, which is a key difference from the ordinary α-attractors explained in [100]. Another important observation is that the slopes of the ns − r lines get changed when we go from low to high values of α. The tilts of the lines ensure that the potential in our framework is concave which is an essential requirement of Planck data for successful model building.",
            "Figure 4. Planck-2018 results for As, ns and r are regenerated using the experimental data obtained as the public chains from the Planck Legacy Archive (https://pla.esac.esa.int/) by running the GetDist (https://getdist.readthedocs.io/en/latest/) plotting utility. The best-fit results for ns = 0.9649± 0.0042 at 68% CL and r0.002 < 0.064 at 95% CL are found around As ≈ 2.1× 10−9.",
            "Figure 5. Unperturbed parts of the potential (2.11), where ψ ≡ ψ(k) is the mode function for four values of α for a given value of n. The values of V (0)(k) increase on increase in α for a particular value of k.",
            "Figure 6. First order perturbed parts of the potential (2.11) for four values of α for a given value of n. The values of δV (k) increase on increase in α for a particular value of k. The amount of perturbation is larger for small k’s than that of high k’s for α = 1/10, 1/6 and likewise for α = 1, 4.3 the corresponding values for small k’s are smaller than that of high k’s.",
            "Figure 7. Unperturbed parts of the inflaton field ψ(k) for four values of α for a given value of n. The values of ψ(0)(k) increase on increase in α for a particular value of k.",
            "Figure 8. First order perturbed parts of the inflaton field ψ(k) for four values of α for a given value of n. The values of δψ(k) increase on increase in α for a particular value of k. Just like δV (k) here also the amount of inflaton perturbation is larger for small k’s than that of high k’s for α = 1/10, 1/6 and for α = 1, 4.3 the corresponding values for small k’s are smaller than that of high k’s.",
            "Figure 9. Scalar power spectra for four values of α for a given value of n. The values of ∆s(k) decrease on increase in α for a particular value of k.",
            "Table 1. Constraints for M by COBE/Planck normalisation for a given value of α. The conversion factor is MP = 2.43× 1018 GeV.",
            "Table 2. Constraints for VΛ for a given values of n and M ."
        ],
        "imgs": [
            "$2305.00230v1-Figure1-1.png",
            "$2305.00230v1-Figure10-1.png",
            "$2305.00230v1-Figure11-1.png",
            "$2305.00230v1-Figure12-1.png",
            "$2305.00230v1-Figure13-1.png",
            "$2305.00230v1-Figure14-1.png",
            "$2305.00230v1-Figure15-1.png",
            "$2305.00230v1-Figure16-1.png",
            "$2305.00230v1-Figure17-1.png",
            "$2305.00230v1-Figure18-1.png",
            "$2305.00230v1-Figure19-1.png",
            "$2305.00230v1-Figure2-1.png",
            "$2305.00230v1-Figure20-1.png",
            "$2305.00230v1-Figure4-1.png",
            "$2305.00230v1-Figure5-1.png",
            "$2305.00230v1-Figure6-1.png",
            "$2305.00230v1-Figure7-1.png",
            "$2305.00230v1-Figure8-1.png",
            "$2305.00230v1-Figure9-1.png",
            "$2305.00230v1-Table1-1.png",
            "$2305.00230v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00232",
        "abstract": "  In this article on variational regularization for ill-posed nonlinear\nproblems, we are once again discussing the consequences of an oversmoothing\npenalty term. This means in our model that the searched-for solution of the\nconsidered nonlinear operator equation does not belong to the domain of\ndefinition of the penalty functional. In the past years, such variational\nregularization has been investigated comprehensively in Hilbert scales, but\nrarely in a Banach space setting. Our present results try to establish a\ntheoretical justification of oversmoothing regularization in Banach scales.\nThis new study includes convergence rates results for a priori and a posteriori\nchoices of the regularization parameter, both for H\\\"older-type smoothness and\nlow order-type smoothness. An illustrative example is intended to indicate the\nspecificity of occurring non-reflexive Banach spaces.\n",
        "title": "New results for variational regularization with oversmoothing penalty\n  term in Banach spaces",
        "texts": [
            "Figure 1: Behaviour of minimizing functions uδα for δ = 0.0125 and decreasing values of α.",
            "Table 1: Numerical results of Algorithm 8 for p = 0.3.",
            "Table 2: Numerical results of Algorithm 8 for p = 0.7."
        ],
        "imgs": [
            "$2305.00232v1-Figure1-1.png",
            "$2305.00232v1-Table1-1.png",
            "$2305.00232v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00238",
        "abstract": "  Genetic Algorithm (GA) is a popular meta-heuristic evolutionary algorithm\nthat uses stochastic operators to find optimal solution and has proved its\neffectiveness in solving many complex optimization problems (such as\nclassification, optimization, and scheduling). However, despite its\nperformance, popularity and simplicity, not much attention has been paid\ntowards reproducibility and reusability of GA. In this paper, we have extended\nFindable, Accessible, Interoperable and Reusable (FAIR) data principles to\nenable the reproducibility and reusability of algorithms. We have chosen GA as\na usecase to the demonstrate the applicability of the proposed principles. Also\nwe have presented an overview of methodological developments and variants of GA\nthat makes it challenging to reproduce or even find the right source.\nAdditionally, to enable FAIR algorithms, we propose a vocabulary (i.e. $evo$)\nusing light weight RDF format, facilitating the reproducibility. Given the\nstochastic nature of GAs, this work can be extended to numerous Optimization\nand machine learning algorithms/methods.\n",
        "title": "The FAIRy Tale of Genetic Algorithms",
        "texts": [
            "Figure 1: Detailed metadata parameters to improve the reusability and reproducibility of GA.",
            "Figure 2: GA iteration cycle starting from the problem specification till the performance measures.",
            "Figure 3: Algorithm related parameter specification for GA",
            "Figure 4: Performance related parameter specification for GA",
            "Table 1: FAIR data principles",
            "Table 2: Different variants of GA",
            "Table 4: Population structures in different variants of GA",
            "Table 6: Metadata specification for Algorithm.",
            "Table 7: Proposed evo vocabulary for GA"
        ],
        "imgs": [
            "$2305.00238v1-Figure1-1.png",
            "$2305.00238v1-Figure2-1.png",
            "$2305.00238v1-Figure3-1.png",
            "$2305.00238v1-Figure4-1.png",
            "$2305.00238v1-Table1-1.png",
            "$2305.00238v1-Table2-1.png",
            "$2305.00238v1-Table4-1.png",
            "$2305.00238v1-Table6-1.png",
            "$2305.00238v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00239",
        "abstract": "  Superionic conductors offer unique advantages for novel technological devices\nin various fields, such as energy storage and neuromorphic computing. Above 414\nK, Cu2Se turns into a well-known superionic conductor via a phase transition,\nand it is demonstrated to exhibit peculiar electrical and thermoelectric\nproperties in bulk. Here, we report a large-area synthesis of ultra-thin single\ncrystalline Cu2Se using the chemical vapor deposition method. We demonstrate\nthat Cu2Se crystals exhibit optically and electrically controllable robust\nphase reconfiguration below 414 K. Moreover, our results show that the mobility\nof the liquid-like Cu ion vacancies in Cu2Se causes macroscopic fluctuations in\nthe Cu ordering. Consequently, phase variations are not dictated by the\ndiffusive motion of the ions but by the local energy minima formed due to the\ninterplay between the extrinsic and the intrinsic material parameters. As a\nresult, long-range ordering of the crystal below 414 K is optically observable\nat a micrometer scale. Our results show that Cu2Se could find applications\nbeyond thermoelectric such as smart optical coatings, optoelectronic switching,\nand ionic transistors.\n",
        "title": "Synthesis of Ultra-Thin Superionic Cu2Se and New Aspects of the\n  Low-Temperature Crystal Configurations",
        "texts": [
            "Figure 1 a. Unit cell of the room temperature Cu2Se with Cu, Tetrahedral, and Cu, Octahedral sites depicted. The red arrow points along the monoclinic [001] direction. b. Optical micrograph of a large Cu2Se crystal on a sapphire substrate. c. AFM height trace map of an 11 nm thick Cu2Se with the line trace overlayed on the image. The bright lines going across the image are the folds of the mica substrate. Inset shows the optical micrograph. The scale bar is 10 µm.",
            "Figure 2 a. XRD θ-2θ scan of the Cu2Se crystals at room temperature. Red lines indicate the peak positions in JCPDS-00-019-0401 data card. b. HAADF STEM image of the crystal collected perpendicular to the crystal. c. SAED pattern indexed along [111] zone axis. The scale bar is 2 1/nm. d. Cross-sectional high-resolution TEM image of the crystal shows the interplanar spacing along (110) planes. The scale bar is 4 nm. e. EDX survey of a Cu2Se crystal with EDX maps overlayed on the graph. The scale bar is 2 µm. f. XPS surveys of Cu 2p and Se 3d peaks. The smaller peaks fitted to the Cu survey correspond to Cu2+ oxidation state.",
            "Figure 3 a. Optical micrograph of Cu2Se on a mica and b. on a sapphire substrate at room temperature. The optically contrasting regions are evident in the images. The sharp angle indicated on the crystal is 130° and measures the same for other crystals. Scale bars are 20 and 10 µm, respectively. c. A series of temperature-dependent optical micrographs of a crystal on mica. Red and blue arrows indicate the heating and cooling with the temperatures marked between the panels. There is a hysteresis between the area covered by the dark phases upon heating and cooling cycles. The yellow arrows indicate the filament-like dark phase formation at 358 K. The scale bar is 5 µm. d. 8-bit R+G index read from the dark regions of the sample at different temperatures. Green and red arrows mark the green and red indices, respectively. As the temperature increases green and red indices shift. This shows that there are two optically distinguishable dark configurations. e. Optical microscope images of a crystal taken at various temperatures show the shift of the color tint. The edge of the crystal is 19 µm long. f. Arrhenius plot of the dark phase area over the total area of the crystal versus 𝑇−1 for four different samples of similar size. The activation energy is calculated from the slope of the line fit to be 𝐸𝐴 = 0.207 ± 0.053 eV.",
            "Figure 4 a. Photoluminescence spectra of the dark and the bright configurations are shown. The panel on the right shows the optical microscope image and the PL intensity map around 600 nm of the dashed region. The scale bar is 10 µm. b. Temperature-dependent PL spectra of the dark (upper graph) and the bright (lower graph) are given. Intensity is normalized to 1. c. Optical microscope images of i. pristine crystal with dark configurations at the corners, ii. the laser beam marked with the green dot focused on the center of the crystal, attracts the dark configuration to the center, iii. the dark configuration is completely pulled at the center. iv. Laser power is increased to ~1 mW. The dark area expands to a point where further increase of the laser power doesn’t change the 𝐴/𝐴0 ratio. v. Once the laser power is reduced and the laser is positioned at the corner of the crystal, the dark region is moved to the corner, partially. The scale bar is 5 µm. d. The same crystal in c is shown. The dark phase is collected at the left upper corner of the crystal. The series of images from i to iv shows the effect of laser power increased when the laser is over the dark phase. i. From 0 µW to 125 µW, we observed no change in 𝐴/𝐴0 ratio. ii-iv. 𝐴/𝐴0 ratio increases with the increasing laser power. Beyond 1150 µW, no change in 𝐴/𝐴0 ratio is observed. v. Once the laser beam is blocked, the 𝐴/𝐴0 ratio shrinks to the pristine value.",
            "Figure 5 a. Minimum laser power required to create the dark and the high-T dark configurations from the bright configuration. The solid line shows a polynomial fit to aid the eye. b. Free energy configurations at three different temperature regimes are given qualitatively in the graphs. D, D’, and B correspond to the dark, high-T dark, and the bright configurations, respectively. Near room temperature, by introducing Cu vacancies through oxidation, the D configuration can be obtained. As the temperature increases, D’ configuration becomes meta-stable and can be obtained by locally heating the D or B configuration. Above 390 K, only D’ configuration remains stable.",
            "Figure 6 a. I-V curve before applying the forming voltage, 1 V with 1 mA compliance. b. I-V curve of the same device after forming the device. c. The resistance-Temperature graph shows a positive temperature coefficient of resistance. d. A series of optical micrographs were collected during the I-V cycling. Panel i shows the optical contrast of the crystal before the application of the forming voltage. ii shows after forming the device and iii when a reverse bias is applied. The ground terminal is marked on the first panel. The scale bar is 10 µm."
        ],
        "imgs": [
            "$2305.00239v1-Figure1-1.png",
            "$2305.00239v1-Figure2-1.png",
            "$2305.00239v1-Figure3-1.png",
            "$2305.00239v1-Figure4-1.png",
            "$2305.00239v1-Figure5-1.png",
            "$2305.00239v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00240",
        "abstract": "  This Research Note presents VLT B-band imaging of a candidate runaway\nsupermassive black hole that was recently discovered in HST/ACS F606W+F814W\nimaging. The ACS data show an extremely thin, linear feature at z=0.964 that\npoints toward a compact galaxy at the same redshift. There is a gap between the\nfeature and the compact galaxy, which means that the proposed causal connection\nbetween the two objects is not definitive. We show here that the linear feature\nextends all the way to the compact galaxy in the B-band, with no gap. The\nB-band morphology is difficult to reconcile with models where the compact\ngalaxy and the linear feature are independent objects, and in particular with\nthe proposal of Sanchez Almeida et al. (2023) that the linear feature is an\nedge-on disk galaxy.\n",
        "title": "A direct connection between the wake and the former host galaxy of a\n  proposed runaway supermassive black hole",
        "texts": [
            "Figure 1. Top: summed ACS F606W+F814W image of the linear feature and the compact galaxy GX, both at z = 0.964. The brightest emission is in orange. In van Dokkum et al. (2023) the linear feature is interpreted as young stars behind a runaway supermassive black hole that originated in GX. There is a gap between the feature and GX, and Sanchez Almeida et al. (2023) explore the alternative interpretation that they are two independent galaxies. Bottom: VLT B band image, sampling λrest ∼ 0.22µm. In the rest-frame far-UV there is no gap and the feature extends all the way to GX. This is consistent with what was seen in the observed u band and the [O iii] line in vD23, and difficult to reconcile with the Sanchez Almeida et al. (2023) hypothesis. In the runaway black hole model the emission in the gap is shocked gas."
        ],
        "imgs": [
            "$2305.00240v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00241",
        "abstract": "  In the past decade, deep learning became the prevalent methodology for\npredictive modeling thanks to the remarkable accuracy of deep neural networks\nin tasks such as computer vision and natural language processing. Meanwhile,\nthe structure of neural networks converged back to simpler representations\nbased on piecewise constant and piecewise linear functions such as the\nRectified Linear Unit (ReLU), which became the most commonly used type of\nactivation function in neural networks. That made certain types of network\nstructure $\\unicode{x2014}$such as the typical fully-connected feedforward\nneural network$\\unicode{x2014}$ amenable to analysis through polyhedral theory\nand to the application of methodologies such as Linear Programming (LP) and\nMixed-Integer Linear Programming (MILP) for a variety of purposes. In this\npaper, we survey the main topics emerging from this fast-paced area of work,\nwhich bring a fresh perspective to understanding neural networks in more detail\nas well as to applying linear optimization techniques to train, verify, and\nreduce the size of such networks.\n",
        "title": "When Deep Learning Meets Polyhedral Theory: A Survey",
        "texts": [
            "Figure 1: Example classification task on the MNIST database of handwritten digits, in which the image of a handwritten digit is given as input and the probability of that digit being from each possible class is provided as output.",
            "Figure 10: Convex approximations for the ReLU function commonly used by propagation algorithms, given as a function of the preactivation function ĥli. The ReLU applies hli = max(0, ĥli).",
            "Figure 11: Illustration of Neural Network with LTU activations using MSMT. Inside each node of the hidden layer, we show the thresholds used in each LTU activation.",
            "Figure 2: Mapping from x ∈ Rn0 to y ∈ RnL through a feedforward neural network with L layers, layer widths {nl}l∈L, and activation functions {σl}l∈L.",
            "Figure 3: Mapping from the input x ∈ [0, 1] to the intermediary output h2 ∈ [0, 1]4 through the first two layers of a neural network in which the number of linear regions growths exponentially on the depth, as described in Example 1. The parameters of subsequent layers are the same as those in the second layer.",
            "Figure 4: Set of activation functions {fi(x)}4i=1 of the units in the first layer and combined outputs of the first two layers —F (x) = f1(x)−f2(x)+f3(x)−f4(x) for the first and F (F (x)) for the second— of a neural network in which the number of linear regions grows exponentially on the depth, as described in Example 1.",
            "Figure 5: Linear regions defined by the shallow neural network described in Example 2. Every line corresponds to the activation hyperplane of a different neuron, which is given by α, β, and γ in parentheses. The arrow next to each line points to the half space in which the inputs activate that neuron. Every linear region has a subset of {α, β, γ} as its corresponding activation set.",
            "Figure 6: Linear regions defined by the 2 layers of the neural network described in Example 3, following the same notation as in Figure 5. The first and second plots show the linear regions and corresponding activation sets defined by the first and the second layers in terms of their input spaces (x and h1). The third plot shows the linear regions defined by the combination of the 2 layers and the union of their activation sets in terms of the input space of the first layer (x).",
            "Figure 7: Dimension of the image of the affine function yI(x) associated with each linear region I defined by the neural network described in Example 3. The linear regions are the same illustrated in the third plot of Figure 6.",
            "Figure 8: Example of adversarial attack on MobileNetV2 (Sandler et al., 2018). The original image taken by one of the survey authors is classified as ‘siberian husky,’ but is re-classified as ‘wallaby’ with a small (in an `∞-norm sense) targeted attack.",
            "Figure 9: Left: The convex hull of a ReLU neuron (5), and Right: the convex relaxation offered by the big-M formulation (4) Adapted from Anderson et al. (2019, 2020)",
            "Table 4: Summary for various architectures. DNN refers to a fully-connected Deep Neural Network, CNN to a Convolutional Neural Network and ResNet to a Residual Network. G is the graph defining the Network and ∆ is the maximum in-degree in G."
        ],
        "imgs": [
            "$2305.00241v1-Figure1-1.png",
            "$2305.00241v1-Figure10-1.png",
            "$2305.00241v1-Figure11-1.png",
            "$2305.00241v1-Figure2-1.png",
            "$2305.00241v1-Figure3-1.png",
            "$2305.00241v1-Figure4-1.png",
            "$2305.00241v1-Figure5-1.png",
            "$2305.00241v1-Figure6-1.png",
            "$2305.00241v1-Figure7-1.png",
            "$2305.00241v1-Figure8-1.png",
            "$2305.00241v1-Figure9-1.png",
            "$2305.00241v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00242",
        "abstract": "  Asthma is one of the chronic inflammatory diseases of the airways, which\ncauses chest tightness, wheezing, breathlessness, and cough. Spirometry is an\neffort-dependent test used to monitor and diagnose lung conditions like Asthma.\nVocal breath sound (VBS) based analysis can be an alternative to spirometry as\nVBS characteristics change depending on the lung condition. VBS test consumes\nless time, and it also requires less effort, unlike spirometry. In this work,\nVBS characteristics are analyzed before and after administering bronchodilator\nin a subject-dependent manner using linear discriminant analysis (LDA). We find\nthat features learned through LDA show a significant difference between VBS\nrecorded before and after administering bronchodilator in all 30 subjects\nconsidered in this work, whereas the baseline features could achieve a\nsignificant difference between VBS only for 26 subjects. We also observe that\nall frequency ranges do not contribute equally to the discrimination between\npre and post bronchodilator conditions. From experiments, we find that two\nfrequency ranges, namely 400-500Hz and 1480-1900Hz, maximally contribute to the\ndiscrimination of all the subjects. The study presented in this paper analyzes\nthe pre and post-bronchodilator effect on the inhalation sound recorded at the\nmouth in a subject-dependent manner. The findings of this work suggest that,\ninhalation sound recorded at mouth can be a good stimulus to discriminate pre\nand post-bronchodilator conditions in asthmatic subjects. Inhale sound-based\npre and post-bronchodilator discrimination can be of potential use in clinical\nsettings.\n",
        "title": "Analysis of vocal breath sounds before and after administering\n  Bronchodilator in Asthmatic patients",
        "texts": [
            "Figure 1: For a given baseline feature on x-axis, yellow color indicates subject index which has shown significant difference between IPVBS recorded before and after administering bronchodilator and blue color indicates a subject that does not have significant difference. Bar graph at the top shows total number of subjects which show significant between differences IPVBS recorded before and after taking bronchodilator using each baseline feature.",
            "Figure 2: Box plot of best performing baseline feature FB , i.e., P4/Pt, computed on IPVBS recorded before and after administering bronchodilator separately for all the subjects.",
            "Figure 4: Bar plot of percent change in average value of FB=P4/Pt and FP before and after administering bronchodilator in separately for every subject. Indices for the subjects which do not show significant change in FB before and after bronchodilator are shown in magenta color in the X-axis.",
            "Figure 5: Trend of total number of subjects for whom the proposed feature is significantly different before and after administering bronchodilator with varying weights percentile. Top plot shows an illustrative weight vector when weights are progressively set to zero with increasing percentile value.",
            "Figure 6: Stacked bar plot of FDR values obtained using Fαp for αp = 54 and FP for comparison.",
            "Figure 7: The frequencies which have weights above 54th percentiles in each subject are shown in white. The black dots indicate weights below 54th percentile. Bar plot at the top shows the total number of subjects for whom the weight at a particular frequency is above 54th percentile. Purple color bar in the bar plot shows top two most occurring frequencies.",
            "Figure 8: Comparison of FDR by using average weights of all subjects (FPA), proposed weights (FP ) and 11 subject weights (F 11). By using FPA, subjects 7th, 12th, 17th and 26th (shown in magenta color) do not show significant change pre and post bronchodilator conditions.",
            "Figure 9: Performance of weights learned for one subjects when used on another subjects. For a given subject weights, yellow color indicates which subjects shows significant difference before and after taking bronchodilator and blue color shows which subject doesn’t show significant difference between pre and post bronchodilator conditions.",
            "Table 1: Number of subjects for whom average FP , Fαp for αp=54 and FPA, change significantly after administering bronchodilator compared to before."
        ],
        "imgs": [
            "$2305.00242v1-Figure1-1.png",
            "$2305.00242v1-Figure2-1.png",
            "$2305.00242v1-Figure4-1.png",
            "$2305.00242v1-Figure5-1.png",
            "$2305.00242v1-Figure6-1.png",
            "$2305.00242v1-Figure7-1.png",
            "$2305.00242v1-Figure8-1.png",
            "$2305.00242v1-Figure9-1.png",
            "$2305.00242v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00243",
        "abstract": "  Assuming the self-consistent theory of localization due to Abou-Chacra et\nal., we solve the N=1 Wegner model in the regime of strong disorder and high\ndimension. In the process, we uncover a non-standard electronic phase with\nspontaneously broken U(1) symmetry -- the missing field-theory basis underlying\nphenomena associated with fractal eigenstates and singular continuous spectra.\n",
        "title": "Wegner model on a tree graph: U(1) symmetry breaking and a non-standard\n  phase of disordered electronic matter",
        "texts": [
            "FIG. 1. Schematic renormalization group (RG) flow diagram for a two-parameter field theory underlying Anderson transitions at strong coupling (conjecture). The field theory has a global Lorentzian symmetry. The reciprocal coupling λτ (resp. λσ) is the stiffness for field fluctuations tangent to Lorentz boost directions (resp. tangent to motions of compact type) of the target space. In addition to the two known RG-fixed points “ac” (λσ = λτ = ∞ : metal) and “pp” (λσ = λτ = 0 : insulator), there is a third ‘trivial’ RG-fixed point,“s”, at λσ = ∞, λτ = 0. In a certain parameter range, the N = 1 Wegner model is argued to flow to that fixed point."
        ],
        "imgs": [
            "$2305.00243v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00244",
        "abstract": "  Tooth segmentation from intraoral scans is a crucial part of digital\ndentistry. Many Deep Learning based tooth segmentation algorithms have been\ndeveloped for this task. In most of the cases, high accuracy has been achieved,\nalthough, most of the available tooth segmentation techniques make an implicit\nrestrictive assumption of full jaw model and they report accuracy based on full\njaw models. Medically, however, in certain cases, full jaw tooth scan is not\nrequired or may not be available. Given this practical issue, it is important\nto understand the robustness of currently available widely used Deep Learning\nbased tooth segmentation techniques. For this purpose, we applied available\nsegmentation techniques on partial intraoral scans and we discovered that the\navailable deep Learning techniques under-perform drastically. The analysis and\ncomparison presented in this work would help us in understanding the severity\nof the problem and allow us to develop robust tooth segmentation technique\nwithout strong assumption of full jaw model.\n",
        "title": "A Critical Analysis of the Limitation of Deep Learning based 3D Dental\n  Mesh Segmentation Methods in Segmenting Partial Scans",
        "texts": [
            "Fig. 1. The trained tooth segmentation algorithms fail to achieve good performance when segmenting the partial scans",
            "Fig. 2. The qualitative comparison of tooth labeling for partial scans via trained methods. the leftmost column show the segmentation results of the entire scan whereas other columns show the segmentation results on partial scans. As we can see the performance deteriorates significantly for the partial scans. Whole Jaw, Half Jaw, Single Tooth, Front, Four Teeth, Ten Teeth, Eight Teeth and Three Teeth are shown in the columns 1, 2, 3, 4, 5, 6, 7 and 8 respectively. Best viewed in color and when zoomed in.",
            "TABLE I THE TOOTH SEGMENTATION RESULTS FROM TEN DIFFERENT METHODS IN TERMS OF THE OVERALL ACCURACY (OA), THE DICE SCORE (DSC), SENSITIVITY (SEN) AND POSTIVE PREDICTIVE VALUE (PPV). WHOLE JAW, HALF JAW, FRONT, FOUR TEETH, SINGLE TOOTH, THREE TEETH, EIGHT TEETH, TEN TEETH DENOTE THE EXPERIMENT SETTING 1, 2, 3, 4, 5, 6, 7 AND 8 RESPECTIVELY. AS WE CAN SEE, ALL THE TEN METHODS PERFORM THE WORST FOR THE SMALLEST PARTIAL SCAN IN OUR EXPERIMENTS I.E. SINGLE TOOTH. MESHSEGNET WITH GCO AND POINTMLP OUTPERFORMS OTHER METHODS IN TERMS OF OA, DSC AND SEN. SURPRISINGLY PCT PERFORMS BEST IN TERMS OF PPV. THE GRAPH CUT POSTPROCESSING ALLOWS FOR BETTER RESULTS FOR MESHSEGNET. BUT IF WE CONSIDER PURELY DEEP LEARNING BASED METHODS, POINTMLP PERFORMS COMPARATIVELY ROBUSTLY IN SEGMENTING PARTIAL SCANS.",
            "TABLE II THE TOOTH SEGMENTATION RESULTS FROM TEN DIFFERENT METHODS IN TERMS OF THE LABEL WISE DICE SCORE."
        ],
        "imgs": [
            "$2305.00244v1-Figure1-1.png",
            "$2305.00244v1-Figure2-1.png",
            "$2305.00244v1-TableI-1.png",
            "$2305.00244v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00249",
        "abstract": "  Data-driven approaches for remote detection of Parkinson's Disease and its\nmotor symptoms have proliferated in recent years, owing to the potential\nclinical benefits of early diagnosis. The holy grail of such approaches is the\nfree-living scenario, in which data are collected continuously and\nunobtrusively during every day life. However, obtaining fine-grained\nground-truth and remaining unobtrusive is a contradiction and therefore, the\nproblem is usually addressed via multiple-instance learning. Yet for large\nscale studies, obtaining even the necessary coarse ground-truth is not trivial,\nas a complete neurological evaluation is required. In contrast, large scale\ncollection of data without any ground-truth is much easier. Nevertheless,\nutilizing unlabelled data in a multiple-instance setting is not\nstraightforward, as the topic has received very little research attention. Here\nwe try to fill this gap by introducing a new method for combining\nsemi-supervised with multiple-instance learning. Our approach builds on the\nVirtual Adversarial Training principle, a state-of-the-art approach for regular\nsemi-supervised learning, which we adapt and modify appropriately for the\nmultiple-instance setting. We first establish the validity of the proposed\napproach through proof-of-concept experiments on synthetic problems generated\nfrom two well-known benchmark datasets. We then move on to the actual task of\ndetecting PD tremor from hand acceleration signals collected in-the-wild, but\nin the presence of additional completely unlabelled data. We show that by\nleveraging the unlabelled data of 454 subjects we can achieve large performance\ngains (up to 9% increase in F1-score) in per-subject tremor detection for a\ncohort of 45 subjects with known tremor ground-truth.\n",
        "title": "Leveraging Unlabelled Data in Multiple-Instance Learning Problems for\n  Improved Detection of Parkinsonian Tremor in Free-Living Conditions",
        "texts": [
            "Fig. 1: High-level overview of the main components involved in the proposed semi-supervised MIL methodology.",
            "Fig. 2: Schematic overview of the data collection and pre-processing operations that take place prior to the actual tremor detector training. The data of a subject, collected unobtrusively during free-living conditions, are transformed via a 3 stage pipeline (pre-processing, segmentation and post-processing stages) to a bag of acceleration segments.",
            "Fig. 3: Tremor detection performance under different unlabelled set sizes. Each y-value represents the average F1score computed over 10 randomly-sampled subsets of the full unlabelled set, that are stratified with respect to the selfreported PD status of the subjects. The standard deviation across trials is also presented via error bars.",
            "Fig. 4: Visualization of the learned bag embeddings z for a toy MIL problem based on the two-moons dataset.",
            "TABLE I: Average ROC-AUC scores across 10 trials of the MNIST experiment. Positive bags are those with at least one ”9” digit.",
            "TABLE II: Average AUC scores across 5 trials of the CIFAR10 experiment. Positive bags are those with at least one image of the ”Truck” class.",
            "TABLE III: Basic demographic characteristics of the labelled and unlabelled cohorts used in the tremor detection experiment. Provided values are the mean of the population with the standard deviation in parentheses. PD status for the unlabelled data was self-reported by the participants themselves and not officially provided by neurologists. Tremor positive refers to whether a subject exhibits hand tremor or not (not all PD patients do exhibit tremor).",
            "TABLE V: Semi-supervised classification results for in-thewild PD tremor detection. We report the average performance metrics across all LOSO iterations and random trials."
        ],
        "imgs": [
            "$2305.00249v1-Figure1-1.png",
            "$2305.00249v1-Figure2-1.png",
            "$2305.00249v1-Figure3-1.png",
            "$2305.00249v1-Figure4-1.png",
            "$2305.00249v1-TableI-1.png",
            "$2305.00249v1-TableII-1.png",
            "$2305.00249v1-TableIII-1.png",
            "$2305.00249v1-TableV-1.png"
        ]
    },
    {
        "id": "2305.00250",
        "abstract": "  In this work, we focus on the inverse medium scattering problem (IMSP), which\naims to recover unknown scatterers based on measured scattered data. Motivated\nby the efficient direct sampling method (DSM) introduced in [23], we propose a\nnovel direct sampling-based deep learning approach (DSM-DL)for reconstructing\ninhomogeneous scatterers. In particular, we use the U-Net neural network to\nlearn the relation between the index functions and the true contrasts. Our\nproposed DSM-DL is computationally efficient, robust to noise, easy to\nimplement, and able to naturally incorporate multiple measured data to achieve\nhigh-quality reconstructions. Some representative tests are carried out with\nvarying numbers of incident waves and different noise levels to evaluate the\nperformance of the proposed method. The results demonstrate the promising\nbenefits of combining deep learning techniques with the DSM for IMSP.\n",
        "title": "A Direct Sampling-Based Deep Learning Approach for Inverse Medium\n  Scattering Problems",
        "texts": [
            "Figure 1: An example of the index functions by DSM (left) and the true contrast (right)",
            "Figure 10: The relative L2 testing error and SSIM for the trained networks from the MNIST dataset with different noise levels and numbers of incidences.",
            "Figure 11: Image reconstructions of two “Austria profiles” with 15% and 40% Gaussian noises by using the networks trained by the MNIST dataset. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Figure 12: Image reconstructions of Latin letters “D”, “S” and “M” with 50% and 100% Gaussian noises by the networks trained by the MNIST dataset with Ni = 16. We use 60 receivers equally distributed on a circular curve with a radius 5 centered at the origin to collect the scattered field data.",
            "Figure 13: Image reconstructions of an example from testing data and an ”Austria Ring” with 15% and 40% Gaussian noises in the scattered fields by the networks trained by MNIST dataset. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Figure 2: The architecture of the direct sampling-based deep learning approach",
            "Figure 3: The architecture of the U-Net used in the numerical experiments",
            "Figure 4: Image reconstructions from measured scattered fields with 15% and 40% Gaussian noises by using the networks trained by the circle dataset, where the relative permittivity is between 1.5 and 2.0. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Figure 5: The relative L2 testing error and SSIM for the networks trained by the circle dataset with different noise levels and number of incidences.",
            "Figure 6: Image reconstructions of a test example consisting of four circles with 15% and 40% Gaussian noises in the scattered fields by the networks trained by the circle dataset. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Figure 7: Image reconstructions of the “Austria profile” with 15% and 40% Gaussian noises in the scattered fields by the networks trained by the circle dataset. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Figure 8: Image reconstructions from measured scattered fields with 15% and 40% Gaussian noises by using the networks trained by the high contrast circle dataset, where the relative permittivity is between 3.5 and 4.0. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Figure 9: Reconstructed images from scattered fields with 15% and 40% Gaussian noises by using the networks trained by the MNIST dataset, where the relative permittivity is between 1.5 and 2.5. From left to right: the ground-truth images, the reconstruction with 1,2,4,8, and 16 incident fields.",
            "Table 1: The relative L2 testing error and SSIM for circle and high contrast circle examples with different noise levels and number of incidences.",
            "Table 2: Relative L2 testing error and SSIM for different examples with different noise levels and number of incidences, where the example MNIST ∣∣ Γ refers to that the scattered fields are measured on the half circular curve Γ."
        ],
        "imgs": [
            "$2305.00250v1-Figure1-1.png",
            "$2305.00250v1-Figure10-1.png",
            "$2305.00250v1-Figure11-1.png",
            "$2305.00250v1-Figure12-1.png",
            "$2305.00250v1-Figure13-1.png",
            "$2305.00250v1-Figure2-1.png",
            "$2305.00250v1-Figure3-1.png",
            "$2305.00250v1-Figure4-1.png",
            "$2305.00250v1-Figure5-1.png",
            "$2305.00250v1-Figure6-1.png",
            "$2305.00250v1-Figure7-1.png",
            "$2305.00250v1-Figure8-1.png",
            "$2305.00250v1-Figure9-1.png",
            "$2305.00250v1-Table1-1.png",
            "$2305.00250v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00253",
        "abstract": "  Human society and natural environment form a complex giant ecosystem, where\nhuman activities not only lead to the change of environmental states, but also\nreact to them. By using collective-risk social dilemma game, some studies have\nalready revealed that individual contributions and the risk of future losses\nare inextricably linked. These works, however, often use an idealistic\nassumption that the risk is constant and not affected by individual behaviors.\nWe here develop a coevolutionary game approach that captures the coupled\ndynamics of cooperation and risk. In particular, the level of contributions in\na population affects the state of risk, while the risk in turn influences\nindividuals' behavioral decision-making. Importantly, we explore two\nrepresentative feedback forms describing the possible effect of strategy on\nrisk, namely, linear and exponential feedbacks. We find that cooperation can be\nmaintained in the population by keeping at a certain fraction or forming an\nevolutionary oscillation with risk, independently of the feedback type.\nHowever, such evolutionary outcome depends on the initial state. Taken\ntogether, a two-way coupling between collective actions and risk is essential\nto avoid the tragedy of the commons. More importantly, a critical starting\nportion of cooperators and risk level is what we really need for guiding the\nevolution toward a desired direction.\n",
        "title": "Coevolutionary dynamics via adaptive feedback in collective-risk social\n  dilemma game",
        "texts": [
            "Figure 1. Coevolutionary feedback loop of population and risk states in the coupled game system. The meaning of colors is explained in the legend on the top.",
            "Figure 3. Representative plot of stable evolutionary outcomes in System I when linear strategy feedback on risk level is assumed. Different colors are used to distinguish the stability of different equilibrium points in the parameter space (u, cb ). The blue line indicates that the system undergoes a Hopf bifurcation at u = M−1",
            "Figure 4. Coevolutionary dynamics on phase planes and temporal dynamics of System I when linear feedback is considered. Filled circles represent stable and open circles denote unstable fixed points. The arrows provide the most likely direction of evolution and the continuous color code depicts the speed of convergence in which red denotes the highest speed, while purple represents the lowest speed of transition. On the right-hand side, blue solid line and red dash line respectively denote the fraction of cooperation and the risk level, as indicated in the legend. The first three rows show the coevolutionary dynamics when u > M−1",
            "Figure 5. A representative diagram about stable solutions of System II when strategy feedback on risk level is exponential. We use different colors to distinguish the stability of equilibrium points in the parameter space (T , cb ). The blue line indicates that the system undergoes a Hopf bifurcation at T = M−1",
            "Figure 6. Coevolutionary dynamics on phase planes and temporal dynamics of System II when exponential feedback is assumed. Filled circles represent stable and open circles denote unstable fixed points. The arrows provide the most likely direction of evolution and the continuous color code depicts the speed of convergence in which red denotes the highest speed, while purple represents the lowest speed of transition. Blue solid line and red dash line respectively denote the fraction of cooperation and the risk level, as indicated in the legend. The first three rows show the coevolutionary dynamics when T > M−1",
            "Table 1. Notation symbols and meanings in our work"
        ],
        "imgs": [
            "$2305.00253v1-Figure1-1.png",
            "$2305.00253v1-Figure3-1.png",
            "$2305.00253v1-Figure4-1.png",
            "$2305.00253v1-Figure5-1.png",
            "$2305.00253v1-Figure6-1.png",
            "$2305.00253v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00254",
        "abstract": "  We propose a novel generalization of constrained Markov decision processes\n(CMDPs) that we call the \\emph{semi-infinitely constrained Markov decision\nprocess} (SICMDP). Particularly, we consider a continuum of constraints instead\nof a finite number of constraints as in the case of ordinary CMDPs. We also\ndevise two reinforcement learning algorithms for SICMDPs that we call SI-CRL\nand SI-CPO. SI-CRL is a model-based reinforcement learning algorithm. Given an\nestimate of the transition model, we first transform the reinforcement learning\nproblem into a linear semi-infinitely programming (LSIP) problem and then use\nthe dual exchange method in the LSIP literature to solve it. SI-CPO is a policy\noptimization algorithm. Borrowing the ideas from the cooperative stochastic\napproximation approach, we make alternative updates to the policy parameters to\nmaximize the reward or minimize the cost. To the best of our knowledge, we are\nthe first to apply tools from semi-infinitely programming (SIP) to solve\nconstrained reinforcement learning problems. We present theoretical analysis\nfor SI-CRL and SI-CPO, identifying their iteration complexity and sample\ncomplexity. We also conduct extensive numerical examples to illustrate the\nSICMDP model and demonstrate that our proposed algorithms are able to solve\ncomplex sequential decision-making tasks leveraging modern deep reinforcement\nlearning techniques.\n",
        "title": "Semi-Infinitely Constrained Markov Decision Processes and Efficient\n  Reinforcement Learning",
        "texts": [
            "Figure 1. (Discharge of Sewage) The icons represent locations of the sewage outfalls. The satellite image is from NASA and only for illustrative purpose.",
            "Figure 10. (Ship Route Planning) Maximum constraint violation of SI-CPPO and baselines versus the number of iterations. The solid line is the maximum constraint violation averaged over 20 random seeds. And we also provide the according error bars.",
            "Figure 2. (Ship Route Planning) The island represents the ecological critical point. The green dashed line represents a feasible route, while the red dash-dot-dot line represents a more efficient but ecologically infeasible route. The satellite image is from NASA and only for illustrative purpose.",
            "Figure 3. (Discharge of Sewage) Visualization of violation of constraints using SI-CRL (left) and baseline (right). The heat refers to the number log (∗) (V π̂cy (µ)− uy)+ + 5× 10−6 − log(5 × 10−6). Larger numbers mean a more serious violation of constraints. The red cross icons in the left two subfigures represent the T = Nbaseline = 9 checkpoints selected by the algorithms.",
            "Figure 4. (Discharge of Sewage) Averaged error term of our proposed method and the baseline method over 100 seeds when T and Nbaseline vary. (δ = 0.005",
            "Figure 5. (Discharge of Sewage) Averaged time consumption of our method and the CMDP baseline to get a solution of given accuracy over 100 seeds. (δ = 0.005",
            "Figure 6. (Discharge of Sewage) Visualization of violation of constraints using SI-CPO (left) and the naive discretization baseline with Nbaseline = 500 solved by CRPO (right). The heat refers to the number 18(V π̂cy (µ)− uy)+. Larger numbers mean a more serious violation of constraints.",
            "Figure 7. (Discharge of Sewage) Error term of SI-CPO and baselines versus the number of iterations. The solid line is the error term averaged over 20 random seeds. And we also provide the according error bars.",
            "Figure 8. (Ship Route Planning) Visualization of routes and violation of constraints using SICPPO (left) and naive discretization with Nbaseline = 1000 (right). The heat refers to the number 5(V π̂cy (µ)− uy)+. Larger numbers mean a more serious violation of constraints. The green dashed line represents a feasible route induced by the SI-CPPO policy, while the red dash-dot line represents an infeasible route induced by the baseline policy. The blue icons in the center represent the ecologically critical points.",
            "Figure 9. (Ship Route Planning) Cumulative reward of SI-CPPO and baselines versus the number of iterations. The solid line is the cumulative reward averaged over 20 random seeds. And we also provide the according error bars.",
            "Table 1: (Discharge of Sewage) Time consumption of each iteration in SI-CPO and baselines.",
            "Table 2: (Discharge of Sewage) Time consumption of each iteration in SI-CPO and baselines."
        ],
        "imgs": [
            "$2305.00254v1-Figure1-1.png",
            "$2305.00254v1-Figure10-1.png",
            "$2305.00254v1-Figure2-1.png",
            "$2305.00254v1-Figure3-1.png",
            "$2305.00254v1-Figure4-1.png",
            "$2305.00254v1-Figure5-1.png",
            "$2305.00254v1-Figure6-1.png",
            "$2305.00254v1-Figure7-1.png",
            "$2305.00254v1-Figure8-1.png",
            "$2305.00254v1-Figure9-1.png",
            "$2305.00254v1-Table1-1.png",
            "$2305.00254v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00255",
        "abstract": "  Polydomain liquid crystalline (nematic) elastomers have highly unusual\nmechanical properties, dominated by the dramatically non-linear stress-strain\nresponse that reflects stress-induced evolution of domain patterns. Here, we\nstudy the classical Hertz indentation problem in such a material.\nExperimentally, we find that polydomain nematic elastomers display a smaller\nexponent than the classical 3/2 in the load vs. indentation depth response.\nThis is puzzling: asymptotically a softer stress-strain response requires a\nlarger exponent at small loads. We resolve this by theory where three regimes\nare identified -- an initial elastic regime for shallow indentation that is\nobscured in experiment, an intermediate regime where local domain pattern\nevolution leads to a smaller scaling in agreement with experiments, and a final\nstiffening regime where the completion of local domain evolution returns the\nresponse to elastic. This three-regime structure is universal, but the\nintermediate exponent is not. We discuss how our work reveals a new mechanism\nof enhanced adhesion for pressure-sensitive adhesion of nematic elastomers.\n",
        "title": "Softening of the Hertz indentation contact in nematic elastomers",
        "texts": [
            "Figure 1: (a) The illustration of our Hertz indentation test, with a solid sphere compressed into a flat thick layer of LCE, measuring the load and the vertical displacement. (b) A summary of experimental results, using the log-log scale to compare the ideal Hertz case for two isotropic elastomers (curves a. and b.) accurately following the slope F ∝ d3/2, and two LCE materials (curves c., scaling exponent 1.26, and d., scaling exponent 0.82).",
            "Figure 2: The computed load vs. displacement relationship from the theoretical model (A, black) and comparison with experiment (c., blue). The model parameters for the model are fit to an independent uniaxial tensile test (top-left inset) on 10%-crosslinked polydomain LCE and listed in Table 2 as material A. The calculated results show three regimes: an initial Regime I with classical exponent 3/2, an intermediate softening Regime II with exponent 1.18, and a final Regime III with classical exponent 3/2. The result for the corresponding isotropic model, same parameters except r = 1 (B, purple) shows the classical exponent of 3/2. The bottom-left inset shows the computational setup and a snapshot of the state of stress around the contact region.",
            "Figure 4: The tensile stress-strain data (inset) and corresponding Hertz indentation tests using FE simulations show the non-universal scaling exponent of the F ∝ dx for nematic polydomain LCEs. The black curves correspond to material A shown in Fig. 2, the red curves present the tensile test and Hertz indentation results on a stiffer material C, and the blue curves corresponds to a softer material D with parameters in Table I. The dashed lines show the reference d3/2 scaling of isotropic elastomers.",
            "Table 1: Parameters for cases A, B, C, and D."
        ],
        "imgs": [
            "$2305.00255v1-Figure1-1.png",
            "$2305.00255v1-Figure2-1.png",
            "$2305.00255v1-Figure4-1.png",
            "$2305.00255v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00256",
        "abstract": "  Krylov complexity is an important dynamical quantity with relevance to the\nstudy of operator growth and quantum chaos, and has recently been much studied\nfor various time-independent systems. We initiate the study of K-complexity in\ntime-dependent (driven) quantum systems. For periodic time-dependent (Floquet)\nsystems, we develop a natural method for doing the Krylov construction and then\ndefine (state and operator) K-complexity for such systems. Focusing on kicked\nsystems, in particular the quantum kicked rotor on a torus, we provide a\ndetailed numerical study of the time dependence of Arnoldi coefficients as well\nas of the K-complexity with the system coupling constant interpolating between\nthe weak and strong coupling regime. We also study the growth of the Krylov\nsubspace dimension as a function of the system coupling constant.\n",
        "title": "Krylov construction and complexity for driven quantum systems",
        "texts": [
            "Figure 2: (Left) This plot shows how the fluctuation magnitude, as measured by the standard deviation, in the Arnoldi coefficients varies with system size (N). (Right) Krylov Space Dimension (DK) vs. coupling strength. Note that DK increases with the coupling κ and saturates quickly at the maximum possible value.",
            "Figure 3: Left: State Complexity dynamics. Note the differing saturation behaviour for small and large coupling parameters. Right: K-entropy growth with time (number of kicks).",
            "Figure 5: (Left) Fluctuations versus system size. The plot shows how the size of fluctuations changes as the system size (N) is increased. There is the expected overall decrease, although it is not monotonic. (Right) Krylov Space Dimension DK vs. coupling κ. This plot makes manifest the chaotic nature of the dynamics as the coupling κ is increased. DK increases rapidly to its maximum possible value (shown in red).",
            "Figure 7: Lanczos Coefficients and Krylov Complexity generated by logUF ."
        ],
        "imgs": [
            "$2305.00256v2-Figure2-1.png",
            "$2305.00256v2-Figure3-1.png",
            "$2305.00256v2-Figure5-1.png",
            "$2305.00256v2-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00257",
        "abstract": "  A brain tumor, whether benign or malignant, can potentially be life\nthreatening and requires painstaking efforts in order to identify the type,\norigin and location, let alone cure one. Manual segmentation by medical\nspecialists can be time-consuming, which calls out for the involvement of\ntechnology to hasten the process with high accuracy. For the purpose of medical\nimage segmentation, we inspected and identified the capable deep learning\nmodel, which shows consistent results in the dataset used for brain tumor\nsegmentation. In this study, a public MRI imaging dataset contains 3064\nTI-weighted images from 233 patients with three variants of brain tumor, viz.\nmeningioma, glioma, and pituitary tumor. The dataset files were converted and\npreprocessed before indulging into the methodology which employs implementation\nand training of some well-known image segmentation deep learning models like\nU-Net & Attention U-Net with various backbones, Deep Residual U-Net, ResUnet++\nand Recurrent Residual U-Net. with varying parameters, acquired from our review\nof the literature related to human brain tumor classification and segmentation.\nThe experimental findings showed that among all the applied approaches, the\nrecurrent residual U-Net which uses Adam optimizer reaches a Mean Intersection\nOver Union of 0.8665 and outperforms other compared state-of-the-art deep\nlearning models. The visual findings also show the remarkable results of the\nbrain tumor segmentation from MRI scans and demonstrates how useful the\nalgorithm will be for physicians to extract the brain cancers automatically\nfrom MRI scans and serve humanity.\n",
        "title": "Brain Tumor Segmentation from MRI Images using Deep Learning Techniques",
        "texts": [
            "Fig. 1. Flow chart for conducting this work",
            "Fig. 2. Sample images of T1-weighted MRI dataset, a) MRI scans b) Ground Truth masks",
            "Fig. 3. U-net architecture for tumor segmentation",
            "Fig. 4. Attention gate with gating signal (g) from encoder and current level decoder feature map (x) with X̂ as output to be concatenated with x",
            "Fig. 5. Residual learning: a building block",
            "Fig. 6. Recurrent Residual convolutional units (RRCU)",
            "Fig. 7. Precision and Recall of all applied deep learning models for tumor segmentation",
            "Fig. 8. Visual (Qualitative) results of various brain tumor segmentation models on T1Weighted MRI scans",
            "Table 1. Hyper-parameters used for training of various deep learning models",
            "Table 3. Statistical results of various state-of-art deep learning models for tumor segmentation"
        ],
        "imgs": [
            "$2305.00257v1-Figure1-1.png",
            "$2305.00257v1-Figure2-1.png",
            "$2305.00257v1-Figure3-1.png",
            "$2305.00257v1-Figure4-1.png",
            "$2305.00257v1-Figure5-1.png",
            "$2305.00257v1-Figure6-1.png",
            "$2305.00257v1-Figure7-1.png",
            "$2305.00257v1-Figure8-1.png",
            "$2305.00257v1-Table1-1.png",
            "$2305.00257v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00258",
        "abstract": "  The Sun constantly releases radiation and plasma into the heliosphere.\nSporadically, the Sun launches solar eruptions such as flares and coronal mass\nejections (CMEs). CMEs carry away a huge amount of mass and magnetic flux with\nthem. An Earth-directed CME can cause serious consequences to the human system.\nIt can destroy power grids/pipelines, satellites, and communications.\nTherefore, accurately monitoring and predicting CMEs is important to minimize\ndamages to the human system. In this study we propose an ensemble learning\napproach, named CMETNet, for predicting the arrival time of CMEs from the Sun\nto the Earth. We collect and integrate eruptive events from two solar cycles,\n#23 and #24, from 1996 to 2021 with a total of 363 geoeffective CMEs. The data\nused for making predictions include CME features, solar wind parameters and CME\nimages obtained from the SOHO/LASCO C2 coronagraph. Our ensemble learning\nframework comprises regression algorithms for numerical data analysis and a\nconvolutional neural network for image processing. Experimental results show\nthat CMETNet performs better than existing machine learning methods reported in\nthe literature, with a Pearson product-moment correlation coefficient of 0.83\nand a mean absolute error of 9.75 hours.\n",
        "title": "Ensemble Learning for CME Arrival Time Prediction",
        "texts": [
            "Figure 1. Time evolution of a CME, which occurred on April 10, 2001. Images were taken from https://soho.nascom. nasa.gov.",
            "Figure 2. Annual counts of the CMEs considered in this study. These CMEs occurred between August 1996 and May 2021. Solar cycle 23 (1996 - 2008) has more CMEs than solar cycle 24 (2008 - late 2019).",
            "Figure 3. Distribution of the transit times of the CMEs considered in this study. For the CMEs, the smallest transit time is 18 hours while the largest transit time is 138 hours.",
            "Figure 4. Illustration of our CMETNet framework. The framework consists of five machine learning-based regression models: SVR, RF, GP, XGB and CNN. For a CME event E, the first four models (SVR, RF, GP, XGB) accept E’s CME features and solar wind parameters as input while the fifth model (CNN) accepts E’s CME images as input. The five regression models are followed by an ensemble method, which combines the results from the five models and produces the predicted transit time of E.",
            "Figure 5. Illustration of the CNN model in CMETNet where the CNN model is used to predict the CME transit time for an input CME LASCO C2 image. (a) Overall architecture of the CNN model. The model starts with a 2D convolutional layer with 64 filters of size 11× 11 and 1 stride, followed by a Leaky Rectified Linear Unit (LeakyReLU) layer. The output of the LeakyReLU layer is then sent to five convolutional blocks. The output feature map of the last convolutional block is sent to two dense layers with 1024 neurons and 1 neuron, respectively. Finally, the model outputs the predicted CME transit time by using a linear activation function. (b) Detailed configuration of a convolutional block. The convolutional block contains a 2D convolutional layer with F filters where F = 64, 128, 128, 256, 256 respectively and S strides where S = 2, 1, 2, 1, 2 respectively and the filter size K = 11× 11. The 2D convolutional layer is followed by a batch normalization layer, which is followed by a LeakyReLU layer.",
            "Figure 6. Results of the ablation tests for assessing the components (SVR, RF, GP, XGB, CNN) of CMETNet where COMB is the ensemble model of SVR, RF, GP and XGB. (a) Pearson product-moment correlation coefficients (PPMCCs) of the tested models. (b) Mean absolute errors (MAEs) of the tested models. CMETNet achieves the best performance among all the tested models.",
            "Figure 7. Results of the ablation tests for assessing seven cases (FWI, FW, FI, WI, F, W, I) where FWI represents the combination of CME features, solar wind parameters and CME images, FW represents the combination of CME features and solar wind parameters, FI represents the combination of CME features and CME images, WI represents the combination of solar wind parameters and CME images, F represents the CME features, W represents the solar wind parameters, and I represents the CME images. (a) Pearson product-moment correlation coefficients (PPMCCs) of the tested cases. (b) Mean absolute errors (MAEs) of the tested cases. FWI yields the best performance among all the tested cases.",
            "Figure 8. Performance comparison of six methods for CME arrival time prediction. CMETNet is the ensemble learning framework proposed in this paper. SVR and PCNN are previously published machine learning methods. WECNOAA, SIDC, and WECGSFC are physics-based models presented on NASA’s CCMC CME Scoreboard. (a) Pearson product-moment correlation coefficients (PPMCCs) of the six methods. (b) Mean absolute errors (MAEs) of the six methods. CMETNet outperforms the other five methods in terms of both PPMCC and MAE."
        ],
        "imgs": [
            "$2305.00258v1-Figure1-1.png",
            "$2305.00258v1-Figure2-1.png",
            "$2305.00258v1-Figure3-1.png",
            "$2305.00258v1-Figure4-1.png",
            "$2305.00258v1-Figure5-1.png",
            "$2305.00258v1-Figure6-1.png",
            "$2305.00258v1-Figure7-1.png",
            "$2305.00258v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00260",
        "abstract": "  Over time, the performance of clinical prediction models may deteriorate due\nto changes in clinical management, data quality, disease risk and/or patient\nmix. Such prediction models must be updated in order to remain useful. Here, we\ninvestigate methods for discrete and dynamic model updating of clinical\nsurvival prediction models based on refitting, recalibration and Bayesian\nupdating. In contrast to discrete or one-time updating, dynamic updating refers\nto a process in which a prediction model is repeatedly updated with new data.\nMotivated by infectious disease settings, our focus was on model performance in\nrapidly changing environments. We first compared the methods using a simulation\nstudy. We simulated scenarios with changing survival rates, the introduction of\na new treatment and predictors of survival that are rare in the population.\nNext, the updating strategies were applied to patient data from the QResearch\ndatabase, an electronic health records database from general practices in the\nUK, to study the updating of a model for predicting 70-day covid-19 related\nmortality. We found that a dynamic updating process outperformed one-time\ndiscrete updating in the simulations. Bayesian dynamic updating has the\nadvantages of making use of knowledge from previous updates and requiring less\ndata compared to refitting.\n",
        "title": "Dynamic Updating of Clinical Survival Prediction Models in a Rapidly\n  Changing Environment",
        "texts": [
            "Figure 1: Illustration of the dynamic updating and evaluation process. Beginning at the top left, an original model was fit to the development dataset and evaluated out-of-sample on the Q1 new data. The model was then updated each quarter with new data and evaluated on the subsequent quarter’s data. These updates are called Update 1, 2, 3 and 4 where update u was performed using data from Quarter u. A colour version of this figure can be found in the electronic version of the article.",
            "Figure 2: Open cohort simulation results for a scenario with calibration drift. The left graphic shows the average C-index for each updating method across the 600 simulated datasets at each of the 5 prediction times for a scenario where the event rate decreased over time from 5% per year in Q1 to 2% per year in Q5. On the right, the average calibration intercept is shown for the same scenario. Results for ‘Recal once’ and ‘Refit once’ strategies are ordered by update time with the earliest time on the left.",
            "Figure 3: New cohorts simulation results for the new treatment scenario. The left graphic shows the average C-index for each updating method across the 600 simulated datasets at each of the 5 prediction times for the scenario where a new treatment was introduced at the beginning of Q2. On the right, the average calibration intercept is shown for the same scenario. Results for ‘Recal once’ and ‘Refit once’ strategies are ordered by update time with the earliest time on the left.",
            "Table 1: Listing of all simulation scenarios and the abbreviated name used in the Results section.",
            "Table 2: Performance of intercept recalibration (Recal), refitting (Refit), and Bayesian dynamic updating (Bayesian) methods to update the prediction model for 70-day covid-19 related death. The original model was fit using data from Period 1 and evaluated using data from period 2. The original model was then updated each period with new data and evaluated using the following period’s data. †No update refers to the original model fit in Period 1 and evaluated in each subsequent period without any updating."
        ],
        "imgs": [
            "$2305.00260v1-Figure1-1.png",
            "$2305.00260v1-Figure2-1.png",
            "$2305.00260v1-Figure3-1.png",
            "$2305.00260v1-Table1-1.png",
            "$2305.00260v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00261",
        "abstract": "  Predicting drop coalescence based on process parameters is crucial for\nexperiment design in chemical engineering. However, predictive models can\nsuffer from the lack of training data and more importantly, the label imbalance\nproblem. In this study, we propose the use of deep learning generative models\nto tackle this bottleneck by training the predictive models using generated\nsynthetic data. A novel generative model, named double space conditional\nvariational autoencoder (DSCVAE) is developed for labelled tabular data. By\nintroducing label constraints in both the latent and the original space, DSCVAE\nis capable of generating consistent and realistic samples compared to standard\nconditional variational autoencoder (CVAE). Two predictive models, namely\nrandom forest and gradient boosting classifiers, are enhanced on synthetic data\nand their performances are evaluated on real experimental data. Numerical\nresults show that considerable improvement in prediction accuracy can be\nachieved by using synthetic data and the proposed DSCVAE clearly outperforms\nthe standard CVAE. This research clearly brings more insight into handling\nimbalanced data for classification problems, especially in chemical engineering\n",
        "title": "Analyzing drop coalescence in microfluidic device with a deep learning\n  generative model",
        "texts": [
            "Fig. 1 Drop coalescence experiments in microfluidic device",
            "Fig. 2 Experimental dataset characteristics",
            "Fig. 4 Existing VAE structures",
            "Fig. 6 Losses of the generative models",
            "Fig. 7 Validation heatmaps for the tuning hyperparameters of the various generative models",
            "Fig. 8 SHAP values for Training Dataset",
            "Fig. 9 \"Gap\" comparison according to predictive labels from DSCVAE enhanced predictors",
            "Table 2 An example of confusion Matrix",
            "Table 4 Validation results for hyperparameter tuning",
            "Table 5 Test results using Initial or mixed datasets"
        ],
        "imgs": [
            "$2305.00261v1-Figure1-1.png",
            "$2305.00261v1-Figure2-1.png",
            "$2305.00261v1-Figure4-1.png",
            "$2305.00261v1-Figure6-1.png",
            "$2305.00261v1-Figure7-1.png",
            "$2305.00261v1-Figure8-1.png",
            "$2305.00261v1-Figure9-1.png",
            "$2305.00261v1-Table2-1.png",
            "$2305.00261v1-Table4-1.png",
            "$2305.00261v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00262",
        "abstract": "  Compared with standard text, understanding dialogue is more challenging for\nmachines as the dynamic and unexpected semantic changes in each turn. To model\nsuch inconsistent semantics, we propose a simple but effective Hierarchical\nDialogue Understanding model, HiDialog. Specifically, we first insert multiple\nspecial tokens into a dialogue and propose the turn-level attention to learn\nturn embeddings hierarchically. Then, a heterogeneous graph module is leveraged\nto polish the learned embeddings. We evaluate our model on various dialogue\nunderstanding tasks including dialogue relation extraction, dialogue emotion\nrecognition, and dialogue act classification. Results show that our simple\napproach achieves state-of-the-art performance on all three tasks above. All\nour source code is publicly available at https://github.com/ShawX825/HiDialog.\n",
        "title": "Hierarchical Dialogue Understanding with Special Tokens and Turn-level\n  Attention",
        "texts": [
            "Figure 1: Illustration of the proposed intra-turn modeling. In the turn-level attention, the restriction is applied on turn-level special tokens, denoted as [T ], where tokens outside the turn are masked out (colored in grey).",
            "Figure 2: Analysis of robustness of HiDialog tackling increasing utterance length compared to baseline TUCORE-GCN on DialogRE dataset.",
            "Table 1: All methods performance on the DialogRE and MELD, averaged over five runs, where the standard deviations are 0.4, 0.2, 0.4, 0.3, 0.2 respectively. † uses RoBERTa as the encoder. Performance gains over the previous state-of-the-art are highlighted in green.",
            "Table 2: All methods performance on 5 multi-turn dialogue-based understanding datasets: MELD, EmoryNLP, DailyDialog, MRDA, DialogRE, averaged over five runs. Performance gains over the RoBERTas are highlighted in green.",
            "Table 3: Ablation Study on HiDialog components on DialogRE to evaluate the individual effect of turn-level attention, turn-level special tokens, and graph module.",
            "Table 4: All methods performance on DialogRE. We break down the performance into three groups (I) asymmetric inverse relations, (II) symmetric inverse relations, and (III) others."
        ],
        "imgs": [
            "$2305.00262v1-Figure1-1.png",
            "$2305.00262v1-Figure2-1.png",
            "$2305.00262v1-Table1-1.png",
            "$2305.00262v1-Table2-1.png",
            "$2305.00262v1-Table3-1.png",
            "$2305.00262v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00263",
        "abstract": "  We present results of stroboscopic microwave spectroscopy of radio-frequency\ndressed optically pumped magnetometer. Interaction between radio-frequency\ndressed atoms and a synchronously pulsed microwave field followed by Voigt\neffect-based optical probing allows us to perform partial state tomography and\nassess the efficiency of the state preparation process. To theoretically\ndescribe the system, we solve the dynamical equation of the density matrix\nemploying Floquet expansion. Our theoretical results are in good agreement with\nexperimental measurements over a wide range of parameters and pumping\nconditions. Finally, the theoretical and experimental analysis presented in\nthis work can be generalised to other systems involving complex state\npreparation techniques.\n",
        "title": "Stroboscopic microwave spectroscopy of Voigt based optically pumped\n  magnetometers",
        "texts": [
            "FIG. 3. Experimental and theoretical dressed microwave spectra of the Re(m2) mode amplitude as a function of the microwave frequency. Here the measured and calculated spectra are obtained based on the sequence in Fig. 2. (a) Probe F = 2, mw CW, repump ON. (b) Probe F = 2, mw CW, repump OFF. Here the theoretical mw is applied in a CW mode over 20 rf periods, T = 2π/ωrf . In both cases we considered an effective rotation of ∼ 35◦.",
            "FIG. 4. Experimental and theoretical dressed microwave spectra of the Re(m2) mode amplitude as a function of the microwave detuning with respect to the clock transition. Here, the measured and calculated spectra are obtained based on the sequence in Fig. 5 where the mw is pulsed. (a) Extremal aligned state with repump ON. (b) Clock state with repump ON. In both cases we considered an effective rotation of ∼ 35◦.",
            "FIG. 5. Illustration of the experimental sequence and the the microwave coupling of the ground state manifolds during stroboscopic microwave probing. Here the states in each manifold are probed only at a specific time (stroboscopic microwave interaction) which means that the population transfer between the two levels happens only at a certain orientation between the two cones. The microwave pulses are in phase with the rf field.",
            "FIG. 6. Theoretical dressed microwave spectra of the Re(m2) mode amplitude as a function of the microwave frequency detuning. Here the measured and calculated spectra are obtained based on the sequence in Fig. 5 where the mw interaction is stroboscopic and no propagation effect is considered.",
            "FIG. 7. Sequence to produce the mw spectroscopy. The sequence is composed of three separate stages. First the process is initiated by the state preparation process where the rf-dressed atoms are synchronously pumped to prepare an aligned state. This is then followed by switching all of the optical fields off and applying a short mw pulsed tuned to the ground hyperfine splitting to induce a population transfer. The atomic dynamics are then probed by an off-resonant probe beam to measure the Voigt effect.",
            "FIG. 8. Experimental and theoretical dressed microwave spectra of the Re(m2) mode amplitude probing the F = 1 manyfold following the sequence in Fig. 2. (a) Repump ON. (b) Repump OFF. In both cases we considered an effective rotation of 35◦.",
            "FIG. 9. Experimental and theoretical dressed microwave spectra of the Re(m2) mode amplitude for sinchronously mw interaction. (a) Aligned state. (b) Clock state. In both cases we considered an effective rotation of 35◦."
        ],
        "imgs": [
            "$2305.00263v1-Figure3-1.png",
            "$2305.00263v1-Figure4-1.png",
            "$2305.00263v1-Figure5-1.png",
            "$2305.00263v1-Figure6-1.png",
            "$2305.00263v1-Figure7-1.png",
            "$2305.00263v1-Figure8-1.png",
            "$2305.00263v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00264",
        "abstract": "  An image line segment is a fundamental low-level visual feature that\ndelineates straight, slender, and uninterrupted portions of objects and\nscenarios within images. Detection and description of line segments lay the\nbasis for numerous vision tasks. Although many studies have aimed to detect and\ndescribe line segments, a comprehensive review is lacking, obstructing their\nprogress. This study fills the gap by comprehensively reviewing related studies\non detecting and describing two-dimensional image line segments to provide\nresearchers with an overall picture and deep understanding. Based on their\nmechanisms, two taxonomies for line segment detection and description are\npresented to introduce, analyze, and summarize these studies, facilitating\nresearchers to learn about them quickly and extensively. The key issues, core\nideas, advantages and disadvantages of existing methods, and their potential\napplications for each category are analyzed and summarized, including\npreviously unknown findings. The challenges in existing methods and\ncorresponding insights for potentially solving them are also provided to\ninspire researchers. In addition, some state-of-the-art line segment detection\nand description algorithms are evaluated without bias, and the evaluation code\nwill be publicly available. The theoretical analysis, coupled with the\nexperimental results, can guide researchers in selecting the best method for\ntheir intended vision applications. Finally, this study provides insights for\npotentially interesting future research directions to attract more attention\nfrom researchers to this field.\n",
        "title": "A Comprehensive Review of Image Line Segment Detection and Description:\n  Taxonomies, Comparisons, and Challenges",
        "texts": [
            "Fig. 1: Local image features on a test image: (b) SIFT interest points [3], (c) LSD line segments [2], and (d) Canny edges [7]. Line segments contain more structural and geometric features about a scene than points and are more compact in data expression than edges.",
            "Fig. 10: Inspired by [54], two line segments li and lj are a correct line segment pair if the projected line segment lj lies in the neighborhood of li, in which the distance dij between the middle point of lj and li, their angle difference |θj − θi|, and overlap ratio rij must satisfy the threshold requirements listed in the figure.",
            "Fig. 11: The plots show the average repeatability scores of eleven testing methods for line segment detection evaluated on the HPatches [185], VGGAffine [184], and KADID [187] datasets under three evaluation configurations.",
            "Fig. 12: Line segments of two test images detected by six methods in four categories, detailed in TABLE 6. The top test image comes from the Wireframe dataset, and the bottom image comes from the YorkUrban dataset.",
            "Fig. 13: The two plots show the average F1 scores of eleven testing methods for line segment detection evaluated on the Wireframe (top) and improved YorkUrban (bottom) datasets under three evaluation configurations.",
            "Fig. 15: The figure shows matching precision (Pm) and recall (Cm) values of six testing line segment descriptors evaluated on the HPatches, VGGAffine, and KADID datasets.",
            "Fig. 6: Labeled ground truth of line segments and junctions in the Wireframe [89] dataset.",
            "Fig. 9: The detected line segments in I1 are valid if the projected line segments, according to the homography matrix, lie in image I2. In addition, the length of line segments before and after projection should be larger than a threshold, e.g., 15 pixels in this review, to remove line fragments.",
            "TABLE 1 Qualitative comparisons of line segment detection algorithms from the four categories.",
            "TABLE 3 Qualitative comparisons for three categories of line segment description algorithms.",
            "TABLE 5 Widely used datasets for performance evaluation on line segment detection and description."
        ],
        "imgs": [
            "$2305.00264v1-Figure1-1.png",
            "$2305.00264v1-Figure10-1.png",
            "$2305.00264v1-Figure11-1.png",
            "$2305.00264v1-Figure12-1.png",
            "$2305.00264v1-Figure13-1.png",
            "$2305.00264v1-Figure15-1.png",
            "$2305.00264v1-Figure6-1.png",
            "$2305.00264v1-Figure9-1.png",
            "$2305.00264v1-Table1-1.png",
            "$2305.00264v1-Table3-1.png",
            "$2305.00264v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00266",
        "abstract": "  The Internet of Things (IoT) is integrating the Internet and smart devices in\nalmost every domain such as home automation, e-healthcare systems, vehicular\nnetworks, industrial control and military applications. In these sectors,\nsensory data, which is collected from multiple sources and managed through\nintermediate processing by multiple nodes, is used for decision-making\nprocesses. Ensuring data integrity and keeping track of data provenance is a\ncore requirement in such a highly dynamic context, since data provenance is an\nimportant tool for the assurance of data trustworthiness. Dealing with such\nrequirements is challenging due to the limited computational and energy\nresources in IoT networks. This requires addressing several challenges such as\nprocessing overhead, secure provenance, bandwidth consumption and storage\nefficiency. In this paper, we propose ZIRCON, a novel zero-watermarking\napproach to establish end-to-end data trustworthiness in an IoT network. In\nZIRCON, provenance information is stored in a tamper-proof centralized network\ndatabase through watermarks, generated at source node before transmission. We\nprovide an extensive security analysis showing the resilience of our scheme\nagainst passive and active attacks. We also compare our scheme with existing\nworks based on performance metrics such as computational time, energy\nutilization and cost analysis. The results show that ZIRCON is robust against\nseveral attacks, lightweight, storage efficient, and better in energy\nutilization and bandwidth consumption, compared to prior art.\n",
        "title": "ZIRCON: Zero-watermarking-based approach for data integrity and secure\n  provenance in IoT networks",
        "texts": [
            "Fig. 1: Single hop network model.",
            "Fig. 10: Sensor node operation cycle.",
            "Fig. 11: Energy consumption cost per single source node.",
            "Fig. 12: Energy consumption cost per single intermediate node.",
            "Fig. 13: Cost comparison. (a) Transmission data size in single hop scenario. (b) Provenance length in Multi-hop scenario.",
            "Fig. 2: Multi hop network model.",
            "Fig. 3: Zero-watermark generation, storing and verification block diagram in single hop scenario.",
            "Fig. 8: SHA Comparison. (a) Watermark generation and embedding time using different SHA functions. (b) Watermark verification time using different SHA functions.",
            "Fig. 9: Computational time. (a) Watermark generation and embedding time. (b) Watermark verification time.",
            "Table 1: System Notation and Parameters"
        ],
        "imgs": [
            "$2305.00266v1-Figure1-1.png",
            "$2305.00266v1-Figure10-1.png",
            "$2305.00266v1-Figure11-1.png",
            "$2305.00266v1-Figure12-1.png",
            "$2305.00266v1-Figure13-1.png",
            "$2305.00266v1-Figure2-1.png",
            "$2305.00266v1-Figure3-1.png",
            "$2305.00266v1-Figure8-1.png",
            "$2305.00266v1-Figure9-1.png",
            "$2305.00266v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00268",
        "abstract": "  In Luparello et al. 2023, a new and hitherto unknown CMB foreground was\ndetected. A systematic decrease in Cosmic Microwave Background (CMB)\ntemperatures around nearby large spiral galaxies points to an unknown\ninteraction with CMB photons in a sphere up to several projected Mpc around\nthese galaxies. We investigate to which extent this foreground may impact the\nCMB fluctuations map and create the so-called CMB anomalies. Using the observed\ntemperature decrements around the galaxies, and making some general assumptions\nabout the unknown interaction, we propose a common radial temperature profile.\nBy assigning this profile to nearby galaxies in the redshift range\n$z=[0.004,0.02]$ we create a foreground map model. We find a remarkable\nresemblance between this temperature model map based on nearby galaxies and the\nPlanck CMB map. Out of 1000 simulated maps, none of them show such a strong\ncorrelation with the foreground map over both large and small angular scales.\nIn particular, the quadrupole, octopole, as well as $\\ell=4$ and $\\ell=5$ modes\ncorrelate with the foreground map to high significance. Furthermore, one of the\nmost prominent temperature decrements in the foreground map coincides with the\nposition of the CMB cold spot. The largest scales of the CMB and thereby the\ncosmological parameters, may have important changes after proper corrections of\nthis foreground component. However, a reliable corrected CMB map can only be\nderived when suitable physical mechanisms are proposed and tested.\n",
        "title": "A possible common explanation for several cosmic microwave background\n  (CMB) anomalies: A strong impact of nearby galaxies on observed large-scale\n  CMB fluctuations",
        "texts": [
            "Fig. 1. Upper plot: Examples of mean profiles for a subset of isolated late type spiral galaxies with different size ranges at z ∼ 0.01. The number of galaxies in these samples are ∼ 10 and ∼ 50 for the largest/smallest sample respectively. The dashed line shows the model profile which we assign to galaxies of size 8.5 kpc. The grey band shows the 1σ spread of the profiles for simulated CMB maps taken at the position of the galaxies with sizes [6, 11] kpc. Lower plot: The mean profile taken over spiral galaxies within redshift range z = [0.004, 0.017] and size range [8.5, 20] kpc for both curves: Observed data (solid line) and foreground model (dotted redline) created with galaxies in the redshift range [0.004, 0.02]. The grey band shows the 1σ spread of the profile for simulated CMB maps at the same position as the galaxies.",
            "Fig. 2. Above: Foreground model map in µK. This map is generated by assigning a temperature profile to nearby galaxies z < 0.02. The decrement profile is found by making some general assumption about the L2023 foreground and fitting the mean profile to observations. Middle: the Planck SMICA CMB map. Below: A simplified foreground model in which all spiral galaxies > 8.5 kpc have been assigned the same profile independently of its size and environment. This is therefore also a density map of nearby spiral galaxies on the sky. In all maps, the grey circle in the lower right corner shows the position of the cold spot. Both maps are also divided in two hemispheres, the hemispheres of maximum and minimum power in the multipoles range ` = 2− 220 obtained from the CMB. In the above CMB map, the blue disc points to the hemisphere with more power in the foreground map whereas the yellow disc points to the center of the hemisphere with more power in the CMB.",
            "Fig. 3. Extraction of the first multipole modes from the maps in Fig. 2. The multipoles are estimated outside the Planck common mask. Left column: Multipoles of the Planck SMICA CMB map. Right column: Multipoles of the foreground model map. From above to below: The ` = 2 (quadrupole), ` = 3 (octopole), ` = 4 and ` = 5 modes. The grey lines serve to aid the by-eye comparison of the position of cold/hot spots between the maps based on the pixels with temperature close to zero in the CMB map.",
            "Fig. 4. Correlation coefficients between wavelet coefficients for maps of the CMB and the foreground model at the given physical angular scales (corresponding to 2.5 times the SMHW wavelet scale). The black points show the correlation coefficients normalized by the standard deviation of the given wavelet scale. The percentiles show the distribution of normalized correlation coefficients of 1000 simulated CMB maps and the foreground model. The red points show the unormalized correlation coefficients."
        ],
        "imgs": [
            "$2305.00268v1-Figure1-1.png",
            "$2305.00268v1-Figure2-1.png",
            "$2305.00268v1-Figure3-1.png",
            "$2305.00268v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00270",
        "abstract": "  The Time-Fractional Schr\\\"odinger Equation (TFSE) is well-adjusted to study a\nquantum system interacting with its dissipative environment. The Quantum Speed\nLimit (QSL) time captures the shortest time required for a quantum system to\nevolve between two states, which is significant for evaluating the maximum\nspeed in quantum processes. In this work, we solve exactly for a generic\ntime-fractional single qubit open system by applying the TFSE to a basic open\nquantum system model, namely the resonant dissipative Jaynes-Cummings (JC)\nmodel, and investigate the QSL time for the system. It is shown that the\nnon-Markovian memory effects of the environment can accelerate the\ntime-fractional quantum evolution, thus resulting in a smaller QSL time.\nAdditionally, the condition for the acceleration evolution of the\ntime-fractional open quantum system at a given driving time, i.e., a tradeoff\namong the fractional order, coupling strength, and photon number, is brought to\nlight. In particular, a method to manipulate the non-Markovian dissipative\ndynamics of a time-fractional open quantum system by adjusting the fractional\norder for a long driving time is presented.\n",
        "title": "Quantum Speed Limit for Time-Fractional Open Systems",
        "texts": [
            "FIG. 1. Non-Markovian quantum dissipative dynamics. (a) Schematic illustration of the trajectory describing the Markovian dynamics of an open quantum system. For this case, the state of the open system (dots) at time tη+1 is only dependent on that at time of its immediate preceding step, that is, at time tη. (b) Schematic illustration of the time evolution of an open quantum system in a non-Markovian manner. Under the circumstance, the state at time tη+1 is generally dependent on the states of the open system throughout the trajectory.",
            "FIG. 2. QSL time for a generic time-fractional single qubit open system, quantized by the ratio τQSL/τ as a function of the driving time τ , for different fractional order β = 0.1, 0.4, 0.7, 1. Parameters are chosen as λ = 0.5 and n = 20.",
            "FIG. 3. Comparison of τQSL/τ for a generic time-fractional single qubit open system versus the coupling strength λ for four different driving times τ = 0.1, 0.4, 0.7, 1 and fractional orders β = 0.2, 0.5, 0.8, 1 in four subfigures (a) ∼ (d). Parameter is set as n = 40.",
            "FIG. 4. The plot of τQSL/τ for a generic time-fractional single qubit open system with different coupling strengths λ = 0.3, 0.5, 0.8, 1 as a function of the driving time τ . Settings of parameters are β = 0.5, n = 20. In the inset, we show how the small τQSL/τ changes with different λ for long driving times.",
            "FIG. 5. Comparison of τQSL/τ for a generic time-fractional single qubit open system as a function of the coupling strength λ between four different photon numbers n = 0, 5, 10, 20 and fractional orders β = 0.2, 0.5, 0.8, 1, as displayed by four subfigures (a) ∼ (d). Parameter is taken as τ = 1."
        ],
        "imgs": [
            "$2305.00270v2-Figure1-1.png",
            "$2305.00270v2-Figure2-1.png",
            "$2305.00270v2-Figure3-1.png",
            "$2305.00270v2-Figure4-1.png",
            "$2305.00270v2-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00271",
        "abstract": "  Path planning for multiple tethered robots is a challenging problem due to\nthe complex interactions among the cables and the possibility of severe\nentanglements. Previous works on this problem either consider idealistic cable\nmodels or provide no guarantee for entanglement-free paths. In this work, we\npresent a new approach to address this problem using the theory of braids. By\nestablishing a topological equivalence between the physical cables and the\nspace-time trajectories of the robots, and identifying particular braid\npatterns that emerge from the entangled trajectories, we obtain the key finding\nthat all complex entanglements stem from a finite number of interaction\npatterns between 2 or 3 robots. Hence, non-entanglement can be guaranteed by\navoiding these interaction patterns in the trajectories of the robots. Based on\nthis finding, we present a graph search algorithm using the permutation grid to\nefficiently search for a feasible topology of paths and reject braid patterns\nthat result in an entanglement. We demonstrate that the proposed algorithm can\nachieve 100% goal-reaching capability without entanglement for up to 10 drones\nwith a slack cable model in a high-fidelity simulation platform. The\npracticality of the proposed approach is verified using three small tethered\nUAVs in indoor flight experiments.\n",
        "title": "Path Planning for Multiple Tethered Robots Using Topological Braids",
        "texts": [
            "Fig. 1: Simulations of multiple tethered UAVs to reach random targets using (a) the proposed approach and (b) a baseline approach that does not take tethers into consideration.",
            "Fig. 11: Plots of the success rate, the average computation time, and the average distance traveled for the proposed and the compared approaches.",
            "Fig. 12: Left: photos of a flight experiment. Right: visualization of positions and goal points of the robots.",
            "Fig. 2: An illustration of an elementary move.",
            "Fig. 3: Overview of the approach.",
            "Fig. 4: The projected polygonal segments onto X-Y plane for robot i. The maximum angle of rotation, γi, is the rotation angle between c4c5 and c0c1. The dashed line is parallel to c0c1.",
            "Fig. 5: An illustration of entanglement. The blue and green solid lines are the cables/trajectories of robot i and j. The blue dashed lines are the cable/trajectory of robot i projected onto the X-Y plane. The bottom two plots show the projections of the cables/trajectories onto a plane P(α). In the bottom left plot, the blue projected trajectory is non-monotonic.",
            "Fig. 6: The projected trajectories of robots. The gray dashed lines outline the partitioned triangles.",
            "Fig. 7: Four types of triangles. The small circles indicate either an overpass or an underpass. An elementary move may be executed from any one (respectively, two) edge of a triangle to the other two (respectively, one) edges, provided such a move preserves plane isotopy and both the edges before and after the move are ascending. To follow a temporal sequence, the edge(s) before a move should not intersect with any outgoing trajectories, except when the edge(s) belong(s) to the original polygonal trajectory.",
            "Fig. 8: Three types of local tangles. The solid blue segments cannot be moved to the dashed segments through plane isotopy. (a) A 2-trajectory tangle with a braid word σ1σ1, (b) A 3-trajectory tangle with a braid word σ−1 1 σ2σ −1 1 . (c) A 3-trajectory tangle with a braid word σ1σ−1 2 σ1σ −1 2 σ1."
        ],
        "imgs": [
            "$2305.00271v1-Figure1-1.png",
            "$2305.00271v1-Figure11-1.png",
            "$2305.00271v1-Figure12-1.png",
            "$2305.00271v1-Figure2-1.png",
            "$2305.00271v1-Figure3-1.png",
            "$2305.00271v1-Figure4-1.png",
            "$2305.00271v1-Figure5-1.png",
            "$2305.00271v1-Figure6-1.png",
            "$2305.00271v1-Figure7-1.png",
            "$2305.00271v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00273",
        "abstract": "  Recent studies show that, without any prior model, the unsupervised\nrestoration learning problem can be optimally formulated as an optimal\ntransport (OT) problem, which has shown promising performance on denoising\ntasks to approach the performance of supervised methods. However, it still\nsignificantly lags behind state-of-the-art supervised methods on complex\nrestoration tasks such as super-resolution, deraining, and dehazing. In this\npaper, we exploit the sparsity of degradation in the OT framework to\nsignificantly boost its performance on these tasks. First, we disclose an\nobservation that the degradation in these tasks is quite sparse in the\nfrequency domain, and then propose a sparsity-aware optimal transport (SOT)\ncriterion for unsupervised restoration learning. Further, we provide an\nanalytic example to illustrate that exploiting the sparsity helps to reduce the\nambiguity in finding an inverse map for restoration. Experiments on real-world\nsuper-resolution, deraining, and dehazing demonstrate that SOT can improve the\nPSNR of OT by about 2.6 dB, 2.7 dB and 1.3 dB, respectively, while achieving\nthe best perception scores among the compared supervised and unsupervised\nmethods. Particularly, on the three tasks, SOT significantly outperforms\nexisting unsupervised methods and approaches the performance of\nstate-of-the-art supervised methods.\n",
        "title": "Sparsity-Aware Optimal Transport for Unsupervised Restoration Learning",
        "texts": [
            "Fig. 3. Restoration PSNR of SOT in image super-resolution for different values of λ.",
            "Fig. 6. Visual comparison on synthetic image deraining. The PSNR/SSIM/LPIPS results are provided in the brackets. The images are enlarged for clarity.",
            "Fig. 7. Visual comparison on real-world image deraining. The PSNR/SSIM/LPIPS results are provided in the brackets.",
            "Fig. 8. Visual comparison on synthetic image dehazing. The PSNR/SSIM/LPIPS results are provided in the brackets. The images are enlarged for clarity.",
            "Fig. 9. Visual comparison on a challenging real-word image dehazing task with severe haze. The PSNR/SSIM/LPIPS results are provided in the brackets. The images are enlarged for clarity.",
            "TABLE 1 Quantitative comparison on 4x super-resolution of synthetic images (using the DIV2K dataset).",
            "TABLE 2 Quantitative comparison on real-world image super-resolution (using the RealVSR dataset).",
            "TABLE 3 Quantitative comparison of the deraining methods on synthetic data (the Rain1800 and Rain100L datasets are used for training and testing, respectively).",
            "TABLE 4 Quantitative comparison of the deraining methods on real-world data (using the SPA dataset [86]).",
            "TABLE 5 Quantitative comparison of the dehazing methods on synthetic data (using the OTS dataset [96]).",
            "TABLE 6 Quantitative comparison of the compared methods on real-world data (using hteDense-haze dataset [87])."
        ],
        "imgs": [
            "$2305.00273v1-Figure3-1.png",
            "$2305.00273v1-Figure6-1.png",
            "$2305.00273v1-Figure7-1.png",
            "$2305.00273v1-Figure8-1.png",
            "$2305.00273v1-Figure9-1.png",
            "$2305.00273v1-Table1-1.png",
            "$2305.00273v1-Table2-1.png",
            "$2305.00273v1-Table3-1.png",
            "$2305.00273v1-Table4-1.png",
            "$2305.00273v1-Table5-1.png",
            "$2305.00273v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00274",
        "abstract": "  Fe-based metallic glasses are promising functional materials for advanced\nmagnetism and sensor fields. Tailoring magnetic performance in amorphous\nmaterials requires a thorough knowledge of the correlation between structural\ndisorder and magnetic order, which remains ambiguous. Two practical\ndifficulties remain: the first is directly observing subtle magnetic structural\nchanges on multiple scales, and the second is precisely regulating the various\namorphous states. Here we propose a novel approach to tailor the amorphous\nstructure through the liquid liquid phase transition. In-situ synchrotron\ndiffraction has unraveled a medium-range ordering process dominated by\nedge-sharing cluster connectivity during the liquid-liquid phase transition.\nMoreover, nanodomains with topological order have been found to exist in\ncomposition with liquid-liquid phase transition, manifesting as hexagonal\npatterns in small-angle neutron scattering profiles. The liquid-liquid phase\ntransition can induce the nanodomains to be more locally ordered, generating\nstronger exchange interactions due to the reduced Fe-Fe bond and the enhanced\nstructural order, leading to the increment of saturation magnetization.\nFurthermore, the increased local heterogeneity in the medium range scale\nenhances the magnetic anisotropy, promoting the permeability response under\napplied stress and leading to a better stress-impedance effect. These\nexperimental results pave the way to tailor the magnetic structure and\nperformance through the liquid-liquid phase transition.\n",
        "title": "Evolution of medium-range order and its correlation with magnetic\n  nanodomains in Fe-Dy-B-Nb bulk metallic glasses",
        "texts": [
            "Fig. 1. (a) DSC curves of Fe-Nb-B-Dy bulk metallic glasses. An anomalous exothermic peak exists in the supercooled-liquid region, labeled TAEP. (b) Hysteresis loops of Dy5 for different heat-treatment states. The illustration shows the saturation magnetization and coercivity at different heat-treatment states. (c) Stress-impedance ratio of as-cast state compared with that of annealed state in Dy5 and Dy3 MGs. (d) Evolution of the corresponding effective magnetic permeability μeff between the as-cast and annealed state.",
            "Fig. 2. Structure factor of Dy5 bulk metallic glasses: (a) S(Q) of Dy5 BMG, (c) ΔS(Q) in Dy5 BMG, (b) first moment Q1 and (d) peak height in Dy5 BMG.",
            "Fig. 3. Real-space analysis of the synchrotron x-ray diffraction results. (a) Reduced pair distribution function G(r) for Dy5 BMG upon heating. (b) Intensity of first coordination shell r1 (right axis) and shoulder of second coordination shell r22 (left axis) as functions of temperature. (c) Gaussian fitting of second coordination shell in pair distribution function g(r) at TAEP. The decomposed peaks are the corresponding 1-, 2-, 3-, and 4- atom cluster connections. (d) Evolution of corresponding atomic connectivity. The percent of different connection modes as a function of temperature.",
            "Fig. 4 (a) 2D total scattering SANS cross section for TAEP-annealed Dy5. (b) d∑/dΩ for Dy5 in different states and with an applied field of 0.05 T. (c) Normalized correlation function of Dy5 for different heat treatments. (d) Power-law exponent n as a function of heat-treatment temperature for total scattering d∑/dΩ and for magnetic scattering d∑M/dΩ. The Q range is restricted to 0.015 Å−1 < q <0.03 Å−1.",
            "Fig. 5. (a) d∑/dΩ for Dy5 in different states at 1 T field. (b) d∑/dΩ for Dy5 in as-cast state and TAEP-annealed state with no magnetic field. (c) Magnetic azimuthally averaged SANS cross sections in the vertical direction, and (d) magnetic azimuthally averaged SANS cross sections in the horizontal direction under an applied magnetic field of 0.05 T.",
            "Fig. 6 2D total scattering SANS cross section for (a) as-cast, (c) TAEP-annealed, and (e) crystal Dy5 under zero magnetic field with a reduced Q range. 2D total scattering SANS cross section for (b) as-cast, (d) TAEP-annealed, and (f) crystal Dy5 under 0.05 field (measured at CSNS). (g) Normalized intensity under 0.05 T (upper) and 0 T (lower) at",
            "Fig. 8. (a) Evolution of 2-atom cluster connectivity, saturation magnetization, magnetic correlation length, and intraparticle correlation length as a function of temperature upon heating Dy5 BMG. (b)–(d) Response of nanoscale magnetic spin-misalignment structure during LLPT."
        ],
        "imgs": [
            "$2305.00274v1-Figure1-1.png",
            "$2305.00274v1-Figure2-1.png",
            "$2305.00274v1-Figure3-1.png",
            "$2305.00274v1-Figure4-1.png",
            "$2305.00274v1-Figure5-1.png",
            "$2305.00274v1-Figure6-1.png",
            "$2305.00274v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00275",
        "abstract": "  In this work, we consider the Fokker-Planck equation of the Nonlinear Noisy\nLeaky Integrate-and-Fire (NNLIF) model for neuron networks. Due to the firing\nevents of neurons at the microscopic level, this Fokker-Planck equation\ncontains dynamic boundary conditions involving specific internal points. To\nefficiently solve this problem and explore the properties of the unknown, we\nconstruct a flexible numerical scheme for the Fokker-Planck equation in the\nframework of spectral methods that can accurately handle the dynamic boundary\ncondition. This numerical scheme is stable with suitable choices of test\nfunction spaces, and asymptotic preserving, and it is easily extendable to\nvariant models with multiple time scales. We also present extensive numerical\nexamples to verify the scheme properties, including order of convergence and\ntime efficiency, and explore unique properties of the model, including blow-up\nphenomena for the NNLIF model and learning and discriminative properties for\nthe NNLIF model with learning rules.\n",
        "title": "A spectral method for a Fokker-Planck equation in neuroscience with\n  applications in neural networks with learning rules",
        "texts": [
            "Figure 1: The basis functions of p3 with Equation parameters Vmin = −1, VR = 0, VF = 1. Here, g1 and g2 are measured using the left axis, while g3 is measured with the right axis.",
            "Figure 10: Equation parameters a0 = 1, a1 = 0.1, b = 0 with Gaussian initial condition v0 = −1, σ2 0 = 0.5. Left: evolution of firing rate N(t). Right: evolution of relative entropy S(t) with G(x) = (x−1)2",
            "Figure 11: Equation parameters a = 1, b = 1.5 with Gaussian initial condition v0 = −1, σ2 0 = 0.5. In this case, the model has two stationary states with firing rates N∞ = 0.1924 and N∞ = 2.319. Left: evolution of relative entropy S(t) with G(x) = (x−1)2",
            "Figure 12: Equation parameters a = 1 and ε = 0.1. The evolution of total firing rate N̄ . Left: the input function period D = 1. Middle: the input function period D = 0.5. Right: the input function period D = 0.2.",
            "Figure 13: Equation parameters a = 1 and ε = 0.1. The prediction signal at t = 4 with different input function periods. Top: the input function period D = 4, 0.4, 0.2 from left to right. Bottom: the input function period 0.1, 0.05, 0.01 from left to right.",
            "Figure 14: (Output signal for the large period learning input) The final firing rate N(w) with different testing input J(w). Equation parameters a = 1 and ε = 0.1, and the period of the input function in the learning phase is D = 4. Left: Output signal with testing input function J = I1. Middle: Output signal with testing input function J = I2. Right: Output signal with testing input function J = I1+I2 2 .",
            "Figure 15: Output signal for the small period learning input) The final firing rate N(w) with different testing input J(w). Equation parameters a = 1 and ε = 0.1, and the period of the input function in the learning phase is D = 0.01. Left: Output signal with testing input function J = I1. Middle: Output signal with testing input function J = I2. Right: Output signal with testing input function J = I1+I2 2 .",
            "Figure 16: Equation parameter a = 1. Left: The value of Eε,D J under different D and ε with input function J = I1. Right: The value of Eε,D",
            "Figure 2: When the test function space is ṼN (3.48), the numerical method might be unstable. Left: The maximum eigenvalue of matrix K̂ at different N . Right: A typical unstable solution. Equation parameters a = 1, b = 0 with Gaussian initial condition v0 = −1, σ2 0 = 0.5 and N = 11,∆t = 0.001.",
            "Figure 3: Equation parameters a = 1, b = 0 with Gaussian initial condition v0 = −1, σ2 0 = 0.5 and N = 10,∆t = 0.001, Tmax = 5. Left: Variation of total mass with time by the LGM. Right: Variation of total mass with time by the MPGM.",
            "Figure 4: Logarithm of the error of the proposed numerical scheme for NNLIF model with learning rules with different N . The temporal size is fixed as ∆t = 10−5. Left: N is odd; Right: N is even.",
            "Figure 5: Logarithm of the error of the proposed numerical scheme for NNLIF model with learning rules with different N . The temporal size is fixed as ∆t = 10−5. Left: N is odd; Right: N is even",
            "Figure 6: Equation parameters a = 1, b = 3 with Gaussian initial condition v0 = −1, σ2 0 = 0.5. Left: evolution of firing rate N(t). Right: density function p(v, t) at t = 2.95, 3.15, 3.35.",
            "Figure 7: Equation parameters a = 1, b = 1.5 with Gaussian initial condition v0 = 1.5, σ2 0 = 0.005.Left: evolution of firing rate N(t). Right: density function p(v, t) at t = 0.0325, 0.0365, 0.0405.",
            "Figure 9: Equation parameters a = 1, b = −0.5 with Gaussian initial condition v0 = −1, σ2 0 = 0.5. Left: evolution of firing rate N(t). Right: evolution of relative entropy S(t) with G(x) = (x−1)2",
            "Table 1: Error and order of accuracy of the proposed numerical scheme for NNLIF model with different temporal sizes. The parameter N is fixed as N = 12.",
            "Table 2: Error and order of accuracy of the proposed numerical scheme for NNLIF model with learning rules with different ∆w and ∆t. The parameter N is fixed as N = 16.",
            "Table 3: Errors using the spectral method with different numbers of basis functions.",
            "Table 4: Errors using the finite difference method with different spatial grid sizes"
        ],
        "imgs": [
            "$2305.00275v1-Figure1-1.png",
            "$2305.00275v1-Figure10-1.png",
            "$2305.00275v1-Figure11-1.png",
            "$2305.00275v1-Figure12-1.png",
            "$2305.00275v1-Figure13-1.png",
            "$2305.00275v1-Figure14-1.png",
            "$2305.00275v1-Figure15-1.png",
            "$2305.00275v1-Figure16-1.png",
            "$2305.00275v1-Figure2-1.png",
            "$2305.00275v1-Figure3-1.png",
            "$2305.00275v1-Figure4-1.png",
            "$2305.00275v1-Figure5-1.png",
            "$2305.00275v1-Figure6-1.png",
            "$2305.00275v1-Figure7-1.png",
            "$2305.00275v1-Figure9-1.png",
            "$2305.00275v1-Table1-1.png",
            "$2305.00275v1-Table2-1.png",
            "$2305.00275v1-Table3-1.png",
            "$2305.00275v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00282",
        "abstract": "  Immersive novel view generation is an important technology in the field of\ngraphics and has recently also received attention for operator-based\nhuman-robot interaction. However, the involved training is time-consuming, and\nthus the current test scope is majorly on object capturing. This limits the\nusage of related models in the robotics community for 3D reconstruction since\nrobots (1) usually only capture a very small range of view directions to\nsurfaces that cause arbitrary predictions on unseen, novel direction, (2)\nrequires real-time algorithms, and (3) work with growing scenes, e.g., in\nrobotic exploration. The paper proposes a novel Neural Surface Light Fields\nmodel that copes with the small range of view directions while producing a good\nresult in unseen directions. Exploiting recent encoding techniques, the\ntraining of our model is highly efficient.\n  In addition, we design Multiple Asynchronous Neural Agents (MANA), a\nuniversal framework to learn each small region in parallel for large-scale\ngrowing scenes. Our model learns online the Neural Surface Light Fields (NSLF)\naside from real-time 3D reconstruction with a sequential data stream as the\nshared input. In addition to online training, our model also provides real-time\nrendering after completing the data stream for visualization. We implement\nexperiments using well-known RGBD indoor datasets, showing the high flexibility\nto embed our model into real-time 3D reconstruction and demonstrating\nhigh-fidelity view synthesis for these scenes. The code is available on github.\n",
        "title": "NSLF-OL: Online Learning of Neural Surface Light Fields alongside\n  Real-time Incremental 3D Reconstruction",
        "texts": [
            "Fig. 1: Light difference between object capturing for graphics applications and scene capturing in robotic SLAM & reconstruction. At 3D point p, lights are cast from direction d. The sphere shows the S2 space for the direction vectors d that are partially covered by light rays.",
            "Fig. 2: Patterns of models designed for Neural Light Field. (a) is most widely used. Our (b) learn one sphere for each p and use a φwp to map the 1D value on direction d to 3D RGB.",
            "Fig. 3: MANA learns online a NSLF by serving as an external function to 3D reconstruction.",
            "Fig. 4: Online Learning of NSLF. (a) shows MANA distributing data into different Neural Agents by region. Each Neural agent maintains its thread and optimizes individually as (b).",
            "Fig. 5: Demonstration on ICL-NUIM dataset lrkt0n sequence.",
            "Fig. 6: Demonstration on unseen direction of observed surface.",
            "TABLE I: Comparison on ICL-NUIM sequence lrkt0n.",
            "TABLE II: PSNR comparison on Replica sequences.",
            "TABLE IV: PSNR comparison on object sequences."
        ],
        "imgs": [
            "$2305.00282v1-Figure1-1.png",
            "$2305.00282v1-Figure2-1.png",
            "$2305.00282v1-Figure3-1.png",
            "$2305.00282v1-Figure4-1.png",
            "$2305.00282v1-Figure5-1.png",
            "$2305.00282v1-Figure6-1.png",
            "$2305.00282v1-TableI-1.png",
            "$2305.00282v1-TableII-1.png",
            "$2305.00282v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00283",
        "abstract": "  Lithium-drifted silicon [Si(Li)] has been used for decades as an ionizing\nradiation detector in nuclear, particle, and astrophysical experiments, though\nsuch detectors have frequently been limited to small sizes (few cm$^2$) and\ncryogenic operating temperatures. The 10-cm-diameter Si(Li) detectors developed\nfor the General Antiparticle Spectrometer (GAPS) balloon-borne dark matter\nexperiment are novel particularly for their requirements of low cost, large\nsensitive area (~10 m$^2$ for the full 1440-detector array), high temperatures\n(near -40$\\,^\\circ$C), and energy resolution below 4 keV FWHM for 20--100-keV\nx-rays. Previous works have discussed the manufacturing, passivation, and\nsmall-scale testing of prototype GAPS Si(Li) detectors. Here we show for the\nfirst time the results from detailed characterization of over 1100 flight\ndetectors, illustrating the consistent intrinsic low-noise performance of a\nlarge sample of GAPS detectors. This work demonstrates the feasibility of\nlarge-area and low-cost Si(Li) detector arrays for next-generation astrophysics\nand nuclear physics applications.\n",
        "title": "Large-scale detector testing for the GAPS Si(Li) Tracker",
        "texts": [
            "Fig. 2. Electrical connection diagram for the Si(Li) module testing system. For clarity, only one of the four Si(Li) detectors is shown, with all four detectors receiving the same –250-V bias via the 1-MΩ resistor. The electrical ground for the Si(Li) module and preamplifier holder boards is defined by the LVPS. The exterior electronics (LVPS, patch panel, and NIM crate) receive clean AC power and grounding from the isolation transformer, with the lab computer (PC) and cold chamber receiving AC power and grounding from the building mains. For more details see Sec. II.",
            "Fig. 7. Histograms showing fitted Ileak (top) and Af (bottom) for Si(Li) strips on x-ray detectors (solid blue) and tracking detectors (dashed red). Values of Ileak and Af less than zero are placed in the leftmost bin. There are ∼30 strips with fit Ileak > 50 nA and ∼20 strips with Af > 10−12 V2, though since the discrete preamplifiers are expected to saturate near 50 nA, those results should be taken with care.",
            "TABLE I TABLE OF CRITERIA AND YIELD RATES FOR X-RAY, TRACKING, AND NON-USABLE STRIPS AND DETECTORS. THE PRE-SELECTION CRITERIA ARE BASED ON RT PERFORMANCE, AND ALL ILEAK VALUES ARE QUOTED AT –250-V BIAS."
        ],
        "imgs": [
            "$2305.00283v2-Figure2-1.png",
            "$2305.00283v2-Figure7-1.png",
            "$2305.00283v2-TableI-1.png"
        ]
    },
    {
        "id": "2305.00285",
        "abstract": "  This paper examines the rigid body motion of a spheroid sedimenting in a\nNewtonian fluid with a spatially varying viscosity field. The fluid is at zero\nReynolds number, and the viscosity varies linearly in space in an arbitrary\ndirection with respect to the external force. First, we obtain the correction\nto the spheroid's rigid body motion in the limit of small viscosity gradients,\nusing a perturbation expansion combined with the reciprocal theorem. Next, we\ndetermine the general form of the particle's mobility tensor relating its rigid\nbody motion to an external force and torque. The viscosity gradient does not\nalter the force/translation and torque/rotation relationships, but introduces\nnew force/rotation and torque/translation couplings that are determined for a\nwide range of particle aspect ratios. Finally, we discuss results for the\nspheroid's rotation and center-of-mass trajectory during sedimentation.\nDepending on the viscosity gradient direction and particle shape, a steady\norientation may arise at long times or the particle may tumble continuously.\nThese results are significantly different from the case when no viscosity\ngradient is present, where the particle stays at its initial orientation for\nall times. The particle's center of mass trajectory can also be altered\ndepending on the particle's orientation behavior, for example giving rise to\ndiagonal motion or zig-zagging motion. We summarize the observations for\nprolate and oblate spheroids for different viscosity gradient directions and\nprovide phase plots delineating different dynamical regimes. We also provide\nguidelines to extend the analysis when the viscosity gradient exhibits a more\ncomplicated spatial behavior.\n",
        "title": "Sedimentation of spheroids in Newtonian fluids with spatially varying\n  viscosity",
        "texts": [
            "Figure 1: Illustration of spheroid orientation and trajectory during sedimentation in (a) Stokes flow (zero Reynolds number), (b) fluid with finite inertia, and (c) polymeric fluid with normal stresses (large Elasticity number). This paper investigates the behavior when viscosity stratification is present – i.e., case (d)",
            "Figure 10: Illustration of unequal torques created on a prolate spheroid when the force and viscosity gradient are co-linear. The left figure (a) is when the viscosity gradient and force are in the same direction, while the right figure (b) is when they are in opposite directions.",
            "Figure 11: Particle trajectories for (a) prolate and (b) oblate spheroids when the external force and viscosity gradient are in the same direction (F = ẑ,∇η = βẑ). The dashed curves correspond to when no viscosity gradient is present (β = 0), while the solid curve is when a viscosity gradient is present (β = 0.1). Different color curves correspond to different initial starting angles α0. The prolate spheroid has AR = 5 while the oblate spheroid has AR = 1/5.",
            "Figure 13: Schematic explaining the absence of steady orientations at α = 0 and α = π/2 for (a) prolate and (b) oblate spheroids when the external force and viscosity gradient are perpendicular. This schematic is shown in the particle’s frame of reference.",
            "Figure 14: Orientation angles α(t) and φ(t) for prolate and oblate spheroids when the external force and viscosity gradient are perpendicular (F = ẑ,∇η = βx̂). The dashed curves show the evolution of φ, while the solid curves show the evolution of α. For all cases, the initial orientation is given by the ordered pair (φ0, α0) = (π/3, π/4) and the dimensionless viscosity gradient is β = 0.1. The results show that φ → 0 or π, and hence the particle becomes co-planar with F and ∇η.",
            "Figure 15: Stable orientations αse for prolate and oblate spheroids of different aspect ratio parameters AR when the external force and viscosity gradient are perpendicular to each other (F = ẑ ∇η = βx̂, β = 0.1). Regions that do not have data points are regions where the particle tumbles and does not exhibit a stable orientation.",
            "Figure 16: Tumbling of (a) prolate spheroids and (b) oblate spheroids when the external force and viscosity gradient are perpendicular to each other (F = ẑ ∇η = βx̂, β = 0.1). For the aspect ratio parameter shown in this figure (AR = 13 for prolate and AR = 1/13 for oblate), there is no stable orientation and the spheroids continue to tumble.",
            "Figure 17: Particle trajectories for prolate spheroids with (a) AR = 5 and (b) AR = 11 when the external force and viscosity gradient are perpendicular (F = ẑ,∇η = βx̂). The dashed curves correspond to when no viscosity gradient is present (β = 0), while the solid curve is when a viscosity gradient is present (β = 0.1). Different color curves correspond to different initial starting angles α0. Plot (a) illustrates a case when the spheroid attains a steady orientation, while (b) illustrates a case when the spheroid tumbles.",
            "Figure 18: Stable orientation angles αse for prolate and oblate spheroids when the viscosity gradient ∇η and the external force F are inclined at an angle θ to each other.",
            "Figure 19: Phase diagram demarcating the region in (θ, AR) space where a stable orientation is reached (blue circles) and where the spheroid tumbles without reaching any stable orientation (yellow triangles). Here θ is the angle between the viscosity gradient ∇η and external force F , while AR is the aspect ratio parameter.",
            "Figure 2: Schematic of a prolate and oblate spheroid falling under an external force acting in the 3-direction. The viscosity gradient is along the 3-direction (parallel or antiparallel). The particle’s orientation vector p makes a polar angle α ∈ [0, π] with respect to the sedimentation direction.",
            "Figure 3: Schematic of a prolate and oblate spheroid falling under an external force F acting in the 3-direction, while the viscosity varies spatially in the 1-direction. The particle’s orientation p makes a polar angle α ∈ [0, π] with respect to the 3-direction, and makes an azimuthal angle φ ∈ [0, 2π) in the 1-2 plane.",
            "Figure 4: Code validation for a sphere sedimenting in a fluid with a prescribed viscosity gradient in the (a) y-direction and (b) x-direction. For all the cases, the external force is a unit vector acting in the x-direction, while the external torque is T = 0. The radius and fluid viscosity are a = 1 and η0 = 1, respectively. The results of the theory are from (Datt & Elfring 2019), expanded in Sec. 3.2.1.",
            "Figure 5: Simulations carried out to estimate the parameters (λ1, λ3, λ4) in the third order pseudo tensor Mijk given by Eq. (4.7). The orientation angles (α, φ) are defined in Figs. 2 and 3 respectively.",
            "Figure 6: Verification of theory by plotting of Eq. (4.11) for different values of α, for a prolate spheroid with external force F and viscosity gradient ∇η in the positive zdirection. This situation corresponds to Case A shown in Fig. 5a.",
            "Figure 7: Computed values of (λ1, λ3, λ4) for prolate and oblate spheroids for different values of aspect ratio parameters AR.",
            "Figure 9: Steady configurations attained by (a) prolate and (b) oblate spheroids when the external force F and viscosity gradient ∇η are co-linear. The top row is for the case when the external force and the viscosity gradient are in the same direction, while the bottom row is when they are in the opposite direction."
        ],
        "imgs": [
            "$2305.00285v1-Figure1-1.png",
            "$2305.00285v1-Figure10-1.png",
            "$2305.00285v1-Figure11-1.png",
            "$2305.00285v1-Figure13-1.png",
            "$2305.00285v1-Figure14-1.png",
            "$2305.00285v1-Figure15-1.png",
            "$2305.00285v1-Figure16-1.png",
            "$2305.00285v1-Figure17-1.png",
            "$2305.00285v1-Figure18-1.png",
            "$2305.00285v1-Figure19-1.png",
            "$2305.00285v1-Figure2-1.png",
            "$2305.00285v1-Figure3-1.png",
            "$2305.00285v1-Figure4-1.png",
            "$2305.00285v1-Figure5-1.png",
            "$2305.00285v1-Figure6-1.png",
            "$2305.00285v1-Figure7-1.png",
            "$2305.00285v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00286",
        "abstract": "  Meta-reinforcement learning enables artificial agents to learn from related\ntraining tasks and adapt to new tasks efficiently with minimal interaction\ndata. However, most existing research is still limited to narrow task\ndistributions that are parametric and stationary, and does not consider\nout-of-distribution tasks during the evaluation, thus, restricting its\napplication. In this paper, we propose MoSS, a context-based Meta-reinforcement\nlearning algorithm based on Self-Supervised task representation learning to\naddress this challenge. We extend meta-RL to broad non-parametric task\ndistributions which have never been explored before, and also achieve\nstate-of-the-art results in non-stationary and out-of-distribution tasks.\nSpecifically, MoSS consists of a task inference module and a policy module. We\nutilize the Gaussian mixture model for task representation to imitate the\nparametric and non-parametric task variations. Additionally, our online\nadaptation strategy enables the agent to react at the first sight of a task\nchange, thus being applicable in non-stationary tasks. MoSS also exhibits\nstrong generalization robustness in out-of-distributions tasks which benefits\nfrom the reliable and robust task representation. The policy is built on top of\nan off-policy RL algorithm and the entire network is trained completely\noff-policy to ensure high sample efficiency. On MuJoCo and Meta-World\nbenchmarks, MoSS outperforms prior works in terms of asymptotic performance,\nsample efficiency (3-50x faster), adaptation efficiency, and generalization\nrobustness on broad and diverse task distributions.\n",
        "title": "Meta-Reinforcement Learning Based on Self-Supervised Task Representation\n  Learning",
        "texts": [
            "Figure 1: MoSS Architecture: MoSS consists of a task inference module and a policy module. The inference module encodes the task context τ as latent task distributions qφ(z), then the policy module conditions on the agent state s and the task representation qφ(z) to act in the environment.",
            "Figure 10: Agent responses to task changes in non-stationary MuJoCo environments: We change the goal value (velocity or direction) randomly at every 100 time step at the probability of 0.5 and visualize the agent response to task changes. As shown, the MoSS agent shows good tracking behavior, it can detect the task change and quickly adapt to the new task.",
            "Figure 11: Training curves of MoSS on Meta-World V1 and V2 benchmarks: Average return (y-axis) against collected environment steps during meta-training (x-axis).",
            "Figure 12: Full timescale results in parametric MuJoCo environments with in-distribution and out-of-distribution test tasks",
            "Figure 13: Full timescale results in non-stationary MuJoCo environments",
            "Figure 14: Full timescale results in non-parametric MuJoCo environments",
            "Figure 15: We use the latent task embeddings as queries and keys, where embeddings from the same trajectory (but of different time steps) are positive pairs and embeddings from trajectories of different tasks are negative pairs. Contrastive learning aims to identify positive sample pairs amongst a set of negative pairs.",
            "Figure 16: We parameterize the decoder as two independent networks: the state decoder and the reward deocder. We use the reconstruction loss between the prediction (ŝt+1, r̂t) and the true target (st+1, rt) to optimize the encoder-decoder network.",
            "Figure 17: Illustration of non-parametric benchmarks",
            "Figure 2: Meta-test performance in parametric MuJoCo environments: Average return (y-axis) against collected environment steps during meta-training (x-axis).",
            "Figure 3: Meta-test performance in parametric MuJoCo environments with OOD tasks",
            "Figure 4: Meta-test performance in non-stationary MuJoCo environments: (Left) Training curves; (Right) Agent Response in the Cheetah-Direction-Non-Stat environment.",
            "Figure 5: Meta-test performance in non-parametric MuJoCo environments",
            "Figure 6: Online adaptation ablation: MoSS updates the posterior task distribution at each time step so as to enable online task inference and adaptation. For comparison, we update the latent distribution at the trajectory level and report the first three episodes performance.",
            "Figure 7: MoSS ablation results: We compare the standard MoSS against ablation versions without Gaussian mixture latent space, without contrastive learning and without Bayes planning. The standard MoSS outperforms other methods and especially shows better stability.",
            "Figure 8: Latent embeddings ablation: We visualize the latent embedding space of MoSS and its ablation versions on Cheetah-Multi-Task. (a) Latent task embeddings of the standard MoSS; (b) Latent task embeddings of MoSS with single Gaussian distribution for task representation; (c) Latent task embeddings of MoSS without contrastive learning objective.",
            "Figure 9: Complete meta-test performance in parametric MuJoCo environments",
            "Table 1: Meta-World V2 ML1 result comparison: Success rate results are given in percentage2",
            "Table 2: Meta-World ML 1 V1 and V2 results",
            "Table 5: MoSS comparison with baseline methods"
        ],
        "imgs": [
            "$2305.00286v1-Figure1-1.png",
            "$2305.00286v1-Figure10-1.png",
            "$2305.00286v1-Figure11-1.png",
            "$2305.00286v1-Figure12-1.png",
            "$2305.00286v1-Figure13-1.png",
            "$2305.00286v1-Figure14-1.png",
            "$2305.00286v1-Figure15-1.png",
            "$2305.00286v1-Figure16-1.png",
            "$2305.00286v1-Figure17-1.png",
            "$2305.00286v1-Figure2-1.png",
            "$2305.00286v1-Figure3-1.png",
            "$2305.00286v1-Figure4-1.png",
            "$2305.00286v1-Figure5-1.png",
            "$2305.00286v1-Figure6-1.png",
            "$2305.00286v1-Figure7-1.png",
            "$2305.00286v1-Figure8-1.png",
            "$2305.00286v1-Figure9-1.png",
            "$2305.00286v1-Table1-1.png",
            "$2305.00286v1-Table2-1.png",
            "$2305.00286v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00287",
        "abstract": "  Bundle adjustment (BA) on LiDAR point clouds has been extensively\ninvestigated in recent years due to its ability to optimize multiple poses\ntogether, resulting in high accuracy and global consistency for point cloud.\nHowever, the accuracy and speed of LiDAR bundle adjustment depend on the\nquality of plane extraction, which provides point association for LiDAR BA. In\nthis study, we propose a novel and efficient voxel-based approach for plane\nextraction that is specially designed to provide point association for LiDAR\nbundle adjustment. To begin, we partition the space into multiple voxels of a\nfixed size and then split these root voxels based on whether the points are on\nthe same plane, using an octree structure. We also design a novel plane\ndetermination method based on principle component analysis (PCA), which\nsegments the points into four even quarters and compare their minimum\neigenvalues with that of the initial point cloud. Finally, we adopt a plane\nmerging method to prevent too many small planes from being in a single voxel,\nwhich can increase the optimization time required for BA. Our experimental\nresults on HILTI demonstrate that our approach achieves the best precision and\nleast time cost compared to other plane extraction methods.\n",
        "title": "An Efficient Plane Extraction Approach for Bundle Adjustment on LiDAR\n  Point clouds",
        "texts": [
            "Fig. 1. (a) True positive plane. (b) False positive plane if using the criterion in (2). (c) Smaller parts of a true plane are still planes. (d) Smaller parts of a false plane no longer form planes (i.e., the green part).",
            "Fig. 2. The side view of a set of points which are on the same plane. (a) Splitting on the centroid, which mistakenly separates the points into eight parts (only four parts are visible from the side view, while the other four un-visible parts are labelled in the parentheses.). (b) Translation of the split center from centroid along the normal in the distance of 5σ (σ = √ λ3). (c) Splitting along xyz-axis, which separates the points into six parts (three parts can be seen from the side view). (d) Splitting along the plane normal, which separates the points into four parts evenly as expected (two parts can be seen from the side view).",
            "Fig. 3. Adaptive voxelization and merging of planes. (a) shows the point cloud consisting of root voxel nodes. (b) is the root voxel which will be used to illustrate our theory. (c)-(e) is the first, second and third partition respectively. (f) removes the voxels which do not form qualified feature. (g) is the final merging result.",
            "Fig. 4. (a) The plane extraction results of RANSAC in HILTI Exp01. (b) A local map of (a), which shows the point cloud is sliced into multiple layers parallel to ground. (c) A large plane extracted by RANSAC, which generates false plane association for LiDAR BA.",
            "Fig. 5. The plane extraction results of different methods in Exp01 of the HILTI 2022 dataset. The figure in first row is the overall extraction result. The figure in second row is a typical case of the extraction.",
            "TABLE I ABSOLUTE TRAJECTORY ERROR (ATE) AND RUNNING TIME FOR DIFFERENT METHODS."
        ],
        "imgs": [
            "$2305.00287v1-Figure1-1.png",
            "$2305.00287v1-Figure2-1.png",
            "$2305.00287v1-Figure3-1.png",
            "$2305.00287v1-Figure4-1.png",
            "$2305.00287v1-Figure5-1.png",
            "$2305.00287v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00289",
        "abstract": "  Tuning GaAs-based quantum emitters to telecom wavelengths makes it possible\nto use the existing mature technology for applications in, e.g., long-haul\nultra-secure communication in the fiber networks. A promising method\nre-developed recently is to use a metamorphic InGaAs buffer that redshifts the\nemission by reducing strain. However, the impact of such a buffer causes also a\nsimultaneous modification of other quantum dot properties. Knowledge of these\neffects is crucial for actual implementations of QD-based non-classical light\nsources for quantum communication schemes. Here, we thoroughly study single\nGaAs-based quantum dots grown by molecular-beam epitaxy on specially designed,\ndigital-alloy InGaAs metamorphic buffers. With a set of structures varying in\nthe buffer indium content and providing quantum dot emission through the\ntelecom spectral range up to 1.6 $\\mu$m, we analyze the impact of the buffer\nand its composition on QD structural and optical properties. We identify the\nmechanisms of quantum dot emission shift with varying buffer composition. We\nalso look into the charge trapping processes and compare excitonic properties\nfor different growth conditions with single-dot emission successfully shifted\nto both, the second and the third telecom windows.\n",
        "title": "Impact of MBE-grown (In,Ga)As/GaAs metamorphic buffers on excitonic and\n  optical properties of single quantum dots with single-photon emission tuned\n  to the telecom range",
        "texts": [
            "FIG. 1. (a) Scheme of the investigated structure with InGaAs QDs. (b) SEM image of QDs for In-29% structure. (c) AFM",
            "FIG. 10. TRPL results for (a) fast single exponential decay and (b) combination of short and long decay times with additional exponential fit (red line) for single QD (structure In-38%) non-resonantly excited.",
            "FIG. 11. Second-order correlation function g(2)(τ) for X emission under cw excitation with 640 nm line (a) for structure In-38% and (b) for structure In-29%. The blue line is the fit to the experimental data, and the insets show the emission spectra of the investigated lines. (c) Values for all investigated cases from both structures.",
            "FIG. 12. Second-order correlation function g(2)(τ) for X emission under pulsed excitation with 805 nm line (a) for structure In-38% and (b) for structure In-29%. The blue line is the fit to the experimental data based on the additional recapture process and two-component decay, and the insets show the emission spectra of the investigated lines. Zoom-in ranges for small delays for g(2)(τ) dependence and fit (c) for the third telecom range and (d) for the second telecom range, respectively.",
            "FIG. 2. (a) Normalized PL spectra for structures from 15% to 38% indium content in the top part of MBL (temperature: 10 K, excitation wavelength: 532 nm, cw) with overlaid single QD emission lines in the range of second and third telecom windows (temperature: 5 K, excitation wavelength: 640 nm, cw). (b) Calculated QD emission energies as a function of MBL indium content (xMBL) for varying QD indium content (xQD: 0.5, 0.6, 0.7, 0.8, 1.0) and optically-measured emission energies for the investigated structures. (c) Results including QD indium content change (from 0.50 to 0.65) for two QD geometries: H = 5 nm, D = 40 nm, and H = 6 nm, D = 30 nm (solid black and dashed red lines).",
            "FIG. 3. (a) The linewidth of single QD emission lines as a function of emission energy for investigated structures from 15% to 38% MBL indium content (marked range between the first and third quartile and red dashed line median for individual samples). (b) DOLP values for single QD emission lines in a function of emission energy for the investigated structures. (c) Calculated DOLP values as a function of MBL indium content for various QD parameters: H = 5 nm, D = 40 nm (solid squares), H = 6 nm, D = 30 nm (open squares) with different lateral aspect ratios.",
            "FIG. 4. (a) Single QD emission as a function of the temperature for the structure In-38%. (b) Temperature dependence of the single-QD emission energy (black dots) and linewidth (red dots). Solid lines show fits based on the influence of phonons; dashed lines show standard energy gap dependences for InAs and GaAs bulk materials. (c) PL intensity (black dots) as a function of the temperature with a fit (dashed line) based on a single carrier activation process.",
            "FIG. 5. (a) Phonon energies obtained from the temperature dependences of single QD emission energy based on Eq. (1) for structures In-29% and In-38%. (b) Activation energies from the temperature dependences of single QD emission for structures In-29% and In-38%, with an underlaid calculated ladder of bright excited QD states (blue lines with intensities proportional to the oscillator strength).",
            "FIG. 6. (a) Single QD emission for the structure In-38% in the temperature range 10-65 K. (b) Temperature dependence of the PL intensity (black dots) with the fit (solid red line) based on a single activation process with an additional carriersupplying process [17].",
            "FIG. 7. (a) PL spectrum from a single QD for the In-38% structure for non-resonant excitation (black line). PLE spectrum (red line) for the indicated emission line (red arrow). PL spectra (blue line) based on the quasi-resonant excitation at the indicated PLE resonance (blue arrow). Observation of a signal for higher QD state in both PL and PLE spectra (green arrow). (b) The relative energy of excited QD states from single-dot PLE spectra with the underlaid simulated levels (blue lines with intensities proportional to the oscillator strength).",
            "FIG. 8. (a) PL spectra from a single QD for non-resonant excitation (sample In-38%) for the excitation power values from 0.1 to 5 µW. (b) The intensity of the exciton (X) and biexciton (XX) lines in a function of excitation power with powerfunction fits (lines). (c) Emission energy of X and XX lines for different linear polarization angles with sine fits (lines).",
            "FIG. 9. (a) XX binding energies (solid points) as a function of emission energy with a marked range between the first and third quartile and dashed red line median for individual samples. Theoretical simulations of binding energies for QDs (H = 6 nm, D = 30 nm) with different LAR (open points). (b) The fine structure splitting of single QD emission lines as a function of emission energy (marked range between the first and third quartile and dashed red line median for individual samples).",
            "TABLE I. Structure parameters: indium content and the measured thickness of the MBL layer.",
            "TABLE II. Decay times of single QD emission lines (mean values) for all investigated structures divided into the spectral ranges of the emission. 𝜏1 and 𝜏2 cover all measured exciton complexes while 𝜏X and 𝜏XX are for identified X and XX lines only."
        ],
        "imgs": [
            "$2305.00289v1-Figure1-1.png",
            "$2305.00289v1-Figure10-1.png",
            "$2305.00289v1-Figure11-1.png",
            "$2305.00289v1-Figure12-1.png",
            "$2305.00289v1-Figure2-1.png",
            "$2305.00289v1-Figure3-1.png",
            "$2305.00289v1-Figure4-1.png",
            "$2305.00289v1-Figure5-1.png",
            "$2305.00289v1-Figure6-1.png",
            "$2305.00289v1-Figure7-1.png",
            "$2305.00289v1-Figure8-1.png",
            "$2305.00289v1-Figure9-1.png",
            "$2305.00289v1-TableI-1.png",
            "$2305.00289v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00297",
        "abstract": "  Generalizing the results of 1211.6077 and 1703.00905, we prove a formula for\nthe pushforward of an arbitrary analytic function of the exceptional divisor\nclass of a weighted blowup of an algebraic variety centered at a smooth\ncomplete intersection with normal crossing. We check this formula extensively\nby computing the generating function of intersection numbers of a weighted\nblowup of the generic SU(5) Tate model over arbitrary smooth base, and\ncomparing the answer to known results. Motivated by applications to\nfour-dimensional F-theory flux compactifications, we use our formula to compute\nthe intersection pairing on the vertical part of the middle cohomology of\nelliptic Calabi-Yau 4-folds resolving the generic F$_4$ and Sp(6) Tate models\nwith non-minimal singularities. These resolutions lead to non-flat fibrations\nin which certain fibers contain 3-fold (divisor) components, whose physical\ninterpretation in M/F-theory remains to be fully explored.\n",
        "title": "Intersection Theory on Weighted Blowups of F-theory Vacua",
        "texts": [
            "Figure 1: Left: Toric fan in Z2 for the unweighted blowup of P2 centered at x = y = 0. Right: Toric fan for the weighted blowup of P2 with weights (2, 3). We denote lattice points by pairs of coordinates ~v = (v1, v2), with ~vx = (1, 0), ~vy = (0, 1), ~vz = (−1, −1) (in blue), and ~ve = (1, 1) for the unweighted blowup and ~ve = (2, 3) for the weighted blowup, both in red. In the unweighted case, the exceptional divisor is a copy of P1, whereas in the weighted case, the exceptional divisor is a copy of the weighted projective line P1 (2,3). Note that the weighted blowup of P2 contains cyclic quotient singularities along the exceptional divisor, and hence its intersection numbers are fractional— see, e.g., Eq. (5.5).",
            "Figure 2: The proof of Theorem 4.1 exploits the fact that a weighted blowup of a toric space can be viewed as composition of a root stack, an ordinary blowup, and a “de-rooting”, as depicted in Eq. (4.2). We illustrate this composition of maps using (stacky) toric fans in the lattice Z2 with coordinates ~v = (v1, v2), as illustrated on p. 43 of [32]. Lower right: Ordinary fan for C2. Lower left: Stacky fan for ~w √ C2, where wx = 2, wy = 3. Upper left: Ordinary blowup of ~w √ C2, centered at the origin V ( √ x, 3 √ y). Upper right: Weighted blowup of C2 centered at the origin. Notice that the weighted blowup, which can be implemented by the substitution x → e2x, y → e3y is formally equivalent to the substitution √ x → e √ x, 3 √ y → e 3 √ y, which is consistent with the root stack r′."
        ],
        "imgs": [
            "$2305.00297v2-Figure1-1.png",
            "$2305.00297v2-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00299",
        "abstract": "  Polynomial dynamical systems (i.e. dynamical systems with polynomial right\nhand side) are ubiquitous in applications, especially as models of reaction\nnetworks and interaction networks. The properties of general polynomial\ndynamical systems can be very difficult to analyze, due to nonlinearity,\nbifurcations, and the possibility for chaotic dynamics. On the other hand,\ntoric dynamical systems are polynomial dynamical systems that appear naturally\nas models of reaction networks, and have very robust and stable properties. A\ndisguised toric dynamical system is a polynomial dynamical system generated by\na reaction network $\\mathcal N$ and some choice of positive parameters, such\nthat (even though it may not be toric with respect to $\\mathcal N$) it has a\ntoric realization with respect to some network $\\mathcal N'$. Disguised toric\ndynamical systems enjoy all the robust stability properties of toric dynamical\nsystems. In this paper, we study a larger set of dynamical systems where the\nrate constants are allowed to take both positive and negative values. More\nprecisely, we analyze the $\\mathbb{R}$-disguised toric locus of a reaction\nnetwork $\\mathcal N$, i.e., the subset in the space rate constants (positive or\nnegative) of $\\mathcal N$ for which the corresponding polynomial dynamical\nsystem is disguised toric. We focus especially on finding a lower bound on the\ndimension of the $\\mathbb{R}$-disguised toric locus.\n",
        "title": "A Lower Bound on the Dimension of the $\\mathbb{R}$-Disguised Toric Locus\n  of a Reaction Network",
        "texts": [
            "Figure 1: (a) This reaction network consists of two linkage classes. (b) This reaction network is weakly reversible and contains one linkage class.",
            "Figure 3: Two weakly reversible E-graphs G1 and G2."
        ],
        "imgs": [
            "$2305.00299v2-Figure1-1.png",
            "$2305.00299v2-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00300",
        "abstract": "  The four-dimensional variational data assimilation methodology for\nassimilating noisy observations into a deterministic model has been the\nworkhorse of forecasting centers for over three decades. While this method\nprovides a computationally efficient framework for dynamic data assimilation,\nit is largely silent on the important question concerning the minimum number\nand placement of observations. To answer this question, we demonstrate the dual\nadvantage of placing the observations where the square of the sensitivity of\nthe model solution with respect to the unknown control variables, called\nforward sensitivities, attains its maximum. Therefore, we can force the\nobservability Gramian to be of full rank, which in turn guarantees efficient\nrecovery of the optimal values of the control variables, which is the first of\nthe two advantages of this strategy. We further show that the proposed strategy\nof placing observations has another inherent optimality: the square of the\nsensitivity of the optimal estimates of the control with respect to the\nobservations (used to obtain these estimates) attains its minimum value, a\nsecond advantage that is a direct consequence of the above strategy for placing\nobservations. Our analytical framework and numerical experiments on linear and\nnonlinear systems confirm the effectiveness of our proposed strategy.\n",
        "title": "On the dual advantage of placing observations through forward\n  sensitivity analysis",
        "texts": [
            "Figure 1: Solution of the decay model using the true and guess controls.",
            "Figure 10: Cost function for nonlinear decay model: ẋ = αx2.",
            "Figure 11: Sensitivity of the optimal estimates of the initial condition x0 to the first observation z1 for the nonlinear system ẋ = αx2. Left: contour plot of y21(t) at different values of t1 and t2. Middle: y21(t) values at t1 = 0.1 and different values of t2. Right: y21(t) values at t2 = 0.5 and different values of t1.",
            "Figure 12: Sensitivity of the optimal estimates of the decay parameter a to the first observation z1 for the nonlinear system ẋ = αx2. Left: contour plot of w2 1(t) at different values of t1 and t2. Middle: y21(t) values at t1 = 0.1 and different values of t2. Right: w2 1(t) values at t2 = 0.5 and different values of t1.",
            "Figure 13: Sensitivity of the optimal estimates of the initial condition x0 to the second observation z2 for the nonlinear system ẋ = αx2. Left: contour plot of y22(t) at different values of t1 and t2. Middle: y22(t) values at t1 = 0.1 and different values of t2. Right: y21(t) values at t2 = 0.5 and different values of t1.",
            "Figure 14: Sensitivity of the optimal estimates of the decay parameter a to the second observation z2 for the nonlinear system ẋ = αx2. Left: contour plot of w2 2(t) at different values of t1 and t2. Middle: y21(t) values at t1 = 0.1 and different values of t2. Right: w2 1(t) values at t2 = 0.5 and different values of t1.",
            "Figure 16: A comparison between inverse problem solutions (for initial conditions) at different observation placement times and varying levels of noise for the 1D viscous Burgers problem. Background refers to the guessed (inaccurate) initial conditions while the analysis refers to the solution of the inverse problem after observations have been assimilated.",
            "Figure 17: The predicted velocity field at t = 0.5 (left) and t = 1.0 (middle) for the 1D viscous Burgers problem with different observation placement times with 10% measurement noise along with the relative `2 error of the predicted velocity field at different times (right). Background solution refers to the forecast using the guessed (inaccurate) initial conditions while the analysis refers to the forecast after observations have been assimilated.",
            "Figure 18: The first two invariants for the model forecast sensitivities with respect to initial conditions for the 2D advection diffusion problem.",
            "Figure 19: A comparison between inverse problem solutions (for initial conditions) at different observation placement times with 10% measurement noise for the 2D advection diffusion problem. Background refers to the guessed (inaccurate) initial conditions while the analysis refers to the solution of the inverse problem after observations have been assimilated.",
            "Figure 2: Model sensitivity with respect to (a) initial condition x0 (left) and (b) the decay parameter a (right).",
            "Figure 20: The predicted solution at t = 1 for the 2D advection diffusion problem following the proposed observation placement strategy (with 10% measurement noise) along with the relative `2 error of the predicted velocity field at different times (right). Background solution refers to the forecast using the guessed (inaccurate) initial conditions while the analysis refers to the forecast after observations have been assimilated.",
            "Figure 3: Cost function for exponential decay model.",
            "Figure 4: Sensitivity of the optimal estimates of the initial condition x0 to the first observation z1. Left: contour plot of y21(t) at different values of t1 and t2. Middle: y21(t) values at t1 = 0.1 and different values of t2. Right: y21(t) values at t2 = 1.0 and different values of t1. Note that minimum values of y21 are obtained at t1 = 0.1 and t2 = 1.0.",
            "Figure 5: Sensitivity of the optimal estimates of the decay parameter a to the first observation z1. Left: contour plot of w2 1(t) at different values of t1 and t2. Middle: y21(t) values at t1 = 0.1 and different values of t2. Right: w2 1(t) values at t2 = 1.0 and different values of t1. Note that minimum values of w2 1 are obtained at t1 = 0.1 and t2 = 1.0.",
            "Figure 6: Sensitivity of the optimal estimates of the initial condition x0 to the second observation z2. Left: contour plot of y22(t) at different values of t1 and t2. Middle: y22(t) values at t1 = 0.1 and different values of t2. Right: y21(t) values at t2 = 1.0 and different values of t1. Note that minimum values of y22 are obtained at t1 = 0.1 and t2 = 1.0.",
            "Figure 7: Sensitivity of the optimal estimates of the decay parameter a to the second observation z2. Left: contour plot of w2 2(t) at different values of t1 and t2. Middle: y21(t) values at t1 = 0.1 and different values of t2. Right: w2 1(t) values at t2 = 1.0 and different values of t1. Note that minimum values of w2 2 are obtained at t1 = 0.1 and t2 = 1.0."
        ],
        "imgs": [
            "$2305.00300v1-Figure1-1.png",
            "$2305.00300v1-Figure10-1.png",
            "$2305.00300v1-Figure11-1.png",
            "$2305.00300v1-Figure12-1.png",
            "$2305.00300v1-Figure13-1.png",
            "$2305.00300v1-Figure14-1.png",
            "$2305.00300v1-Figure16-1.png",
            "$2305.00300v1-Figure17-1.png",
            "$2305.00300v1-Figure18-1.png",
            "$2305.00300v1-Figure19-1.png",
            "$2305.00300v1-Figure2-1.png",
            "$2305.00300v1-Figure20-1.png",
            "$2305.00300v1-Figure3-1.png",
            "$2305.00300v1-Figure4-1.png",
            "$2305.00300v1-Figure5-1.png",
            "$2305.00300v1-Figure6-1.png",
            "$2305.00300v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00301",
        "abstract": "  In this article, we establish the Hopf-Tsuji-Sullivan dichotomy for geodesic\nflows on certain manifolds with no conjugate points: either the geodesic flow\nis conservative and ergodic, or it is completely dissipative and non-ergodic.\nWe also show several equivalent conditions to the conservativity, such the\nPoincar\\'e series diverges at the critical exponent, the conical limit set has\nfull Patterson-Sullivan measure, etc.\n",
        "title": "The Hopf-Tsuji-Sullivan Dichotomy on Visibility Manifolds Without\n  Conjugate Points",
        "texts": [
            "Figure 1: Illustration of βp(ξ, η).",
            "Figure 2: Bound for the Busemann Function.",
            "Figure 6: Sketch of Σ1 and Σ2.",
            "Figure 9: Measure the Angle at pn."
        ],
        "imgs": [
            "$2305.00301v2-Figure1-1.png",
            "$2305.00301v2-Figure2-1.png",
            "$2305.00301v2-Figure6-1.png",
            "$2305.00301v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00302",
        "abstract": "  One way of expressing an environmental sound is using vocal imitations, which\ninvolve the process of replicating or mimicking the rhythm and pitch of sounds\nby voice. We can effectively express the features of environmental sounds, such\nas rhythm and pitch, using vocal imitations, which cannot be expressed by\nconventional input information, such as sound event labels, images, or texts,\nin an environmental sound synthesis model. In this paper, we propose a\nframework for environmental sound synthesis from vocal imitations and sound\nevent labels based on a framework of a vector quantized encoder and the\nTacotron2 decoder. Using vocal imitations is expected to control the pitch and\nrhythm of the synthesized sound, which only sound event labels cannot control.\nOur objective and subjective experimental results show that vocal imitations\neffectively control the pitch and rhythm of synthesized sounds.\n",
        "title": "Environmental sound synthesis from vocal imitations and sound event\n  labels",
        "texts": [
            "Fig. 1. Proposed method. An environmental sound is synthesized from a vocal imitation and a sound event label.",
            "Fig. 2. MOS distributions: “Label” vs “Label + vocal.” Blue points mean that “Label + vocal.” is superior to “Label.”",
            "Fig. 3. Results of objective and subjective evaluations of sound control by pitch change",
            "Fig. 4. Results of objective and subjective evaluations of sound control by rhythm change"
        ],
        "imgs": [
            "$2305.00302v2-Figure1-1.png",
            "$2305.00302v2-Figure2-1.png",
            "$2305.00302v2-Figure3-1.png",
            "$2305.00302v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00303",
        "abstract": "  In reinforcement learning and imitation learning, an object of central\nimportance is the state distribution induced by the policy. It plays a crucial\nrole in the policy gradient theorem, and references to it--along with the\nrelated state-action distribution--can be found all across the literature.\nDespite its importance, the state distribution is mostly discussed indirectly\nand theoretically, rather than being modeled explicitly. The reason being an\nabsence of appropriate density estimation tools. In this work, we investigate\napplications of a normalizing flow-based model for the aforementioned\ndistributions. In particular, we use a pair of flows coupled through the\noptimality point of the Donsker-Varadhan representation of the Kullback-Leibler\n(KL) divergence, for distribution matching based imitation learning. Our\nalgorithm, Coupled Flow Imitation Learning (CFIL), achieves state-of-the-art\nperformance on benchmark tasks with a single expert trajectory and extends\nnaturally to a variety of other settings, including the subsampled and\nstate-only regimes.\n",
        "title": "A Coupled Flow Approach to Imitation Learning",
        "texts": [
            "Figure 1. Left: The BC graph of an uncoupled flow for the HalfCheetah-v2 environment. Right: The BC graph of a coupled flow for the HalfCheetah-v2 environment. BC graphs for an estimator are generated by updating the estimator analogously to an RL run using N saved BC rollouts. This yields N estimators corresponding to N intermediate BC agents. The BC graph is then, for all i, the scatter of the i’th estimator’s evaluation of an i’th BC agent’s trajectory against its true environment reward.",
            "Figure 10. Two-dimensional BC analysis of RegularNet for the HalfCheetah-v2 environment. See Figure 8’s caption.",
            "Figure 2. Top: A comparison of CFIL to ValueDICE and DAC on a single expert trajectory in the standard state-action setting. Bottom: A comparison of two versions of CFIL to OPOLO on a single expert trajectory in the LFO setting, with one version limiting itself only to single states. CFIL uses identical hyperparameters on all environments in all three incarnations, showing outstanding results, particularly in the LFO setting where it far outperforms the highly tailored competitor OPOLO.",
            "Figure 3. A comparison of CFIL and DAC on four subsampling rates with a single expert trajectory. SubsampleN refers to sampling every N ’th transition in the trajectory.",
            "Figure 4. Averages (as color) and standard deviations (as size) of normalized asymptotic rewards for CFIL with varied levels of smoothing and regularization. Each point summarizes 25 seeds (5 per environment). The utility of the smoothing and regularization is apparent as well as CFIL’s lack of sensitivity to them.",
            "Figure 5. Extended version of Figure 4, showing per environment the average (as color) and standard deviations (as size) of normalized asymptotic rewards for CFIL with varied levels of smoothing and regularization. Each point summarizes 5 seeds. Once again, the importance of the smoothing and regularization is apparent, as well as CFIL lack of sensitivity.",
            "Figure 6. CFIL’s performance with varying numbers of expert trajectories (1, 5, and 10), demonstrating its consistency. Note, the single trajectory run is identical to that of Figure 2.",
            "Figure 7. The BC graph of RegularNet (see ablation) for the HalfCheetah-v2 environment.",
            "Figure 8. Two-dimensional BC analysis of coupled flows for the HalfCheetah-v2 environment. In contrast to the BC graph which is the i’th estimator’s evaluation of the i’th BC trajectory vs the true environment reward of that same trajectory, here we see scatters for individual estimators along the way. That is, their evaluations of all BC trajectories scattered against the true environment rewards of the trajectories.",
            "Figure 9. Two-dimensional BC analysis of uncoupled flows for the HalfCheetah-v2 environment. See Figure 8’s caption.",
            "Table 1. A comparison of CFIL to some alternatives, ablating its squasher, coupling and inductive bias. The score is the average normalized asymptotic reward over 25 seeds (5 for each environment). Note: rows with two values indicate runs with smoothing of 0 (left) and 0.5 (right).",
            "Table 2. Extended version of Table 1, showing the ablation results per environment. The table contains averages and standard deviations of normalized asymptotic rewards over 5 seeds."
        ],
        "imgs": [
            "$2305.00303v1-Figure1-1.png",
            "$2305.00303v1-Figure10-1.png",
            "$2305.00303v1-Figure2-1.png",
            "$2305.00303v1-Figure3-1.png",
            "$2305.00303v1-Figure4-1.png",
            "$2305.00303v1-Figure5-1.png",
            "$2305.00303v1-Figure6-1.png",
            "$2305.00303v1-Figure7-1.png",
            "$2305.00303v1-Figure8-1.png",
            "$2305.00303v1-Figure9-1.png",
            "$2305.00303v1-Table1-1.png",
            "$2305.00303v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00304",
        "abstract": "  In this paper we investigate the relationships between a multipreferential\nsemantics for defeasible reasoning in knowledge representation and a multilayer\nneural network model. Weighted knowledge bases for a simple description logic\nwith typicality are considered under a (many-valued) ``concept-wise\"\nmultipreference semantics. The semantics is used to provide a preferential\ninterpretation of MultiLayer Perceptrons (MLPs). A model checking and an\nentailment based approach are exploited in the verification of conditional\nproperties of MLPs.\n",
        "title": "A preferential interpretation of MultiLayer Perceptrons in a conditional\n  logic with typicality",
        "texts": [
            "Table 1: Properties for t-norms and s-norms",
            "Table 2: Properties for implication and negation functions",
            "Table 3: Results for checking formulae on the test set. The number of counterexamples for T(E) ⊑ F ≥ k/n is provided for k = 1, . . . , 4, as well as the total number of instances of T(E)."
        ],
        "imgs": [
            "$2305.00304v3-Table1-1.png",
            "$2305.00304v3-Table2-1.png",
            "$2305.00304v3-Table3-1.png"
        ]
    },
    {
        "id": "2305.00305",
        "abstract": "  Blue supergiants (BSGs) are important objects to study the intermediate\nphases of massive star evolution, helping to constrain evolutionary models.\nHowever, the lack of a holistic study of a statistically significant and\nunbiased sample of these objects makes several long-standing questions about\ntheir nature to remain unsolved. The present and other upcoming papers of the\nIACOB series are focused in studying - from a pure empirical point of view - a\nsample of 500 Galactic O9 - B9 stars with luminosity classes I and II (plus 250\nlate O- and early B-type stars with luminosity classes III, IV and V) and\ncovering distances up to 4 kpc from the Sun. We compile an initial set of 11000\nhigh-resolution spectra of 1600 Galactic late O- and B-type stars. We use a new\nnovel spectroscopic strategy based on a simple fitting of the Hbeta line to\nselect stars in a specific region of the spectroscopic HR diagram. We evaluate\nthe completeness of our sample using the Alma Luminous Star catalog (ALS III)\nand Gaia-DR3 data. We show the benefits of the proposed strategy for\nidentifying BSGs descending from stellar objects born as O-type stars, in the\ncontext of single star evolution. The resulting sample reaches a high level of\ncompleteness with respect to the ALS III catalog, gathering the 80% for all-sky\ntargets brighter than Bmag < 9 located within 2 kpc. However, we identify the\nneed for new observations in specific regions of the Southern hemisphere. In\nconclusion, we have explored a very fast and robust method to select BSGs,\nproviding a valuable tool for large spectroscopic surveys like WEAVE-SCIP or\n4MIDABLE-LR, and highlighting the risk of using spectral classifications from\nthe literature. Upcoming works will make use of this large and homogeneous\nspectroscopic sample to study specific properties of these stars in detail. We\ninitially provide first results about their rotational properties.\n",
        "title": "The IACOB project IX. Building a modern empirical database of Galactic\n  O9-B9 supergiants: sample selection, description, and completeness",
        "texts": [
            "Fig. 1. Sub-sample of 246 Galactic O- and B-type stars investigated by Simón-Díaz et al. (2017), color-coded by the LC taken from Simbad. Left panel: Location of the stars in an spectroscopic Hertzsprung-Russel diagram (see Sect. 3.1.1). The rough boundary between the O- and B-type star domains is indicated with a black dotted diagonal line. Evolutionary tracks taken from the MESA Isochrones & Stellar Tracks online tool for solar metallicity and no initial rotation are also included for reference purposes. Right panel: log(L/L ) against FW3414(Hβ) for the same stars. The vertical red dashed line and back dashed horizontal lines at log(L/L ) = 3.5 dex in both panels are included for reference (see Sect. 4.1).",
            "Fig. 10. Gaia DR3 Gmag corrected from distance against GBP - GRP for the selected sample, color-coded with the LC. Black solid line is the ZAMS. Evolutionary tracks for 9, 15, 20 and 40 M obtained from MESA with no initial rotation and no extinction are shown in gray. A reddening vector with ∆(Av) = 1 is indicated with a red arrow. Two diagonal black dashed lines show two extinction lines for a 20 M star and for the approximate position in Fig. 5 where the same track crosses the value of log(L/L )≈3.5 dex, respectively.",
            "Fig. 11. Same figure as in Fig. 10 but now including O9 to B9 stars from the ALS III catalog (Pantaleoni González, et al., in prep.) limited to stars Bmag < 11, and distances of 4 000 pc. Two diagonal black-dashed lines mark the reddening line of a 20 M star, one starting from the ZAMS (bottom) and the other at the approximate age where intersects the horizontal black-dashed line in the left panel of Fig. 5 at log(L/L ) = 3.5 dex, (top) both extended up to a ∆(Av) = 2. See Sect. 4.2.3 for the different colors. Four tracks from MESA with AV = 0.0 and no initial rotation are included for 9M , 15M , 20M and 40M .",
            "Fig. 14. Results of the number of stars against their spectral type (two leftmost panels) and luminosity class (two rightmost panels), represented in histograms. Each bin stacks the number of stars with different morphologies found for the Hβ and Hα profiles following the classification in Sect.3.2.1 and grouped as in the legend. Stars labeled within the “Absorption\" label include profiles “CF, DsP, PCy, RF\". The sources with LC I without sub-type in the literature are grouped in a separate bin. The sources classified as SB2+ are removed from the bins.",
            "Fig. 15. Histogram and cumulative distribution of the v sin i in the sample stars, excluding the identified SB2+ stars. In the top panel, each bin of the histogram is 20km s−1 wide and stacks the stars separated and color-coded by their LC. In the bottom panel, cumulative distributions separated by LCs.",
            "Fig. 16. Main figure: Distribution of the median of v sin i obtained through the GoF method of IACOB-BROAD against the SpT, separating in stars with LCs I and II. Solid error-bars indicate the upper and lower limits corresponding to the percentiles 75% and 25% while the dashed error-bars correspond to percentiles 90% and 10%. Stars without LC or SB2+ systems are not included. Sub-figure: histogram of the subsample of B1 I-II stars against the v sin i for better interpretation of the main figure and Sect. 4.3. The error-bars corresponding to the B1 I-II stars are plotted horizontally.",
            "Fig. 2. Results from testing the methodology described in Sect. 3.1.2 measuring the FW3414(Hβ). Top panel: four illustrative Hβ profiles named A, B, C and D for FASTWIND models with Teff = 24 000 K and R = 25 000, and different pairs of log g and v sin i. The horizontal pink lines indicate the position at 3/4, 1/2 and 1/4 of the line depth for the example D. Middle and bottom panels: log(L/L ) against FW3414(Hβ) and FWHM, respectively, both measured in a grid of synthetic Hβ profiles from FASTWIND with the same Teff and R as in the top panel, and values of v sin i between 10 and 360 km s−1. The four profiles of the top panel are indicated with open circles and letters. The error-bars in the middle panel show the average shift in all measurements due to the effect of different resolutions, and the effect of increasing Teff up to 30 000 K (approximate temperature for a B0 I-II star).",
            "Fig. 3. Examples of different Hα profiles found within our sample of study. The name of the stars, spectral types and morphological labels (see Sect. 3.2.1) are included. The spectra are corrected from radial velocity by using a set of photospheric metal lines. The vertical red dashed lines indicate the reference position of the line.",
            "Fig. 4. Histogram of the number of stars in bins of FW3414(Hβ) for the initial sample of O9 – B9 type stars. In each bin, the number of stars are stacked by luminosity class with different colors. The spectral classifications have been taken from Simbad. The sources without a luminosity class are grouped in pink color under the “No inf.\" label. Independently from their LC, all stars classified as SB2+ are grouped in bins with gray color.",
            "Fig. 5. Preliminary results from the quantitative spectroscopic analysis of ∼500 O9 – B6 type stars presented in this work for which the FW3414(Hβ) has been measured. The color-code in both panels indicates the LC taken from Simbad. Left panel: sHRD for these stars and additional results from Holgado et al. (2018), indicated with gray dots. The evolutionary tracks are taken from the MESA Isochrones & Stellar Tracks online tool for solar metallicity and no initial rotation. The approximate separation between the O-type stars and the B-type stars is indicated with a black dotted diagonal line. The black dashed horizontal line at log(L/L ) = 3.5 dex used in the selection of the working sample is indicated (also shown in the right panel). Right panel: log(L/L ) against FW3414(Hβ) for the same ∼500 stars. The vertical red dashed line shows the adopted value to select the working sample. Open circles indicate stars with v sin i > 120 km s−1, and gray crosses are SB2+ systems.",
            "Fig. 6. Histogram of the number of stars in bins of spectral types for the final sample of stars. In each bin, the number of stars are stacked by luminosity class with different colors. Independently from their LC, all stars classified as SB2+ are stacked in bins of gray color.",
            "Fig. 8. Polar plot in Galactic coordinates of the stars in the final sample, centered at the position of the Sun and up to a distance of 4 kpc. The stars are colored by the σ$/$ parameter between 0% and 25%. Stars with distances taken from Hipparcos are limited to those with σ$/$ ≤ 0.1.",
            "Fig. B.1. Top panel: distances from the inverse of the parallax (corrected from zero-point) against the distances from (Bailer-Jones et al. 2021) for the initial full sample of O9 – B9 type stars. Bottom panel: for the same stars, distances from Pantaleoni González, et al. (in prep.) against those from (Bailer-Jones et al. 2021). The stars are color-coded by their error over parallax from the Gaia DR3 data. In both panels, the two dotter lines indicate a deviation of ±1 000 pc.",
            "Fig. C.1. He i λ5875.62 Å line for six SB2 systems identified in this work. In top two figures, two cases of lines blended with short separation. The middle-right figure shows an example of a fast-rotating stars with a normal-rotating star. Bottom figures shows the easiest examples of SB2 where the lines from each star are widely separated.",
            "Table 1. Summary of the completeness of the sample for four different ranges of distances."
        ],
        "imgs": [
            "$2305.00305v2-Figure1-1.png",
            "$2305.00305v2-Figure10-1.png",
            "$2305.00305v2-Figure11-1.png",
            "$2305.00305v2-Figure14-1.png",
            "$2305.00305v2-Figure15-1.png",
            "$2305.00305v2-Figure16-1.png",
            "$2305.00305v2-Figure2-1.png",
            "$2305.00305v2-Figure3-1.png",
            "$2305.00305v2-Figure4-1.png",
            "$2305.00305v2-Figure5-1.png",
            "$2305.00305v2-Figure6-1.png",
            "$2305.00305v2-Figure8-1.png",
            "$2305.00305v2-FigureB.1-1.png",
            "$2305.00305v2-FigureC.1-1.png",
            "$2305.00305v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00309",
        "abstract": "  Patents provide a rich source of information about design innovations. Patent\nmining techniques employ various technologies, such as text mining, machine\nlearning, natural language processing, and ontology-building techniques. An\nautomated graph data modelling method is proposed for extracting functional\nrepresentations for building a semantic database of patents of mechanical\ndesigns. The method has several benefits: The schema-free characteristic of the\nproposed graph modelling enables the ontology it is based on to evolve and\ngeneralise to upper ontologies across technology domains and to specify lower\nontologies to more specific domains. Graph modelling benefits from enhanced\nperformance of deep queries across many levels of relationships and\ninteractions and provides efficient storage. Graph modelling also enables\nvisualisation libraries to use the graph data structure immediately, avoiding\nthe need for graph extraction programs from relational databases. Patent/Design\ncomparisons are computed by search queries using counting of overlaps of\ndifferent levels and weights. This work has produced the PatMine SolidWorks\nAdd-in \\c{opyright}, which compares annotated CAD designs with patents and\nhighlights overlapping design concepts. The patent annotation extracts its\nfunctional analysis, representing its structure as geometric feature\ninteractions. Additional features such as full-text search and semantic search\nof the PatMine patents database are available, and graph analytic methods and\nmachine learning algorithms are enabled and can be implemented as plug-ins in\nfuture work. Keywords: Patent Mining; Semantic Analysis; Functional Analysis\nDiagrams; Graph Data Modelling; Visualisation; Similarity Scoring; Big Data\nAnalytics; Machine Learning; Artificial Intelligence; Natural Language\nProcessing\n",
        "title": "Patent Mining by Extracting Functional Analysis Information Modelled As\n  Graph Structure: A Patent Knowledge-base Collaborative Building Approach",
        "texts": [
            "Fig 1: PatMine SolidWorks Add-in © Corkscrew design FAD model Definition screens and visualisation",
            "Fig 2: PatMine SolidWorks Add-in © Patents Database Query Generation",
            "Fig 3: PatMine SolidWorks Add-in © Patents Database Query Results Interface",
            "Fig 4: PatMine SolidWorks Add-in © Corkscrew example design scored against a 54% similar Patent, and overlapping interaction identified",
            "Fig 5: Corkscrew Design FAD visualisation in Neo4j Server Browser",
            "Fig 6: Corkscrew Apparatus Patent FAD visualisation in Neo4j Server Browser",
            "Fig 7: Corkscrew FAD visualisation in PatMine SolidWorks Add-in ©",
            "Fig 8: corkscrew apparatus patent FAD visualisation in PatMine SolidWorks Add-in ©"
        ],
        "imgs": [
            "$2305.00309v1-Figure1-1.png",
            "$2305.00309v1-Figure2-1.png",
            "$2305.00309v1-Figure3-1.png",
            "$2305.00309v1-Figure4-1.png",
            "$2305.00309v1-Figure5-1.png",
            "$2305.00309v1-Figure6-1.png",
            "$2305.00309v1-Figure7-1.png",
            "$2305.00309v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00311",
        "abstract": "  Vector autoregressive (VAR) models are widely used in multivariate time\nseries analysis for describing the short-time dynamics of the data. The\nreduced-rank VAR models are of particular interest when dealing with\nhigh-dimensional and highly correlated time series. Many results for these\nmodels are based on the stationarity assumption that does not hold in several\napplications when the data exhibits structural breaks. We consider a low-rank\npiecewise stationary VAR model with possible changes in the transition matrix\nof the observed process. We develop a new test of presence of a change-point in\nthe transition matrix and show its minimax optimality with respect to the\ndimension and the sample size. Our two-step change-point detection strategy is\nbased on the construction of estimators for the transition matrices and using\nthem in a penalized version of the likelihood ratio test statistic. The\neffectiveness of the proposed procedure is illustrated on synthetic data.\n",
        "title": "Change point detection in low-rank VAR processes",
        "texts": [
            "Figure 1: Test power depending on the dimension of transition matrices",
            "Figure 2: Test power for known or unknown location of the change-point",
            "Figure 3: The test power for known location of the change-point and different number of observations T",
            "Figure 4: Dependence of the test power on different locations of the change-point",
            "Figure 5: The test power depending on rank of the transition matrices"
        ],
        "imgs": [
            "$2305.00311v1-Figure1-1.png",
            "$2305.00311v1-Figure2-1.png",
            "$2305.00311v1-Figure3-1.png",
            "$2305.00311v1-Figure4-1.png",
            "$2305.00311v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00312",
        "abstract": "  Conventionally, federated learning aims to optimize a single objective,\ntypically the utility. However, for a federated learning system to be\ntrustworthy, it needs to simultaneously satisfy multiple/many objectives, such\nas maximizing model performance, minimizing privacy leakage and training cost,\nand being robust to malicious attacks. Multi-Objective Optimization (MOO)\naiming to optimize multiple conflicting objectives at the same time is quite\nsuitable for solving the optimization problem of Trustworthy Federated Learning\n(TFL). In this paper, we unify MOO and TFL by formulating the problem of\nconstrained multi-objective federated learning (CMOFL). Under this formulation,\nexisting MOO algorithms can be adapted to TFL straightforwardly. Different from\nexisting CMOFL works focusing on utility, efficiency, fairness, and robustness,\nwe consider optimizing privacy leakage along with utility loss and training\ncost, the three primary objectives of a TFL system. We develop two improved\nCMOFL algorithms based on NSGA-II and PSL, respectively, for effectively and\nefficiently finding Pareto optimal solutions, and we provide theoretical\nanalysis on their convergence. We design specific measurements of privacy\nleakage, utility loss, and training cost for three privacy protection\nmechanisms: Randomization, BatchCrypt (An efficient version of homomorphic\nencryption), and Sparsification. Empirical experiments conducted under each of\nthe three protection mechanisms demonstrate the effectiveness of our proposed\nalgorithms.\n",
        "title": "Optimizing Privacy, Utility and Efficiency in Constrained\n  Multi-Objective Federated Learning",
        "texts": [
            "Fig. 1. Formulating the problem of constrained multi-objective federated learning to unify the multi-objective optimization and trustworthy federated learning (see Sec. 4.2 for detail).",
            "Fig. 2. The Constrained Multi-Objective Federated Learning Workflow. The left panel illustrates a typical federated learning training procedure. The right panel gives the general constrained multi-objective optimization procedure involving five sub-procedures: training MOO models, generating solutions, evaluating solutions, selecting solutions, and constraint handling. The select solutions sub-procedure and the evaluate solutions sub-procedure may call the federated learning procedure to obtain utility loss 𝜖𝑢 , privacy leakage 𝜖𝑝 , and training cost 𝜖𝑐 by evaluating a given solution 𝑥 ∈ X.",
            "Fig. 3. Comparing hypervolume values of our proposed CMOFL algorithms with those of baseline MOFL algorithms on the Fashion-MNIST dataset for BC, RD, and SF, respectively. The first line compares CMOFLNSGA-II and MOFL-NSGA-II for the three protection mechanisms. The second line compares CMOFL-PSL and MOFL-PSL for the three protection mechanisms.",
            "Fig. 4. Comparing hypervolume values of our proposed CMOFL algorithms with those of baseline MOFL algorithms on the CIFAR10 dataset for BC, RD, and SF, respectively. The first line compares CMOFL-NSGAII and MOFL-NSGA-II for the three protection mechanisms. The second line compares CMOFL-PSL and MOFL-PSL for the three protection mechanisms.",
            "Fig. 5. Comparing Pareto fronts (at the 20th generation) of our proposed CMOFL algorithms and those of baseline MOFL algorithms on the Fashion-MNIST dataset for BC, RD, and SF, respectively. The first line shows CMOFL-NSGA-II (red) vs. MOFL-NSGA-II (blue) for each protection mechanism. The second line shows CMOFL-PSL (brown) vs. MOFL-PSL (green) for each protection mechanism. A better Pareto front curve should be more toward the bottom-left corner of each sub-figure.",
            "Fig. 6. Comparing hypervolume values of CMOFL-PSL (brown) and CMOFL-NSGA-II (red) when each generation uses 5 federated learning evaluations. Comparisons are conducted on the Fashion-MNIST dataset for BC, RD, and SF, respectively.",
            "Table 1. Existing multi-objective federated learning works.",
            "Table 3. Datasets and models for experiments. 𝑘𝑠 is kernel size, 𝑓𝑚 is the number of feature maps.",
            "Table 4. The three experimental settings that apply Randomization (RD), BatchCrypt (BC), and Sparsification (SF), respectively, to protect data privacy. FC: fully-connected layer."
        ],
        "imgs": [
            "$2305.00312v3-Figure1-1.png",
            "$2305.00312v3-Figure2-1.png",
            "$2305.00312v3-Figure3-1.png",
            "$2305.00312v3-Figure4-1.png",
            "$2305.00312v3-Figure5-1.png",
            "$2305.00312v3-Figure6-1.png",
            "$2305.00312v3-Table1-1.png",
            "$2305.00312v3-Table3-1.png",
            "$2305.00312v3-Table4-1.png"
        ]
    },
    {
        "id": "2305.00314",
        "abstract": "  Current multi-modal object detection approaches focus on the vehicle domain\nand are limited in the perception range and the processing capabilities.\nRoadside sensor units (RSUs) introduce a new domain for perception systems and\nleverage altitude to observe traffic. Cameras and LiDARs mounted on gantry\nbridges increase the perception range and produce a full digital twin of the\ntraffic. In this work, we introduce InfraDet3D, a multi-modal 3D object\ndetector for roadside infrastructure sensors. We fuse two LiDARs using early\nfusion and further incorporate detections from monocular cameras to increase\nthe robustness and to detect small objects. Our monocular 3D detection module\nuses HD maps to ground object yaw hypotheses, improving the final perception\nresults. The perception framework is deployed on a real-world intersection that\nis part of the A9 Test Stretch in Munich, Germany. We perform several ablation\nstudies and experiments and show that fusing two LiDARs with two cameras leads\nto an improvement of +1.90 mAP compared to a camera-only solution. We evaluate\nour results on the A9 infrastructure dataset and achieve 68.48 mAP on the test\nset. The dataset and code will be available at https://a9-dataset.com to allow\nthe research community to further improve the perception results and make\nautonomous driving safer.\n",
        "title": "InfraDet3D: Multi-Modal 3D Object Detection based on Roadside\n  Infrastructure Camera and LiDAR Sensors",
        "texts": [
            "Fig. 1: Early and late fusion of two roadside cameras and LiDARs. We register point clouds from two LiDARs using G-ICP [1] and project them with the camera-LiDAR detections into the image. Left column: Night detection results in more and better classified LiDAR detections. Right column: Detections during day time demonstrate a 41.67% increase in detections using the fusion approach. Moreover, even occluded objects, like the car behind the trailer (right) or the truck behind the gantry bridge (left), can be detected with our InfraDet3D Fusion Framework.",
            "Fig. 2: InfraDet3D Perception Framework Architecture. Our proposed model is deployed on a real intersection (S110) part of the A9 Test Stretch for Autonomous Driving in Munich, Germany.",
            "Fig. 3: Automatic calibration pipeline. We integrate four camera image and seven LiDAR point cloud preprocessing modules into our pipeline in order to increase the robustness of real-world outdoor calibration of roadside sensors. The algorithm takes the image and point cloud that is published continuously on the live system as input and outputs both, the calibration results and qualitative projections of point clouds into camera images.",
            "Fig. 4: Monocular 3D object detection pipeline, grounding shape hypotheses via tracking and the HD map.",
            "Fig. 5: Multi-modal 3D object detection pipeline. We apply a camera field-of-view filtering for all detections.",
            "Fig. 6: Qualitative results for south1 camera (first and second row) and south2 camera (third and fourth row). We show the perception results during day time (first and third row) and night time (second and fourth row). The detections are colored by their class color. Column four shows the fusion results in the following colors: green (unmatched camera detections), blue (unmatched LiDAR detections) and red (fused detections). From left to right: a) Instance segmentation, b) MonoDet3D, c) PointPillars, d) InfraDet3D, e) Visualization of the fused perception results in CARLA (using early and late fusion).",
            "TABLE I: Evaluation results on the A9-I intersection test set (N=North, S=South, EF=Early Fusion, LF=Late Fusion). We report the mAP3D@0.1 results for the following six classes: Car, Truck, Bus, Motorcycle, Pedestrian, Bicycle. * PointPillars inference score threshold is set to 0.3.",
            "TABLE II: Ablation study for matched camera-LiDAR detections calculated for south1 camera using early and late fusion. Taking LiDAR detection attributes leads to mAP3D score improvements in all cases.",
            "TABLE III: Ablation study of L-Shape-Fitting (LSF) augmentations on the vehicle category superset of the A9-I dataset.",
            "TABLE IV: Runtime evaluation of detector modules on the A9-I test set. All modules are implemented in Python 3.8 and run on a 2.9 GHz dual-core Intel Core i5 CPU.",
            "TABLE V: Runtime evaluation of PointPillars on the A9 intersection dataset with a single and registered point clouds. Tested in Python 3.8 and run on a NVIDIA RTX 4090.",
            "TABLE VI: Average Precision (AP) results across classes in the A9-I dataset of the best performing InfraDet3D model."
        ],
        "imgs": [
            "$2305.00314v1-Figure1-1.png",
            "$2305.00314v1-Figure2-1.png",
            "$2305.00314v1-Figure3-1.png",
            "$2305.00314v1-Figure4-1.png",
            "$2305.00314v1-Figure5-1.png",
            "$2305.00314v1-Figure6-1.png",
            "$2305.00314v1-TableI-1.png",
            "$2305.00314v1-TableII-1.png",
            "$2305.00314v1-TableIII-1.png",
            "$2305.00314v1-TableIV-1.png",
            "$2305.00314v1-TableV-1.png",
            "$2305.00314v1-TableVI-1.png"
        ]
    },
    {
        "id": "2305.00315",
        "abstract": "  Federated Identity Management has proven its worth by offering economic\nbenefits and convenience to Service Providers and users alike. In such\nfederations, the Identity Provider (IdP) is the solitary entity responsible for\nmanaging user credentials and generating assertions for the users, who are\nrequesting access to a service provider's resource. This makes the IdP\ncentralised and exhibits a single point of failure for the federation, making\nthe federation prone to catastrophic damages. The paper presents our effort in\ndesigning and implementing a decentralised system in establishing an identity\nfederation. In its attempt to decentralise the IdP in the federation, the\nproposed system relies on blockchain technology, thereby mitigating the single\npoint of failure shortcoming of existing identity federations. The system is\ndesigned using a set of requirements In this article, we explore different\naspects of designing and developing the system, present its protocol flow,\nanalyse its performance, and evaluate its security using ProVerif, a\nstate-of-the-art formal protocol verification tool.\n",
        "title": "Decentralised Identity Federations using Blockchain",
        "texts": [
            "Figure 1: SAML Identity Federation",
            "Figure 11: Login Performance evaluation (Throughput and Latency)",
            "Figure 13: Results of idp registration protocol",
            "Figure 14: Results of user registration protocol",
            "Figure 15: Results of idp resolve and login protocol",
            "Figure 2: Decentralised Identity Federation Architecture",
            "Figure 3: Individual Components inside Combined CoT",
            "Figure 8: Network configurations for experiments",
            "Figure 9: Registration Performance evaluation (Throughput and Latency)"
        ],
        "imgs": [
            "$2305.00315v1-Figure1-1.png",
            "$2305.00315v1-Figure11-1.png",
            "$2305.00315v1-Figure13-1.png",
            "$2305.00315v1-Figure14-1.png",
            "$2305.00315v1-Figure15-1.png",
            "$2305.00315v1-Figure2-1.png",
            "$2305.00315v1-Figure3-1.png",
            "$2305.00315v1-Figure8-1.png",
            "$2305.00315v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00316",
        "abstract": "  The goal of continual learning is to find a model that solves multiple\nlearning tasks which are presented sequentially to the learner. A key challenge\nin this setting is that the learner may forget how to solve a previous task\nwhen learning a new task, a phenomenon known as catastrophic forgetting. To\naddress this challenge, many practical methods have been proposed, including\nmemory-based, regularization-based, and expansion-based methods. However, a\nrigorous theoretical understanding of these methods remains elusive. This paper\naims to bridge this gap between theory and practice by proposing a new\ncontinual learning framework called Ideal Continual Learner (ICL), which is\nguaranteed to avoid catastrophic forgetting by construction. We show that ICL\nunifies multiple well-established continual learning methods and gives new\ntheoretical insights into the strengths and weaknesses of these methods. We\nalso derive generalization bounds for ICL which allow us to theoretically\nquantify how rehearsal affects generalization. Finally, we connect ICL to\nseveral classic subjects and research topics of modern interest, which allows\nus to make historical remarks and inspire future directions.\n",
        "title": "The Ideal Continual Learner: An Agent That Never Forgets",
        "texts": [
            "Figure 1: The Ideal Continual Learner (ICL) and related subjects. The exact connections between ICL and these subjects are discussed throughout the paper and appendix.",
            "Figure 2: For two tasks, Evron et al. (2022) follow the arrows (2a) and project the current estimate onto the affine subspace of solutions (blue or black), in an alternating fashion, eventually reaching a common solution (red). Instead, ICL† solves task 1, stores the affine subspace (2b, blue), uses it to regularize task 2 and finds all solutions (2b, red).",
            "Figure 3: Figure 3 is designed to help the reader understand our results of §4.1 and §4.2 at a high level, and it can be read as follows. Assumptions 1 and 2 guarantee the sufficiency of the Ideal Continual Learner† and the Ideal Continual Learner, respectively, and this is denoted by solid arrows in the figure. Assumptions 1 and 3 indicate an approximate sufficiency of the Ideal Continual Learner† (cf. Theorem 1 and Remark 7), and this is denoted by a dashed arrow in the figure.",
            "Table 1: Structure and messages of the paper."
        ],
        "imgs": [
            "$2305.00316v2-Figure1-1.png",
            "$2305.00316v2-Figure2-1.png",
            "$2305.00316v2-Figure3-1.png",
            "$2305.00316v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00318",
        "abstract": "  $f(Q)$ symmetric-teleparallel gravity is considered in view of Quantum\nCosmology. Specifically, we derive cosmological equations for $f(Q)$ models and\nthen investigate the related energy conditions. In the minisuperspace\nformalism, the point-like $f(Q)$ Hamiltonian is taken into account. In this\nframework, we obtain and solve the Wheeler-De Witt equation, thus finding the\nWave Function of the Universe in different cases. We show that the Hartle\nCriterion can be applied and classical observable universes occur.\n",
        "title": "Minisuperspace quantum cosmology in $f(Q)$ gravity",
        "texts": [
            "Figure 1: Wave Function of the Universe as a function of the scale factor",
            "Figure 2: Comparison between exponential function (orange line) and parabolic cylinder function (blue line)"
        ],
        "imgs": [
            "$2305.00318v4-Figure1-1.png",
            "$2305.00318v4-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00319",
        "abstract": "  Many re-ranking strategies in search systems rely on stochastic ranking\npolicies, encoded as Doubly-Stochastic (DS) matrices, that satisfy desired\nranking constraints in expectation, e.g., Fairness of Exposure (FOE). These\nstrategies are generally two-stage pipelines: \\emph{i)} an offline re-ranking\npolicy construction step and \\emph{ii)} an online sampling of rankings step.\nBuilding a re-ranking policy requires repeatedly solving a constrained\noptimization problem, one for each issued query. Thus, it is necessary to\nrecompute the optimization procedure for any new/unseen query. Regarding\nsampling, the Birkhoff-von-Neumann decomposition (BvND) is the favored approach\nto draw rankings from any DS-based policy. However, the BvND is too costly to\ncompute online. Hence, the BvND as a sampling solution is memory-consuming as\nit can grow as $\\gO(N\\, n^2)$ for $N$ queries and $n$ documents.\n  This paper offers a novel, fast, lightweight way to predict fair stochastic\nre-ranking policies: Constrained Meta-Optimal Transport (CoMOT). This method\nfits a neural network shared across queries like a learning-to-rank system. We\nalso introduce Gumbel-Matching Sampling (GumMS), an online sampling approach\nfrom DS-based policies. Our proposed pipeline, CoMOT + GumMS, only needs to\nstore the parameters of a single model, and it generalizes to unseen queries.\nWe empirically evaluated our pipeline on the TREC 2019 and 2020 datasets under\nFOE constraints. Our experiments show that CoMOT rapidly predicts fair\nre-ranking policies on held-out data, with a speed-up proportional to the\naverage number of documents per query. It also displays fairness and ranking\nperformance similar to the original optimization-based policy. Furthermore, we\nempirically validate the effectiveness of GumMS to approximate DS-based\npolicies in expectation.\n",
        "title": "Learning to Re-rank with Constrained Meta-Optimal Transport",
        "texts": [
            "Figure 1: Illustration of the constrained stochastic reranking problem. We obtain a fair probabilistic re-ranking policy for each query by solving a constrained optimization problem. Then, we decompose each policy to getmany rankings with their corresponding occurrence probabilities and store the tuple (query, probability, ranking). During deployment, we retrieve a ranking using its associated probability.",
            "Figure 2: The proposed framework. A pre-trained ranker assigns a score to each item in the list for each query. Then, we use meta-optimal transport to learn a potential function shared across queries. On average, this potential function optimizes the linear assignment of scores to discount positions for all queries. To impose the fairness constraint, we explicitly compute the approximated re-ranking policy, finetune it using the Sinkhorn algorithm, and apply it to calculate the fairness loss. Finally, we sample a ranking from the re-ranking policy via Gumbel-Matching for each function call during deployment.",
            "Figure 3: Comparing fair ranking policies on TREC 2019 (top row) and TREC 2020 (bottom row) datasets. We compare the fairness performance (the lower, the better) of the original ranking scores (red line) with ranking policies obtained by CoMOT(black line) and by solving a constrained optimization using CVXFOE for various fairness levels 𝜌 (bars). Yellow bars denote the fairness levels where CoMOT outperforms CVXFOE, CoMOT > CVXFOE, and grey bars indicate otherwise.",
            "Figure 4: Computation time comparison. Getting a ranking policy using CoMOT is 6 and 36 times faster than cold-start optimization using CVXFOE on the TREC 2019 and 2020 datasets, respectively.",
            "Figure 5: Comparing the ranking performance of re-ranking policies found by CVXFOE and CoMOT for various ranking architectures. We use CVXFOE with a fairness level 𝜌 = 0.1. This method is not predictive and denotes the best possible stochastic re-ranking policy. On the other hand, CoMOT is fully predictive and produces similar ranking performance.",
            "Figure 6: Approximating stochastic ranking policies in expectation using GumMS. The average of 𝑘 GumMS samples, P̃𝑘 , approximates a target policy PCoMOT for a significant enough number of samples 𝑘 for all rankers.",
            "Table 1: Descriptive statistics of the original and preprocessed TREC 2019 and 2020 Fair Ranking track datasets.",
            "Table 2: Comparing the predictive performance of CoMOT’s re-ranking for a Linear ranker with different LTR losses on the TREC 2019 and 2020 Fair Ranking datasets. We compare eachCoMOT re-ranking against orig. using a two-tailed paired t-test (𝑝 < 0.01). Statistical significantly lower and higher compared to orig. is denoted by △ and ▽ respectively. Bold indicates the best method per policy group.",
            "Table 3: The predictive performance of CoMOT’s re-ranking for various initial ranking architectures. We compare each CoMOT against orig. using a two-tailed paired t-test (𝑝 < 0.01). Statistical significance is denoted the same as Table 2",
            "Table 4: Quality of the GumMS’s policy approximation for various ranking architectures. We use a two-tailed paired ttest (𝑝 < 0.01) to compare each CoMOT policy ref. with its empirical expectation via GumMS (𝑘 = 5 000). Other conventions are the same as in Table 3."
        ],
        "imgs": [
            "$2305.00319v1-Figure1-1.png",
            "$2305.00319v1-Figure2-1.png",
            "$2305.00319v1-Figure3-1.png",
            "$2305.00319v1-Figure4-1.png",
            "$2305.00319v1-Figure5-1.png",
            "$2305.00319v1-Figure6-1.png",
            "$2305.00319v1-Table1-1.png",
            "$2305.00319v1-Table2-1.png",
            "$2305.00319v1-Table3-1.png",
            "$2305.00319v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00323",
        "abstract": "  Context: Recent research has used data mining to develop techniques that can\nguide developers through source code changes. To the best of our knowledge,\nvery few studies have investigated data mining techniques and--or compared\ntheir results with other algorithms or a baseline. Objectives: This paper\nproposes an automatic method for recommending source code changes using four\ndata mining algorithms. We not only use these algorithms to recommend source\ncode changes, but we also conduct an empirical evaluation. Methods: Our\ninvestigation includes seven open-source projects from which we extracted\nsource change history at the file level. We used four widely data mining\nalgorithms \\ie{} Apriori, FP-Growth, Eclat, and Relim to compare the algorithms\nin terms of performance (Precision, Recall and F-measure) and execution time.\nResults: Our findings provide empirical evidence that while some Frequent\nPattern Mining algorithms, such as Apriori may outperform other algorithms in\nsome cases, the results are not consistent throughout all the software\nprojects, which is more likely due to the nature and characteristics of the\nstudied projects, in particular their change history. Conclusion: Apriori seems\nappropriate for large-scale projects, whereas Eclat appears to be suitable for\nsmall-scale projects. Moreover, FP-Growth seems an efficient approach in terms\nof execution time.\n",
        "title": "Leveraging Data Mining Algorithms to Recommend Source Code Changes",
        "texts": [
            "Figure 1: An FP-tree, adopted from Alsulim et al. (2015).",
            "Figure 10: Boxplots of Precision for the Guava project.",
            "Figure 2: Overview of the followed methodology.",
            "Figure 21: Boxplots of F-measure for the Rhino project.",
            "Figure 25: F-measure pattern of algorithms for different projects.",
            "Figure 4: Boxplots of Precision for the Eclipse project",
            "Figure 6: Boxplots of F-measure for the Eclipse project",
            "Figure 9: Boxplots of F-measure for the Elasticsearch project.",
            "Table 1: Transactional data in vertical format adopted from Chee et al. (2019).",
            "Table 10: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for Eclipse.",
            "Table 12: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for Elasticsearch.",
            "Table 14: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for Guava.",
            "Table 16: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for JabRef.",
            "Table 18: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for Kotlin.",
            "Table 2: 2-Itemsets in vertical format adopted from Chee et al. (2019).",
            "Table 20: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for Rhino.",
            "Table 21: Average execution time for Rhino.",
            "Table 22: Adjusted P-values and Cliff’s Delta for paired comparison between the four studied data mining algorithms for SWT.",
            "Table 3: 3-Itemsets in vertical format adopted from Chee et al. (2019).",
            "Table 4: Pros and Cons of the investigated data mining algorithms.",
            "Table 5: Number of transactions for each project.",
            "Table 6: Example of generated rules for Eclipse.",
            "Table 7: Characteristics of investigated projects.",
            "Table 9: Results of the Shapiro-Wilk normality test."
        ],
        "imgs": [
            "$2305.00323v1-Figure1-1.png",
            "$2305.00323v1-Figure10-1.png",
            "$2305.00323v1-Figure2-1.png",
            "$2305.00323v1-Figure21-1.png",
            "$2305.00323v1-Figure25-1.png",
            "$2305.00323v1-Figure4-1.png",
            "$2305.00323v1-Figure6-1.png",
            "$2305.00323v1-Figure9-1.png",
            "$2305.00323v1-Table1-1.png",
            "$2305.00323v1-Table10-1.png",
            "$2305.00323v1-Table12-1.png",
            "$2305.00323v1-Table14-1.png",
            "$2305.00323v1-Table16-1.png",
            "$2305.00323v1-Table18-1.png",
            "$2305.00323v1-Table2-1.png",
            "$2305.00323v1-Table20-1.png",
            "$2305.00323v1-Table21-1.png",
            "$2305.00323v1-Table22-1.png",
            "$2305.00323v1-Table3-1.png",
            "$2305.00323v1-Table4-1.png",
            "$2305.00323v1-Table5-1.png",
            "$2305.00323v1-Table6-1.png",
            "$2305.00323v1-Table7-1.png",
            "$2305.00323v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00324",
        "abstract": "  Among generalized additive models, additive Mat\\'ern Gaussian Processes (GPs)\nare one of the most popular for scalable high-dimensional problems. Thanks to\ntheir additive structure and stochastic differential equation representation,\nback-fitting-based algorithms can reduce the time complexity of computing the\nposterior mean from $O(n^3)$ to $O(n\\log n)$ time where $n$ is the data size.\nHowever, generalizing these algorithms to efficiently compute the posterior\nvariance and maximum log-likelihood remains an open problem. In this study, we\ndemonstrate that for Additive Mat\\'ern GPs, not only the posterior mean, but\nalso the posterior variance, log-likelihood, and gradient of these three\nfunctions can be represented by formulas involving only sparse matrices and\nsparse vectors. We show how to use these sparse formulas to generalize\nback-fitting-based algorithms to efficiently compute the posterior mean,\nposterior variance, log-likelihood, and gradient of these three functions for\nadditive GPs, all in $O(n \\log n)$ time. We apply our algorithms to Bayesian\noptimization and propose efficient algorithms for posterior updates,\nhyperparameters learning, and computations of the acquisition function and its\ngradient in Bayesian optimization. Given the posterior, our algorithms\nsignificantly reduce the time complexity of computing the acquisition function\nand its gradient from $O(n^2)$ to $O(\\log n)$ for general learning rate, and\neven to $O(1)$ for small learning rate.\n",
        "title": "Representing Additive Gaussian Processes by Sparse Matrices",
        "texts": [
            "Figure 1 Left: the addition of five Matérn- 3 2 kernels a jk(·, x j) (colored lines, without compact supports) leads to a KP (black line, with a compact support); Right: converting 10 Matérn- 3 2 kernel functions {k(·, xi)}10 i=1 to 10 KPs, where each KP is non-zeron on at most three points in {xi}10 i=1.",
            "Figure 2 derivative of kernel functions: {∂ωk(·, i/10)}10 i=1 can be converted to compactly support generalized KPs via a banded matrix A",
            "Figure 3 The time complexity of calculating any block matrix is O(ν3), provided that it can be placed in a consecutive row/column with two other known block matrices. This is because H is a block-tridiagonal matrix. When working on the j-th column, we can get M− j = M+ j−1 directly by symmetry and solve an auxiliary matrix M−− j by putting [M j−2; M− j−1; M−− j ] in a consecutive column (left);",
            "Figure 5 RMSE and computational time for test functions. The upper row corresponds to the Schwefel test function and the lower row corresponds to the Rastr test function. The three columns correspond to d = 10,20 and computational time, respectively. The shaded areas areas represent standard deviation of the result",
            "Figure 6 Searched Minimum, computational time, and sampling points. The upper row corresponds to the 10-dimensional Schwefel test function and the lower row corresponds to the 20-dimensional Schwefel test function. The left column is the minimum estimated by algorithms, the mideele is the computational times, the right column is the samples by GKP.",
            "Table 1 Summary of computations for the posterior and log-likelihood"
        ],
        "imgs": [
            "$2305.00324v1-Figure1-1.png",
            "$2305.00324v1-Figure2-1.png",
            "$2305.00324v1-Figure3-1.png",
            "$2305.00324v1-Figure5-1.png",
            "$2305.00324v1-Figure6-1.png",
            "$2305.00324v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00325",
        "abstract": "  Using generalizations of natural orbitals, spin-averaged natural orbitals,\nand two-particle charge correlators for solids, we investigate electronic\nstructure of antiferromagnetic transition-metal oxides with a fully\nself-consistent, finite-temperature GW method. Our findings disagree with\nGoodenough-Kanamori (GK) rules, commonly used for qualitative interpretation of\nsuch solids. First, we found a strong dependence of natural orbital occupancies\non momenta contradicting GK assumptions. Second, along the momentum path, the\ncharacter of natural orbitals changes. In particular, contributions of oxygen\n2s orbitals are important, which has not been considered in the GK rules. To\nanalyze the influence of electronic correlation on the values of effective\nexchange coupling constants, we use both natural orbitals and two-particle\ncorrelators and show that electronic screening modulates the degree of\nsuperexchange by stabilizing the charge-transfer contributions, greatly\naffecting these coupling constants. Finally, we give a set of predictions and\nrecommendations regarding the use of density functional, Green's function, and\nwave-function methods for evaluating effective magnetic couplings in molecules\nand solids.\n",
        "title": "Natural orbitals and two-particle correlators as tools for analysis of\n  effective exchange couplings in solids",
        "texts": [
            "FIG. 1: Two supercells used in this paper to capture solutions of different types.",
            "FIG. 10: Difference of NNk=0 AB between the HS and BS solutions, computed for the NiO cell 2 with UHF (left) and GW (right) with 5× 5× 5 grid.",
            "FIG. 11: Difference of NNAB between the HS and BS solutions, computed for the NiO cell 2 with UHF (left) and GW (right) with 5× 5× 5 grid.",
            "FIG. 4: SA-NOs and their occupancies computed from the broken-symmetry solutions at ~k = (0.3986, 0.080,−0.8770) of NiO in cell 2 within GW (~k is written in the absolute notation). Both real (left) and imaginary (right) parts of the SA-NOs are visualized.",
            "FIG. 5: Occupation numbers of the frontier SA-NOs for the k-points along the interpolated path for NiO in cell 2 evaluated with UHF (top) and GW (down) with 5× 5× 5 grid for HS (left) and BS (right) solutions. The dashed blue line is the average of the occupancies of all 4 frontier SA-NOs at each k-point.",
            "FIG. 6: Occupation numbers of the frontier SA-NOs for the k-points along the interpolated path for NiO in cell 1 evaluated with UHF (top) and GW (down) with 5× 5× 5 grid for HS (left) and BS (right) solutions. The dashed blue line is the average of the occupancies of all 4 frontier SA-NOs at each k-point."
        ],
        "imgs": [
            "$2305.00325v1-Figure1-1.png",
            "$2305.00325v1-Figure10-1.png",
            "$2305.00325v1-Figure11-1.png",
            "$2305.00325v1-Figure4-1.png",
            "$2305.00325v1-Figure5-1.png",
            "$2305.00325v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00326",
        "abstract": "  We extend the traditional framework for estimating subspace bases that\nmaximize the preserved signal energy to additionally preserve the Cram\\'er-Rao\nbound (CRB) of the biophysical parameters and, ultimately, improve accuracy and\nprecision in the quantitative maps. To this end, we introduce an\n\\textit{approximate compressed CRB} based on orthogonalized versions of the\nsignal's derivatives with respect to the model parameters. This approximation\npermits singular value decomposition (SVD)-based minimization of both the CRB\nand signal losses during compression. Compared to the traditional SVD approach,\nthe proposed method better preserves the CRB across all biophysical parameters\nwith negligible cost to the preserved signal energy, leading to reduced bias\nand variance of the parameter estimates in simulation. In vivo, improved\naccuracy and precision are observed in two quantitative neuroimaging\napplications, permitting the use of smaller basis sizes in subspace\nreconstruction and offering significant computational savings.\n",
        "title": "Cram\\'er-Rao Bound Optimized Subspace Reconstruction in Quantitative MRI",
        "texts": [
            "FIGURE 2 (a) Signal energy loss, normalized by the total signal energy, as a function of the weighting parameter (cf. Eq. (5)) for the MRF-FISP test dataset. (b) Cramér-Rao bound (CRB) loss calculated using the approximate compressed CRB (ΔBac ; Eq. (6)) and the exact compressed CRB (ΔBec ; Eq. (8)), averaged over all fingerprints and orthogonalized derivatives in the test set. (c) CRB loss for 1∕T1 and 1∕T2 individually given 5 temporal coefficients (Nc = 5). (d) The average ratio of the approximate compressed CRB and the exact",
            "FIGURE 3 The MRF-FISP’s approximate compressed CRB of R1 = 1∕T1 (Bac(R1)) vs the exact compressed CRB (Bec(R1)) for 3 (a-d) and 4 (e-h) coefficients (Nc) across 4 different CRB weightings ( ), with each dot representing an individual fingerprint. Note each subplot’s axes are scaled by R21 and limited to the same range for improved visualization. Linear regressions across all data points in each subplot (including those not plotted within the axis limits) are shown in purple in reference to the identity line plotted in red. Correlations between Bac and Bec are improved with increasingNc and . Scatter plots for R2 are shown in Sup. Fig. S1.",
            "FIGURE 4 Comparison of T1 and T2 maps extracted from the MRF-FISP data that were reconstructed with a traditional SVD basis ( = 0) and the proposed CRB-SVD basis ( = 0.3) for different sub-space sizes (Nc), whereNc = 10 serves as a gold standard. The mean and standard deviation within the white matter ROI (red box) is shown in Tab. 1. The CRB-SVD basis offers improved image quality atNc = 3, the theoretical",
            "FIGURE 5 (a) Signal energy loss vs normalized by the total signal energy in the qMT test dataset. (b) Cramér-Rao bound (CRB) loss",
            "FIGURE 6 (a) Normalized signal energy loss, (b) approximate compressed CRB loss (ΔBac ; Eq. (6)), (c) exact compressed CRB loss (ΔBec ; Eq. (8)), and (d) ratio R (Eq. (13)) plotted as a function of andNc , all averaged over the qMT test dataset (except (a)). Note (a) and (b) are scaled versions of the two losses in the CRB-SVD optimization objective (Eq. (5)). Two exemplary bases that offer a good balance between preserved CRB and signal energy with reasonably good optimality at different compression levels ({ = 0.5, Nc = 15} and { = 0.5, Nc = 10}) are marked in blue and green, respectively.",
            "FIGURE 7 Scatter plots of the approximate compressed CRB of the semi-solid spin pool fraction (Bac(ms0)) vs the exact compressed CRB (Bec(ms0)) for different numbers of coefficients (Nc) and weightings of the CRB-loss ( ), with each dot representing a fingerprint in the qMT test dataset. Note each subplot’s axes are limited to the same range for improved visualization. Linear regressions across all data points in each subplot (including those not plotted within the axis limits) are shown in purple in reference to the identity line plotted in red. Correlations between Bac and Bec are improved with increasingNc and . Scatter plots for the other qMT parameters are shown in Sup. Figs. S5-S9.",
            "FIGURE 8 Comparison of the semi-solid spin pool’s fractional size ms0 (a) and longitudinal relaxation rate Rs1 (b) extracted from a traditional SVD basis ( = 0) and proposed CRB-SVD basis ( = 0.5) for different numbers of coefficients (Nc), whereNc = 30 serves as a gold standard. Each panel is reconstructed separately and fitted with a neural network trained specifically for that combination of { ,Nc}. 38 The CRB-SVD basis improves the SNR for ms0 (pink magnifications) and improves the accuracy of the Rs1 maps. The remaining qMT parameters are shown in Sup. Fig. S10. The mean and standard deviation for all qMT parameters within the white matter ROI (red box) is shown in Sup. Tab. S1.",
            "TABLE 1 Mean and standard deviation of MRF-FISP derived T1 and T2 estimates within the white matter ROI highlighted by the red box in Fig. 4. Literature values are from the original MRF-FISP paper. 18"
        ],
        "imgs": [
            "$2305.00326v1-Figure2-1.png",
            "$2305.00326v1-Figure3-1.png",
            "$2305.00326v1-Figure4-1.png",
            "$2305.00326v1-Figure5-1.png",
            "$2305.00326v1-Figure6-1.png",
            "$2305.00326v1-Figure7-1.png",
            "$2305.00326v1-Figure8-1.png",
            "$2305.00326v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00331",
        "abstract": "  A key stumbling block for neural cross-language information retrieval (CLIR)\nsystems has been the paucity of training data. The appearance of the MS MARCO\nmonolingual training set led to significant advances in the state of the art in\nneural monolingual retrieval. By translating the MS MARCO documents into other\nlanguages using machine translation, this resource has been made useful to the\nCLIR community. Yet such translation suffers from a number of problems. While\nMS MARCO is a large resource, it is of fixed size; its genre and domain of\ndiscourse are fixed; and the translated documents are not written in the\nlanguage of a native speaker of the language, but rather in translationese. To\naddress these problems, we introduce the JH-POLO CLIR training set creation\nmethodology. The approach begins by selecting a pair of non-English passages. A\ngenerative large language model is then used to produce an English query for\nwhich the first passage is relevant and the second passage is not relevant. By\nrepeating this process, collections of arbitrary size can be created in the\nstyle of MS MARCO but using naturally-occurring documents in any desired genre\nand domain of discourse. This paper describes the methodology in detail, shows\nits use in creating new CLIR training sets, and describes experiments using the\nnewly created training data.\n",
        "title": "Synthetic Cross-language Information Retrieval Training Data",
        "texts": [
            "Figure 1: A depiction of the basic JH-POLO methodology. A target language passage (Chinese in this example, translated into English for convenience) is selected randomly from the target passage collection, and BM25 retrieval is used to identify a related passage. The two Passages are presented to a large language model, which is then prompted to generate queries for which one passage is relevant and the other is not.",
            "Figure 3: Comparison of output when including the prompt addition “No response should require the recipient to have seen the previous responses” (below) or excluding it (above).",
            "Figure 4: Sample queries generated by JH-POLO. Text in italics is the translation of the corresponding Chinese Tweet. ✓ and ✗ indicate whether the generated query passed the cross-encoder filter.",
            "Table 1: Dataset statistics of NeuCLIR 2022 and HC3.",
            "Table 2: Statistics of the generation results.",
            "Table 3: Retrieval Effectiveness. ∗indicates significance with 95% confidence against fine-tuning with English triples using paired t-tests with Bonferrini correction on three tests (over languages). †indicates significance between JH-POLO and finetuning with translated triples using the same statistical test."
        ],
        "imgs": [
            "$2305.00331v1-Figure1-1.png",
            "$2305.00331v1-Figure3-1.png",
            "$2305.00331v1-Figure4-1.png",
            "$2305.00331v1-Table1-1.png",
            "$2305.00331v1-Table2-1.png",
            "$2305.00331v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00332",
        "abstract": "  Visualization plays an important role in analyzing and exploring time series\ndata. To facilitate efficient visualization of large datasets, downsampling has\nemerged as a well-established approach. This work concentrates on LTTB\n(Largest-Triangle-Three-Buckets), a widely adopted downsampling algorithm for\ntime series data point selection. Specifically, we propose MinMaxLTTB, a\ntwo-step algorithm that marks a significant enhancement in the scalability of\nLTTB. MinMaxLTTB entails the following two steps: (i) the MinMax algorithm\npreselects a certain ratio of minimum and maximum data points, followed by (ii)\napplying the LTTB algorithm on only these preselected data points, effectively\nreducing LTTB's time complexity. The low computational cost of the MinMax\nalgorithm, along with its parallelization capabilities, facilitates efficient\npreselection of data points. Additionally, the competitive performance of\nMinMax in terms of visual representativeness also makes it an effective\nreduction method. Experiments show that MinMaxLTTB outperforms LTTB by more\nthan an order of magnitude in terms of computation time. Furthermore,\npreselecting a small multiple of the desired output size already provides\nsimilar visual representativeness compared to LTTB. In summary, MinMaxLTTB\nleverages the computational efficiency of MinMax to scale LTTB, without\ncompromising on LTTB's favored visualization properties. The accompanying code\nand experiments of this paper can be found at\nhttps://github.com/predict-idlab/MinMaxLTTB.\n",
        "title": "MinMaxLTTB: Leveraging MinMax-Preselection to Scale LTTB",
        "texts": [
            "Figure 2: Assessing visual representativeness of MinMaxLTTB with rps ∈ {2,4,6} for various time series templates. Each row displays a distinct time series dataset, with columns indicating the template size. All image templates, including the blue reference templates which are depicted above the metric subplots, were generated using Plotly’s default settings (linear interpolation, line-width of 2 pixels). The metric subplots reveal trends in aggregation algorithm performance as nout (x-axis) increases (range [200, 2000]). More information about these trends, metrics, conv-mask scaling, and templates can be found in [26]. PEM 20 refers to Pixel Error with a Margin of 20, where pixels differences above 20 are binarized and divided by the conv-mask size to obtain a ratio. DSSIM denotes conv-mask scaled structural dissimilarity, while MSE represents conv-mask scaled Mean Squared Error. A GIF and an HTML animation further demonstrate the visual representativeness of MinMaxLTTB for rps ∈ [1−8].",
            "Figure 3: Illustration of LTTB’s tendency to (i) select contrasting extrema values in neighboring buckets and (ii) favor extrema proximity to the left-bin edge. For all points in Bi, triangular areas are calculated using the prior selected point from Bi−1 and the mean x and y values of Bi+1. Points (1) and (3), both opposing the selected extrema of Bi−1, compete for the largest triangular surface. Note that extremum (2) would yield a considerably smaller triangle than points (1) and (3). The dashed line passing through point (1) represents the equisurface line, with points above it generating larger triangles and those below resulting in smaller ones. This line will always be parallel to the one connecting the previous data point and the mean of the next bucket. Despite being the global extrema of Bi, (3) is not selected as it resides below the equisurface line of (1), illustrating LTTB’s tendency to favor data points near the left-bin edge.",
            "Figure 4: In-memory performance analysis of LTTB and MinMaxLTTB. For LTTB the C implementation from plotly-resampler v0.8.3.2 is used, for MinMaxLTTB the implementation can be found here.",
            "Table 1: Overview of time series data point selection algorithms, where N denotes the time series length, and nout represents the aggregation output size. We included the MinMaxLTTB algorithm for comparison."
        ],
        "imgs": [
            "$2305.00332v1-Figure2-1.png",
            "$2305.00332v1-Figure3-1.png",
            "$2305.00332v1-Figure4-1.png",
            "$2305.00332v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00333",
        "abstract": "  In the edge-2star model with hard constraints we prove the existence of an\nopen set of constraint parameters, bisected by a line segment on which there\nare nonunique entropy-optimal graphons related by a symmetry. At each point in\nthe open set but off the line segment there is a unique entropy-optimizer,\nbipodal and varying analytically with the constraints. We also show that\nthroughout another open set, containing a different portion of the same line of\nsymmetry, there is instead a unique optimal graphon, varying analytically with\nthe parameters. We explore the extent of these open sets, determining the point\nat which a symmetric graphon ceases to be a local maximizer of the entropy.\nFinally, we prove some foundational theorems in a general setting, relating\noptimal graphons to the Boltzmann entropy and the generic structure of large\nconstrained random graphs.\n",
        "title": "Optimal graphons in the edge-2star model",
        "texts": [
            "Figure 3. There are only 3 solutions of k(z) = z."
        ],
        "imgs": [
            "$2305.00333v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00334",
        "abstract": "  X-ray phase-contrast tomography (XPCT) is widely used for high contrast 3D\nimaging using either synchrotron or laboratory microfocus X-ray sources. XPCT\nenables an order of magnitude improvement in image contrast of the\nreconstructed material interfaces with low X-ray absorption contrast. The\ndominant approaches to 3D reconstruction using XPCT relies on the use of\nphase-retrieval algorithms that make one or more limiting approximations for\nthe experimental configuration and material properties. Since many experimental\nscenarios violate such approximations, the resulting reconstructions contain\nblur, artifacts, or other quantitative inaccuracies. Our solution to this\nproblem is to formulate new iterative non-linear phase-retrieval (NLPR)\nalgorithms that avoid such limiting approximations. Compared to the widely used\nstate-of-the-art approaches, we show that our proposed algorithms result in\nsharp and quantitatively accurate reconstruction with reduced artifacts. Unlike\nexisting NLPR algorithms, our approaches avoid the laborious manual tuning of\nregularization hyper-parameters while still achieving the stated goals. As an\nalternative to regularization, we propose explicit constraints on the material\nproperties to constrain the solution space and solve the phase-retrieval\nproblem. These constraints are easily user-configurable since they follow\ndirectly from the imaged object's dimensions and material properties.\n",
        "title": "Maximum Likelihood based Phase-Retrieval using Fresnel Propagation\n  Forward Models with Optional Constraints",
        "texts": [
            "Fig. 1. Parallel-beam X-ray phase-contrast tomography (XPCT) experiment at a synchrotron user-facility. The 3D object is rotated along an axis and 2D detector measurements are periodically acquired at several rotation angles. The object-to-detector propagation distance, R, is adjusted to produce phasecontrast in the measured X-ray images. The labels for the X-ray fields are defined in section II.",
            "Fig. 10. Tomographic reconstruction of the refractive index decrement from phase images retrieved using single-distance phase-retrieval (PR) methods. (a) and (b) show the center slice (u− v axes) of the reconstruction using Paganin PR and C-NLPR/One-α respectively. (c) and (d) show line profile comparisons between Paganin and C-NLPR along the yellow marked lines in (a) and (b). In (c, d), the large dynamic range for Paganin and C-NLPR/One-γ indicate the presence of streak artifacts since these line-profiles are in the background region of (a, b). Both C-NLPR/TrOpt-α, γ and C-NLPR/One-α reduce streaking artifacts as illustrated in (c, d). (e, f) zooms into a region along a different slice in the presence of a second material between the SiC fibers, which demonstrates the sharper reconstruction using C-NLPR/One-α when compared to Paganin PR. Images in (a, b, e, f) are scaled between −1.79× 10−7 and 1.43× 10−6. (c, d) use a common legend that is indicated at the top of the plots. (g) is the modulation transfer function (MTF) for the sharpness of the disc inside the red square in (a, b). (g) indicates sharper reconstructions using C-NLPR/One-α and C-NLPR/TrOpt-α, γ since the corresponding curves are above the curve for Paganin PR at the higher frequencies. Our recommendation is to use C-NLPR/One-α that only requires knowledge of δ/β.",
            "Fig. 11. (a) is a plot of the objective function, l(y; z), and the total time elapsed for C-NLPR/One-α as a function of the iteration number of LBFGS. (b) is a plot of the percentage (%) change in the objective function, l(y; z), and the percentage change in the estimated reconstruction, z, as a function of the iteration number of LBFGS. The total run time for C-NLPR/One-α was 6.3 seconds. This analysis is for C-NLPR/One-α at the first view angle for the experimental data results in Fig. 10.",
            "Fig. 5. (a) is the tomographic reconstruction (u− v axes) using GerchbergSaxton PR (GSPR) that is initialized with TIE PR at the best regularization parameter. (b) is the SSIM as a function of the regularization parameter for the PR that is used as initialization. GSPR produces artifacts that resemble Fresnel diffraction fringes in (a). U-NLPR with CTF initialization at the fixed regularization of equation (19) (intersection of the orange dotted line and the red solid line) has higher SSIM than GSPR at any regularization value.",
            "Fig. 6. Tomographic reconstructions of the refractive index decrement from the phase images produced by the single-distance phase-retrieval (PR) algorithms of Paganin and C-NLPR/One-α (proposed). (a-c) show reconstructions of the single material object. (d, e) show reconstructions of the multi-material object. (a-e) show planar slices along the u− v axes that pass through the center of the reconstruction volume. (a) and (d) show reconstructions using Paganin PR. (b) shows the reconstruction using C-NLPR that is initialized with zeros for the phase image (label C-NLPR/0-Initial). (c) and (e) show reconstructions using C-NLPR that is initialized using Paganin PR (label C-NLPR/Pag-Initial). The gray values in (a-e) are scaled between −2.09 × 10−7 and 1.67 × 10−6. C-NLPR with Paganin initialization produces the best reconstruction that minimize noise and artifacts.",
            "Fig. 7. NRMSE and SSIM between reconstruction and ground-truth for the refractive index decrement as a function of the (inaccurate) propagation distance R that is input to Paganin phase-retrieval (PR). The true propagation distance R used for simulation is 200mm. The NRMSE is lowest and SSIM is highest when R is set equal to its true value of 200mm. Initializing CNLPR with zeros for the phase results in sub-optimal performance that is worse than Paganin PR. C-NLPR initialized with Paganin PR (at the correct R) has the best performance. Here, C-NLPR refers to C-NLPR/One-α.",
            "Fig. 8. Quantification of performance and speed of C-NLPR for various choices of α and γ as described in sections IV-B1, IV-B2, and IV-B3. Our analysis is repeated for various δ, β values. True-δ, β uses the ground-truth δ, β of SiC. High-δ refers to a δ that is 10× the δ of SiC. Low-β refers to a β that is 0.02× the β of SiC. (a) shows the performance metrics of RMSE/SSIM within each square block. (a) uses a linear colormap where yellow indicates the best, green is better, blue is bad, and dark blue is the worst performance. (b, c, d) show the number of LBFGS iterations as a function of the view index. Corrupted reconstructions caused by numerical instabilities is indicated by “nan” (not-a-number) in (a) and shaded with a translucent color in (c). From (a, c), we see that C-NLPR/One-γ results in “nan” due to numerical instabilities for High-δ. Hence, we recommend avoiding C-NLPR/One-γ for large ratios of δ/β. With C-NLPR/One-α, while we achieve good overall performance in (a), the number of iterations may reach large numbers for Low-β as shown in (d). With C-NLPR/TrOpt-α, γ, we achieve good overall performance (see (a)) without the need for a large number of iterations (see (b, c, d)). Legend for (c, d) is same as in (b).",
            "Fig. 9. Experimental data reconstruction comparison of the refractive index decrement for various multi-distance phase-retrieval (PR) algorithms. (a-e) show planar reconstruction slices along the u− v axes passing through the center of the volume. The reconstruction in (a-e) is cropped to show the region within the interior of the sample holder. (f-j) and (k-o) zooms into two different regions of the reconstructions in (a-e). Since the quantitative values vary substantially between PR methods (see section V-A), we scale the gray values of each image individually between the value percentiles of 5% and 95%. Both CTF and TIE produce substantial low frequency artifacts in (a), (b), (g), and (l). Mixed reduces the artifacts but has increased noise as shown in (h, m). U-NLPR, irrespective of the initialization, produces the best reconstructions that minimize noise and artifacts. In particular, U-NLPR with CTF initialization (using the fixed regularization in equation (19)) produce less intense artifacts at the center of the images in (d, e) when compared to zero-initialization. Unlike U-NLPR, the CTF, TIE, and Mixed PR results are at optimal regularization values that were manually chosen to achieve the best visual quality of reconstructions."
        ],
        "imgs": [
            "$2305.00334v2-Figure1-1.png",
            "$2305.00334v2-Figure10-1.png",
            "$2305.00334v2-Figure11-1.png",
            "$2305.00334v2-Figure5-1.png",
            "$2305.00334v2-Figure6-1.png",
            "$2305.00334v2-Figure7-1.png",
            "$2305.00334v2-Figure8-1.png",
            "$2305.00334v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00337",
        "abstract": "  On the Ethereum network, it is challenging to determine a gas price that\nensures a transaction will be included in a block within a user's required\ntimeline without overpaying. One way of addressing this problem is through the\nuse of gas price oracles that utilize historical block data to recommend gas\nprices. However, when transaction volumes increase rapidly, these oracles often\nunderestimate or overestimate the price. In this paper, we demonstrate how\nGaussian process models can predict the distribution of the minimum price in an\nupcoming block when transaction volumes are increasing. This is effective\nbecause these processes account for time correlations between blocks. We\nperformed an empirical analysis using the Gaussian process model on historical\nblock data and compared the performance with GasStation-Express and Geth gas\nprice oracles. The results suggest that when transactions volumes fluctuate\ngreatly, the Gaussian process model offers a better estimation. Further, we\ndemonstrated that GasStation-Express and Geth can be improved upon by using a\nsmaller training sample size which is properly pre-processed. Based on the\nresults of empirical analysis, we recommended a gas price oracle made up of a\nhybrid model consisting of both the Gaussian process and GasStation-Express.\nThis oracle provides efficiency, accuracy, and better cost.\n",
        "title": "A Practical and Economical Bayesian Approach to Gas Price Prediction",
        "texts": [
            "Fig. 1: The comparison of the true minimum gas prices in each block and the prediction of P75 from each method. Block number 11799554 to 11800236 (top) and block number 11907262 to 11907569 (bottom) are shown here.",
            "Table 1: The long term success rate R201,68545,200(α) of GP and GS-Express and R201,68545,100(α) of Geth. The average cost with α = 50, 75, 84, 95 of each method is reported at the right hand side of the table. The corresponding inverse probability weights IPW201,68545,200(α) are also reported.",
            "Table 2: The minimum success rate Rs,m,200(α) of GP and GS-Express and Rs,m,100(α) of Geth with α = 50, 75, 84, 95 of each method. We consider m = 25, 50, 100 to represent that the transaction is fast, average, and slow to be included in a block.",
            "Table 3: The minimum short term success rate Rs,m,200, long term success rate R201,68545,200, and the average cost using GP predicted P72.24.",
            "Table 4: The long term success rate R201,13627,200(α) of GP prediction, R201,13427,30(α) and R201,13427,50(α) using GS-Express. And the average cost with α = 50, 75, 84, 95 of each method. The corresponding inverse probability weights IPW201,68545,200(α) are also reported.",
            "Table 5: The minimum success rate Rs,m(α) with α = 50, 75, 84, 95 of each method. We consider m = 25, 50, 100 to represent that the transaction is fast, average, and slow to be included in block.",
            "Table 6: The minimum short term success rate Rs,m,200, long term success rate R, and the average cost using GP predicted P69.67.",
            "Table 7: The long term success rate, the average cost, and the inverse probability weights with α = 50, 75, 84, 95 of our method, GS-Express, and Geth using data from block 11753792 to 11823790 (top two tables). The bottom two tables report the long term success rate, the average cost, and the inverse probability weights using data from block 11903793 to 11917694.",
            "Table 8: The short term success rate of each method with m = 25, 50, 100 from the data of blocks 11753792 to 11823790 and 11903793 to 11917694."
        ],
        "imgs": [
            "$2305.00337v1-Figure1-1.png",
            "$2305.00337v1-Table1-1.png",
            "$2305.00337v1-Table2-1.png",
            "$2305.00337v1-Table3-1.png",
            "$2305.00337v1-Table4-1.png",
            "$2305.00337v1-Table5-1.png",
            "$2305.00337v1-Table6-1.png",
            "$2305.00337v1-Table7-1.png",
            "$2305.00337v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00339",
        "abstract": "  Autonomous systems, such as self-driving vehicles, quadrupeds, and robot\nmanipulators, are largely enabled by the rapid development of artificial\nintelligence. However, such systems involve several trustworthy challenges such\nas safety, robustness, and generalization, due to their deployment in\nopen-ended and real-time environments. To evaluate and improve trustworthiness,\nsimulations or so-called digital twins are largely utilized for system\ndevelopment with low cost and high efficiency. One important thing in virtual\nsimulations is scenarios that consist of static and dynamic objects, specific\ntasks, and evaluation metrics. However, designing diverse, realistic, and\neffective scenarios is still a challenging problem. One straightforward way is\ncreating scenarios through human design, which is time-consuming and limited by\nthe experience of experts. Another method commonly used in self-driving areas\nis log replay. This method collects scenario data in the real world and then\nreplays it in simulations or adds random perturbations. Although the replay\nscenarios are realistic, most of the collected scenarios are redundant since\nthey are all ordinary scenarios that only consider a small portion of critical\ncases. The desired scenarios should cover all cases in the real world,\nespecially rare but critical events with extremely low probability. Critical\nscenarios are rare but important to test autonomous systems under risky\nconditions and unpredictable perturbations, which reveal their trustworthiness.\n",
        "title": "Critical Scenario Generation for Developing Trustworthy Autonomy",
        "texts": [
            "Fig. 1. Examples of critical scenarios in autonomy.",
            "Fig. 2. Left: Critical scenarios have a low probability to happen but are important for improving trustworthiness Middle: My contributed approaches can be divided into three categories. Right: Analysis of three types of methods from five perspectives."
        ],
        "imgs": [
            "$2305.00339v1-Figure1-1.png",
            "$2305.00339v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00341",
        "abstract": "  TDS-CONTROL is an integrated MATLAB package for the analysis and\ncontroller-design of linear time-invariant (LTI) dynamical systems with\n(multiple) discrete delays, supporting both systems of retarded and neutral\ntype. TDS-CONTROL is based on a state-space representations for these TDSs,\nalthough functionality is provided to obtain such a formulation from a\nfrequency-domain description of the system. Firstly, the package offers various\nfunctionality for analyzing such systems, like methods for computing the\nspectral abscissa, the H-infinity norm, the pseudospectral abscissa, and the\ndistance to instability. Furthermore, as TDS-CONTROL is designed with neutral\ntime-delay systems in mind, it has the appealing feature that the sensitivity\nof certain quantities (such as the spectral abscissa) with respect to\ninfinitesimal delay perturbations can explicitly be taken into account.\nSecondly, TDS-CONTROL also allows to design fixed-order dynamic output feedback\ncontrollers. The corresponding controller-design algorithms are based on\nminimizing the spectral abscissa, the H-infinity norm, or a combination of both\nwith respect to the free controller parameters by solving a non-smooth,\nnon-convex optimization problem. As a strictly negative spectral abscissa is a\nnecessary and sufficient condition for stability, the presented design methods\nare thus not conservative. It is also possible to impose structure on the\ncontroller, enabling the design of decentralized and\nproportional-integral-derivative (PID) controllers. Furthermore, by allowing\nthe plant to be described in delay descriptor form (i.e., the system's dynamics\nare given in terms of delay differential algebraic equations), acceleration\nfeedback and Pyragas-type and delay-based controllers can also be considered.\n",
        "title": "Analysis and controller-design of time-delay systems using TDS-CONTROL.\n  A tutorial and manual",
        "texts": [
            "Figure 2.12: Stability boundaries of (2.38) in function of τ and δ.",
            "Figure 3.3: Different approaches for controlling networked systems.",
            "Figure 4.4: Singular value plot of the frequency response of the feedback interconnection of (4.16) and (4.17) for different values of τ1.",
            "Figure 4.5: Situation sketch for Example 4.5: the control output is disturbed by measurement noise.",
            "Figure 4.6: Situation sketch for Example 4.6.",
            "Table 3.1: The quantity γ(0;A (22) cl,1 , . . . , A (22) cl,mcl , ~τcl), the spectral abscissa (c), the strong spectral abscissa of the associated delay difference equation (CD) and the strong spectral abscissa (C) of the closed-loop systems obtained by designing a static output feedback controller using Approaches 1 and 2."
        ],
        "imgs": [
            "$2305.00341v1-Figure2.12-1.png",
            "$2305.00341v1-Figure3.3-1.png",
            "$2305.00341v1-Figure4.4-1.png",
            "$2305.00341v1-Figure4.5-1.png",
            "$2305.00341v1-Figure4.6-1.png",
            "$2305.00341v1-Table3.1-1.png"
        ]
    },
    {
        "id": "2305.00346",
        "abstract": "  Fast and efficient switching of nanomagnets is one of the main challenges in\nthe development of future magnetic memories. We numerically investigate the\nevolution of the static and dynamic spin wave (SW) magnetization in short\n(50-400 nm length and 120 nm diameter) cylindrical ferromagnetic nanowires,\nwhere competing single vortex (SV) and vortex domain wall with a Bloch point\n(BP-DW) magnetization configurations could be formed. For a limited nanowire\nlength range (between 150 and 300 nm) we demonstrate a reversible microwave\nfield induced (forward) and opposite spin currents (backwards) transitions\nbetween the topologically different SV and BP-DW states. By tuning the nanowire\nlength, excitation frequency, the microwave pulse duration and the spin current\nvalues we show that the optimum (low power) manipulation of the BP-DW could be\nreached by a microwave excitation tuned to the main SW mode and for nanowire\nlengths around 230-250 nm, where single vortex domain wall magnetization\nreversal via nucleation and propagation of SV-DW takes place. An analytical\nmodel for dynamics of the Bloch point provides an estimation of the gyrotropic\nmode frequency close the one obtained via micromagnetic simulations. A\npractical implementation of the method on a device has been proposed involving\nmicrowave excitation and the generation of the opposite spin currents via spin\norbit torque. Our findings open a new pathway for the creation of unforeseen\ntopological magnetic memories.\n",
        "title": "Dynamics and reversible control of the vortex Bloch-point vortex domain\n  wall in short cylindrical magnetic nanowires",
        "texts": [
            "FIG. 1. Sketch of the cylindrical nanowire and its orientation with respect to the cartesian coordinate axes (a), showing the direction of the applied microwave magnetic field sinc pulse to excite the spin eigenmodes of the system. Vertical cut (xz-plane) of the 250 nm long nanowire showing a SV (b) and BP-DW magnetization configuration (c) with a vortex-like BP-DW in the middle. Arrows illustrate the in-plane magnetization and the colors are an indication of the out-of-plane magnetization. Transverse cut (xy-plane) of the nanowire in the BP-DW state are shown for the planes z = 3LNW /4 (d) and z = LNW /4, (e) (see dashed lines in (c)). Both vortex domains display opposite vortex polarities. (f) Three dimensional magnetization configuration surrounding the BP-DW centered in the middle a 250 nm long nanowire. Colors represent the magnitude of the axial-aligned magnetization.",
            "FIG. 10. Hysteresis loops for a 250 nm long NW in the case of each of the two presented reversal modes. Insets show the cross-section of the NW for two different types of detected magnetization reversal modes at H=0: spiral rotation of two V-DWs (2 V-DW) and propagation of one V-DW (1 V-DW).",
            "FIG. 11. (a) Energy gap between the BP-DW and the SV state for the different pinning introduced in the NW. Average spin wave modes spectra of the different pinned systems are depicted in (b, c, d, e).",
            "FIG. 2. (a) Total energy density of both studied magnetic configurations (SV and BP-DW) for NWs length comprehended between 70 and 800 nm and the gap (∆E = E(BPDW) - E(SV)) between them in blue. (b) Energy density of the SV and BP-DW states for NWs length comprehended between 70 and 800 nm normalized by the parallel saturated state. (c) Sketch of the two level (BP-DW and SV) system and transitions that exist in the NWs of the studied length range (100-400 nm).",
            "FIG. 3. Evolution of the main SW mode frequencies changing the nanowire length from 50 nm to 400 nm obtained after relaxing the BP-DW configuration. The frequency spectra for the NW lengths below 70 nm correspond to the SV state since the BP-DW state is not stable at such small NW aspect ratios. The FFT power is normalized at each nanowire length. Snapshots of the eigenmode spatial distribution are shown for the main azimuthal modes in the SV state (the NW length is 60 nm) and the main mode at the length 250 nm at the nanowire top/bottom surface, as well as a longitudinal cross-section of the mode spatial distribution, focusing on the Bloch point vicinity (area delimited by the dashed line).",
            "FIG. 4. Spin wave mode spectra of a 250 nm length NW in the BP-DW magnetization configuration originated from each of the four different methods explained in the text. Inset of (a) shows the normalized amplitude of the 11.9 GHz mode over the length of the NW.",
            "FIG. 5. Cross-section sequence of the mz magnetization component of the 250 nm long NW, showing the used method of spin polarized currents to reconstruct the BP-DW state. In (a) a current of 9 ×1012 A/m2 is applied on each half of the NW, with opposite directions, to the initial SV state configuration. After 4 ns the steady BP state is reached (b). Switching off the currents and letting the system relax returns it into the DW state (c). (d) Average axial-aligned magnetization component evolution in a 250 nm length NW with the spin polarized current density of 9 ×1012 A/m2. The three dynamic regimes are presented in the transition. Inset images represent a snapshot of the longitudinal cross-section of the axial Mz component in the NW in each one of the regimes.",
            "FIG. 6. (a) Critical spin current density (Jc) needed to create a steady BP state and time of destruction of the BP-DW with the main mode at 0.1 mT plotted as a function of the NW length. Inset of panel (a) depicts the probability to detect a 1 V-DW propagation reversal mode against the NW length.(b) Time required for the MW excitation to start to displace the DW, in logarithmic scale, plotted against the excitation field amplitude, for different lengths of the NW. For the NW length of 250 nm, the main mode (MM) and gyrotropic mode (GM) have been studied. Inset corresponds to a zoom into the main mode excitations for the NW length ranging from 150 to 250 nm. The point at 300 nm in the time of destruction in (a) is a lower end estimation following its trend on (b).",
            "FIG. 7. Time of destruction of the BP-DW state with an MW excitation field with the amplitude of 1 mT and the frequency of GM and corresponding amplitude of the GM for different stopping times after the application of a 9 × 1012 A/m2 spin current density in a 250 nm nanowire plotted against the average out-of-plane magnetization component. The point at almost 40 ns is a lower estimation of the destruction time.",
            "FIG. 8. Schematic of the suggested device to implement the described transition mechanism. (a) Electric current is simultaneously applied through two Pt electrodes contacting the opposite NW ends in the SV state, triggering two opposite spin polarized currents through NW by SOT, effectively switching the NW to the BP-DW state. (b) MW excitation is applied perpendicularly to the NW in the BP-DW state to trigger the transition into the SV state.",
            "FIG. 9. Cross-section sequence of the mz magnetization component of the 250 nm long NW, showing the used method of opposite magnetic fields to reconstruct the BP-DW state. (a) Displays the initial SV state before the opposite magnetic fields applied. After two 0.6 T opposite fields, the mz magnetization component is almost completely saturated on each half of the NW (b). After relaxing the NW the BP-DW is reached (c).",
            "TABLE I. Second derivative of the BP energy (in units of J/nm2) with respect to the BP’s displacements under applied field in transverse and axial directions in the nanowire. The simulated nanowire has 120 nm of diameter and 250 nm of length. Used magnetic parameters are: µ0Ms (saturation magnetization) = 2 T, Aex (exchange stiffness constant) = 25 pJ/m and α (damping) = 0.01. Pinning is made by increasing two times the saturation magnetization in the middle of the NW where BP is located."
        ],
        "imgs": [
            "$2305.00346v1-Figure1-1.png",
            "$2305.00346v1-Figure10-1.png",
            "$2305.00346v1-Figure11-1.png",
            "$2305.00346v1-Figure2-1.png",
            "$2305.00346v1-Figure3-1.png",
            "$2305.00346v1-Figure4-1.png",
            "$2305.00346v1-Figure5-1.png",
            "$2305.00346v1-Figure6-1.png",
            "$2305.00346v1-Figure7-1.png",
            "$2305.00346v1-Figure8-1.png",
            "$2305.00346v1-Figure9-1.png",
            "$2305.00346v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00347",
        "abstract": "  This short note establishes positionality of mean-payoff games over infinite\ngame graphs by constructing a well-founded monotone universal graph.\n",
        "title": "Positionality of mean-payoff games on infinite graphs",
        "texts": [
            "Figure 2 Constraining all paths below some affine line with negative slope, as in the statement of Claim 3."
        ],
        "imgs": [
            "$2305.00347v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00348",
        "abstract": "  Effectively localizing an agent in a realistic, noisy setting is crucial for\nmany embodied vision tasks. Visual Odometry (VO) is a practical substitute for\nunreliable GPS and compass sensors, especially in indoor environments. While\nSLAM-based methods show a solid performance without large data requirements,\nthey are less flexible and robust w.r.t. to noise and changes in the sensor\nsuite compared to learning-based approaches. Recent deep VO models, however,\nlimit themselves to a fixed set of input modalities, e.g., RGB and depth, while\ntraining on millions of samples. When sensors fail, sensor suites change, or\nmodalities are intentionally looped out due to available resources, e.g., power\nconsumption, the models fail catastrophically. Furthermore, training these\nmodels from scratch is even more expensive without simulator access or suitable\nexisting models that can be fine-tuned. While such scenarios get mostly ignored\nin simulation, they commonly hinder a model's reusability in real-world\napplications. We propose a Transformer-based modality-invariant VO approach\nthat can deal with diverse or changing sensor suites of navigation agents. Our\nmodel outperforms previous methods while training on only a fraction of the\ndata. We hope this method opens the door to a broader range of real-world\napplications that can benefit from flexible and learned VO models.\n",
        "title": "Modality-invariant Visual Odometry for Embodied Vision",
        "texts": [
            "Figure 1. An agent is tasked to navigate to a goal location using RGB-D sensors. Because GPS+Compass are not available, the location is inferred from visual observations only. Nevertheless, sensors can malfunction, or availability can change during test-time (indicated by ∼), resulting in catastrophic failure of the localization. We train our model to react to such scenarios by randomly dropping input modalities. Furthermore, our method can be extended to learn from multiple arbitrary input modalities, e.g., surface normals, point clouds, or internal measurements.",
            "Figure 2. The Visual Odometry Transformer architecture for RGB-D input. Image patches are turned into tokens through modality-specific",
            "Figure 3. Top-down map of the agent navigating the Cantwell scene [58] from start ( ) to goal ( ). The plot shows the shortest path ( ), the path taken by the agent ( ), and the ”imaginary” path the agent took, i.e., its VO estimate ( ). We evaluate the model without RGB or Depth (Drop) to determine performance when modalities are missing. As expected, the VOT relies heavily on both modalities, causing the estimation to drift when either RGB or Depth is unavailable (top row). The localization error accumulates over the course of the trajectory and causes the true and imaginary path to diverge, resulting in failure to complete the episodes. Training a VOT to be modality-invariant (VOT w/ inv.) removes those reliances and leads to success even when modalities are missing (bottom row).",
            "Figure 4. Absolute difference between ground truth translations ξx, ξz and rotation angle β to their estimated counterparts ·̂. We compare Zhao et al. [64] (Table 2, 2) to the VOT (Table 2, 13). Our model estimates fwd translation along the z-axis (middle), left, right along z-, x-axis (left, middle), and the turning angle β (right) more accurately than the baseline. We successfully capture the displacements caused by the noisy actuation with an average error (over both axis x, z) of 0.25 cm (fwd), 0.7 cm (right), and 0.65 cm (left).",
            "Figure 5. Attention maps of the last attention layer of VOT (cf . Table 2 13). Brighter color indicates higher ( ) and darker color lower ( ) weighting of the image patch. The VOT learns to focus on regions present in both time steps t, t+ 1, i.e., outer image regions for turning left, and center regions for moving fwd. Artifacts of the Gibson dataset get ignored (cf . Figure 5b).",
            "Table 1. Results for dropping modalities during test-time. Training a VOT to be modality-invariant (w/ inv.) leads to no performance drop in comparison to a VOT trained on a single modality (VOT RGB, VOT Depth). This shows that a single VOT w/ inv. can replace multiple modality-dependent counterparts. Previous approaches [12,35,64] become inapplicable, converging to a Blind behavior. Metrics reported as e−2. Bold indicates best results.",
            "Table 2. Ablation study of architecture design and input modalities. We further investigate pre-training with MultiMAE [4] in models 11-14. Losses L, Success S, SPL, SSPL, and dg reported as e−2. Bold indicates best results.",
            "Table 3. Habitat Challenge 2021. Results for the Point Nav TestStandard Phase (test-std split) retrieved on 05-Nov-2022."
        ],
        "imgs": [
            "$2305.00348v1-Figure1-1.png",
            "$2305.00348v1-Figure2-1.png",
            "$2305.00348v1-Figure3-1.png",
            "$2305.00348v1-Figure4-1.png",
            "$2305.00348v1-Figure5-1.png",
            "$2305.00348v1-Table1-1.png",
            "$2305.00348v1-Table2-1.png",
            "$2305.00348v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00351",
        "abstract": "  Optimization techniques play a crucial role in estimating parameters and\nstate information for nonlinear systems. However, some critical aspects of\nthese problems have received little attention in previous research. In this\npaper, we address this gap by exploring optimization techniques for parameter\nestimation in nonlinear system modeling, with a focus on chaotic dynamical\nsystems. We introduce three optimization methods - a gradient-based iterative\nalgorithm, the Levenberg-Marquardt algorithm, and the Nelder-Mead simplex\nmethod - that transfer the complex nonlinear optimization problem into a\nsimpler linear or nonlinear one. We apply these methods to determine the\nparameters of nonlinear systems, presenting a numerical example to demonstrate\ntheir effectiveness. Our results show that the Nelder-Mead simplex method is\nparticularly effective in estimating the parameters of nonlinear systems and\nhas the potential to be a valuable tool in various fields that require\nnonlinear system modeling. Overall, our study contributes to the understanding\nand improvement of optimization techniques for parameter estimation in\nnonlinear system modeling, which has implications for a wide range of\napplications in science and engineering.\n",
        "title": "Exploring Optimization Techniques for Parameter Estimation in Nonlinear\n  System Modeling",
        "texts": [
            "Fig. 1 The exact trajectories of the Lotka Volterra systems is compared to the corresponding trajectories of the learned dynamics. Solid blue lines represent the exact dynamics while the red solid lines demonstrate the learned dynamics",
            "Fig. 3 The exact trajectories of the Van der Pol oscillator is compared to the corresponding trajectories of the learned dynamics. Solid blue lines represent the exact dynamics while the red solid lines demonstrate the learned dynamics",
            "Fig. 4 The exact phase portrait of the Van der Pol Oscillator, where dotted points are compared to the corresponding phase portrait of the learned dynamics with all the methods",
            "Fig. 5 The exact trajectories of the Rossler systems is compared to the corresponding trajectories of the learned dynamics. Solid blue lines represent the exact dynamics while the red solid lines demonstrate the learned dynamics",
            "Fig. 6 The exact phase portrait of the Rossler system dotted points is compared to the corresponding phase portrait of the learned dynamics with all the methods",
            "Fig. 7 In this figure, we present the trajectories of the Rossler system for t = 0 to t = 120. The true dynamics are depicted in red, while the identified systems obtained from estimated parameters are displayed in blue. The performance of the identified systems is evaluated under different levels of additive noise.",
            "Table 1 Parameter Identification for Lotka and Volterra",
            "Table 2 RMSE for Lotka and Volterra with different Algorithms",
            "Table 3 Parameter Identification for Van der Pol oscillator",
            "Table 4 RMSE for Van der Pol Oscillator with different Algorithms",
            "Table 5 Parameter Identification for Rössler system",
            "Table 6 RMSE for Rossler systems with different Algorithms"
        ],
        "imgs": [
            "$2305.00351v1-Figure1-1.png",
            "$2305.00351v1-Figure3-1.png",
            "$2305.00351v1-Figure4-1.png",
            "$2305.00351v1-Figure5-1.png",
            "$2305.00351v1-Figure6-1.png",
            "$2305.00351v1-Figure7-1.png",
            "$2305.00351v1-Table1-1.png",
            "$2305.00351v1-Table2-1.png",
            "$2305.00351v1-Table3-1.png",
            "$2305.00351v1-Table4-1.png",
            "$2305.00351v1-Table5-1.png",
            "$2305.00351v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00352",
        "abstract": "  In forensic facial comparison, questioned-source images are usually captured\nin uncontrolled environments, with non-uniform lighting, and from\nnon-cooperative subjects. The poor quality of such material usually compromises\ntheir value as evidence in legal matters. On the other hand, in forensic\ncasework, multiple images of the person of interest are usually available. In\nthis paper, we propose to aggregate deep neural network embeddings from various\nimages of the same person to improve performance in facial verification. We\nobserve significant performance improvements, especially for very low-quality\nimages. Further improvements are obtained by aggregating embeddings of more\nimages and by applying quality-weighted aggregation. We demonstrate the\nbenefits of this approach in forensic evaluation settings with the development\nand validation of score-based likelihood ratio systems and report improvements\nin Cllr of up to 95% (from 0.249 to 0.012) for CCTV images and of up to 96%\n(from 0.083 to 0.003) for social media images.\n",
        "title": "Embedding Aggregation for Forensic Facial Comparison",
        "texts": [
            "Figure 1: Comparison of the proposed framework with traditional forensic facial analysis systems.",
            "Figure 2: Examples of references selected for the Adience and BFW datasets. For each identity, the face at the top left (in green) is selected as a reference, and the others are used as traces.",
            "Figure 3: Bi-modal behavior of genuine scores distributions for the Adience (a) and BFW (b) datasets, suggestive of identity labeling errors. After cleaning, the genuine distributions no longer exhibit this bi-modal behavior (c, d).",
            "Figure 4: Examples of identity labeling errors (red boxes) in the Adience and BFW datasets.",
            "Figure 5: Distributions of Confusion Scores for the references and probes from the BFW and Adience datasets, before and after cleaning.",
            "Figure 7: Tippett plots for the datasets of the surveillance scenario. The box on each plot shows details around log10 LR = 0. Tippett plots for some strategies are omitted for clarity in the figure. Individual plots for every strategy are provided in the supplementary material file.",
            "Figure 8: Tippett plots for the datasets of the social media scenario. Tippett plots for some strategies are omitted for clarity in the figure. Individual plots for every strategy are provided in the supplementary material file."
        ],
        "imgs": [
            "$2305.00352v1-Figure1-1.png",
            "$2305.00352v1-Figure2-1.png",
            "$2305.00352v1-Figure3-1.png",
            "$2305.00352v1-Figure4-1.png",
            "$2305.00352v1-Figure5-1.png",
            "$2305.00352v1-Figure7-1.png",
            "$2305.00352v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00355",
        "abstract": "  With the increasing demand for video understanding, video moment and\nhighlight detection (MHD) has emerged as a critical research topic. MHD aims to\nlocalize all moments and predict clip-wise saliency scores simultaneously.\nDespite progress made by existing DETR-based methods, we observe that these\nmethods coarsely fuse features from different modalities, which weakens the\ntemporal intra-modal context and results in insufficient cross-modal\ninteraction. To address this issue, we propose MH-DETR (Moment and Highlight\nDetection Transformer) tailored for MHD. Specifically, we introduce a simple\nyet efficient pooling operator within the uni-modal encoder to capture global\nintra-modal context. Moreover, to obtain temporally aligned cross-modal\nfeatures, we design a plug-and-play cross-modal interaction module between the\nencoder and decoder, seamlessly integrating visual and textual features.\nComprehensive experiments on QVHighlights, Charades-STA, Activity-Net, and\nTVSum datasets show that MH-DETR outperforms existing state-of-the-art methods,\ndemonstrating its effectiveness and superiority. Our code is available at\nhttps://github.com/YoucanBaby/MH-DETR.\n",
        "title": "MH-DETR: Video Moment and Highlight Detection with Cross-modal\n  Transformer",
        "texts": [
            "Figure 1: An illustrative example of theMHD (videomoment and highlight detection) task. Given a video and a natural language query, MHD aims to localize all the moments and predict clip-wise saliency scores simultaneously.",
            "Figure 2: Overall architecture of our model. Given a video and a textual query, we first utilize frozen pretrained models to extract visual and textual features. The encoder (Section 3.2) models contextualized features under global receptive field. Then, the cross-modal decoder module (Section 3.3) fuses features from different modalities. Finally, the prediction heads (Section 3.4) generatemoment andhighlight results, optimized by the losses shown in the abovefigure. Amore comprehensive overview of our model is provided in Section 3.1.",
            "Figure 3: The architecture of the cross-modal interaction module.",
            "Table 1: Performance comparison on QVHighlights test split. Results from othermodels are reported based on existing papers. All models only use visual and textual features and are trained from scratch. The best scores are in bold.",
            "Table 2: Experimental results on QVHighlights val split.",
            "Table 3: Comparison with representative moment retrieval models on Charades-STA test split. Allmodels use either the official VGG features or the I3D features.",
            "Table 4: Experimental results on ActivityNet Captions test split.",
            "Table 6: Effectiveness of each module in our proposed MH-DETR on QVHighlights val split, where \"enc.\", \"crs-int.\", and \"momdec.\" denote the encoder in Section 3.2, the cross-modal interaction module, and the moment decoder in Section 3.3, respectively. MR and HD represent moment retrieval and highlight detection respectively. VG is the abbreviation for very good.",
            "Table 7: Ablation study of losses on QVHighlights val split.",
            "Table 8: Comparison with Moment-DETR using the same parameters on QVHighlights val split."
        ],
        "imgs": [
            "$2305.00355v1-Figure1-1.png",
            "$2305.00355v1-Figure2-1.png",
            "$2305.00355v1-Figure3-1.png",
            "$2305.00355v1-Table1-1.png",
            "$2305.00355v1-Table2-1.png",
            "$2305.00355v1-Table3-1.png",
            "$2305.00355v1-Table4-1.png",
            "$2305.00355v1-Table6-1.png",
            "$2305.00355v1-Table7-1.png",
            "$2305.00355v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00357",
        "abstract": "  For prime $p$ and small $n$, Jones and Roberts have developed a database\nrecording invariants for $p$-adic extensions of degree $n$. We contributed to\nthis database by computing the Galois slope content, Galois mean slope, and\ninertia subgroup for a variety of wildly ramified extensions of composite\ndegree using the idea of Galois splitting models. We will describe a number of\nstrategies to find Galois splitting models including an original technique\nusing generic polynomials and Panayi's root finding algorithm.\n",
        "title": "Finding Galois splitting models to compute local invariants",
        "texts": [
            "Table 1. Table showing the Galois splitting model and defining polynomial for each C3 ≀ C4 extension."
        ],
        "imgs": [
            "$2305.00357v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00359",
        "abstract": "  The field of speech processing has undergone a transformative shift with the\nadvent of deep learning. The use of multiple processing layers has enabled the\ncreation of models capable of extracting intricate features from speech data.\nThis development has paved the way for unparalleled advancements in speech\nrecognition, text-to-speech synthesis, automatic speech recognition, and\nemotion recognition, propelling the performance of these tasks to unprecedented\nheights. The power of deep learning techniques has opened up new avenues for\nresearch and innovation in the field of speech processing, with far-reaching\nimplications for a range of industries and applications. This review paper\nprovides a comprehensive overview of the key deep learning models and their\napplications in speech-processing tasks. We begin by tracing the evolution of\nspeech processing research, from early approaches, such as MFCC and HMM, to\nmore recent advances in deep learning architectures, such as CNNs, RNNs,\ntransformers, conformers, and diffusion models. We categorize the approaches\nand compare their strengths and weaknesses for solving speech-processing tasks.\nFurthermore, we extensively cover various speech-processing tasks, datasets,\nand benchmarks used in the literature and describe how different deep-learning\nnetworks have been utilized to tackle these tasks. Additionally, we discuss the\nchallenges and future directions of deep learning in speech processing,\nincluding the need for more parameter-efficient, interpretable models and the\npotential of deep learning for multimodal speech processing. By examining the\nfield's evolution, comparing and contrasting different approaches, and\nhighlighting future directions and challenges, we hope to inspire further\nresearch in this exciting and rapidly advancing field.\n",
        "title": "A Review of Deep Learning Techniques for Speech Processing",
        "texts": [
            "Fig. 10. Overview of difference between probabilistic latent variable models and self-supervised learning. In latent variable models learn the functions 𝑓 (.) and 𝑔(.) learn the parameters of distribution 𝑝 and 𝑞. The latent variable 𝑧 is used for representing learning.",
            "Fig. 11. Generative approaches to self-supervised learning.",
            "Fig. 13. Predictive Self-supervised learning: (a) Discrete BERT (b) HuBERT.",
            "Fig. 14. Neural Text-to-speech (TTS) pipeline: a diagram showing the main modules of a typical TTS system. The system takes text input and processes it through various stages to generate speech output. The text analysis module tokenizes the input text and generates linguistic features such as phonemes and prosody. The acoustic model module then converts these linguistic features into acoustic features, such as mel spectrograms, using a neural network. Finally, the waveform generation module synthesizes the speech waveform from the acoustic features using another neural network.",
            "Fig. 15. The architecture of the Generative Spoken Language Model GSLM introduced by Meta in [281]. GSLM model operates through a three-part architecture. Firstly, the encoder takes the speech waveform and transforms it into distinct units represented as S2u. Secondly, the decoder reverses this mapping by converting the units back to the original waveform, represented as u2S. Finally, the language model is unit-based and captures the distribution of unit sequences, which can be viewed as a form of pseudo-text.",
            "Fig. 16. Speaker diarization system diagram showcasing the process of identifying and differentiating multiple speakers in an audio recording using various techniques such as VAD, segmentation, clustering and resegmentation.",
            "Fig. 17. Transformer architecture and Adapter, Prefix Tuning, and LoRA.",
            "Fig. 18. The architecture of 1D convolution layer-based lightweight adapter. 𝑘 is the kernel size of 1D convolution. ∗ denotes depth-wise convolution.",
            "Fig. 2. TCNNs leverage causal and dilated convolutions to model temporal dependencies in sequential data. Causal convolutions ensure that future information is not used during training, while dilated convolutions increase the receptive field without increasing computational complexity. This makes TCNNs an effective and efficient solution for a wide range of tasks, including speech recognition, action recognition, and music analysis.",
            "Fig. 3. Illustrations of attention (left) and multi-headed attention (right).",
            "Fig. 5. Unified formulation for Sequence-to-Sequence architecture in speech applications [244]. 𝑋 and 𝑌 are source and target sequences respectively.",
            "Fig. 6. A standard experimental pipeline for GCNs, which embeds the graph node and embeds the graph node edge features, performs several GNN layers to compute convolutional features, and finally predicts a task-specific MLP layer.",
            "Fig. 7. The Diffusion Probabilistic Model is a generative model that progressively transforms a noise distribution into the target data distribution through a series of diffusion steps, where the noise level decreases as the process continues. The model is trained by maximizing the likelihood of the data distribution and can be used for tasks such as speech synthesis, enhancement, and denoising.",
            "Fig. 8. 𝑑-vector model architecture.",
            "Fig. 9. 𝑥-vector model architecture. 𝑥1,𝑥2,....,𝑥𝑇 are the spectral features such as Mel spectrograms of the speech utterance.",
            "Table 1. The table summarizes various loss functions used in training the speaker recognition models including their formulation [91].",
            "Table 10. Performance of different speech enhancement algorithms on the Deep Noise Suppression (DNS) Challenge dataset. The table showcases improvements in PESQ-WB, PESQ-NB, SI-SDR-WB, and SI-SDR-NB metrics, and identifies the top-performing methods in each category.",
            "Table 11. Table comparing the performance of different speech separation methods using SI-SDRi metrics on various speech separation benchmarks.",
            "Table 12. Comprehensive performance analysis of various models for Keyword Spotting (KS) and Slot Filling (SF) tasks, evaluated on two benchmark datasets: Google Speech Commands for KS and ATIS for SF.",
            "Table 13. The study evaluated various parameter-efficient training methods on pre-trained Word2Vec 2.0, including full fine-tuning, on the SURE benchmark. The fraction of trainable parameters were represented by percentages, with the number of KS task’s trainable parameters given. Results are reported using weighted-f1 as the metric (w-f1) on MELD, with the best performance in bold and the second best underlined. To avoid data imbalance, the researchers opted for using weighted-f1 as the metric. The study cites Li et al. (2023) [315] as a reference.",
            "Table 14. Results on SURE benchmark for full fine-tuning and other parameter-efficient training methods on pre-trained Wav2Vec 2.0 for IC and PR tasks on FS: Fluent Speech [350] and LS: LibriSpeech [410] datasets, respectively.",
            "Table 15. Results on the SURE benchmark for the TTS task. MCD and WER are the metrics used to compare fine-tuning and other parameter-efficient approaches.",
            "Table 2. Summary of generative self-supervised approaches and proposed models for speech processing with associated metrics and training Data. ASR: Automatic Speech Recognition, PR: Phoneme Recognition. PC: Phoneme Classification, SR: Speaker Recognition, LS: LibriSpeech.",
            "Table 3. Summary of contrastive self-supervised approaches and proposed models for speech processing with associated metrics and training Data. ASR: Automatic Speech Recognition, PR: Phoneme Recognition. PC: Phoneme Classification, SR: Speaker Recognition, LS: LibriSpeech, LL: LibriLight, WSJ: Wall Street Journal.",
            "Table 4. Summary of predictive self-supervised approaches and proposed models for speech processing with associated metrics and training Data. ASR: Automatic Speech Recognition, PR: Phoneme Recognition. PC: Phoneme Classification, SR: Speaker Recognition, LL: LibriLight, LS: LibriSpeech.",
            "Table 5. Comparative analysis of speech processing datasets: This table summarizes the essential features of different speech-processing datasets, including their typical applications in various speech-processing tasks. ASR: Automatic Speech Recognition, PR: Phoneme Recognition. PC: Phoneme Classification, SR: Speaker Recognition, SV: Speaker Verification, SER: Speech Emotion Recognition, IC: Intent Classification, TTS: Text-to-Speech, VC: Voice Conversion, ST: Speech Translation, SS: Speech Separation",
            "Table 6. Comprehensive Evaluation Metrics for Speech Processing Tasks. This table provides a comprehensive overview of the evaluation metrics used to assess the performance of speech-based systems across various tasks such as ASR, speaker verification, and TTS. The table highlights the specific metrics employed for each task, along with the score range and commonly used datasets.",
            "Table 7. Table summarizing the performance of different ASR models in terms of WER% on five different datasets (LibriSpeech test, LibriSpeech clean, TIMIT, Common Voice, WSJ eval92, and GigaSpeech) also highlighting the use of extra data during training. ZS stands for Zero-Shot Performance.",
            "Table 8. Comparison of performance between wav2vec2.0 Large and Whisper on different datasets. The zeroshot Whisper model consistently outperforms wav2vec2.0 Large on several datasets, indicating significant performance differences.",
            "Table 9. Exploring the Landscape of TTS and Vocoder Architectures: Autoregressive and Non-Autoregressive Models."
        ],
        "imgs": [
            "$2305.00359v3-Figure10-1.png",
            "$2305.00359v3-Figure11-1.png",
            "$2305.00359v3-Figure13-1.png",
            "$2305.00359v3-Figure14-1.png",
            "$2305.00359v3-Figure15-1.png",
            "$2305.00359v3-Figure16-1.png",
            "$2305.00359v3-Figure17-1.png",
            "$2305.00359v3-Figure18-1.png",
            "$2305.00359v3-Figure2-1.png",
            "$2305.00359v3-Figure3-1.png",
            "$2305.00359v3-Figure5-1.png",
            "$2305.00359v3-Figure6-1.png",
            "$2305.00359v3-Figure7-1.png",
            "$2305.00359v3-Figure8-1.png",
            "$2305.00359v3-Figure9-1.png",
            "$2305.00359v3-Table1-1.png",
            "$2305.00359v3-Table10-1.png",
            "$2305.00359v3-Table11-1.png",
            "$2305.00359v3-Table12-1.png",
            "$2305.00359v3-Table13-1.png",
            "$2305.00359v3-Table14-1.png",
            "$2305.00359v3-Table15-1.png",
            "$2305.00359v3-Table2-1.png",
            "$2305.00359v3-Table3-1.png",
            "$2305.00359v3-Table4-1.png",
            "$2305.00359v3-Table5-1.png",
            "$2305.00359v3-Table6-1.png",
            "$2305.00359v3-Table7-1.png",
            "$2305.00359v3-Table8-1.png",
            "$2305.00359v3-Table9-1.png"
        ]
    },
    {
        "id": "2305.00362",
        "abstract": "  Electricity price prediction plays a vital role in energy storage system\n(ESS) management. Current prediction models focus on reducing prediction errors\nbut overlook their impact on downstream decision-making. So this paper proposes\na decision-focused electricity price prediction approach for ESS arbitrage to\nbridge the gap from the downstream optimization model to the prediction model.\nThe decision-focused approach aims at utilizing the downstream arbitrage model\nfor training prediction models. It measures the difference between actual\ndecisions under the predicted price and oracle decisions under the true price,\ni.e., decision error, by regret, transforms it into the tractable surrogate\nregret, and then derives the gradients to predicted price for training\nprediction models. Based on the prediction and decision errors, this paper\nproposes the hybrid loss and corresponding stochastic gradient descent learning\nmethod to learn prediction models for prediction and decision accuracy. The\ncase study verifies that the proposed approach can efficiently bring more\neconomic benefits and reduce decision errors by flattening the time\ndistribution of prediction errors, compared to prediction models for only\nminimizing prediction errors.\n",
        "title": "Electricity Price Prediction for Energy Storage System Arbitrage: A\n  Decision-focused Approach",
        "texts": [
            "Fig. 1. Day-ahead electricity prediction and ESS arbitrage under predict-thenoptimize framework.",
            "Fig. 10. RMSE in different time intervals of different loss function by ResNet model.",
            "Fig. 2. The decision-focused electricity price prediction approach for ESS arbitrage.",
            "Fig. 3. Geometric illustration of different predicted electricity price with same predicted error but different regrets.",
            "Fig. 5. The structure of ResNet model.",
            "Fig. 6. The errors changing in the training process.",
            "Fig. 7. Predicted price under different methods.",
            "Fig. 8. Benefits of 500 kWh battery under different prediction methods.",
            "Fig. 9. RMSE in different time interval of different loss function by linear model.",
            "TABLE I THE HYPERPARAMETERS OF RESNET PREDICTION AND ESS ARBITRAGE MODELS.",
            "TABLE II COMPARISON OF DIFFERENT PREDICTION MODELS.",
            "TABLE III LOSS FUNCTION COMPARISON OF LINEAR PREDICTION MODEL.",
            "TABLE IV LOSS FUNCTION COMPARISON OF RESNET PREDICTION MODEL."
        ],
        "imgs": [
            "$2305.00362v1-Figure1-1.png",
            "$2305.00362v1-Figure10-1.png",
            "$2305.00362v1-Figure2-1.png",
            "$2305.00362v1-Figure3-1.png",
            "$2305.00362v1-Figure5-1.png",
            "$2305.00362v1-Figure6-1.png",
            "$2305.00362v1-Figure7-1.png",
            "$2305.00362v1-Figure8-1.png",
            "$2305.00362v1-Figure9-1.png",
            "$2305.00362v1-TableI-1.png",
            "$2305.00362v1-TableII-1.png",
            "$2305.00362v1-TableIII-1.png",
            "$2305.00362v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00365",
        "abstract": "  Energy optimization leveraging artificially intelligent algorithms has been\nproven effective. However, when buildings are commissioned, there is no\nhistorical data that could be used to train these algorithms. On-line\nReinforcement Learning (RL) algorithms have shown significant promise, but\ntheir deployment carries a significant risk, because as the RL agent initially\nexplores its action space it could cause significant discomfort to the building\nresidents. In this paper we present ReLBOT - a new technique that uses transfer\nlearning in conjunction with deep RL to transfer knowledge from an existing,\noptimized and instrumented building, to the newly commissioning smart building,\nto reduce the adverse impact of the reinforcement learning agent's warm-up\nperiod. We demonstrate improvements of up to 6.2 times in the duration, and up\nto 132 times in prediction variance, for the reinforcement learning agent's\nwarm-up period.\n",
        "title": "A Transfer Learning Approach to Minimize Reinforcement Learning Risks in\n  Energy Optimization for Smart Buildings",
        "texts": [
            "Figure 3: ReLBOT ANN architecture.",
            "Figure 6: Set point behavior with and without transfer learning during the warm-up period for building combination T-W.",
            "Figure 9: Improvement (times) vs. Similarity plotted for the mean variance reduction.",
            "Table 1: Buildings used as sources of data.",
            "Table 2: Improvements observed with transfer learning."
        ],
        "imgs": [
            "$2305.00365v2-Figure3-1.png",
            "$2305.00365v2-Figure6-1.png",
            "$2305.00365v2-Figure9-1.png",
            "$2305.00365v2-Table1-1.png",
            "$2305.00365v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00366",
        "abstract": "  Entity linking (EL) is the task of linking a textual mention to its\ncorresponding entry in a knowledge base, and is critical for many\nknowledge-intensive NLP applications. When applied to tables in scientific\npapers, EL is a step toward large-scale scientific knowledge bases that could\nenable advanced scientific question answering and analytics. We present the\nfirst dataset for EL in scientific tables. EL for scientific tables is\nespecially challenging because scientific knowledge bases can be very\nincomplete, and disambiguating table mentions typically requires understanding\nthe papers's tet in addition to the table. Our dataset, S2abEL, focuses on EL\nin machine learning results tables and includes hand-labeled cell types,\nattributed sources, and entity links from the PaperswithCode taxonomy for 8,429\ncells from 732 tables. We introduce a neural baseline method designed for EL on\nscientific tables containing many out-of-knowledge-base mentions, and show that\nit significantly outperforms a state-of-the-art generic table EL method. The\nbest baselines fall below human performance, and our analysis highlights\navenues for improvement.\n",
        "title": "S2abEL: A Dataset for Entity Linking from Scientific Tables",
        "texts": [
            "Figure 1: Part of a table in OPT: Open Pre-trained Transformer Language Models (Zhang et al., 2022) showing relevant context needs to be found for entity mentions in the table and part of EL results to PapersWithCode KB.",
            "Figure 2: Evaluation of different candidate entity retrieval methods. The method in the parenthesis indicates whether a fine-tuned SciBert or BM25F is used.",
            "Figure 3: Entity linking results with varying inKB thresholds. Note that the inKB hit rate is low (44.8%) even when all mentions are predicted with an entity (i.e., threshold is 0).",
            "Table 1: Overall statistics of S2abEL. It consists of 52,257 data points for cell types, 9,564 for attributed source matching, and 8,429 for entity linking, with ground truth.",
            "Table 2: Results of cell type classification on our method and AxCell, with image classification papers fixed as the validation set and papers from each remaining category as the test set in turn. Each fold is run five times with different random seeds, and the reported numbers are averaged over 10 folds and 5 runs.",
            "Table 3: Accuracy for end-to-end entity linking for cells that refer to an inKB entity with 10-fold-crossdomain evaluation using our approach and TURL. Our method is specialized for tables in scientific papers and outperforms the more general-purpose TURL method.",
            "Table 4: End-to-end EL results with 10-fold-crossdomain evaluation of our method on learned DR + ASR candidate sets of size 50 with the inKB threshold set to 0.5. Although our model achieved reasonable overall accuracy, it is still far from perfect, leaving ample room for future improvements in the end-to-end table EL task.",
            "Table 5: Detailed statistics of S2abEL.",
            "Table 6: Incorrect examples for end-to-end EL from TURL. The table includes the cell content and the column header in the first two columns, the top-3 ranked results from TURL and our approach in the third and fourth columns, respectively, and the gold entity in the last column.",
            "Table 7: Representative examples of erroneous end-to-end EL cases. The table includes the cause and the percentage for that cause in the first two columns, an example of cell content for that cause and our incorrect prediction in the third and fourth columns, and the gold entity in the last column.",
            "Table 8: Additional end-to-end Entity linking results for outKB cells."
        ],
        "imgs": [
            "$2305.00366v1-Figure1-1.png",
            "$2305.00366v1-Figure2-1.png",
            "$2305.00366v1-Figure3-1.png",
            "$2305.00366v1-Table1-1.png",
            "$2305.00366v1-Table2-1.png",
            "$2305.00366v1-Table3-1.png",
            "$2305.00366v1-Table4-1.png",
            "$2305.00366v1-Table5-1.png",
            "$2305.00366v1-Table6-1.png",
            "$2305.00366v1-Table7-1.png",
            "$2305.00366v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00367",
        "abstract": "  Due to its security, transparency, and flexibility in verifying virtual\nassets, blockchain has been identified as one of the key technologies for\nMetaverse. Unfortunately, blockchain-based Metaverse faces serious challenges\nsuch as massive resource demands, scalability, and security concerns. To\naddress these issues, this paper proposes a novel sharding-based blockchain\nframework, namely MetaShard, for Metaverse applications. Particularly, we first\ndevelop an effective consensus mechanism, namely Proof-of-Engagement, that can\nincentivize MUs' data and computing resource contribution. Moreover, to improve\nthe scalability of MetaShard, we propose an innovative sharding management\nscheme to maximize the network's throughput while protecting the shards from\n51% attacks. Since the optimization problem is NP-complete, we develop a hybrid\napproach that decomposes the problem (using the binary search method) into\nsub-problems that can be solved effectively by the Lagrangian method. As a\nresult, the proposed approach can obtain solutions in polynomial time, thereby\nenabling flexible shard reconfiguration and reducing the risk of corruption\nfrom the adversary. Extensive numerical experiments show that, compared to the\nstate-of-the-art commercial solvers, our proposed approach can achieve up to\n66.6% higher throughput in less than 1/30 running time. Moreover, the proposed\napproach can achieve global optimal solutions in most experiments.\n",
        "title": "MetaShard: A Novel Sharding Blockchain Platform for Metaverse\n  Applications",
        "texts": [
            "Fig. 1: An illustration of the proposed system.",
            "Fig. 2: An illustration of the proposed sharding management and election processes.",
            "Fig. 3: An illustration of Algorithm 1.",
            "Fig. 4: Pr51% achieved by the three methods.",
            "Fig. 7: Pr51% under increasing adversarial probability.",
            "Fig. 9: Impacts of mean and standard deviation.",
            "TABLE 1: Problem instance parameters."
        ],
        "imgs": [
            "$2305.00367v1-Figure1-1.png",
            "$2305.00367v1-Figure2-1.png",
            "$2305.00367v1-Figure3-1.png",
            "$2305.00367v1-Figure4-1.png",
            "$2305.00367v1-Figure7-1.png",
            "$2305.00367v1-Figure9-1.png",
            "$2305.00367v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00369",
        "abstract": "  We developed an efficient active-space particle-particle random phase\napproximation (ppRPA) approach to calculate accurate charge-neutral excitation\nenergies of molecular systems. The active-space ppRPA approach constrains both\nindexes in particle and hole pairs in the ppRPA matrix, which only selects\nfrontier orbitals with dominant contributions to low-lying excitation energies.\nIt employs the truncation in both orbital indexes in the particle-particle and\nthe hole-hole spaces. The resulting matrix, the eigenvalues of which are\nexcitation energies, has a dimension that is independent of the size of the\nsystems. The computational effort for the excitation energy calculation,\ntherefore, scales linearly with system size and is negligible compared with the\nground-state calculation of the (N-2)-electron system, where N is the electron\nnumber of the molecule. With the active space consisting of 30 occupied and 30\nvirtual orbitals, the active-space ppRPA approach predicts excitation energies\nof valence, charge-transfer, Rydberg, double and diradical excitations with the\nmean absolute errors (MAEs) smaller than 0.03 eV compared with the full-space\nppRPA results. As a side product, we also applied the active-space ppRPA\napproach in the renormalized singles (RS) T-matrix approach. Combining the\nnon-interacting pair approximation that approximates the contribution to the\nself-energy outside the active space, the active-space\n$G_{\\text{RS}}T_{\\text{RS}}$@PBE approach predicts accurate absolute and\nrelative core-level binding energies with the MAE around 1.58 eV and 0.3 eV,\nrespectively. The developed linear scaling calculation of excitation energies\nis promising for applications to large and complex systems.\n",
        "title": "Linear Scaling Calculations of Excitation Energies with Active-Space\n  Particle-Particle Random Phase Approximation",
        "texts": [
            "Figure 1: Comparisons of excitation energies obtained from the active-space ppRPA approach in this work and in Ref. 58 with respect to the dimension of the ppRPA matrix. The active spaces include all occupied orbitals and different numbers of virtual orbitals. The dimensions of active spaces are calculated from Eq. 11 and Eq. 13. Left: the 3B2 state of cyclopropene. The full-space dimension is 5050. Right: first singlet state of o-xylene. The full-space dimension is 33930. The aug-cc-pVDZ basis set was used for cyclopropene, the cc-pVDZ basis set was used for o-xylene.",
            "Figure 2: Structures of hydrocarbons. n = 2: the Chichibabin’s hydrocarbon. n = 3: the Müller’s hydrocarbon.",
            "Table 1: Adiabatic singlet-triplet gaps and MAEs of diradicals obtained from the full-space and the active-space ppRPA approaches based on HF, PBE and B3LYP. full stands for the full-space. (20,20)/(30,30) means 20/30 occupied and virtual frontier orbitals are included in the active space. Geometries and reference values were taken from Ref. 59. The aug-cc-pVDZ basis set was used. All values in kcal/mol.",
            "Table 2: CT excitation energies and MAEs in the Stein CT test set obtained from the full-space and the active-space ppRPA approaches based on HF, PBE and B3LYP. full stands for the full-space. (20,20)/(30,30) means 20/30 occupied and virtual frontier orbitals are included in the active space. Geometries were taken from Ref. 73. Experimental values in the gas phase were taken as the reference values.73 The cc-pVDZ basis set was used. All values in eV.",
            "Table 3: Double excitation energies and MAEs of small molecules obtained from the full-space and the active-space ppRPA approaches based on HF, PBE and B3LYP. full stands for the full-space. (20,20)/(30,30) means 20/30 occupied and virtual frontier orbitals are included in the active space. Geometries were optimized at 6-31G*/MP2 level with the GAUSSIAN16 A.03 software.80 Reference values were taken from Ref. 43. The even-tempered basis set defined in Ref. 43 was used for Be and Li, the cc-pVQZ basis set was used for BH, the aug-cc-pVDZ basis set was used for C and cc-pVDZ basis set was used for H in polyenes. All values in eV.",
            "Table 4: Rydberg excitation energies and MAEs of atomic systems obtained from the full-space and the active-space ppRPA approaches based on HF, PBE and B3LYP. full stands for the full-space. (20,20)/(30,30) means 20/30 occupied and virtual frontier orbitals are included in the active space. Reference values were taken from Ref. 74. The aug-cc-pVQZ basis set was used. All values in eV.",
            "Table 5: Valence excitation energies and MAEs of the Thiel test set75,76 and the Tozer test set77 energies obtained from the full-space and the active-space ppRPA approaches based on HF, PBE and B3LYP. full stands for the full-space. (20,20)/(30,30) means 20/30 occupied and virtual frontier orbitals are included in the active space. Geometries and reference values were taken from Ref. 75–77. The aug-cc-pVDZ basis set was used. All values in eV.",
            "Table 6: S-T gaps and the dominant configuration contributions of the Chichibabin’s hydrocarbon and the Müller’s hydrocarbon obtained from the active-space ppRPA approaches based on B3LYP. 30 occupied and 30 virtual frontier orbitals are included in the active space. Geometries were taken from Ref. 81. Reference values were taken from Ref. 82 and Ref. 83. The cc-pVDZ basis set was used.",
            "Table 7: MAEs of absolute CLBEs in the CORE65 set obtained from the fullspace and the active-space and G0T0 and GRSTRS approach based on HF, PBE and B3LYP. Only occupied orbitals are in the active space. The NIP approximation is used to approximate the contribution to the self-energy outside the active space. Full-space results were taken from Ref. 65. Geometries and reference values were taken from the CORE65 set.84 The def2-TZVP basis set was used. All values in eV.",
            "Table 8: MAEs of relative CLBEs in the CORE65 set obtained from the fullspace and the active-space and G0T0 and GRSTRS approach based on HF, PBE and B3LYP. The relative CLBEs are the shifts with respect to a reference molecule, ∆CLBE = CLBE−CLBEref. CH4, NH3, H2O and CF4 have been used as reference molecules for C1s, N1s, O1s and F1s respectively. Only occupied orbitals are included in the active space. The NIP approximation is used to approximate the contribution to the self-energy outside the active space. Full-space results were taken from Ref. 65. Geometries and reference values were taken from the CORE65 set.84 The def2-TZVP basis set was used. All values in eV."
        ],
        "imgs": [
            "$2305.00369v1-Figure1-1.png",
            "$2305.00369v1-Figure2-1.png",
            "$2305.00369v1-Table1-1.png",
            "$2305.00369v1-Table2-1.png",
            "$2305.00369v1-Table3-1.png",
            "$2305.00369v1-Table4-1.png",
            "$2305.00369v1-Table5-1.png",
            "$2305.00369v1-Table6-1.png",
            "$2305.00369v1-Table7-1.png",
            "$2305.00369v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00370",
        "abstract": "  Einstein-Podolsky-Rosen (EPR) steering and Bell nonlocality illustrate two\ndifferent kinds of correlations predicted by quantum mechanics. They not only\nmotivate the exploration of the foundation of quantum mechanics, but also serve\nas important resources for quantum-information processing in the presence of\nuntrusted measurement apparatuses. Herein, we introduce a method for\ncharacterizing the creation of EPR steering and Bell nonlocality for dynamical\nprocesses in experiments. We show that the capability of an experimental\nprocess to create quantum correlations can be quantified and identified simply\nby preparing separable states as test inputs of the process and then performing\nlocal measurements on single qubits of the corresponding outputs. This finding\nenables the construction of objective benchmarks for the two-qubit controlled\noperations used to perform universal quantum computation. We demonstrate this\nutility by examining the experimental capability of creating quantum\ncorrelations with the controlled-phase operations on the IBM Quantum Experience\nand Amazon Braket Rigetti superconducting quantum computers. The results show\nthat our method provides a useful diagnostic tool for evaluating the primitive\noperations of nonclassical correlation creation in noisy intermediate scale\nquantum devices.\n",
        "title": "Quantum correlation generation capability of experimental processes",
        "texts": [
            "FIG. 1. Quantifying the capability of an unknown process for creating quantum correlations. (a) For an unknown process of interest, specific separable input states and their corresponding output states (dark gray) can be used to explore the evolution of a state through the unknown process, χexpt. Specifically, one can experimentally determine the unknown process by QPT. (b) For a process with no steering capability (denoted as χI), all of the separable input states remain unsteerable states [Eq. (6)]. Under this scenario, Alice’s output states are considered untrusted (checker pattern). A process having the capability to generate steering is thus a process that cannot be described by χI . (c) For a process with no ability to generate Bell nonlocality (denoted as χU ), the separable input states remain Bell-local states [Eq. (7)]. Under this scenario, both output states are considered untrusted (checker pattern). A process having the ability to generate Bell nonlocality is thus a process that cannot be described by χU .",
            "FIG. 2. Schematic representations of the quantum circuits used to implement the QPT procedure for the steering generating test (a) and Bell nonlocality generating test (b). (i) The notation Q0 (Q1) indicates logical qubit 0 (1), and U1 is the corresponding unitary transform used to prepare the specific input state. (ii) The CPHASE gate is performed on control qubit Q0 with a CPHASE shift of λ on the target qubit Q1. (iii) UR is a suitable unitary transformation to maximize the difference between the target process and χU , and U2 is chosen for the measurements performed on the Pauli-X basis and Pauli-Y basis..",
            "FIG. 3. Composition results for steering generating test [Fig. 3(a)] and Bell nonlocality generating test [Fig. 3(b)]. The solid blue line shows the steering (Bell nonlocality) generating composition results from the ideal simulation. The other symbols show the results obtained on the IBM Q Experience and AWS Amazon Braket devices (real and simulator).",
            "FIG. 4. Robustness results for steering generating test [Fig. 4(a)] and Bell nonlocality generating test [Fig. 4(b)]. The solid blue line shows the steering (Bell nonlocality) generating robustness results from the ideal simulation. The other symbols show the results obtained on the IBM Q Experience and AWS Amazon Braket devices (real and simulator).",
            "FIG. 5. Fidelity criterion results for steering generating test [Fig. 5(a)] and Bell nonlocality generating test [Fig. 5(b)]. The dashed green line shows the classical upper bound of the fidelity criterion for the steering (Bell nonlocality) generating test. The other symbols show the results obtained on the IBM Q Experience and AWS Amazon Braket devices (real and simulator).",
            "TABLE I. Comparison among parameters of different noise models. First, we used the IBM Q ibmq santiago quantum computer with qubit 3 and qubit 4 in October 2021 and archived its calibration parameters on 8th October 2021. Second, we used the Amazon Braket Rigetti Aspen-9 quantum computer with qubit 10 and qubit 17 in July 2021 and archived its calibration parameters on 30th October and 18th November 2021. Finally, we used the Amazon Braket Rigetti Aspen-M-1 quantum computer with qubit 15 and qubit 16 on 23rd and 30th of March 2022, respectively, and archived the calibration parameters on the same dates."
        ],
        "imgs": [
            "$2305.00370v1-Figure1-1.png",
            "$2305.00370v1-Figure2-1.png",
            "$2305.00370v1-Figure3-1.png",
            "$2305.00370v1-Figure4-1.png",
            "$2305.00370v1-Figure5-1.png",
            "$2305.00370v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00371",
        "abstract": "  Accurate nuclear reaction rates for 26P(p,{\\gamma})27S are pivotal for a\ncomprehensive understanding of rp-process nucleosynthesis path in the region of\nproton-rich sulfur and phosphorus isotopes. However, large uncertainties still\nexist in the current rate of 26P(p,{\\gamma})27S because of the lack of the\nnuclear mass and the energy level structure information of 27S. We reevaluate\nthis reaction rate using the experimentally constrained 27S mass, together with\nthe shell-model predicted level structure. It is found that the\n26P(p,{\\gamma})27S reaction rate is dominated by a direct-capture (DC) reaction\nmechanism despite the presence of three resonances at E = 1.104, 1.597, 1.777\nMeV above the proton threshold in 27S. The new rate is overall smaller than the\nother previous rates from Hauser-Feshbach statistical model by at least one\norder of magnitude in the temperature range of X-ray burst interest. In\naddition, we consistently update the photodisintegration rate using the new 27S\nmass. The influence of new rates of forward and reverse reaction in the\nabundances of isotopes produced in rp-process is explored by post-processing\nnucleosynthesis calculations. The final abundance ratio of 27S/26P obtained\nusing the new rates is only 10% of that from the old rate. The abundance flow\ncalculations show the reaction path 26P(p,{\\gamma})27S(\\b{eta}+,{\\nu})27P is\nnot as important as thought previously for producing 27P. The adoption of the\nnew reaction rates for 26P(p,{\\gamma})27S only reduces the final production of\naluminum by 7.1%, and has no discernible impact on the yield of other elements.\n",
        "title": "New 26P(p,{\\gamma})27S thermonuclear reaction rate and its astrophysical\n  implication in rp-process",
        "texts": [
            "Figure 1. (Color online) Comparison of the experimental and theoretical excitation energies for the mirror nuclei 27S and 27Na, SM is the result of Shell-model, Exp is the result from the experiment.",
            "Figure 2. (Color online) Simplified level scheme of 27S. The drawing is not to scale. The mass excesses and single proton separation energy(Sp) are from AME2020 (Wang et al. 2021) and Sun et al. (2019), whereas the energies are from the shell-model calculation.",
            "Figure 3. (Color online) The contributions of various individual resonances to the 26P(p,γ)27S reaction rate as functions of temperature. In the legend, resonances are labeled with their spin and parity in 27S. The upper panel shows contributions from ground-state capture; the lower panel shows contributions from capture on the first excited state in 26P.",
            "Figure 4. (Color online) Direct capture (DC) and the resonant capture (the sum of the three considered resonances, see the text) contributions for the thermonuclear 26P(p,γ)27S reaction rate (in units of cm3 mol−1 s−1), and the blue (red) shaded band represents the uncertainties of resonant (direct capture) reaction rates.",
            "Figure 5. (Color online) Ratios of the 26P(p,γ)27S rate from different sources (rath (Rauscher & Thielemann 2000), rpsm (Rauscher 1999), ths8 (Cyburt et al. 2010)) to the present rate. (a) Ratios for the forward reaction rate; (b) Ratios for the reverse reaction rate.",
            "Figure 6. (Color online) The abundance ratio of 27S/26P compared using the newly determined rate in this work and for the ths8 rate, plotted as a function of time.",
            "Figure 7. (Color online) The distribution of isotope abundances at cycle 760, which corresponds to the termination time of the rp-process. (a) is for the case using the new forward and reverse rates of 26P(p,γ)27S, while (b) is for the case adopting ths8 rates.",
            "Figure 8. (Color online) The final elemental abundance after full decay of all the unstable isotopes. The solid red square is for the case using the new rates for 26P(p,γ)27S, while the blue triangle is for that adopting the ths8 rates.",
            "Table 1. Parameters for the present 26P(p,γ)27S resonant rate calculation. Listed are excitation energy Ex, center-of-mass resonance energy Er, spin and parity Jπ, spectroscopic factors C2S, γ-decay width Γγ , proton-decay width Γp, and the resonance strength ωγ. The upper part is for ground-state capture; the lower part is for capture on the first excited state in 26P.",
            "Table 2. Direct, resonant, and total reaction rates for 26P(p,γ)27S based on the present work (in units of cm3 mol−1 s−1)."
        ],
        "imgs": [
            "$2305.00371v1-Figure1-1.png",
            "$2305.00371v1-Figure2-1.png",
            "$2305.00371v1-Figure3-1.png",
            "$2305.00371v1-Figure4-1.png",
            "$2305.00371v1-Figure5-1.png",
            "$2305.00371v1-Figure6-1.png",
            "$2305.00371v1-Figure7-1.png",
            "$2305.00371v1-Figure8-1.png",
            "$2305.00371v1-Table1-1.png",
            "$2305.00371v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00376",
        "abstract": "  The three-dimensional electronic structure and the nature of Ce 4f electrons\nof the Kondo insulator CeRu4Sn6 are investigated by angle-resolved\nphotoemission spectroscopy, utilizing tunable photon energies. Our results\nreveal (i) the three-dimensional k-space nature of the Fermi surface, (ii) the\nlocalized-to-itinerant transition of f electrons occurs at a much high\ntemperature than the hybridization gap opening temperature, and (iii) the\n\"relocalization\" of itinerant f electrons below 25 K, which could be the\nprecursor to the establishment of magnetic order.\n",
        "title": "Itinerant to relocalized transition of f electrons in the Kondo\n  insulator CeRu4Sn6",
        "texts": [
            "FIG. 1 . Fermi surface mappings of CeRu4Sn6 at 20 K. (a) The bulk BZ and the projected surface BZ for both (100) and (001) surfaces with high-symmetry momentum points marked, (b) Calculated FS of CeRu4Sn6 with LDA + Gutzwiller method. The 3D FS is presented in the body-centered tetragonal Brillouin zone, in which one unit cell contains one Ce atom. Here different color stands for different FS",
            "FIG. 2. On- and off-resonance ARPES data of CeRu4Sn6 taken at 14 K with (a) off-resonance (114 eV) 5-polarized, (b) on-resonance (121 eV) ^-polarized, and (c) on-resonance /^-polarized light. Inset: second-derivative image with respect to energy, (d) Angle-integrated photoemission spectroscopy of the intensity plot in (a), (b), and (c).",
            "FIG. 3. On-resonance ARPES data of CeRu4Sn6 taken with right(a) and left-polarized (b) light, (c) The normalized difference [(CRCL)/(CR+CL)].",
            "FIG. 4. Temperature evolution of the heavy quasiparticle bands, (a) On-resonance (122 eV) band structure of CeRu4Sn6 at labeled temperatures. (b) Detailed ARPES spectral of CeRu4Sn6 measured at 7，100,and 230 K. Arrow indicates angle increase, (c) The angle-integrated EDCs over the angle range shown in (a) at various temperatures, (d) Temperature dependence of the heavy quasiparticle spectral weight. The cyan and magenta lines represent spectral weight integrals of the light cyan and light pink regions shown in (c), respectively. The blue squares represent the spectral weight integrals over [0.5 eV, 0.7 eV]."
        ],
        "imgs": [
            "$2305.00376v1-Figure1-1.png",
            "$2305.00376v1-Figure2-1.png",
            "$2305.00376v1-Figure3-1.png",
            "$2305.00376v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00382",
        "abstract": "  Knowledge graphs have shown promise for several cybersecurity tasks, such as\nvulnerability assessment and threat analysis. In this work, we present a new\nmethod for constructing a vulnerability knowledge graph from information in the\nNational Vulnerability Database (NVD). Our approach combines named entity\nrecognition (NER), relation extraction (RE), and entity prediction using a\ncombination of neural models, heuristic rules, and knowledge graph embeddings.\nWe demonstrate how our method helps to fix missing entities in knowledge graphs\nused for cybersecurity and evaluate the performance.\n",
        "title": "Constructing a Knowledge Graph from Textual Descriptions of Software\n  Vulnerabilities in the National Vulnerability Database",
        "texts": [
            "Figure 2: The figure illustrates the steps in our approach. We start by downloading our data from NVD, pre-processing the data, and adding labels to the entities. With our labeled data, we perform NER and RE to construct the KG. Because missing entities might occur in the KG, we predict these in the last step.",
            "Figure 3: Ontology for relation extraction. The edges should be interpreted as, for example, “a vendor has a product”, “a product has a version”, “a CVE vulnerability has a CWE type”",
            "Table 1: NER evaluation results for the averaged perception and the fine-tuned SecBERT model.",
            "Table 2: Our reproduction results compared to those reported by Bridges et al. (2014)",
            "Table 3: Performance metrics for our entity prediction model compared to Rastogi et al. (2023)."
        ],
        "imgs": [
            "$2305.00382v2-Figure2-1.png",
            "$2305.00382v2-Figure3-1.png",
            "$2305.00382v2-Table1-1.png",
            "$2305.00382v2-Table2-1.png",
            "$2305.00382v2-Table3-1.png"
        ]
    },
    {
        "id": "2305.00383",
        "abstract": "  In the Internet of Things (IoT) networks, edge learning for data-driven tasks\nprovides intelligent applications and services. As the network size becomes\nlarge, different users may generate distinct datasets. Thus, to suit multiple\nedge learning tasks for large-scale IoT networks, this paper performs efficient\ncommunication under the task-oriented principle by using the collaborative\ndesign of wireless resource allocation and edge learning error prediction. In\nparticular, we start with multi-user scheduling to alleviate co-channel\ninterference in dense networks. Then, we perform optimal power allocation in\nparallel for different learning tasks. Thanks to the high parallelization of\nthe designed algorithm, extensive experimental results corroborate that the\nmulti-user scheduling and task-oriented power allocation improve the\nperformance of distinct edge learning tasks efficiently compared with the\nstate-of-the-art benchmark algorithms.\n",
        "title": "Edge Learning for Large-Scale Internet of Things With Task-Oriented\n  Efficient Communication",
        "texts": [
            "Fig. 2. Block diagram of the proposed parallel algorithm.",
            "Fig. 3. Block diagram of the accelerated algorithm.",
            "Fig. 4. Mean squared error vs. the number of iterations.",
            "Fig. 5. Average execution time vs. the number of users.",
            "Fig. 6. Mean learning error vs. the number of users.",
            "Fig. 8. Qualitative and quantitative results of multi-task perception for autonomous driving.",
            "TABLE II SUMMARY OF THE LEARNING PARAMETERS [17]."
        ],
        "imgs": [
            "$2305.00383v1-Figure2-1.png",
            "$2305.00383v1-Figure3-1.png",
            "$2305.00383v1-Figure4-1.png",
            "$2305.00383v1-Figure5-1.png",
            "$2305.00383v1-Figure6-1.png",
            "$2305.00383v1-Figure8-1.png",
            "$2305.00383v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00384",
        "abstract": "  Emerging wireless applications are requiring ever more accurate\nlocation-positioning from sensor measurements. In this paper, we develop sensor\nselection strategies for 3D wireless positioning based on time of arrival (TOA)\nand received signal strength (RSS) measurements to handle two distinct\nscenarios: (i) known approximated target location, for which we conduct dynamic\nsensor selection to minimize the positioning error; and (ii) unknown\napproximated target location, in which the worst-case positioning error is\nminimized via robust sensor selection. We derive expressions for the\nCram\\'er-Rao lower bound (CRLB) as a performance metric to quantify the\npositioning accuracy resulted from selected sensors. For dynamic sensor\nselection, two greedy selection strategies are proposed, each of which exploits\nproperties revealed in the derived CRLB expressions. These selection strategies\nare shown to strike an efficient balance between computational complexity and\nperformance suboptimality. For robust sensor selection, we show that the\nconventional convex relaxation approach leads to instability, and then develop\nthree algorithms based on (i) iterative convex optimization (ICO), (ii)\ndifference of convex functions programming (DCP), and (iii) discrete monotonic\noptimization (DMO). Each of these strategies exhibits a different tradeoff\nbetween computational complexity and optimality guarantee. Simulation results\nshow that the proposed sensor selection strategies provide significant\nimprovements in terms of accuracy and/or complexity compared to existing sensor\nselection methods.\n",
        "title": "Dynamic and Robust Sensor Selection Strategies for Wireless Positioning\n  with TOA/RSS Measurement",
        "texts": [
            "Fig. 1: Geographical configuration of the sensors and candidate target locations in our wireless positioning model.",
            "Fig. 10: Comparison in the CRLB performance among multiple robust sensor selection algorithms over different values of M .",
            "Fig. 2: System model of 3D wireless positioning using multiple sensors. Yellow boxes indicate selected sensors.",
            "Fig. 3: A visual illustration of θm1m2 and φm1m2m3 in the F-CRLB expression for a given target and a sensor set M = {1, 2, 3}.",
            "Fig. 4: 3D visual representation of 14 sensors in a prism shape with ds = 4 (left) and robust sensor selection performance comparison between binary and continuous selection cases (right).",
            "Fig. 5: Worst-case CRLBs and zero-penalty rates over different values of κ.",
            "Fig. 6: Comparison between the CRLB and a MLE method (Taylor expansion) over different values of M .",
            "Fig. 7: Comparison of the CRLB obtained from different dynamic sensor selection algorithms over M when Mmax = 14.",
            "Fig. 8: Comparison between running time from different dynamic sensor selection algorithms over M when Mmax = 14.",
            "Fig. 9: Comparison of the running time of different dynamic sensor selection algorithms over Mmax when M=b0.5Mmaxc (left) and M=Mmax (right).",
            "TABLE I A list of variables describing our system model",
            "TABLE II Complexity comparison of the two proposed dynamic sensor selection algorithms. While Algorithm 1 has lower asymptotic complexity, it requires more arithmetic operations for small values of Mmax.",
            "TABLE III Runtime measurements in seconds of robust sensor selection algorithms over different values of M , Mmax, and G."
        ],
        "imgs": [
            "$2305.00384v1-Figure1-1.png",
            "$2305.00384v1-Figure10-1.png",
            "$2305.00384v1-Figure2-1.png",
            "$2305.00384v1-Figure3-1.png",
            "$2305.00384v1-Figure4-1.png",
            "$2305.00384v1-Figure5-1.png",
            "$2305.00384v1-Figure6-1.png",
            "$2305.00384v1-Figure7-1.png",
            "$2305.00384v1-Figure8-1.png",
            "$2305.00384v1-Figure9-1.png",
            "$2305.00384v1-TableI-1.png",
            "$2305.00384v1-TableII-1.png",
            "$2305.00384v1-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00385",
        "abstract": "  Biparametric magnetic resonance imaging (bpMRI) has demonstrated promising\nresults in prostate cancer (PCa) detection using convolutional neural networks\n(CNNs). Recently, transformers have achieved competitive performance compared\nto CNNs in computer vision. Large scale transformers need abundant annotated\ndata for training, which are difficult to obtain in medical imaging.\nSelf-supervised learning (SSL) utilizes unlabeled data to generate meaningful\nsemantic representations without the need for costly annotations, enhancing\nmodel performance on tasks with limited labeled data. We introduce a novel\nend-to-end Cross-Shaped windows (CSwin) transformer UNet model, CSwin UNet, to\ndetect clinically significant prostate cancer (csPCa) in prostate bi-parametric\nMR imaging (bpMRI) and demonstrate the effectiveness of our proposed\nself-supervised pre-training framework. Using a large prostate bpMRI dataset\nwith 1500 patients, we first pretrain CSwin transformer using multi-task\nself-supervised learning to improve data-efficiency and network\ngeneralizability. We then finetune using lesion annotations to perform csPCa\ndetection. Five-fold cross validation shows that self-supervised CSwin UNet\nachieves 0.888 AUC and 0.545 Average Precision (AP), significantly\noutperforming four comparable models (Swin UNETR, DynUNet, Attention UNet,\nUNet). Using a separate bpMRI dataset with 158 patients, we evaluate our method\nrobustness to external hold-out data. Self-supervised CSwin UNet achieves 0.79\nAUC and 0.45 AP, still outperforming all other comparable methods and\ndemonstrating good generalization to external data.\n",
        "title": "Cross-Shaped Windows Transformer with Self-supervised Pretraining for\n  Clinically Significant Prostate Cancer Detection in Bi-parametric MRI",
        "texts": [
            "Figure 1. Overview of our proposed (a) self-supervised pretraining and (b) finetuning workflow for csPCa detection. Each unlabelled prostate bpMRI image underwent data augmentations twice to generate two separate views with similar semantics information. Then, CSwin encoder is pretrained on unlabeled data using three pretext tasks: contrastive learning (CL), context restoration (CR), and rotation prediction (Rot) with automatic weighted loss. Finally, we fine-tune the model with labelled bpMRI to csPCa detection using pre-trained CSwin encoder.",
            "Figure 10. Visualization of csPCa detection maps from our proposed systems and comparable methods. GradCAMs and their corresponding T2W, DWI and ADC scans for three patient cases from Prostate158 are shown above. CSwin UNet detected csPCa while other candidate models failed (middle row, bottom row). Self-supervised pretraining improved lesion detection overlap with ground truth (middle row).",
            "Figure 2. Proposed structure of 3D CSwin UNet for detecting csPCa. a) The overall network consists of a CSwin encoder and a CNN decoder. CSwin encoder sequentially down-samples the input by a ratio of 1/4, 1/8, 1/16, and 1/32. The filter number of each layer is 24, 48, 96, 192, and 384. The decoder mirrors the configurations of the encoder and up-samples the features. The last stage Conv Token Embedding maintains the spatial resolution of the feature.",
            "Figure 3. Cross-shaped window attention mechanism for 3D data. First, we split G multi-heads into three groups and calculate self-attention in longitudinal, vertical and horizontal directions simultaneously (L-, V- and H-Attention).",
            "Figure 4. Illustrations of data augmentation for self-supervised learning. (a) shows the original T2W MRI image. (b) shows image rotated by 90 degrees along z-axis. (c) shows result of intensity transformation (gaussian blur, contrast adjustment). (d) shows the random cutout regions to be restored. (e) shows the result of pixel shuffling (red rectangles indicate shuffled pixels).",
            "Figure 5. Patient-based ROC analysis of csPCa detection in PI-CAI using the proposed models and other comparable methods. Transparent areas indicate the 95% confidence intervals.",
            "Figure 6. Lesion-based PR analysis (left) and FROC analysis (right) of csPCa detection in PI-CAI using the proposed models and other comparable methods. Transparent areas indicate the 95% confidence intervals.",
            "Figure 7. Visualization of csPCa detection maps from our proposed systems and comparable methods. Gradientweighted class activation maps (GradCAM) and their corresponding T2W, DWI and ADC scans for three patient cases from PI-CAI validation set are shown above. 3D GradCAMs were generated from csPCa segmentation maps and activation levels were normalized to (0,1). CSwin UNet detected csPCa with clear boundary and good overlap. Self-supervised learning improved detection of small lesions (bottom row).",
            "Figure 8. Patient-based ROC analysis of csPCa detection on external data using the proposed models and other comparable methods.",
            "Figure 9. Lesion-based PR analysis (left) and FROC analysis (right) of csPCa detection on external data using the proposed models and other comparable methods.",
            "Table 2. Comparison of different CSwin architectures. We study the effect of cosine attention and dynamic stripe width (sw) on csPCa detection."
        ],
        "imgs": [
            "$2305.00385v1-Figure1-1.png",
            "$2305.00385v1-Figure10-1.png",
            "$2305.00385v1-Figure2-1.png",
            "$2305.00385v1-Figure3-1.png",
            "$2305.00385v1-Figure4-1.png",
            "$2305.00385v1-Figure5-1.png",
            "$2305.00385v1-Figure6-1.png",
            "$2305.00385v1-Figure7-1.png",
            "$2305.00385v1-Figure8-1.png",
            "$2305.00385v1-Figure9-1.png",
            "$2305.00385v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00386",
        "abstract": "  Designing protein sequences with desired biological function is crucial in\nbiology and chemistry. Recent machine learning methods use a surrogate\nsequence-function model to replace the expensive wet-lab validation. How can we\nefficiently generate diverse and novel protein sequences with high fitness? In\nthis paper, we propose IsEM-Pro, an approach to generate protein sequences\ntowards a given fitness criterion. At its core, IsEM-Pro is a latent generative\nmodel, augmented by combinatorial structure features from a separately learned\nMarkov random fields (MRFs). We develop an Monte Carlo Expectation-Maximization\nmethod (MCEM) to learn the model. During inference, sampling from its latent\nspace enhances diversity while its MRFs features guide the exploration in high\nfitness regions. Experiments on eight protein sequence design tasks show that\nour IsEM-Pro outperforms the previous best methods by at least 55% on average\nfitness score and generates more diverse and novel protein sequences.\n",
        "title": "Importance Weighted Expectation-Maximization for Protein Sequence Design",
        "texts": [
            "Figure 2. Workflow of traditional protein sequence design. We aim to accelerate this process by directly generating desirable sequences.",
            "Figure 3. Learning combinatorial structure constraints through Markov random fields.",
            "Figure 4. Approximate KL divergence on eight protein datasets.",
            "Figure 5. 3-D visualization of a designed sequence of green fluorescent protein.",
            "Figure 6. Complete sequence and secondary structure comparison between the designed sequence of avGFP and chain B of Cytochrome b562 integral fusion with with enhanced green fluorescent protein. Green and blue parts respectively represent the Alpha helix and Beta strand.",
            "Table 1. Maximum fitness scores (MFS) of all methods on eight datasets. Higher values indicate better functional properties in the dataset.",
            "Table 2. Diversity scores of all models on eight datasets. Higher values indicate more diverse protein sequences.",
            "Table 3. Novelty scores of all models on eight datasets. Higher values indicate more novel protein sequences.",
            "Table 4. Results of different schemes of introducing a latent variable with a pretrained encoder evaluated on avGFP dataset.",
            "Table 5. Detailed statistics of the eight protein datasets."
        ],
        "imgs": [
            "$2305.00386v1-Figure2-1.png",
            "$2305.00386v1-Figure3-1.png",
            "$2305.00386v1-Figure4-1.png",
            "$2305.00386v1-Figure5-1.png",
            "$2305.00386v1-Figure6-1.png",
            "$2305.00386v1-Table1-1.png",
            "$2305.00386v1-Table2-1.png",
            "$2305.00386v1-Table3-1.png",
            "$2305.00386v1-Table4-1.png",
            "$2305.00386v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00387",
        "abstract": "  We present an in-depth analysis of a newly proposed correlation function in\nvisibility space, between the E and B modes of the linear polarization,\nhereafter the EB-correlation, for a set of time-averaged GRMHD simulations\ncompared with the phase map from different semi-analytic models as well as the\nEvent Horizon Telescope (EHT) 2017 data for M87* source. We demonstrate that\nthe phase map of the time-averaged EB-correlation contains novel information\nthat might be linked to the BH spin, accretion state and the electron\ntemperature. A detailed comparison with a semi-analytic approach with different\nazimuthal expansion modes shows that to recover the morphology of the\nreal/imaginary part of the correlation function and its phase, we require\nhigher orders of these azimuthal modes. To extract the phase features, we\npropose to use the Zernike polynomial reconstruction developing an empirical\nmetric to break degeneracies between models with different BH spins that are\nqualitatively similar. We use a set of different geometrical ring models with\nvarious magnetic and velocity field morphologies and show that both the image\nspace and visibility based EB-correlation morphologies in MAD simulations can\nbe explained with simple fluid and magnetic field geometries as used in ring\nmodels. SANEs by contrast are harder to model, demonstrating that the simple\nfluid and magnetic field geometries of ring models are not sufficient to\ndescribe them owing to higher Faraday Rotation depths. A qualitative comparison\nwith the EHT data demonstrates that some of the features in the phase of\nEB-correlation might be well explained by the current models for BH spins as\nwell as electron temperatures, while others may require a larger theoretical\nsurveys.\n",
        "title": "The EB-correlation in Resolved Polarized Images: Connections to\n  Astrophysics of Black Holes",
        "texts": [
            "Figure 1. The polarized image of M87* from EHT 2017 data on April 6 and April 11 as well as the 𝐸𝐵-correlation phase in the visibility space (bottom).",
            "Figure 10. The Zernike moments vs. the absolute value of the 𝑚 index for MAD (top) and SANE (bottom) simulations. From left to the right, we increase the BH spin in 𝑎 = (−0.94,−0.5, 0.0 + 0.5, +0.94). In each panel, we compute the summed 𝐶𝑛𝑚 for all 𝑛 indices that include the associated 𝑚 index, splitting the positive and the negative terms with solid-magenta and dashed-green lines, respectively. Different simulations show different patterns in their 𝐶 |𝑚 | (as defined in Eq. 16) vs |𝑚 | that might be used to distinguish them from one another. In each panel, the subplot refers to the case with an extended value of |𝑚 |s that again indicate we do not need to consider 𝑚 orders above 20.",
            "Figure 11. The time-averaged phase map for the 𝐸𝐵-correlation for MAD and SANE simulations using the 𝑀2 method described in Section 2.2.2, where we first compute the 𝐸𝐵-correlation at every snapshot and then calculate the time-averaged phase map. Comparing the results with Figures 7 and8, it is seen that both maps are qualitatively similar.",
            "Figure 12. The time averaged phase map for the 𝐸𝐵-correlation in MAD simulations from the GRMHD simulations of iharm. To infer the phase map we follow 𝑀1 method described in Section 2.2.1. It is clearly seen that the phase map is very similar to that of the MAD simulations from H-AMR simulations, which demonstrates that the observed patterns in MAD simulations are robust and rather independent of initial conditions.",
            "Figure 13. The comparison between the real part of the 𝐸𝐵-correlation in MAD simulations from the full-numeric as well as the 𝑚-order cut. From the top to bottom, we present the full numeric, the case with 𝑚cut =2, 𝑚cut =3 and 𝑚cut =4, respectively.",
            "Figure 14. Comparison between the real part of the 𝐸𝐵-correlation in SANE simulations from the full-numeric as well as the 𝑚-order cut. From the top to bottom, we present the full numeric, the case with 𝑚cut =2, 𝑚cut =3 and 𝑚cut =4, respectively.",
            "Figure 15. The comparison between the imaginary part of the 𝐸𝐵-correlation in MAD simulations from the full-numeric as well as the 𝑚-order cut. From the top to bottom, we present the full numeric, the case with 𝑚cut =2, 𝑚cut =3 and 𝑚cut =4, respectively.",
            "Figure 16. The comparison between the imaginary part of the 𝐸𝐵-correlation in SANE simulations from the full-numeric as well as with different 𝑚-order cuts. From the top to bottom, we present the full numeric, the case with 𝑚cut =2, 𝑚cut =3 and 𝑚cut =4, respectively.",
            "Figure 17. The geometrical ring model vs. the time-averaged GRMHD MAD simulations. From the top to bottom we present the polarized images, the real part and the phases of the 𝐸𝐵-correlation for the ring model and the phase from the time-averaged GRMHD simulation, respectively. It is inferred that the ring model recovers the full phase features in MADs.",
            "Figure 18. The geometrical ring model vs. the time-averaged GRMHD SANE simulations. From the top to bottom we present the polarized images, the real part and the phases of the 𝐸𝐵-correlation for the ring model and the phase from the time-averaged GRMHD simulation, respectively. It is inferred that the ring model does not seem to recover the full phase features in SANEs.",
            "Figure 19. The real, imaginary, and the phase of the gridded 𝐸𝐵-correlation function for the EHT 2017 data for 3598 (1st-row) and 3601 (2nd-row) and the time-averaged GRMHD simulations in MAD with 𝑎 = 0.0 and 𝑎 = +0.5 spins, respectively. The phase map in the EHT data contains both of the dark and bright regions which is similar to the MAD with 𝑎 = 0.0 in the dark regions while similar to MADs with 𝑎 = +0.5 for bright regions.",
            "Figure 2. A family of different Gaussian models. For a single Gaussian model, top panel, the phase of the 𝐸𝐵-correlation is either zero or 180 deg. In a double Gaussian model, middle panel, with the same EVPA ticks, the phase remains the same despite the brightness asymmetry. Finally, for a double Gaussian model with different EVPA ticks, the bottom panel, the phase gets non-vanished owing to the polarization anisotropies.",
            "Figure 20. The phase map for the 𝐸𝐵-correlation for the time-averaged GRMHD simulations using the EHT coverage for M87* and taking into account the EHT finite resolution of 20 `as. Comparing this with Figure 6 demonstrates no noticeable differences.",
            "Figure 21. The impact of time-variability as a variance in the phase map of the time-averaged 𝐸𝐵-correlation map for MAD and SANE simulations with different BH spins.",
            "Figure 3. The 𝐸𝐵-correlation phase for models with zero incliation and fluid speed (top row), models with i=17 deg while no fluid speed (middle row) and models with i=17 deg and non-zero fluid speed bottom row, respectively. I each row, from the left to right we study different magnetic field morphologies including a radial, toroidal and a mixed magnetic field, respectively. In each panel we overlay the ring image, on the top right corer, to build an intuition about the geometry of the ring. The phase is zero for cases with zero inclination, while it is non-zero for models with non-zero inclination. It is also degenerate between models with different B and v field geometries.",
            "Figure 4. Time averaged images of MAD simulations with different BH spins. From the top to bottom, we present the total intensity (I), fractional linear polarization (P/I), and the Stokes Q parameter. As expected images show a clear-handedness in their EVPAs.",
            "Figure 5. The time-averaged images of SANE simulations with different BH spins. From top to bottom, we present the total intensity (I), fractional linear polarization (P/I), and the Stokes Q parameter. As the system is controlled by turbulence, there is not any clear-handedness in the EVPAs.",
            "Figure 6. The phase map for the 𝐸𝐵-correlation function in the visibility space from the time-averaged GRMHD simulations using the EHT 2017 coverage for M87*. In the top(bottom) panel, we have used the MAD(SANE) simulations to make the synthetic data.",
            "Figure 7. The time-averaged phase map for the 𝐸𝐵-correlation for MAD simulations (top-row), the reconstructed phase map using the Zernike polynomials (middle-row) and for MAD simulations with No Faraday Rotation (NFR) (bottom-row). To infer the phase map we adopt the 𝑀1 method presented in Section 2.2.1 in which we first compute the time-averaged 𝐸 and 𝐵 modes and then compute the correlation phase using these averaged quantities. The Zernike expansion is truncated at 𝑛 = 40 order. As the Zernike polynomials are defined on a unit circle, we have multiplied them to 8 to be similar to the original phase map from the GRMHD simulations.",
            "Figure 8. The time-averaged phase map for the 𝐸𝐵-correlation for SANE simulations (top-row), the reconstructed phase map using the Zernike polynomials (middle-row) and for SANE simulations with No Faraday Rotation (NFR) (bottom-row). To infer the phase map we adopt the 𝑀1 method presented in Section 2.2.1 in which we first compute the time-averaged 𝐸 and 𝐵 modes and then compute the correlation phase using these averaged quantities. The Zernike expansion is truncated at 𝑛 = 40 order. As the Zernike polynomials are defined on a unit circle, we have multiplied them to 8 to be similar to the original phase map from the GRMHD simulations.",
            "Figure 9. The Zernike moments vs. the 𝑛 index for MAD (top) and SANE simulations (bottom). From left to the right, we increase the BH spin 𝑎 = (−0.94,−0.5, 0.0, +0.5, +0.94). In each panel, we sum over all of the non-zero 𝑚 indices for a given 𝑛 splitting the positive and negative terms with the solid-magenta and dashed-green lines, respectively. Different simulations show distinct patterns in 𝐶𝑛 (as defined in Eq. 15) vs. 𝑛 that can eventually be used to distinguish them from one another. In each panel, the subplot refers to the case with an extended value of 𝑛s, indicating that in most cases we do not need to consider n-orders above 20.",
            "Table 1. The ring model parameters are similar to the time-averaged GRMHD simulations of MAD (top) and SANE (bottom). From left to right we increase the BH spin in 𝑎 = (−0.94,−0.5, 0.0, +0.5, +0.94). In each case, we present the magnetic field inclination, 𝑖𝐵 , its orientation in the equatorial plane, [, together with the velocity field orientation, 𝜒, in the equatorial plane."
        ],
        "imgs": [
            "$2305.00387v2-Figure1-1.png",
            "$2305.00387v2-Figure10-1.png",
            "$2305.00387v2-Figure11-1.png",
            "$2305.00387v2-Figure12-1.png",
            "$2305.00387v2-Figure13-1.png",
            "$2305.00387v2-Figure14-1.png",
            "$2305.00387v2-Figure15-1.png",
            "$2305.00387v2-Figure16-1.png",
            "$2305.00387v2-Figure17-1.png",
            "$2305.00387v2-Figure18-1.png",
            "$2305.00387v2-Figure19-1.png",
            "$2305.00387v2-Figure2-1.png",
            "$2305.00387v2-Figure20-1.png",
            "$2305.00387v2-Figure21-1.png",
            "$2305.00387v2-Figure3-1.png",
            "$2305.00387v2-Figure4-1.png",
            "$2305.00387v2-Figure5-1.png",
            "$2305.00387v2-Figure6-1.png",
            "$2305.00387v2-Figure7-1.png",
            "$2305.00387v2-Figure8-1.png",
            "$2305.00387v2-Figure9-1.png",
            "$2305.00387v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00388",
        "abstract": "  This study proposes algorithms for building tilt grain boundary (GB) models\nwith a boundary plane-oriented approach that does not rely on existence of a\ncoincidence site lattice (CSL). As conventional GB model generation uses the\nCSL of superimposed grains as the starting point, our totally different\napproach allows systematic treatment of diverse grain boundary systems that was\npreviously not possible. Candidates of a pair of GB planes for a selected\nrotation axis, constituting a symmetrical or asymmetrical tilt GB, are\nthoroughly obtained by computational search that is applicable to any crystal\nstructure. A GB interface for feasible computational analysis would have\ntwo-dimensional (2D) periodicity shared by the 2D lattices of the two GB\nplanes, hence surface-slab supercells (slab-and-vacuum models) with common\nin-plane basis vectors of the shared 2D lattice are obtained. Finally, a\nprocedure to obtain a GB-model supercell with alternately stacking such slabs\nis given. Symmetry operations of each slab may be considered such that the\niterated interfaces are symmetrically equivalent, which is beneficial in ab\ninitio calculations. The proposed algorithms allow streamlined generation of GB\nmodels, both symmetric and asymmetric, with or without an exact 3D-CSL\nrelation.\n",
        "title": "Boundary Plane-Oriented Grain Boundary Model Generation",
        "texts": [
            "Fig. 1. Schematic images of tilt, reflection twin, and screw grain boundaries. The cross in a circle indicates the position of the rotation axis, which is perpendicular to the page.",
            "Fig. 2. Schematic on how to obtain a GB model based on a (a) conventional and (b) GB plane-oriented procedure.",
            "Fig. 4. Relation between the rotation vector s , in-plane rotation vector IPr , and distance between rows of atoms (blue circles) parallel to the rotation axis (black lines), dref, in a reference plane. (a) Rectangular lattice, (b) oblique lattice and (c,d) centered lattices with different periodicity.",
            "Fig. 5. Derivation of a target GB plane, which is (211), from the (111) reference plane in fcc Cu. The derivation is given in §S4. Important vectors are shown, and the same information is drawn from three directions. The definition of the angle θ between the reference and target plane is shown in (b); note that the rotation vector s (direction",
            "Fig. 6. Making a (111) slab of primitive cubic CsCl. Large blue and small green circles indicate Cs and Cl atoms, respectively. (a) (111)-primitive cell 48). (b) (111) 4-supercell, which is an 1×1×4 supercell of the (111)-primitive cell. (c) Slab-and-vacuum model obtained by removing atoms from the (111) 4-supercell. (d) The out-of-plane basis vector is retaken to be normal to the (111) plane in the vacuum layer; the resulting model is a slab-and-vacuum model although the out-of-plane basis vector is not a lattice vector of the original lattice.",
            "Fig. 9. Symmetry elements in an alternate-stacking model. Pink and blue motifs indicate symmetry elements in a different slab. The symmetry elements are (a) inversion, (b) mirror parallel to the ab-plane, and (c,d) two-fold rotation parallel to the b axis, shown from two directions. The a-and b-axes are parallel to an interface, while the c-axis is not. All eight inversion centers, two mirror planes, and four rotation axes are shown in a",
            "Table II. Internal coordinates (x,y,z), in Cartesian coordinates, of a MgO (100) and (001) three-layer slab. The lattice parameter of MgO is 4.2 Å. The basis vectors of the slab are"
        ],
        "imgs": [
            "$2305.00388v1-Figure1-1.png",
            "$2305.00388v1-Figure2-1.png",
            "$2305.00388v1-Figure4-1.png",
            "$2305.00388v1-Figure5-1.png",
            "$2305.00388v1-Figure6-1.png",
            "$2305.00388v1-Figure9-1.png",
            "$2305.00388v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00390",
        "abstract": "  Metal/oxide support perimeter sites are known to provide unique properties\nbecause the nearby metal changes the local environment on the support surface.\nIn particular, the electron scavenger effect reduces the energy necessary for\nsurface anion desorption, thereby contributes to activation of the (reverse)\nMars-van Krevelen mechanism. This study investigated the possibility of such\nactivation in hydrides, carbides, nitrides, and sulfides. The work functions\n(WFs) of known hydrides, carbides, nitrides, oxides, and sulfides with group 3,\n4, or 5 cations (Sc, Y, La, Ti, Zr, Hf, V, Nb, and Ta) were calculated. The WFs\nof most hydrides, carbides, and nitrides are smaller than the WF of Ag,\nimplying that the electron scavenger effect may occur when late transition\nmetal nanoparticles are adsorbed on the surface. The WF of oxides and sulfides\ndecrease when reduced. The surface anion vacancy formation energy correlates\nwell with the bulk formation energy in carbides and nitrides, while almost no\ncorrelation is found in hydrides because of the small range of surface hydrogen\nvacancy formation energy values. The electron scavenger effect is explicitly\nobserved in nanorods adsorbed on TiH2 and Ti2O3; the surface vacancy formation\nenergy decreases at anion sites near the nanorod, and charge transfer to the\nnanorod happens when an anion is removed at such sites. Activation of hydrides,\ncarbides, and nitrides by nanorod adsorption and screening support materials\nthrough WF calculation are expected to open up a new category of supported\ncatalysts.\n",
        "title": "Surface activation by electron scavenger metal nanorod adsorption on\n  TiH2, TiC, TiN, and Ti2O3",
        "texts": [
            "Fig. 1. Representative surfaces of compounds investigated in this study. Blue and red circles indicate cations and anions, respectively.",
            "Fig. 13. Relation between EOvac for O sites D, E, and F and WF in Fig. 12. The WF is from (a) a slab of the most stable surface in the most stable structure in Table S6 and (b) the nanorod with the atomic configuration in Fig. S2 but without the Ti2O3 support.",
            "Fig. 14. Relation between Evac and Bader charge transfer to the nanorod upon surface anion removal. A positive value in the horizontal axis means that the nanorod gains electrons (reduced) with anion removal. The dotted line indicates Evac without nanorods.",
            "Fig. 2. Representative surfaces of compounds investigated in this study. Blue and red circles indicate cations and anions, respectively.",
            "Fig. 4. WF (circles, defined as the surface-sensitive IP 54) as well as the IP and EA based on the bulk-based definition 54 ( ar) of the representative surface of various oxides. The WF of metal elements (crosses) are also shown.",
            "Fig. 5. WF (circles, defined as the surface-sensitive IP 54) as well as the IP and EA based on the bulk-based definition54 (bar) of the representative surface of various sulfides. The WF of metal elements (crosses) are also shown.",
            "Fig. 6. Surface anion vacancy formation energy (Evac) versus (a) bulk formation energy (Ebulk) and (b) WF. Hydrides have the CaF2 (fluorite) or ThH2 (distorted fluorite) structure, and the CaF2 structure (111) surface or the equivalent (101) surface in the ThH2 structure is considered. Carbides and nitrides have the NaCl (rocksalt) structure, and the (100) surface is considered. Some compounds are hypothetical.",
            "Fig. 7. Correlation map for E(H,C,N)vac, physicochemical properties of hydride, carbide, and nitride compounds (MX) in Fig. 6, and elemental properties of cation and anion elements for those compounds (M and X, respectively). The physicochemical properties of hydride, carbide, and nitride compounds include bulk density, Ebulk, WF, and length of M–X bond where X is an anion atom which will be removed. The latter three quantities were obtained by DFT calculations in this study. The correlation coefficients (R) are indicated by the numbers in the squares.",
            "Fig. 8. (a) The out-of-sample prediction performance by 100 times of random leave25%-out cross validation; DFT-calculated E(H,C,N)vac and values predicted using ETR. (b) SHAP values of the six descriptors in predicting E(H,C,N)vac using ETR. SHAP values for individual factors are plotted as dots (blue corresponds to low features, red to high features). Here, features are ordered in descending order according to the sum of the absolute values of the SHAP values (importance of the descriptors for prediction). Dots are displaced vertically to reflect the density of datapoints at a given SHAP value.",
            "Fig. 9. Adsorption of a nanorod of a face-centered cubic metal on the TiH2 (101) surface (corresponds to the fluorite (111) surface). The {100} orientation of the nanorod is parallel to the slab surface. (a) Side view. Bottom row of the (b) Re and (c) Ru nanorod shown together with the slab surface. The numbers are EHvac of the corresponding H atom in eV/defect. Circles in blue, red, and the other color indicate Ti, H, and Pd or Ru, respectively. The WF in solid and italic letters are those of the slab and nanorod, respectively. The atomic coordinates of the nanorod used to obtain the WF are those of the nanorod on the slab without anion removal.",
            "Table 1. Information on hydrides investigated in this study. MP ID is the Materials Project material ID for the first structure of each prototype. The band gap is the minimum band gap in eV.",
            "Table 2. Information on carbides investigated in this study. MP ID is the Materials Project material ID for the first structure of each prototype. The band gap is the minimum band gap in eV.",
            "Table 3. Information on nitrides investigated in this study. MP ID is the Materials Project material ID for the first structure of each prototype. The band gap is the minimum band gap in eV.",
            "Table 4. Information on oxides investigated in this study. MP ID is the Materials Project material ID for the first structure of each prototype. The band gap is the minimum band gap in eV.",
            "Table 5. Information on sulfides investigated in this study. MP ID is the Materials Project material ID for the first structure of each prototype. The band gap is the minimum band gap in eV."
        ],
        "imgs": [
            "$2305.00390v1-Figure1-1.png",
            "$2305.00390v1-Figure13-1.png",
            "$2305.00390v1-Figure14-1.png",
            "$2305.00390v1-Figure2-1.png",
            "$2305.00390v1-Figure4-1.png",
            "$2305.00390v1-Figure5-1.png",
            "$2305.00390v1-Figure6-1.png",
            "$2305.00390v1-Figure7-1.png",
            "$2305.00390v1-Figure8-1.png",
            "$2305.00390v1-Figure9-1.png",
            "$2305.00390v1-Table1-1.png",
            "$2305.00390v1-Table2-1.png",
            "$2305.00390v1-Table3-1.png",
            "$2305.00390v1-Table4-1.png",
            "$2305.00390v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00392",
        "abstract": "  We implement the Bayesian inference to retrieve energy spectra of all\nneutrinos from a galactic core-collapse supernova (CCSN). To achieve high\nstatistics and full sensitivity to all flavours of neutrinos, we adopt a\ncombination of several reaction channels from different large-scale neutrino\nobservatories, namely inverse beta decay on proton and elastic scattering on\nelectron from Hyper-Kamiokande (Hyper-K), charged current absorption on Argon\nfrom Deep Underground Neutrino Experiment (DUNE) and coherent elastic\nscattering on Lead from RES-NOVA. Assuming no neutrino oscillation or specific\noscillation models, we obtain mock data for each channel through Poisson\nprocesses with the predictions, for a typical source distance of 10 kpc in our\nGalaxy, and then evaluate the probability distributions for all spectral\nparameters of theoretical neutrino spectrum model with Bayes' theorem. Although\nthe results for either the electron-neutrinos or electron-antineutrinos reserve\nrelatively large uncertainties (according to the neutrino mass hierarchy), a\nprecision of a few percent (i.e., $\\pm 1 \\% \\sim \\pm 4 \\%$ at a credible\ninterval of $2 \\sigma$) is achieved for primary spectral parameters (e.g., mean\nenergy and total emitted energy) of other neutrino species. Moreover, the\ncorrelation coefficients between different parameters are computed as well and\ninteresting patterns are found. Especially, the mixing-induced correlations are\nsensitive to the neutrino mass hierarchy, which potentially makes it a brand\nnew probe to determine the neutrino mass hierarchy in the detection of galactic\nsupernova neutrinos. Finally, we discuss the origin of such correlation\npatterns and perspectives for further improvement on our results.\n",
        "title": "Bayesian Inference of Supernova Neutrino Spectra with Multiple Detectors",
        "texts": [
            "Figure 1: Predicted events and mock data for each reaction channel in Hyper-k, DUNE and RES-NOVA. Eν and Er are the reconstructed neutrino energy and nuclear recoil energy, respectively. The source is assumed to be located at a typical distance, i.e., d = 10 kpc, and no oscillation effect is under evaluation.",
            "Figure 2: Predicted events in each reaction channel under inverted mass ordering (IMO) or normal mass ordering (NMO). Eν (Er) denotes the reconstructed neutrino energy (nuclear recoil energy). The distance is assumed to be 10 kpc. The mock data for each case can be extracted with the same strategy in figure 1 and we did not show them here.",
            "Figure 3: Posterior distributions for the no oscillation case. The Gaussian prior distributions are functioning here. Plots on the diagonal show posterior distributions for the corresponding parameter after marginalization over other parameters, and the off-diagonal ones show correlations between them. Contours in the off-diagonal plots demonstrate the area of 1σ, 2σ and 3σ credible level, respectively. The blue lines mark the parameter values to generate the mock data used in this analysis.",
            "Figure 4: The same as figure 3, but the oscillation effects with normal mass ordering are under evaluation.",
            "Figure 5: The same as figure 3, but the oscillation effects with inverted mass ordering are under evaluation.",
            "Figure 7: The same as figure 3, but the flat prior distributions are involved.",
            "Table 1: Spectral parameters for the time-integrated spectra of supernova neutrino fluxes (see table 1 in ref. [40]).",
            "Table 2: The parameters of Gauss distributions in priors. µ and σ represent the center values and standard deviations, respectively. ⟨Eν⟩s are in the unit of MeV.",
            "Table 3: The representative values of 1-D posterior distributions. NO indicates the case without neutrino oscillation, while NMO (IMO) represents the case of normal (inverted) mass ordering. Gaussian priors are adopted in all cases. The rows denoted with MAP give the most probable values of the posteriors, while (2σ−, 2σ+) show the relative credible intervals at the 2σ level of probability. % rows give the corresponding symmetrized fractional uncertainties. Meanwhile, %(csu) rows show the estimated symmetrized fractional uncertainties after including a ±5% uncertainty on the cross section of vAr(CC) reaction in DUNE."
        ],
        "imgs": [
            "$2305.00392v2-Figure1-1.png",
            "$2305.00392v2-Figure2-1.png",
            "$2305.00392v2-Figure3-1.png",
            "$2305.00392v2-Figure4-1.png",
            "$2305.00392v2-Figure5-1.png",
            "$2305.00392v2-Figure7-1.png",
            "$2305.00392v2-Table1-1.png",
            "$2305.00392v2-Table2-1.png",
            "$2305.00392v2-Table3-1.png"
        ]
    },
    {
        "id": "2305.00393",
        "abstract": "  Unsupervised learning of object-centric representations in dynamic visual\nscenes is challenging. Unlike most previous approaches that learn to decompose\n2D images, we present DynaVol, a 3D scene generative model that unifies\ngeometric structures and object-centric learning in a differentiable volume\nrendering framework. The key idea is to perform object-centric voxelization to\ncapture the 3D nature of the scene, which infers the probability distribution\nover objects at individual spatial locations. These voxel features evolve over\ntime through a canonical-space deformation function, forming the basis for\nglobal representation learning via slot attention. The voxel features and\nglobal features are complementary and are both leveraged by a compositional\nNeRF decoder for volume rendering. DynaVol remarkably outperforms existing\napproaches for unsupervised dynamic scene decomposition. Once trained, the\nexplicitly meaningful voxel features enable additional capabilities that 2D\nscene decomposition methods cannot achieve: it is possible to freely edit the\ngeometric shapes or manipulate the motion trajectories of the objects.\n",
        "title": "DynaVol: Unsupervised Learning for Dynamic Scenes through Object-Centric\n  Voxelization",
        "texts": [
            "Figure 1: Contributions: DynaVol explores an unsupervised object-centric voxelization approach for dynamic scene decomposition. Unlike its 2D counterparts, such as SAVi [15], DynaVol ensures 3D consistency and provides additional capabilities, e.g., novel view synthesis and scene editing.",
            "Figure 10: Object replacement based on 3ObjFall and 3ObjRealCmpx (Top: before editing; Bottom: after editing). It is an enlarged version of Figure 5(c) in the main manuscript.",
            "Figure 2: An overview of DynaVol. The model comprises three network components, including the voxel grid deformation module, the slot features refinement module, and the neural rendering module. The model has two training stages, including a warmup stage and a dynamic grounding stage.",
            "Figure 3: Visualization of novel view synthesis and scene decomposition results.",
            "Figure 4: Novel view synthesis for different dynamic scenes. For each scene, we randomly select a novel view at an arbitrary timestamp. Note that the vanilla D-NeRF fails on 3ObjRand.",
            "Figure 5: Showcases of dynamic scene editing in both (a) the real-world scene [23], (b-c) the synthetic scenes with real-world object geometry and textures, and (d) the synthetic scene with severe occlusions between objects. The top row in each sub-figure indicates the results of novel view synthesis and scene decomposition. The bottom row indicates the results of scene editing.",
            "Figure 6: Visualization of the average value across all feature dimensions of S̄e at different training episodes on 3ObjRealCmpx, 6ObjFall, and 3ObjRand.",
            "Figure 7: Scene decomposition results of using different numbers (V = {1, 3, 5}) of images captured from different viewpoints at the initial timestamp.",
            "Figure 8: Real-world decomposition and scene editing. The top images illustrate the original scene prior to any editing, while the bottom images present the scene after object removal. It is an enlarged version of Figure 5(a) in the main manuscript.",
            "Figure 9: Trajectory modification based on 3ObjRealCmpx (Top: before editing; Bottom: after editing). It is an enlarged version of Figure 5(b) in the main manuscript.",
            "Table 1: Novel view synthesis results of our approach compared with D-NeRF [24] and DeVRF [18], as well as their variants for dynamic scenes (see text for details). We evaluate the results averaged over 60 novel views per timestamp.",
            "Table 2: Comparisons with existing approaches based on 2D/3D object-centric representations, i.e., SAVi [5], uORF [34], and SAM [16]. In particular, for uORF, we present novel view synthesis and object segmentation results. For SAVi, since it requires videos with fixed viewpoints, we generate an image sequence at a certain fixed camera position and present the result of SAVi. To compare with it, we evaluate DynaVol (Fix) with images that are also collected at this fixed camera view.",
            "Table 3: Ablation study on the impact of the LPoint loss. We present novel view synthesis and decomposition results on three datasets.",
            "Table 4: Quantitative results with error bars (mean± std) of DynaVol, corresponding to Table 1 and Table 2 in the main manuscript."
        ],
        "imgs": [
            "$2305.00393v3-Figure1-1.png",
            "$2305.00393v3-Figure10-1.png",
            "$2305.00393v3-Figure2-1.png",
            "$2305.00393v3-Figure3-1.png",
            "$2305.00393v3-Figure4-1.png",
            "$2305.00393v3-Figure5-1.png",
            "$2305.00393v3-Figure6-1.png",
            "$2305.00393v3-Figure7-1.png",
            "$2305.00393v3-Figure8-1.png",
            "$2305.00393v3-Figure9-1.png",
            "$2305.00393v3-Table1-1.png",
            "$2305.00393v3-Table2-1.png",
            "$2305.00393v3-Table3-1.png",
            "$2305.00393v3-Table4-1.png"
        ]
    },
    {
        "id": "2305.00395",
        "abstract": "  Spinel oxides are an important class of materials for heterogeneous catalysis\nincluding photocatalysis and electrocatalysis. The surface O vacancy formation\nenergy (EOvac) is a critical quantity on catalyst performance because the\nsurface of metal oxide catalysts often acts as reaction sites, for example, in\nthe Mars-van Krevelen mechanism. However, experimental evaluation of EOvac is\nvery challenging. We obtained the EOvac for (100), (110), and (111) surfaces of\nnormal zinc-based spinel oxides ZnAl2O4, ZnGa2O4, ZnIn2O4, ZnV2O4, ZnCr2O4,\nZnMn2O4, ZnFe2O4, and ZnCo2O4. The most stable surface is (100) for all\ncompounds. The smallest EOvac for a surface is the largest in the (100) surface\nexcept for ZnCo2O4. For (100) and (110) surfaces, there is a good correlation,\nover all spinels, between the smallest EOvac for the surface and bulk formation\nenergy, while the ionization potential correlates well in (111) surfaces.\nMachine learning over EOvac of all surface sites in all orientations and all\ncompounds to find the important factors, or descriptors, that decide the EOvac\nrevealed that bulk and surface-dependent descriptors are the most important,\nnamely the bulk formation energy, a Boolean descriptor on whether the surface\nis (111), and the ionization potential, followed by geometrical descriptors\nthat are different in each O site.\n",
        "title": "Factors determining surface oxygen vacancy formation energy in ternary\n  spinel structure oxides with zinc",
        "texts": [
            "Fig. 5. Average RMSEs for predicting EOvac for all the surface O sites of ZnM2O4 by 100 times of random leave-10%-out trials with various ML methods.",
            "Fig. 6. SHAP values of the descriptors in predicting EOvac using ETR. SHAP values for individual factors are plotted as dots (blue corresponds to low features, red to high features). Here, features are ordered in descending order according to the sum of the absolute values of the SHAP values.",
            "Table 1. Bulk properties of ZnM2O4. v, Ebulk, and band gap (BG) are the volume per atom, formation energy per atom, and minimum band gap, respectively. Experimentally reported BGs are also shown.",
            "Table 2. Calculated Esurf, difference between the number of spin up and down electrons (spin), IP, and EA. Units of spin is electron magnetic moment per cell (two surfaces)."
        ],
        "imgs": [
            "$2305.00395v1-Figure5-1.png",
            "$2305.00395v1-Figure6-1.png",
            "$2305.00395v1-Table1-1.png",
            "$2305.00395v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00397",
        "abstract": "  Despite radar's popularity in the automotive industry, for fusion-based 3D\nobject detection, most existing works focus on LiDAR and camera fusion. In this\npaper, we propose TransCAR, a Transformer-based Camera-And-Radar fusion\nsolution for 3D object detection. Our TransCAR consists of two modules. The\nfirst module learns 2D features from surround-view camera images and then uses\na sparse set of 3D object queries to index into these 2D features. The\nvision-updated queries then interact with each other via transformer\nself-attention layer. The second module learns radar features from multiple\nradar scans and then applies transformer decoder to learn the interactions\nbetween radar features and vision-updated queries. The cross-attention layer\nwithin the transformer decoder can adaptively learn the soft-association\nbetween the radar features and vision-updated queries instead of\nhard-association based on sensor calibration only. Finally, our model estimates\na bounding box per query using set-to-set Hungarian loss, which enables the\nmethod to avoid non-maximum suppression. TransCAR improves the velocity\nestimation using the radar scans without temporal information. The superior\nexperimental results of our TransCAR on the challenging nuScenes datasets\nillustrate that our TransCAR outperforms state-of-the-art Camera-Radar\nfusion-based 3D object detection approaches.\n",
        "title": "TransCAR: Transformer-based Camera-And-Radar Fusion for 3D Object\n  Detection",
        "texts": [
            "Figure 1: An example from nuScenes [3] showing how TransCAR fusion works. Vision-only detection has significant range error. Our TransCAR fusion can learn the interactions between vision-based query and related radar signals and predict improved detection. Unrelated radar points are prevented from attention by Query-Radar attention mask.",
            "Figure 2: TransCAR system architecture. There are three primary components in the system: (1) A camera network (DETR3D [35]) based on transformer decoders to generate image-based 3D object queries. The initial object queries are generated randomly; (2) A radar network that encodes radar point locations and extracts radar features; (3) The TransCAR fusion module based on three transformer cross-attention decoders. We propose to use transformer to learn the interactions between radar features and vision-updated object queries for adaptive camera-radar association.",
            "Figure 3: Details of radar network. The position encoding network (left) takes radar point positions (xyz) as input. The radar data after preprocessing (Section 2.2) are sent to the radar feature extraction network (right) to learn useful radar features. Since radar signal is very sparse, each radar point is treated independently. The numbers within the square brackets represent the shape of the data.",
            "Figure 5: Qualitative comparison between TransCAR and baseline DETR3D on the nuScenes dataset [3]. Blue and red boxes are the predictions from TransCAR and DETR3D respectively, green filled rectangles are ground truths. The larger dark points are radar points, smaller color points are LiDAR points for reference (color yallow to green indicates the increasing distance). The oval regions on the left column highlight the improvements made by TransCAR, the orange boxes on the image highlight the corresponding oval region in the top-down view. Best viewed with zoom-in and color.",
            "Table 1: Quantitative comparison with SOTA methods on nuScenes test set. In ‘Sensor’ colum, ‘C’, ‘L’ and ‘CR’ represent camera, LiDAR, and camera-radar fusion, respectively. ‘C.V.’, ‘Ped’,‘Motor’ and ‘T.C’ are short for construction vehicle, pedestrian, motorcycle, and traffic cone, respectively. TransCAR is currently the best camera-radar fusion-based method with the highest NDS and mAP, and it even outperforms early-released LiDAR-based approaches. The best performers are highlighted in bold, excluding LiDAR-only solutions.",
            "Table 10: Comparison with other SOTA methods in other secondary evaluation metrics defined by nuScenes dataset on nuScenes test set. The best performers are highlighted in bold exclude LiDAR-only solutions",
            "Table 11: Evaluation on all classes detection results from accumulating different number of radar frames for fusion.",
            "Table 12: Evaluation on Car detection results from accumulating different number of radar frames for fusion.",
            "Table 13: Comparison of different attention mask radii for each transformer decoder in our TransCAR.",
            "Table 2: Average Precision (AP) comparison with baseline DETR3D in Car class with different center-distance evaluation metrics on nuScenes validation set. Our TransCAR improves the AP by a large margin in all evaluation metrics.",
            "Table 3: Ablation of the proposed TransCAR components on nuScenes val set.",
            "Table 4: Evaluation on detection results from different number of transformer decoders in TransCAR.",
            "Table 5: Mean Average Precision (mAP, %), nuScenes Detection Score (NDS) and mean Average Velocity Error (AVE,m/s) for all classes of different distance ranges on nuScenes validation set. Our TransCAR outperforms the baseline (DETR3D) in all distance ranges.",
            "Table 6: Average Precision (AP, %) and Average Velocity Error (AVE, m/s) for Car class of different distance ranges on nuScenes validation set. We also present the miss rate of radar sensor for different distance ranges. A car missed by radar is defined as a car that does not have radar return. Our TransCAR improves the AP and reduces the velocity estimation error by a large margin in all distance ranges.",
            "Table 7: Comparison of Average Precision (AP) and Average Velocity Error (AVE, m/s) for class Car under the rain and no-rain scenes on nuScenes validation set. There are 1088 frames (27 scenes) among 6019 frames (150 scenes) in nuScenes validation set are annotated as rain. TransCAR can significant improve the detection performance and reduce the velocity estimation error under rainy conditions.",
            "Table 8: Comparison of Average Precision (AP) and Average Velocity Error (AVE, m/s) for class Car during the night and daytime scenes on nuScenes validation set. There are 602 frames among 6019 frames in nuScenes validation set are collected during the night. TransCAR can leverage the radar data to significantly improve the performance and reduce the velocity estimation error during the night when the camera is affected.",
            "Table 9: Statistics of objects in different classes in nuScenes training set within 50 meters of the ego vehicle. * ‘C.V.’, ‘Ped’, ‘Motor’ and ‘T.C’ represent construction vehicle, pedestrian, motorcycle and traffic cone, respectively. An object that is missed by radar or LiDAR is defined as having no hit/return from that object. Radar misses more objects. For the two most common classes in autonomous driving applications, car and pedestrian, radar misses 36.05% cars and 78.16% pedestrians. Although nuScenes does not provide detailed visibilities of objects in the image, we believe that it is much higher than radar. Therefore, we use camera instead of radar to generate 3D object queries for fusion."
        ],
        "imgs": [
            "$2305.00397v1-Figure1-1.png",
            "$2305.00397v1-Figure2-1.png",
            "$2305.00397v1-Figure3-1.png",
            "$2305.00397v1-Figure5-1.png",
            "$2305.00397v1-Table1-1.png",
            "$2305.00397v1-Table10-1.png",
            "$2305.00397v1-Table11-1.png",
            "$2305.00397v1-Table12-1.png",
            "$2305.00397v1-Table13-1.png",
            "$2305.00397v1-Table2-1.png",
            "$2305.00397v1-Table3-1.png",
            "$2305.00397v1-Table4-1.png",
            "$2305.00397v1-Table5-1.png",
            "$2305.00397v1-Table6-1.png",
            "$2305.00397v1-Table7-1.png",
            "$2305.00397v1-Table8-1.png",
            "$2305.00397v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00398",
        "abstract": "  Industrial image anomaly detection under the setting of one-class\nclassification has significant practical value. However, most existing models\nstruggle to extract separable feature representations when performing feature\nembedding and struggle to build compact descriptions of normal features when\nperforming one-class classification. One direct consequence of this is that\nmost models perform poorly in detecting logical anomalies which violate\ncontextual relationships. Focusing on more effective and comprehensive anomaly\ndetection, we propose a network based on self-supervised learning and\nself-attentive graph convolution (SLSG) for anomaly detection. SLSG uses a\ngenerative pre-training network to assist the encoder in learning the embedding\nof normal patterns and the reasoning of position relationships. Subsequently,\nSLSG introduces the pseudo-prior knowledge of anomaly through simulated\nabnormal samples. By comparing the simulated anomalies, SLSG can better\nsummarize the normal features and narrow down the hypersphere used for\none-class classification. In addition, with the construction of a more general\ngraph structure, SLSG comprehensively models the dense and sparse relationships\namong elements in the image, which further strengthens the detection of logical\nanomalies. Extensive experiments on benchmark datasets show that SLSG achieves\nsuperior anomaly detection performance, demonstrating the effectiveness of our\nmethod.\n",
        "title": "SLSG: Industrial Image Anomaly Detection by Learning Better Feature\n  Embeddings and One-Class Classification",
        "texts": [
            "Figure 1. SLSG uses normal and simulated anomalies for training and completes anomaly discrimination directly during the inference stage.",
            "Figure 10. Effect of different loss functions on image reconstruction during the pre-training stage.",
            "Figure 11. FPR and sPRO values of PaDiM and SLSG at different thresholds.",
            "Figure 2. The pipeline of SLSG. SLSG uses a generative pre-training network (GPT-Net) to pre-train the encoder, and this process introduces adversarial loss through the discriminative network (D-Net) to improve the sharpness of the reconstructed image. Then, SLSG uses the pretrained encoder and the one-class classification decoder to compose the segmentation network (SegNet). SegNet performs end-to-end pixel-level anomaly localization with the help of simulated abnormal samples. Also, SegNet introduces a self-attention-based graph convolutional network (SG block) at the bottleneck structure to better capture logical anomalies.",
            "Figure 3. Structural anomaly simulation and logical anomaly simulation. The Hadamard product of the mask image and the noise source image defines the anomaly foreground. The anomaly foreground is superimposed on the normal image to produce the simulated anomaly image .",
            "Figure 4. Self-attention-based graph convolutional block.",
            "Figure 5. The result of anomaly localization of SPADE, PaDiM, PatchCore and our method on the MVTec LOCO AD dataset. Logical anomalies (left) and structural anomalies (right). SLSG gives anomaly discrimination with a higher confidence level.",
            "Figure 6. Comparison of our model with different models for the detection of structural and logical anomalies.",
            "Figure 7. The distribution of simulated abnormal samples, real abnormal samples, and normal samples in two-dimensional space. The approximate decision boundaries drawn show that SLSG implements the one-class classification by learning.",
            "Figure 8. Graph structure constructed by GCN.",
            "Figure 9. Effect of different loss functions on anomaly localization.",
            "Table 1. The performance for anomaly detection and localization of different methods on the BeanTech AD dataset with the format of (Image-level ROC-AUC%, Pixel-level ROC-AUC%).",
            "Table 2. The performance for anomaly detection and localization of different methods on the MVTec AD dataset with the format of (Image-level ROC-AUC%, Pixel-level ROC-AUC%).",
            "Table 3. The performance for anomaly detection and localization of different methods on the MVTec LOCO AD dataset with the format of (Imagelevel ROC-AUC%, Pixel-level sPRO-AUC%).",
            "Table 4. Image-level ROC-AUC scores of SLSG on the LOCO AD dataset when using different pre-training strategies.",
            "Table 5. Image-level ROC-AUC scores of SLSG on the LOCO AD dataset when using different anomaly simulation strategies.",
            "Table 6. The image-level ROC-AUC scores of SLSG when using different modules and parameters.",
            "Table 7. Evaluation of different loss functions. The image-level ROCAUC scores on the LOCO AD dataset are reported for different loss functions."
        ],
        "imgs": [
            "$2305.00398v1-Figure1-1.png",
            "$2305.00398v1-Figure10-1.png",
            "$2305.00398v1-Figure11-1.png",
            "$2305.00398v1-Figure2-1.png",
            "$2305.00398v1-Figure3-1.png",
            "$2305.00398v1-Figure4-1.png",
            "$2305.00398v1-Figure5-1.png",
            "$2305.00398v1-Figure6-1.png",
            "$2305.00398v1-Figure7-1.png",
            "$2305.00398v1-Figure8-1.png",
            "$2305.00398v1-Figure9-1.png",
            "$2305.00398v1-Table1-1.png",
            "$2305.00398v1-Table2-1.png",
            "$2305.00398v1-Table3-1.png",
            "$2305.00398v1-Table4-1.png",
            "$2305.00398v1-Table5-1.png",
            "$2305.00398v1-Table6-1.png",
            "$2305.00398v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00400",
        "abstract": "  The optimal power flow (OPF) problem is an important mathematical program\nthat aims at obtaining the best operating point of an electric power grid. The\noptimization problem typically minimizes the total generation cost subject to\ncertain physical constraints of the system. The so-called linearized\ndistribution flow (LinDistFlow) model leverages a set of linear equations to\napproximate the nonlinear AC power flows. In this paper, we consider an OPF\nproblem based on the LinDistFlow model for a single-phase radial power network.\nWe derive closed-form solutions to the marginal values of both real and\nreactive power demands. We also derive upper bounds on the congestion price\n(a.k.a. `shadow price'), which denotes the change in marginal demand prices\nwhen the apparent power flow limits of certain lines are binding at optimum.\nVarious cases of our result are discussed while simulations are carried out on\na $141$-bus radial power network.\n",
        "title": "On LinDistFlow Model Congestion Pricing: Bounding the Changes in Power\n  Tariffs",
        "texts": [
            "Fig. 1: Illustrative example of a 4-bus radial network.",
            "Fig. 2: 141-bus distribution system, adapted from MATPOWER case141. We retain the topology and real/reactive load demands from case141, but randomly add 25 distributed generation buses. The real power generation of each distributed generator is limited to pg ∈ [0, 0.0654]pu, while the reactive power generation follows limits qg ∈ [−0.0270, 0.0270]pu.",
            "Fig. 3: Results from simultaneously perturbing two branch flow limits from Figure 2. We choose branches 16 and 18 to perturb since branch 18 is downstream to branch 16, making for easier interpretability of results. The first two figures indicate marginal costs of real and reactive power respectively, while the third figure is the proposed upper bound on the quantities derived in both the first and second figure. As we see, the upper bound is valid for both the quantities."
        ],
        "imgs": [
            "$2305.00400v1-Figure1-1.png",
            "$2305.00400v1-Figure2-1.png",
            "$2305.00400v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00401",
        "abstract": "  Ultralight bosons are predicted in many extensions to the Standard Model and\nare popular dark matter candidates. The black hole superradiance mechanism\nallows for these particles to be probed using only their gravitational\ninteraction. In this scenario, an ultralight boson cloud may form spontaneously\naround a spinning black hole and extract a non-negligible fraction of the black\nhole's mass. These oscillating clouds produce quasi-monochromatic,\nlong-duration gravitational waves that may be detectable by ground-based or\nspace-based gravitational wave detectors. We discuss the capability of a new\nlong-duration signal tracking method, based on a hidden Markov model, to detect\ngravitational wave signals generated by ultralight vector boson clouds,\nincluding cases where the signal frequency evolution timescale is much shorter\nthan that of a typical continuous wave signal. We quantify the detection\nhorizon distances for vector boson clouds with current- and next-generation\nground-based detectors. We demonstrate that vector clouds hosted by black holes\nwith mass $\\gtrsim 60 M_{\\odot}$ and spin $\\gtrsim 0.6$ are within the reach of\ncurrent-generation detectors up to a luminosity distance of $\\sim 1$ Gpc. This\nsearch method enables one to target vector boson clouds around remnant black\nholes from compact binary mergers detected by gravitational-wave detectors. We\ndiscuss the impact of the sky localization of the merger events and demonstrate\nthat a typical remnant black hole reasonably well-localized by the current\ngeneration detector network is accessible in a follow-up search.\n",
        "title": "Methods and prospects for gravitational wave searches targeting\n  ultralight vector boson clouds around known black holes",
        "texts": [
            "FIG. 10. Horizon distance (colored contour) as a function of the initial black hole mass Mi and initial spin χi for two aLIGO detectors at design sensitivity (top), one Cosmic Explorer (middle), and one Einstein Telescope (bottom). The gray region marks the parameter space where the signal is evolving too quickly to be tracked using the method in this paper (ḟdet > 1.39 × 10−4 Hz s−1). The white contours mark the optimally matched [as defined in Eq. (20)] boson masses (in eV), roughly indicating the parameter space that can be probed with these ground-based detectors.",
            "FIG. 11. Horizon distance (colored contour) as a function of Mi and α (at χi = 0.7) for two aLIGO detectors at design sensitivity. The dashed white line marks αopt = 0.176, the α-value corresponding to the optimally matched boson mass for each black hole mass.",
            "FIG. 12. Colored contour of L̄/L̄th as a function of the offset in RA and Dec for a short-duration signal (left) and a long-duration signal (right). See Table II for the injection parameters. Left: We have L > L̄th in the whole panel. Right: The bright EPSF enclosed within the white contour marks the region of the sky with L̄ > L̄th where the signal is successfully recovered.",
            "FIG. 6. L̄th as a function of NT for Tcoh = 30 min (data points are taken at NT = 25, 50, 100, 200, 300, 400, and 500 steps). The solid curve is an exponential decay fit: L̄th = ae−bNT + c with fit parameters a = 2.99, b = 0.0168, and c = 6.66.",
            "FIG. 7. Viterbi tracking (solid orange curve) for a synthetic vector boson signal (dashed blue curve) injected into Gaussian noise with S 1/2 h = 4× 10−24 Hz−1/2 for two aLIGO detectors (system parameters: Mi = 200 M , χi = 0.6, αopt = 0.141, and d = 500 Mpc). We use Tcoh = 207 min = 3.45 hr and run the search for a total duration of ∼ 26 d (NT = 181 steps). The detection statistic is L̄ = 57.43 > L̄th = 6.73.",
            "FIG. 8. Viterbi tracking (solid orange curve) for a synthetic vector boson signal (dashed blue curve) injected into Gaussian noise with S 1/2 h = 4 × 10−24 Hz−1/2 for two aLIGO detectors (system parameters: Mi = 60 M , χi = 0.7, αopt = 0.176, and d = 500 Mpc). We use Tcoh = 11.6 min and run the search for a) 23 steps, b) 46 steps, c) 92 steps, and d) 184 steps, corresponding to Tobs = 0.25τGW, 0.5τGW, τGW, and 2τGW, respectively (τGW = 0.74 days). In panels b), c), and d), L̄ is above the corresponding threshold, whereas in panel a), L̄ < L̄th, which is a non-detection.",
            "FIG. 9. Horizon distance (colored contour) as a function of the initial black hole mass Mi and initial spin χi for two aLIGO detectors at design sensitivity. The gray region marks the parameter space where the signal is evolving too quickly to be tracked using the method in this paper (ḟdet > 1.39× 10−4 Hz s−1). The white contours mark the optimally matched boson masses [as defined in Eq. (20)] in eV.",
            "TABLE I. Matched filter SNRs for three sample systems at the estimated horizon distances using two aLIGO detectors."
        ],
        "imgs": [
            "$2305.00401v1-Figure10-1.png",
            "$2305.00401v1-Figure11-1.png",
            "$2305.00401v1-Figure12-1.png",
            "$2305.00401v1-Figure6-1.png",
            "$2305.00401v1-Figure7-1.png",
            "$2305.00401v1-Figure8-1.png",
            "$2305.00401v1-Figure9-1.png",
            "$2305.00401v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00403",
        "abstract": "  Recent years have seen tremendous advances in the theory and application of\nsequential experiments. While these experiments are not always designed with\nhypothesis testing in mind, researchers may still be interested in performing\ntests after the experiment is completed. The purpose of this paper is to aid in\nthe development of optimal tests for sequential experiments by analyzing their\nasymptotic properties. Our key finding is that the asymptotic power function of\nany test can be matched by a test in a limit experiment where a Gaussian\nprocess is observed for each treatment, and inference is made for the drifts of\nthese processes. This result has important implications, including a powerful\nsufficiency result: any candidate test only needs to rely on a fixed set of\nstatistics, regardless of the type of sequential experiment. These statistics\nare the number of times each treatment has been sampled by the end of the\nexperiment, along with final value of the score (for parametric models) or\nefficient influence function (for non-parametric models) process for each\ntreatment. We then characterize asymptotically optimal tests under various\nrestrictions such as unbiasedness, \\alpha-spending constraints etc. Finally, we\napply our our results to three key classes of sequential experiments: costly\nsampling, group sequential trials, and bandit experiments, and show how optimal\ninference can be conducted in these scenarios.\n",
        "title": "Optimal tests following sequential experiments",
        "texts": [
            "Figure 6.1. Finite sample performance of ϕ̂ under horizontal boundary designs"
        ],
        "imgs": [
            "$2305.00403v1-Figure6.1-1.png"
        ]
    },
    {
        "id": "2305.00404",
        "abstract": "  The China Space Station Telescope (CSST) is a forthcoming Stage IV galaxy\nsurvey. It will simultaneously undertake the photometric redshift (photo-z) and\nslitless spectroscopic redshift (spec-z) surveys mainly for weak lensing and\ngalaxy clustering studies. The two surveys cover the same sky area and overlap\non the redshift range. At $z>1$, due to the sparse number density of the spec-z\nsample, it limits the constraints on the scale of baryon acoustic oscillations\n(BAO). By cross-correlating the spec-z sample with the high density photo-z\nsample, we can effectively enhance the constraints on the angular diameter\ndistances $D_A(z)$ from the BAO measurement. Based on the Fisher matrix, we\nforecast a $\\geq$ 30 per cent improvement on constraining $D_A(z)$ from the\njoint analysis of the spec-z and cross galaxy power spectra at $1.0<z<1.2$.\nSuch improvement is generally robust against different systematic effects\nincluding the systematic noise and the redshift success rate of the spec-z\nsurvey, as well as the photo-z error. We also show the BAO constraints from\nother Stage-IV spectroscopic surveys for the comparison with CSST. Our study\ncan be a reference for the future BAO analysis on real CSST data. The\nmethodology can be applied to other surveys with spec-z and photo-z data in the\nsame survey volume.\n",
        "title": "Fisher forecast for the BAO measurements from the CSST spectroscopic and\n  photometric galaxy clustering",
        "texts": [
            "Figure 1.Normalized galaxy redshift distribution of theCSSTphoto-z survey. The mock distribution is built from the COSMOS catalogue. In the upper panel, the blue and orange bars denote the subsets of the COSMOS catalogue with different photo-z errors from the SED fitting. In the lower panel, we show the ratio between the two subsets.",
            "Figure 2. Galaxy redshift distribution of CSST slitless spec-z survey after normalization. We model the mock distribution based on the zCOSMOS catalogue. The gray bars are the normalized galaxy number distribution. The blue line denotes the galaxy number density distribution with the fiducial setting. The density drops below 10−4 ℎ3Mpc−3 at 𝑧 > 1.0. The vertical dotted lines denote the boundaries of the eight redshift bins that we divide.",
            "Figure 3. Fisher forecast of the 1𝜎 constraints on 𝐷𝐴 (𝑧)/𝑟d (in left panel) and 𝐻 (𝑧)𝑟d (in right panel) from the BAO measurements based on the CSST spec-z and photo-z galaxy power spectra, as well as their joint analyses. Each type of markers represents one case, denoted in the legend. We do not take any systematic noise in the power spectra. For 𝐷𝐴 (𝑧)/𝑟𝑑 , the spec-z constraint increases as redshift increases until 𝑧 ' 1.0, beyond which the shot noise dominates. From the photo-z constraint keeps increasing as 𝑧 is larger, and surpasses the spec-z one when 𝑧 > 1.0. At high redshifts, adding the cross-correlation between the spec-z and photo-z data can tighten the constraints from the spec-z alone, shown as the green and red points. For 𝐻 (𝑧)𝑟d, due to large photo-z error, the dominant constraint is from the spec-z. The highest constraint is about 2 per cent at 0.8 < 𝑧 < 1.0.",
            "Figure 4. Reduction of the constraints on 𝐷A (𝑧)/𝑟d and 𝐻 (𝑧)𝑟d due to the systematic noise 𝑃sys in the spec-z galaxy power spectrum. We show the ratio of the 1𝜎 constraints from the spec-z tracer with and without considering 𝑃sys. The left panel is for 𝐷A (𝑧)/𝑟d, and the right panel is for 𝐻 (𝑧)𝑟d. Different colors denote different values of 𝑃sys considered. We vary the systematic noise from 0 to 104 ℎ−3Mpc3.",
            "Figure 5. Increase of the constraints on 𝐷𝐴 (𝑧)/𝑟d from the spec-z+cross compared to that from the spec-z tracer, shown as the solid lines. Different colors indicate different systematic noises considered in the spec-z power spectrum. We overplot the results from the spec-z+cross+photo-z, shown as the dotted lines.",
            "Figure 6. Dependence of the 𝐷A (𝑧)/𝑟d constraints on the redshift success rate. We divide the constraint from the spec-z+cross joint analyses with a lower or higher redshift success rate in the spec-z data over that with the fiducial one. The upper (lower) panel is for the case with a lower (higher) redshift success rate. Different colors denote different 𝑃sys considered in the spec-z power spectrum.",
            "Figure 7.Dependence of the𝐷A (𝑧)/𝑟d constraints on the redshift error of the photo-z sample in the joint analyses.We show the ratio of the constraints from the fiducial case over that with larger photo-z error 𝜎𝑧 = 0.05(1 + 𝑧) . The solid lines are the results of the spec-z+cross, and the dotted lines are from the spec-z+cross+photo-z. Increasing the photo-z error reduces the constraints from the joint analyses.",
            "Table 1. Parameters of the CSST spec-z and photo-z surveys with the sky coverage 17500 deg2. We set eight tomographic bins in the redshift range 0 < 𝑧 < 1.6 with the bin width 0.2. The galaxy bias is assumed as 𝑏𝑔 (𝑧) = 1 + 0.84𝑧 for both the spec-z and photo-z galaxy distributions. We show the number density of galaxies from the two surveys. For the spec-z sample, the redshift error is set to be 𝜎𝑧 = 0.002(1 + 𝑧) , and the number density is down-sampled by 0.5/(1 + 𝑧) on the original distribution based on ZCOSMOS. For the photo-z sample, we use the distribution with the redshift error 𝜎𝑧 = 0.025(1+ 𝑧) , and show the results in parentheses. The power spectrum damping parameter Σ𝑧 = 𝑐𝜎𝑧/𝐻 (𝑧) due to the redshift measurement error is also given. Furthermore, we show the S/N ratio ?̄?𝑔𝑃𝑔 and the effective volume 𝑉eff at (𝑘 = 0.16 ℎMpc−1, ` = 0.6) and (𝑘 = 0.2 ℎMpc−1, ` = 0) , respectively. As the default case, we assume the spec-z systematic noise 𝑃sys = 0.",
            "Table 2. Fisher forecast on the 1𝜎 fractional errors of 𝐷A (𝑧)/𝑟d and 𝐻 (𝑧)𝑟d (in per cent) constrained by the BAO measurements from the CSST galaxy surveys. As the fiducial case, we do not consider any systematic noise in the spec-z galaxy power spectrum. For each redshift bin, we consider the constraints from the spec-z and the photo-z auto power spectrum, respectively. In addition, we show the results from the spec-z power spectrum combined with the cross power spectra between the spec-z and photo-z data, as well as the joint analyses of the spec-z, photo-z auto and cross power spectra."
        ],
        "imgs": [
            "$2305.00404v1-Figure1-1.png",
            "$2305.00404v1-Figure2-1.png",
            "$2305.00404v1-Figure3-1.png",
            "$2305.00404v1-Figure4-1.png",
            "$2305.00404v1-Figure5-1.png",
            "$2305.00404v1-Figure6-1.png",
            "$2305.00404v1-Figure7-1.png",
            "$2305.00404v1-Table1-1.png",
            "$2305.00404v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00406",
        "abstract": "  Simultaneous localization and mapping (SLAM) is critical to the\nimplementation of autonomous driving. Most LiDAR-inertial SLAM algorithms\nassume a static environment, leading to unreliable localization in dynamic\nenvironments. Moreover, the accurate tracking of moving objects is of great\nsignificance for the control and planning of autonomous vehicles. This study\nproposes LIMOT, a tightly-coupled multi-object tracking and LiDAR-inertial\nodometry system that is capable of accurately estimating the poses of both\nego-vehicle and objects. We propose a trajectory-based dynamic feature\nfiltering method, which filters out features belonging to moving objects by\nleveraging tracking results before scan-matching. Factor graph-based\noptimization is then conducted to optimize the bias of the IMU and the poses of\nboth the ego-vehicle and surrounding objects in a sliding window. Experiments\nconducted on the KITTI tracking dataset and self-collected dataset show that\nour method achieves better pose and tracking accuracy than our previous work\nDL-SLOT and other baseline methods. Our open-source implementation is available\nat https://github.com/tiev-tongji/LIMOT.\n",
        "title": "LIMOT: A Tightly-Coupled System for LiDAR-Inertial Odometry and\n  Multi-Object Tracking",
        "texts": [
            "Fig. 1. The system architecture of LIMOT. The system consists of the preprocessing, LiDAR odometry, the sliding window-based 3D multi-object tracking, and factor graph optimization.",
            "Fig. 2. Example of filtering out dynamic feature points. The light blue points denote the original point cloud and the red points denote the feature points. The feature points on the moving cars (b) and (c) are removed exactly by LIMOT, while the feature points on the static car (a) are remained.",
            "Fig. 4. Qualitative results of LIMOT on the KITTI tracking dataset. (a) Comparison of ego-trajectories in sequence 04 of the KITTI tracking dataset. (b) Comparison of point cloud maps generated by LIO-SAM and LIMOT. (c) Trajectories of the main tracked object (id 0) and ego-vehicle in sequence 10 of the KITTI tracking dataset. (d) Comparison between the ground truth and estimated instantaneous velocity of the tracked object in (c).",
            "Fig. 5. The overview of the self-collected dataset. (a) LIMOT mapping result aligning with the satellite map. (b) A representative front view image of the self-collected dataset.",
            "TABLE II MOTP [%] RESULT COMPARISON OF DIFFERENT MULTI-OBJECT TRACKING ALGORITHMS ON THE KITTI TRACKING DATASET",
            "TABLE III RESULTS OF OBJECT POSE ESTIMATION COMPARISON ON THE KITTI TRACKING DATASET. BOLD AND UNDERLINED TEXT INDICATE THE BEST AND THE SUBOPTIMAL RESULT, RESPECTIVELY",
            "TABLE IV RESULTS OF POSE ESTIMATION COMPARISON ON THE SELF-COLLECTED DATASET. BOLD AND UNDERLINED TEXT INDICATE THE BEST AND THE SUBOPTIMAL RESULT, RESPECTIVELY",
            "TABLE V AVERAGE TIME-CONSUMING OF THE MAIN FUNCTIONAL MODULES FOR PROCESSING ONE SCAN"
        ],
        "imgs": [
            "$2305.00406v2-Figure1-1.png",
            "$2305.00406v2-Figure2-1.png",
            "$2305.00406v2-Figure4-1.png",
            "$2305.00406v2-Figure5-1.png",
            "$2305.00406v2-TableII-1.png",
            "$2305.00406v2-TableIII-1.png",
            "$2305.00406v2-TableIV-1.png",
            "$2305.00406v2-TableV-1.png"
        ]
    },
    {
        "id": "2305.00408",
        "abstract": "  Extended Boolean functions (EBFs) are one of the most important tools in\ncryptography and spreading sequence design in communication systems. In this\npaper, we use EBFs to design new sets of spreading sequences for non-orthogonal\nmultiple access (NOMA), which is an emerging technique capable of supporting\nmassive machine-type communications (mMTC) in 5G and beyond. In this work,\nfirst $p$-ary complementary sequences are constructed using EBFs and then,\nthese sequences are used to design new sets of non-orthogonal spreading\nsequence sets having very low coherence and peak to average power ratio (PAPR).\nThe proposed spreading sequence sets are capable of supporting a large number\nof active devices simultaneously. In fact, for a $p$-ary spreading sequence\nset, we theoretically achieve an overloading factor of $2p$, where $p$ is an\nodd prime. Specifically, for $p=3$, we achieve an overloading factor of $6$,\nwhich cannot be achieved through the existing constructions till date.\n",
        "title": "New sets of Non-Orthogonal Spreading Sequences With Low Correlation and\n  Low PAPR Using Extended Boolean Functions",
        "texts": [
            "Table 1 The spreading sequences corresponding to the matrices Ai for 1 ≤ i ≤ 6, in Example 4.",
            "Table 2 The parameters of the spreading sequence matrices proposed till date."
        ],
        "imgs": [
            "$2305.00408v2-Table1-1.png",
            "$2305.00408v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00411",
        "abstract": "  Globally, Coronary Heart Disease (CHD) is one of the main causes of death.\nEarly detection of CHD can improve patient outcomes and reduce mortality rates.\nWe propose a novel framework for predicting the presence of CHD using a\ncombination of machine learning and image processing techniques. The framework\ncomprises various phases, including analyzing the data, feature selection using\nReliefF, 3D CNN-based segmentation, feature extraction by means of transfer\nlearning, feature fusion as well as classification, and Adagrad optimization.\nThe first step of the proposed framework involves analyzing the data to\nidentify patterns and correlations that may be indicative of CHD. Next, ReliefF\nfeature selection is applied to decide on the most relevant features from the\nsample images. The 3D CNN-based segmentation technique is then used to segment\nthe optic disc and macula, which are important regions for CHD diagnosis.\nFeature extraction using transfer learning is performed to extract features\nfrom the segmented regions of interest. The extracted features are then fused\nusing a feature fusion technique, and a classifier is trained to predict the\npresence of CHD. Finally, Adagrad optimization is used to optimize the\nperformance of the classifier. Our framework is evaluated on a dataset of\nsample images collected from patients with and without CHD. The results show\nthat the anticipated framework accomplishes elevated accuracy in predicting the\npresence of CHD. either a particular user with a reasonable degree of accuracy\ncompared to the previously employed classifiers like SVM, etc.\n",
        "title": "Optimized Machine Learning for CHD Detection using 3D CNN-based\n  Segmentation, Transfer Learning and Adagrad Optimization",
        "texts": [
            "Fig. 1 Technical architecture of coronary heart disease (CHD) detection",
            "Fig. 2 Feature extraction by means of transfer learning",
            "Fig. 6 Comparison of occurrences in heart disease due to pain type",
            "Fig. 7 Accuracy comparison between various classifiers",
            "Fig. 8 Precision, recall, and F measure comparison between various classifiers",
            "Table 1. Key study on coronary heart disease",
            "Table 2. Performance of classifiers"
        ],
        "imgs": [
            "$2305.00411v1-Figure1-1.png",
            "$2305.00411v1-Figure2-1.png",
            "$2305.00411v1-Figure6-1.png",
            "$2305.00411v1-Figure7-1.png",
            "$2305.00411v1-Figure8-1.png",
            "$2305.00411v1-Table1-1.png",
            "$2305.00411v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00414",
        "abstract": "  As a possible alternative to black holes, horizonless compact objects have\nsignificant implications for gravitational-wave physics. In this work, we\nutilize the standard linearized theory of general relativity to calculate the\nquadrupolar tidal Love numbers of a nonexotic compact object with a thin shell\nproposed by Rosa and Pi\\c{c}arra. It is found that both types of tidal Love\nnumbers are positive and increase with the initial radius for almost all values\nof the compactness parameter. Furthermore, they have an unexpected upper bound\nand vanish in the most compact configurations. As a result, this model is\nindeed a suitable mimicker of a black hole. However, we also observed that the\nspeed of sound within the fluid on the shell diverges in the black hole limit.\n",
        "title": "Tidal Love numbers of a nonexotic compact object with a thin shell",
        "texts": [
            "FIG. 2. Speed of sound v2 s on the shell against the compactness C for few values of R. Except for the case of R = RΣ (dashed black), it is easily found that v2 s ranges between (0, 1) for a wide region of C, but diverges in the BH limit. Actually, the sound speed of the R → ∞ configuration (solid red) has already reached the speed of light, when C = 0.48."
        ],
        "imgs": [
            "$2305.00414v2-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00415",
        "abstract": "  We analyze the measurement of cosmological distances in the presence of\ntorsion in both Einstein-Cartan and Poincare gauge theory of gravity. Using the\nmodified cosmological distance measurements, we use the observed time delays in\ngravitational lensing systems to determine the Hubble parameter. The results\nshow the measured Hubble parameter from a lensing system can be less than its\nexpected value in General Relativity for certain models of torsion and its\nassociated density parameter. This can reduce the tension between late-time and\nearly-universe measurements of the Hubble parameter, the so-called Hubble\ntension.\n",
        "title": "Cosmological Distances And Hubble Tension In Einstein-Cartan Theory",
        "texts": [
            "TABLE I: Hubble parameter measurement for some well-studied gravitational lensing systems. The first column gives the name of the source and references where the table values are given. The next three columns give the measured time delays, redshift of the lens, and redshift of the source respectively, as given in the mentioned references. The fifth column gives the measured value of H0 in the framework of ΛCDM cosmology and General Relativity, as measured in the aforementioned references. The last column gives the results of this paper where the effects of torsion in the measurement of cosmological distances are considered in determining the value of H0. The H0 value in the last column is derived for the case B mentioned in equation (35) and value of η0 is assumed to be −0.1."
        ],
        "imgs": [
            "$2305.00415v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00417",
        "abstract": "  Audio classification is vital in areas such as speech and music recognition.\nFeature extraction from the audio signal, such as Mel-Spectrograms and MFCCs,\nis a critical step in audio classification. These features are transformed into\nspectrograms for classification. Researchers have explored various techniques,\nincluding traditional machine and deep learning methods to classify\nspectrograms, but these can be computationally expensive. To simplify this\nprocess, a more straightforward approach inspired by sequence classification in\nNLP can be used. This paper proposes a Transformer-encoder-based model for\naudio classification using MFCCs. The model was benchmarked against the ESC-50,\nSpeech Commands v0.02 and UrbanSound8k datasets and has shown strong\nperformance, with the highest accuracy of 95.2% obtained upon training the\nmodel on the UrbanSound8k dataset. The model consisted of a mere 127,544 total\nparameters, making it light-weight yet highly efficient at the audio\nclassification task.\n",
        "title": "Transformer-based Sequence Labeling for Audio Classification based on\n  MFCCs",
        "texts": [
            "TABLE II. ESC-50: STATISTICS PER FOLD",
            "TABLE III. SPEECH COMMANDS V0.2: STATISTICS PER FOLD",
            "TABLE IV. URBANSOUND8K: STATISTICS PER FOLD"
        ],
        "imgs": [
            "$2305.00417v1-TableII-1.png",
            "$2305.00417v1-TableIII-1.png",
            "$2305.00417v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00418",
        "abstract": "  A code generation model generates code by taking a prompt from a code\ncomment, existing code, or a combination of both. Although code generation\nmodels (e.g., GitHub Copilot) are increasingly being adopted in practice, it is\nunclear whether they can successfully be used for unit test generation without\nfine-tuning for a strongly typed language like Java. To fill this gap, we\ninvestigated how well three models (Codex, GPT-3.5-Turbo, and StarCoder) can\ngenerate unit tests. We used two benchmarks (HumanEval and Evosuite SF110) to\ninvestigate the effect of context generation on the unit test generation\nprocess. We evaluated the models based on compilation rates, test correctness,\ntest coverage, and test smells. We found that the Codex model achieved above\n80% coverage for the HumanEval dataset, but no model had more than 2% coverage\nfor the EvoSuite SF110 benchmark. The generated tests also suffered from test\nsmells, such as Duplicated Asserts and Empty Tests.\n",
        "title": "Using Large Language Models to Generate JUnit Tests: An Empirical Study",
        "texts": [
            "Fig. 1. Compilation rates for HumanEval and SF110 across different scenarios",
            "Fig. 2. Correctness rates across different datasets, scenarios, and LLMs",
            "Fig. 3. Line and Branch Coverage across different datasets, scenarios, and LLMs (EVS = Evosuite; MNL = Manual).",
            "TABLE I COMPILATION STATUS OF THE GENERATED UNIT TESTS",
            "TABLE III LINE AND BRANCH COVERAGE",
            "TABLE IV TEST SMELLS DISTRIBUTION FOR THE HUMANEVAL DATASET (RQ1).",
            "TABLE V TEST SMELLS DISTRIBUTION FOR THE SF110 DATASET (RQ1).",
            "TABLE VI TEST SMELLS DISTRIBUTION FOR THE HUMANEVAL DATASET (RQ2).",
            "TABLE VII TEST SMELLS DISTRIBUTION FOR THE SF110 DATASET (RQ2)."
        ],
        "imgs": [
            "$2305.00418v1-Figure1-1.png",
            "$2305.00418v1-Figure2-1.png",
            "$2305.00418v1-Figure3-1.png",
            "$2305.00418v1-TableI-1.png",
            "$2305.00418v1-TableIII-1.png",
            "$2305.00418v1-TableIV-1.png",
            "$2305.00418v1-TableV-1.png",
            "$2305.00418v1-TableVI-1.png",
            "$2305.00418v1-TableVII-1.png"
        ]
    },
    {
        "id": "2305.00419",
        "abstract": "  Socially assistive robots (SARs) are becoming more prevalent in everyday\nlife, emphasizing the need to make them socially acceptable and aligned with\nusers' expectations. Robots' appearance impacts users' behaviors and attitudes\ntowards them. Therefore, product designers choose visual qualities to give the\nrobot a character and to imply its functionality and personality. In this work,\nwe sought to investigate the effect of cultural differences on Israeli and\nGerman designers' perceptions and preferences regarding the suitable visual\nqualities of SARs in four different contexts: a service robot for an assisted\nliving/retirement residence facility, a medical assistant robot for a hospital\nenvironment, a COVID-19 officer robot, and a personal assistant robot for\ndomestic use. Our results indicate that Israeli and German designers share\nsimilar perceptions of visual qualities and most of the robotics roles.\nHowever, we found differences in the perception of the COVID-19 officer robot's\nrole and, by that, its most suitable visual design. This work indicates that\ncontext and culture play a role in users' perceptions and expectations;\ntherefore, they should be taken into account when designing new SARs for\ndiverse contexts.\n",
        "title": "Designing Socially Assistive Robots: Exploring Israeli and German\n  Designers' Perceptions",
        "texts": [
            "Figure 10: Israeli and German designers' body structure selection in the COR context.",
            "Figure 13: Relations between selected characteristics and structure selection.",
            "Figure 2: Relations between selected characteristics and color selection.",
            "Figure 3: Respondents' assigned characteristics for the context of MAR by culture",
            "Figure 4: Respondents' assigned characteristics for the context of ALR by culture.",
            "Figure 5: Respondents' assigned characteristics for the context of PAR by culture.",
            "Figure 6: Respondents' assigned characteristics for the context of COR by culture.",
            "Figure 7: designers' structure selections by context",
            "Figure 8: the designers' outline selections by context.",
            "Figure 9: The designers' color selections by context.",
            "Table 1. Respondents' data by use case",
            "Table 10: Designers' selection of Visual qualities.",
            "Table 2: Respondents' professional backgrounds",
            "Table 3: Factors affecting the designers' selection of words",
            "Table 4. Most selected words (over 65%) for each context and their rate.",
            "Table 6. Most selected words by Israeli and German designers (over 65%) for the context of MAR and their rate.",
            "Table 7. Most selected words by Israeli and German designers (over 65%) for the context of ALR and their rate.",
            "Table 8. Most selected words by Israeli and German designers (over 65%) for the context of PAR and their rate.",
            "Table 9. Most selected words by Israeli and German designers (over 65%) for the context of COR and their rate."
        ],
        "imgs": [
            "$2305.00419v1-Figure10-1.png",
            "$2305.00419v1-Figure13-1.png",
            "$2305.00419v1-Figure2-1.png",
            "$2305.00419v1-Figure3-1.png",
            "$2305.00419v1-Figure4-1.png",
            "$2305.00419v1-Figure5-1.png",
            "$2305.00419v1-Figure6-1.png",
            "$2305.00419v1-Figure7-1.png",
            "$2305.00419v1-Figure8-1.png",
            "$2305.00419v1-Figure9-1.png",
            "$2305.00419v1-Table1-1.png",
            "$2305.00419v1-Table10-1.png",
            "$2305.00419v1-Table2-1.png",
            "$2305.00419v1-Table3-1.png",
            "$2305.00419v1-Table4-1.png",
            "$2305.00419v1-Table6-1.png",
            "$2305.00419v1-Table7-1.png",
            "$2305.00419v1-Table8-1.png",
            "$2305.00419v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00421",
        "abstract": "  Quantum sensors provide unprecedented magnetic field detection sensitivities,\nenabling these to extend the common magnetometry range of applications and\nenvironments of operation. In this framework, many applications also require\nhigh spatial resolution magnetic measurements for biomedical research,\nenvironmental monitoring and industrial production. In this regard, Optically\nPumped Magnetometers (OPMs) are considered as prominent candidates, but are\nimpaired in size with micrometer scale magnetic particles, e.g. magnetic\ndroplets. In order to address this limitation, here we study the effects of\nadding a micrometer-to-millimeter magnetic guide to a miniature OPM. This\ndevice is applied to detect Fe3O4 magnetic droplets flowing at rates up to $25$\ndrop./s in a microfluidic channel. The computed spatial resolution is $300$\n$\\mu$m and the measured SNR is larger than $15$ dB for the different sizes of\nconsidered magnetic droplets.\n",
        "title": "Optically Pumped Magnetometer with High Spatial Resolution Magnetic\n  Guide for the Detection of Magnetic Droplets in a Microfluidic Channel",
        "texts": [
            "Figure 1: Schematics of (a) the OPM with conical magnetic guide (OPM-MG) aligned to the microchannel and (b) the test system.",
            "Figure 2: Schematics and prototype of the assembled mounting structure to hold the OPM-MG and the microfluidic channel chip. (a) Inside the Zero Gauss chamber, (b) close view of the alignment system to the microchannel, and (c) the microfluidic system assembly.",
            "Figure 3: Numerical estimation of the behavior of the MG with regard to magnetic field transferring performance (as gain) and spatial resolution of depth/width (as FWHM) for different parameters.",
            "Figure 4: Normalized Bz with the OPM-MG system where (a) represents the scalar magnitude and (b) the spatial coupled magnetic field ratio (dashed line indicating the FWHM), both in the xz-plane.",
            "Figure 5: Estimation of the loss factor in sensitivity (or signal) of the OPM module for different rates of droplets, considering (a) 1% magnetic field inhomogeneity ratio, normalized (with respect to 5 drop./s) volume size of magnetic droplets (Norm. size mag. drop.), confirmed with experimental values (magenta diamonds), and 980Hz modulation frequency (Mod. freq.), and (b) numerical study with different magnetic polarization values, for different dimensions of the MG, to produce a relevant inhomogeneity ratio above 1% (black solid line).",
            "Figure 6: Magnetic droplets detection at a rate of 25 drop./s (a) in the frequency domain and (b) in the time domain.",
            "Figure 7: Logarithmic representation of the magnetic droplet volume (in nL) vs. SNR (magenta diamonds) from Table 1. Accordingly, an exponential fitting curve (purple dashed line) is also represented to show the near-linear relation with R2 = 0.88 correlation coefficient.",
            "Table 1: 5 to 25 drop./s rate characteristics of the detected peaks from the magnetic droplets."
        ],
        "imgs": [
            "$2305.00421v1-Figure1-1.png",
            "$2305.00421v1-Figure2-1.png",
            "$2305.00421v1-Figure3-1.png",
            "$2305.00421v1-Figure4-1.png",
            "$2305.00421v1-Figure5-1.png",
            "$2305.00421v1-Figure6-1.png",
            "$2305.00421v1-Figure7-1.png",
            "$2305.00421v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00426",
        "abstract": "  Automatic music transcription (AMT) is one of the most challenging tasks in\nthe music information retrieval domain. It is the process of converting an\naudio recording of music into a symbolic representation containing information\nabout the notes, chords, and rhythm. Current research in this domain focuses on\ndeveloping new models based on transformer architecture or using methods to\nperform semi-supervised training, which gives outstanding results, but the\ncomputational cost of training such models is enormous.\n  This work shows how to employ easily generated synthesized audio data\nproduced by software synthesizers to train a universal model. It is a good base\nfor further transfer learning to quickly adapt transcription model for other\ninstruments. Achieved results prove that using synthesized data for training\nmay be a good base for pretraining general-purpose models, where the task of\ntranscription is not focused on one instrument.\n",
        "title": "Transfer of knowledge among instruments in automatic music transcription",
        "texts": [
            "Fig. 1. Architecture of base model used for experiments.",
            "Fig. 2. Pipeline for training based on synthesized instruments and evaluation of results.",
            "Fig. 3. Validation on target datasets during training of models.",
            "Table 1. Results for frame metrics",
            "Table 2. Results for note metrics"
        ],
        "imgs": [
            "$2305.00426v1-Figure1-1.png",
            "$2305.00426v1-Figure2-1.png",
            "$2305.00426v1-Figure3-1.png",
            "$2305.00426v1-Table1-1.png",
            "$2305.00426v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00427",
        "abstract": "  Web3, the next generation of the Internet, represents a decentralized and\ndemocratized web. Although it has garnered significant public interest and\nfound numerous real-world applications, there is a limited understanding of\npeople's perceptions and experiences with Web3. In this study, we conducted an\nempirical study to investigate the categories of Web3 application and their\npopularity, as well as the potential challenges and opportunities within this\nemerging landscape. Our research was carried out in two phases. In the first\nphase, we analyzed 200 popular Web3 projects associated with 10 leading Web3\nventure capital firms. In the second phase, we collected and examined\ncode-related data from GitHub and market-related data from blockchain browsers\n(e.g., Etherscan) for these projects. Our analysis revealed that the Web3\necosystem can be categorized into two groups, i.e., Web3 infrastructure and\nWeb3 applications, with each consisting of several subcategories or subdomains.\nWe also gained insights into the popularity of these Web3 projects at both the\ncode and market levels and pointed out the challenges in the Web3 ecosystem at\nthe system, developer, and user levels, as well as the opportunities it\npresents. Our findings contribute to a better understanding of Web3 for\nresearchers and developers, promoting further exploration and advancement in\nthis innovative field.\n",
        "title": "An overview of Web3.0 Technology: Infrastructure, Applications, and\n  Popularity",
        "texts": [
            "Fig. 1 The ecosystem of Web3",
            "Fig. 2 Distributions of blockchain networks",
            "Fig. 4 Distributions of user counts and market cap. mBCs denotes the Applications deployed across multiple blockchains. sBC denotes the applications deployed on a single blockchain. OSAs denote open source applications, while NOSAs denote non-open-source applications",
            "Fig. 5 Number of users of a Web3 applications between January 2022 and January 2023.",
            "Table 1 Code-related data of Web3 projects.",
            "Table 2 Market-related data of Web3 projects. # Cnt denotes the number of Web3 projects in the subcategory. # property rights denotes the subcategory of NFT Property rights. # Eliminating inters denotes the subcategory of Web3 for eliminating intermediaries."
        ],
        "imgs": [
            "$2305.00427v1-Figure1-1.png",
            "$2305.00427v1-Figure2-1.png",
            "$2305.00427v1-Figure4-1.png",
            "$2305.00427v1-Figure5-1.png",
            "$2305.00427v1-Table1-1.png",
            "$2305.00427v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00428",
        "abstract": "  In this paper, simultaneously transmitting and reflecting (STAR)\nreconfigurable intelligent surface (RIS) is investigated in the multi-user\nmobile edge computing (MEC) system to improve the computation rate. Compared\nwith traditional RIS-aided MEC, STAR-RIS extends the service coverage from\nhalf-space to full-space and provides new flexibility for improving the\ncomputation rate for end users. However, the STAR-RIS-aided MEC system design\nis a challenging problem due to the non-smooth and non-convex binary amplitude\ncoefficients with coupled phase shifters. To fill this gap, this paper\nformulates a computation rate maximization problem via the joint design of the\nSTAR-RIS phase shifts, reflection and transmission amplitude coefficients, the\nreceive beamforming vectors, and energy partition strategies for local\ncomputing and offloading. To tackle the discontinuity caused by binary\nvariables, we propose an efficient smoothing-based method to decrease\nconvergence error, in contrast to the conventional penalty-based method, which\nbrings many undesired stationary points and local optima. Furthermore, a fast\niterative algorithm is proposed to obtain a stationary point for the joint\noptimization problem, with each subproblem solved by a low-complexity\nalgorithm, making the proposed design scalable to a massive number of users and\nSTAR-RIS elements. Simulation results validate the strength of the proposed\nsmoothing-based method and show that the proposed fast iterative algorithm\nachieves a higher computation rate than the conventional method while saving\nthe computation time by at least an order of magnitude. Moreover, the resultant\nSTAR-RIS-aided MEC system significantly improves the computation rate compared\nto other baseline schemes with conventional reflect-only/transmit-only RIS.\n",
        "title": "STAR-RIS-Aided Mobile Edge Computing: Computation Rate Maximization with\n  Binary Amplitude Coefficients",
        "texts": [
            "Fig. 3: Comparisons of convergence behavior with M = 30, N = 10, K = 8.",
            "Fig. 4: Convergence behaviour of the proposed algorithms with M = 30, N = 10, K = 8.",
            "Fig. 5: Performance gains over the penalty-based method with N = 10, K = 8.",
            "Fig. 6: Average computation time compared with the SDR-DC and penalty-based method.",
            "Fig. 7: Computation rate versus the number of elements with K = 8, N = 10.",
            "Fig. 8: Computation rate versus the number of users and number of antennas at the AP with M = 30."
        ],
        "imgs": [
            "$2305.00428v1-Figure3-1.png",
            "$2305.00428v1-Figure4-1.png",
            "$2305.00428v1-Figure5-1.png",
            "$2305.00428v1-Figure6-1.png",
            "$2305.00428v1-Figure7-1.png",
            "$2305.00428v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00429",
        "abstract": "  Stringent line-of-sight demands necessitated by the fast attenuating nature\nof millimeter waves (mmWaves) through obstacles pose one of the central\nproblems of next generation wireless networks. These mmWave links are easily\ndisrupted due to obstacles, including vehicles and pedestrians, which cause\ndegradation in link quality and even link failure. Dynamic obstacles are\nusually tracked by dedicated tracking hardware like RGB-D cameras, which\nusually have small ranges, and hence lead to prohibitively increased deployment\ncosts to achieve complete coverage of the deployment area. In this manuscript,\nwe propose an altogether different approach to track multiple dynamic obstacles\nin an mmWave network, solely based on short-term historical link failure\ninformation, without resorting to any dedicated tracking hardware. After\nproving that the said problem is NP-complete, we employ a greedy set-cover\nbased approach to solve it. Using the obtained trajectories, we perform\nproactive handoffs for at-risk links. We compare our approach with an RGB-D\ncamera-based approach and show that our approach provides better tracking and\nhandoff performances when the camera coverage is low to moderate, which is\noften the case in real deployment scenarios.\n",
        "title": "A Dynamic Obstacle Tracking Strategy for Proactive Handoffs in\n  Millimeter-wave Networks",
        "texts": [
            "Figure 1: A dynamic obstacle blocking a few links",
            "Figure 2: A time epoch 𝑇",
            "Figure 5: Handoff performance vs RGB-D camera count",
            "Figure 6: Accuracy, Sensitivity and Precision vs. Discovery time 𝜏 for varying number of dynamic obstacles and link requests"
        ],
        "imgs": [
            "$2305.00429v2-Figure1-1.png",
            "$2305.00429v2-Figure2-1.png",
            "$2305.00429v2-Figure5-1.png",
            "$2305.00429v2-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00431",
        "abstract": "  The Advanced Wakefield Experiment (AWAKE) at CERN relies on the seeded\nSelf-Modulation (SM) of a long relativistic proton bunch in plasma to\naccelerate an externally injected MeV witness electron bunch to GeV energies.\nDuring AWAKE Run 1 (2016-2018) and Run 2a (2021-2022), two seeding methods were\ninvestigated experimentally: relativistic ionization front seeding and electron\nbunch seeding. In the first one, a short laser pulse copropagates within the\nproton bunch and ionizes the rubidium vapor, generating the plasma. In the\nsecond, a short electron bunch propagates in plasma ahead of the proton bunch\nand drives the seed wakefields. Both seeding methods will be further employed\nduring AWAKE Run 2b (2023-2024) to study their effect on the SM evolution in\nthe presence of a plasma density step. In this contribution, we will show the\nmain experimental results and discuss their impact for the future design of the\nexperiment, in particular for Run 2c (starting in 2028), where the plasma will\nbe split in two sections: one dedicated to SM of the proton bunch, and the\nother to the electron acceleration process.\n",
        "title": "Techniques to seed the self-modulation instability of a long proton\n  bunch in plasma",
        "texts": [
            "Figure 1: Experimental setup of AWAKE Run 1, 2a-b (a) and Run 2c (b).",
            "Figure 2: Ten consecutive time-resolved images of the selfmodulated 𝑝+ bunch in case of RIF propagating 600 ps (a) and 350 ps (b) ahead of the bunch center. The bunch propagates from left to right. 𝑛𝑝𝑒 = 0.94 × 1014 cm−3. Figure reproduced from [16].",
            "Figure 3: Time-resolved images of the 𝑝+ bunch at a screen emitting optical transition radiation and positioned 3.5 m downstream of the plasma exit. Each image is the average of 10 single-event images. Bunch center at t=0 ps, the bunch travels from left to right. (a) No plasma (incoming bunch). (b) Plasma (𝑛𝑝𝑒 = 1.02× 1014 cm−3) and seed 𝑒− bunch. (c) Same as (b) but 𝑒− bunch delayed by 6.7 ps All images have the same color scale. (d) On-axis time profiles of (b) (blue line) and (c) (red line) obtained by summing counts over -0.217 ≤ 𝑦 ≤ 0.217 mm. Figure reproduced from [17]."
        ],
        "imgs": [
            "$2305.00431v1-Figure1-1.png",
            "$2305.00431v1-Figure2-1.png",
            "$2305.00431v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00432",
        "abstract": "  Nowadays, there is a wide availability of datasets that enable the training\nof common object detectors or human detectors. These come in the form of\nlabelled real-world images and require either a significant amount of human\neffort, with a high probability of errors such as missing labels, or very\nconstrained scenarios, e.g. VICON systems. On the other hand, uncommon\nscenarios, like aerial views, animals, like wild zebras, or difficult-to-obtain\ninformation, such as human shapes, are hardly available. To overcome this,\nsynthetic data generation with realistic rendering technologies has recently\ngained traction and advanced research areas such as target tracking and human\npose estimation. However, subjects such as wild animals are still usually not\nwell represented in such datasets. In this work, we first show that a\npre-trained YOLO detector can not identify zebras in real images recorded from\naerial viewpoints. To solve this, we present an approach for training an animal\ndetector using only synthetic data. We start by generating a novel synthetic\nzebra dataset using GRADE, a state-of-the-art framework for data generation.\nThe dataset includes RGB, depth, skeletal joint locations, pose, shape and\ninstance segmentations for each subject. We use this to train a YOLO detector\nfrom scratch. Through extensive evaluations of our model with real-world data\nfrom i) limited datasets available on the internet and ii) a new one collected\nand manually labelled by us, we show that we can detect zebras by using only\nsynthetic data during training. The code, results, trained models, and both the\ngenerated and training data are provided as open-source at\nhttps://eliabntt.github.io/grade-rr.\n",
        "title": "Synthetic Data-based Detection of Zebras in Drone Imagery",
        "texts": [
            "Fig. 1: An example image of our synthetically generated zebras in a Savanna environment.",
            "Fig. 2: Examples of missing bounding boxes and keypoints from the Grévy’s zebra [18] dataset. Image ids 869 (left) and 882 (right).",
            "Fig. 4: An example of the generated data following the pipeline described in Sec. III. On the first row, from the left, we can see the rendered RGB image, depth data, 2D bounding boxes, and semantic instances. On the second row, from the left, we can see 3D-oriented bounding boxes, the vertices of each mesh drawed over a black background, and the second and third views of the same scene as taken from the other drones. Best viewed in color.",
            "Fig. 5: An example of our real-world collected images used for testing. Three aerial and one ‘ground-level’ views. Best viewed in color.",
            "Fig. 7: Sampled detections. We show in column (a) the ground truth and then the results obtained from (b) the default model (pre-trained on COCO), and the ones trained on (c) RP-1920, (d) SC-1920, and (e) SC+COCO+R3100-1920. The images are randomly taken from the COCO (first row), APT-36K, R2, and RP (last row) datasets. Best viewed in color and zoomed-in.",
            "TABLE II: Zebras datasets legend and training/validation sizes",
            "TABLE III: Results of the evaluations of the trained models. We report mAP50 and mAP for each dataset as well as both the average and weighted average of these metrics. We divide between models trained on mixed datasets, vanilla ones, and the model pre-trained with COCO. In bold the best results. We underline the best model not using the RP dataset during training in the corresponding validation column."
        ],
        "imgs": [
            "$2305.00432v2-Figure1-1.png",
            "$2305.00432v2-Figure2-1.png",
            "$2305.00432v2-Figure4-1.png",
            "$2305.00432v2-Figure5-1.png",
            "$2305.00432v2-Figure7-1.png",
            "$2305.00432v2-TableII-1.png",
            "$2305.00432v2-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00435",
        "abstract": "  Interest point detection methods have received increasing attention and are\nwidely used in computer vision tasks such as image retrieval and 3D\nreconstruction. In this work, second-order anisotropic Gaussian directional\nderivative filters with multiple scales are used to smooth the input image and\na novel blob detection method is proposed. Extensive experiments demonstrate\nthe superiority of our proposed method over state-of-the-art benchmarks in\nterms of detection performance and robustness to affine transformations.\n",
        "title": "Second-order Anisotropic Gaussian Directional Derivative Filters for\n  Blob Detection",
        "texts": [
            "Fig. 1: Examples of SOAGDD filters along eight orientations (θ = kπ 8 , k = 0, 1, · · · , 7) with different anisotropic factor ρ and scale factor σ .",
            "Fig. 2: Example of pyramid images.",
            "Fig. 3: Illustration of blob selection.",
            "Fig. 4: Illustration of different blob detections on the ‘Graffiti’ images. The detection results of SIFT are shown in (a) and (e). The detection results of KAZE are shown in (b) and (f). The detection results of SOIGDD are shown in (ac) and (g). The detection results of proposed method are shown in (d) and (h).",
            "Fig. 5: Image matching. (a) SIFT; (b) The proposed method."
        ],
        "imgs": [
            "$2305.00435v1-Figure1-1.png",
            "$2305.00435v1-Figure2-1.png",
            "$2305.00435v1-Figure3-1.png",
            "$2305.00435v1-Figure4-1.png",
            "$2305.00435v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00436",
        "abstract": "  Achieving the UN Sustainable Development Goals (SDGs) demands adequate levels\nof awareness and actions to address sustainability challenges. Software systems\nwill play an important role in moving towards these targets. Sustainability\nskills are necessary to support the development of software systems and to\nprovide sustainable IT-supported services for citizens. While there is a\ngrowing number of academic bodies, including sustainability education in\nengineering and computer science curricula, there is not yet comprehensive\nresearch on the competencies and skills required by IT professionals to develop\nsuch systems. This study aims to identify the industrial sustainability needs\nfor education and training from software engineers' perspective. We conducted\ninterviews and focus groups with experts from twenty-eight organisations with\nan IT division from nine countries to understand their interests, goals and\nachievements related to sustainability, and the skills and competencies needed\nto achieve their goals. Our findings show that organisations are interested in\nsustainability, both idealistically and increasingly for core business reasons.\nThey seek to improve the sustainability of processes and products but encounter\ndifficulties, like the trade-off between short-term financial profitability and\nlong-term sustainability goals. To fill the gaps, they have promoted in-house\ntraining courses, collaborated with universities, and sent employees to\nexternal training. The acquired competencies make sustainability an integral\npart of software development. We conclude that educational programs should\ninclude knowledge and skills on core sustainability concepts, system thinking,\nsoft skills, technical sustainability, sustainability impact and measurements,\nvalues and ethics, standards and legal aspects, and advocacy and lobbying.\n",
        "title": "Sustainability Competencies and Skills in Software Engineering: An\n  Industry Perspective",
        "texts": [
            "Fig. 3: Structure of the codebook",
            "TABLE 1: Organisations (anonymised) interviewed per country",
            "TABLE 2: List of participants per company"
        ],
        "imgs": [
            "$2305.00436v2-Figure3-1.png",
            "$2305.00436v2-Table1-1.png",
            "$2305.00436v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00437",
        "abstract": "  The coupling between band structure and magnetism can lead to intricate Fermi\nsurface modifications. Here we report on the comprehensive study of the\nShubnikov-de Haas (SdH) effect in two rare-earth-based magnetic Weyl\nsemimetals, NdAlSi and CeAlSi$_{0.8}$Ge$_{0.2}$. The results show that the\ntemperature evolution of topologically nontrivial Fermi surfaces strongly\ndepends on magnetic configurations. In NdAlSi, the SdH frequencies vary with\ntemperature in both the paramagnetic state and the magnetically ordered state\nwith a chiral spin texture, but become temperature independent in the\nhigh-field fully polarized state. In CeAlSi$_{0.8}$Ge$_{0.2}$, SdH frequencies\nare temperature-dependent only in the ferromagnetic state with magnetic fields\napplied along the $c$ axis. First-principles calculations suggest that the\nnotable temperature and magnetic-configuration dependence of Fermi surface\nmorphology can be attributed to strong exchange coupling between the conduction\nelectrons and local magnetic moments.\n",
        "title": "Temperature-Dependent and Magnetism-Controlled Fermi Surface Changes in\n  Magnetic Weyl Semimetals",
        "texts": [
            "FIG. 2. (a) FFT spectra of SdH oscillations in NdAlSi measured with varying tilt angle θ (from c toward a axis) at T = 1.7K. FFTs are performed above Hm, i.e., in the FIP state. (b) SdH frequencies as functions of θ for the canted u-d-d (circles), PM (triangles), and FIP (squares) states. The solid line is fit to an ellipsoidal FS model (see text). (c) Best fits of the LifshitzKosevich (LK) model (solid lines) to the oscillatory MR in the FIP state (circles) measured at θ = 0◦ (black), 10◦ (blue), 35◦ (purple), and T = 2K. Inset: T -dependent SdH oscillation amplitudes measured at θ ≃ 30◦ and the LK fit (solid line) (d) DFT-calculated Fermi surfaces (FSs) in the FIP state of NdAlSi. Dark purple and green colors represent hole and electron FS pockets, respectively. An expanded view of the hole pocket (λ) along the Z −Σ′ direction is provided. The extremal orbits are highlighted accordingly.",
            "FIG. 3. (a) ∆ρxx measured in CeAlSi0.8Ge0.2 with H ‖ c at different temperatures. Below Tc = 6.5K (horizontal line), SdH extrema start to shift with varying T (dotted arrow). (b),(c) T dependence of SdH frequencies (see Fig. S3 in [16] for FFT spectra) for (b) H ‖ c and (c) H ‖ a. In (b), the solid and hollow circles are data obtained in two samples #1 and #2 in the field intervals of 8T ≤ B ≤ 14T and 8T ≤ B ≤ 33T, respectively. Data presented in (c) were measured in sample #1, with FFT performed between 8 and 14T. (d) The DFT calculated hole (yellow) and electron (blue) FS pockets for the polarized state with Ce 4f moments aligning along c in an out-of-plane H (arrow). The expanded view shows the outer (spin-majority) and inner (spin-minority) FS sheets for the pocket λ. Circles highlight the possible extremal orbits.",
            "FIG. 4. (a)-(d) The evolution of spin-resolved band structures of NdAlSi obtained from first-principles calculations; the local moment of Nd3+ is constrained to 〈Mz〉 values of (a) 0, (b) 1.0 µB, (c) 2.0 µB , and (d) 3.0 µB . Note that (a) corresponds to the PM phase under zero field and (d) corresponds to the case of free magnetism (i.e., a FM state from self-consistent calculations). Red and blue colors indicate the z component of spin-up and spin-down states, respectively. (e) The spindependent extremal (minimum or maximum) cross-sectional areas on FS pocket λ, as a function of the polarized local moment, 〈Mz〉, of the Nd3+ ions in NdAlSi. (f) and (g) show the spin-resolved band structures of CeAlSi in the FM (Ce 4f moments align along the c axis) and PM phases, respectively. All calculations include the SOC."
        ],
        "imgs": [
            "$2305.00437v1-Figure2-1.png",
            "$2305.00437v1-Figure3-1.png",
            "$2305.00437v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00438",
        "abstract": "  When solving global optimization problems in practice, one often ends up\nrepeatedly solving problems that are similar to each others. By providing a\nrigorous definition of similarity, in this work we propose to incorporate the\nMETA-learning rationale into SMGO-$\\Delta$, a global optimization approach\nrecently proposed in the literature, to exploit priors obtained from similar\npast experience to efficiently solve new (similar) problems. Through a\nbenchmark numerical example we show the practical benefits of our\nMETA-extension of the baseline algorithm, while providing theoretical bounds on\nits performance.\n",
        "title": "META-SMGO-$\\Delta$: similarity as a prior in black-box optimization",
        "texts": [
            "Fig. 3: Average trajectory of z∗(n) during optimization",
            "Fig. 5: Contour plot of f , with sampled points with META (blue) and SMGO-∆ (red) (a) and average number of infeasible points during the optimization (b).",
            "Fig. 6: Sensitivity to M – Average z∗(n) over N = 10 experiments (a) and average number of constraint violations (b) over N = 10 experiments.",
            "Fig. 7: Sensitivity to τ – Average z∗(n) over N = 10 experiments (a) and average number of constraint violations (b) over N = 10 experiments."
        ],
        "imgs": [
            "$2305.00438v1-Figure3-1.png",
            "$2305.00438v1-Figure5-1.png",
            "$2305.00438v1-Figure6-1.png",
            "$2305.00438v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00440",
        "abstract": "  Asymmetric features in exoplanet transit light curves are often interpreted\nas a gravity darkening effect especially if there is spectroscopic evidence of\na spin-orbit misalignment. Since other processes can also lead to light curve\nasymmetries this may lead to inaccurate gravity darkening parameters. Here we\ninvestigate the case of non-radial pulsations as possible sources of asymmetry\nand likely source of misinterpreted parameters through simulations. We obtained\na series of simulated transit light curves of a hypothetical exoplanet-star\nsystem: a host star with no gravity darkening exhibiting small amplitude\npulsations, and a typical hot Jupiter in a circular, edge-on orbit. A number of\nscenarios of pulsations of various amplitudes were considered, and a proper\naccount of the obscuring effect of transits on all the surface intensity\ncomponents was made. The magnitude of amplitude and phase modulations of\nnonradial pulsations during transits was also also investigated. We then fitted\nboth a non-gravity-darkened, and a gravity-darkened, free spin-orbit axis model\non the data. The Akaike and Bayesian Information Criteria were used for an\nobjective selection of the most plausible model. We then explored the\ndependence of the parameter deviations on the pulsation properties, in order to\nidentify configurations that can lead to falsely misaligned solutions.\nLow-amplitude pulsations in general do not affect the determination of the\nsystem parameters beyond their noise nature. However, frequencies close to\nmultiples of the orbital frequency are found to cause distortions leading to\nsolutions with a side tilted stellar rotational axis, they are therefore\npreferable to clean beforehand for the sake of a correct analysis.\nAdditionally, for cases with higher-amplitude pulsations, it is recommended to\npre-process and clean the pulsations before analysis.\n",
        "title": "Stellar pulsations interfering with the transit light curve:\n  configurations with false positive misalignment",
        "texts": [
            "Fig. 10. Illustration of the prewhitening process on the data in the pxx series. The top and bottom rows correspond to the data before and after prewhitening, respectively. Left panels: the Fourier transform of the full dataset, shown both with the inclusion and exclusion of the transit phases (brown and green colours, respectively). Note that the amplitude of the prewhitened spectrum (bottom left) is shown increased 10 times. The frequencies detected by Period04 are shown by filled or empty circles depending on whether the signal is present or not in the data. Right panels: the corresponding folded synthetic dataset (light gray), as well as the data of the first orbital cycle (black).",
            "Fig. 2. Summary of the results for selected iXX models. Blue colours mark the aligned case with β = 0 and magenta colours mark the free angles cases with β = 0.25 in all graphs. Left panel: the relative deviations of a/RS and Rp/RS fits from their input values. Middle panel: the fitted angles Ω? and I? free angles case assuming β = 0.25 Right panel: the computed differences ∆AIC and ∆BIC between the free angles and fixed angles cases. Filled circles mark the ’yn’ scenarios (red noise considered), empty circles mark the ’nn’ scenarios (no red noise). The two grey shaded zones correspond to differences of 5 and 10 respectively, representing two thresholds of rejection.",
            "Fig. 3. Sample fits and residuals of three simulated systems from the iXX series. Top panel: Folded light curves with grey points, with simulated transit curve samples for the first orbital period, including noise and pulsation with black circle. There are also the fits of the two models: the fixed angle, β = 0 model with blue dashed line, and the free angles, β = 0.25 model with orange solid line. The two fits are virtually indistinguishable on these graphs. Middle panel: the residuals in the red noise case. Bottom panel: the residuals in the white noise case. The colours along the horizontal line at y = 0 encode the sign of the difference between the predicted fluxes of the fixed angles (λ = 0, I? = 90; at β = 0) and free angles (β = 0.25) models. Positive difference is shown in red, negative in blue; otherwise it is magenta.",
            "Fig. 4. An example for modulations of some nonradial pulsations during the exoplanet transit phases in a system with aligned orbit (i = 90◦, λ = 0o). The four panels on the left show the residuals in the signals after the subtraction of mode (0,0). The panels on the right show the variations in the amplitudes (top) and phases (bottom) of all visible nonradial modes. Note the small vertical scale of the phase modulation diagram, implying that such a change will be barely noticeable.",
            "Fig. 5. Summary of the results for the nXX cases. The structure of the figure is similar to Fig. 2, but on the left and middle panel the marginal distribution of the corresponding parameter is depicted with so called violin plot. The circles and bars are belonging to the found median values and the uncertainty ranges.",
            "Fig. 6. Model fits achieved for test case n00. The models are shown in the column titles. The top row shows the synthetic data with black symbols and the modelled curves with blue lines. The middle and bottom rows show the fitted red noise and the final residuals, respectively. The coloured areas show the differences between the fits of the actual model and the leftmost model (i.e. aligned, fixed angle). Red and blue correspond to positive and negative discrepancy, respectively, and the regions with no difference are coded with magenta.",
            "Fig. 7. Model fits achieved for test case n02. The structure and notations are the same as in Fig. 6.",
            "Fig. 8. The contributions of some of the sinusoidal signals to the total flux around the transit phases. Top left: the contributions of F2 around the individual transit events with blue symbols and shifted vertically from each other for a better view, overlaid on the folded transit curve. Bottom left: the contribution of F2 after folding with the orbital period and binning, shown on a scale of 100 ppm. The right panels show the contributions of F2, F5, F6 and F10, as well as their sum.",
            "Fig. 9. Summary of the results for the pXX cases. The structure of the figure is similar to Fig. 7, except that the left panel corresponds to a data series having all the frequencies, while on the other two columns the 10 detected frequencies were removed as sine model. Therefore the differences between the models are only given for the latter.",
            "Table 1. The geometric and physical properties of the test system, shown as the two equivalent parameter sets passed to the two modelling tools.",
            "Table 2. Data of pulsations used for single-mode, radial mode cases. The frequencies are in units of the orbital frequency. The initial phases ϕ were chosen randomly in the interval [0, 1]. The amplitude was uniformly 0.0006. The IDs of the models were composed from the frequency and initial phase numbers, with the simple model id initial \"i\". E.g. \"i02\" used the first frequency and the third initial phase values (counting starts from zero).",
            "Table 3. The frequency sets used in the nXX model series. The frequencies are given in units of the orbital frequency as usual, the amplitude A and initial phase φ are those used in the sine formula of Eq. (2). Bullets (•) in the nXX columns mark the frequencies included in that particular model. The last column shows the mode numbers (`,m) assigned to each frequency.",
            "Table A.1. Summary of fit results for the n00 case having 4 frequencies. The conjunction parameter b was fixed during these fits. The computed AIC and BIC values, presented at the bottom of the table, clearly favor the more simple model (i.e. without gravity darkening).",
            "Table A.2. Summary of fit results for case n02 with all 10 frequencies included.",
            "Table A.3. Summary of fit results for case pxx with all 10 frequencies included."
        ],
        "imgs": [
            "$2305.00440v1-Figure10-1.png",
            "$2305.00440v1-Figure2-1.png",
            "$2305.00440v1-Figure3-1.png",
            "$2305.00440v1-Figure4-1.png",
            "$2305.00440v1-Figure5-1.png",
            "$2305.00440v1-Figure6-1.png",
            "$2305.00440v1-Figure7-1.png",
            "$2305.00440v1-Figure8-1.png",
            "$2305.00440v1-Figure9-1.png",
            "$2305.00440v1-Table1-1.png",
            "$2305.00440v1-Table2-1.png",
            "$2305.00440v1-Table3-1.png",
            "$2305.00440v1-TableA.1-1.png",
            "$2305.00440v1-TableA.2-1.png",
            "$2305.00440v1-TableA.3-1.png"
        ]
    },
    {
        "id": "2305.00441",
        "abstract": "  Multi-task learning has the potential to improve generalization by maximizing\npositive transfer between tasks while reducing task interference. Fully\nachieving this potential is hindered by manually designed architectures that\nremain static throughout training. On the contrary, learning in the brain\noccurs through structural changes that are in tandem with changes in synaptic\nstrength. Thus, we propose \\textit{Multi-Task Structural Learning (MTSL)} that\nsimultaneously learns the multi-task architecture and its parameters. MTSL\nbegins with an identical single-task network for each task and alternates\nbetween a task-learning phase and a structural-learning phase. In the task\nlearning phase, each network specializes in the corresponding task. In each of\nthe structural learning phases, starting from the earliest layer, locally\nsimilar task layers first transfer their knowledge to a newly created group\nlayer before being removed. MTSL then uses the group layer in place of the\ncorresponding removed task layers and moves on to the next layers. Our\nempirical results show that MTSL achieves competitive generalization with\nvarious baselines and improves robustness to out-of-distribution data.\n",
        "title": "Multi-Task Structural Learning using Local Task Similarity induced\n  Neuron Creation and Removal",
        "texts": [
            "Figure 1. Schematic of the MTSL Algorithm. The grey regions (initial state, alignment, next state) are part of the task learning phase while the white regions (neuron creation, and neuron removal) are part of the structural learning phase. During training, our algorithm loops between alignment in the task learning phase followed by neuron creation and neuron removal in the structural learning phase leading to the next state (last column).",
            "Figure 2. Visualization of the One-Net architecture and the MTSL resultant architectures. In both datasets, tasks branch out at layer six but differences emerge in the branching structure in the following layers. The oval shapes at the end of each path represents the task heads.",
            "Figure 3. Converged architecture of LTB, BMTAS, and MTSL on the Cityscapes dataset. Each row of circles represents a layer on the encoder. At the last layer of the encoder, each task branch out with their own heads.",
            "Figure 4. Illustration of the converged architecture of LTB, BMTAS, and MTSL on NYUv2 datase. Each row of circles represents a layer on the encoder. At the last layer of the encoder, each task branch out with their own heads.",
            "Figure 5. Task vs. total similarity of the corresponding task representations with all other task representations at the output of the first layer. MTSL leads to higher CKA similarities with the aid of CKA regularization, as shown by the taller green bars.",
            "Table 1. IID Generalization and inference efficiency comparisons between MTSL and state-of-the-art methods, namely Cross-stitch, MTAN, LTB and BMTAS. LTB-R and BMTAS-R represent results obtained by retraining the final converged architecture of LTB and BMTAS, respectively. # (M) denotes parameter count in millions, and GMac denotes Giga multiply-accumulate.",
            "Table 11. Generalization and robustness comparison of MTSL against a version in which the learned architecture is reinitialized and retrained (MTSL-R).",
            "Table 12. Switching of the converged architectures. # (M) denotes the number of parameters in millions.",
            "Table 13. MTSL with a different similarity metric called RSA. # (M) denotes the number of parameters in millions.",
            "Table 14. Generalization and inference efficiency comparisons between MTSL and state-of-the-art methods, namely cross stitch (Misra et al., 2016), MTAN (Liu et al., 2019), LTB (Guo et al., 2020) and BMTAS (Bruggemann et al., 2020). LTB-R, BMTAS-R and MTSL-R denote the results obtained by retraining the converged models of LTB, BMTAS and MTSL. # (M) denotes the number of parameters in millions.",
            "Table 15. Robustness to PGD attack of the baselines and MTSL.",
            "Table 16. Generalization comparisons between MTSL and baselines. # (M) denotes the number of parameters in millions.",
            "Table 17. Ablation results of different tasks.",
            "Table 2. IID generalization and inference efficiency comparisons between MTSL and baselines. MTSL performs better than One-Net in most cases and achieves an inference efficiency close to One-Net. # (M) denotes the number of parameters in millions.",
            "Table 3. Robustness to natural corruptions under four categories. MTSL shows better robustness compared to One-Net in most cases.",
            "Table 4. Effect of alignment (Align), average initialization (Avg), and attention-based knowledge amalgamation (ATT). Without alignment (first 3 rows), the resultant networks remain close to STN. With alignment (last 3 rows), the resultant networks are closer to One-Net.",
            "Table 5. Sensitivity of the converged architecture to different initialization of the encoder and random seeds in both datasets. The random seeds groupings using ImageNet pre-trained weights for the encoder.",
            "Table 6. Sensitivity of MTSL to the grouping threshold. For example, MTSL-0.1 denotes MTSL with a grouping threshold of 0.1. # (M) denotes the number of parameters in millions.",
            "Table 7. Sensitivity of MTSL to the number of tasks. # (M) denotes the number of parameters in millions.",
            "Table 8. Sensitivity of MTSL to the CKA loss weight λ. # (M) denotes the number of parameters in millions.",
            "Table 9. Sensitivity of BMTAS to the resource loss weight. For example, BMTAS-0.1 refers to BMTAS with resource weight 0.1. # (M) denotes the number of parameters in millions."
        ],
        "imgs": [
            "$2305.00441v1-Figure1-1.png",
            "$2305.00441v1-Figure2-1.png",
            "$2305.00441v1-Figure3-1.png",
            "$2305.00441v1-Figure4-1.png",
            "$2305.00441v1-Figure5-1.png",
            "$2305.00441v1-Table1-1.png",
            "$2305.00441v1-Table11-1.png",
            "$2305.00441v1-Table12-1.png",
            "$2305.00441v1-Table13-1.png",
            "$2305.00441v1-Table14-1.png",
            "$2305.00441v1-Table15-1.png",
            "$2305.00441v1-Table16-1.png",
            "$2305.00441v1-Table17-1.png",
            "$2305.00441v1-Table2-1.png",
            "$2305.00441v1-Table3-1.png",
            "$2305.00441v1-Table4-1.png",
            "$2305.00441v1-Table5-1.png",
            "$2305.00441v1-Table6-1.png",
            "$2305.00441v1-Table7-1.png",
            "$2305.00441v1-Table8-1.png",
            "$2305.00441v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00444",
        "abstract": "  The discovery of superconductivity in CaC6 with a critical temperature (Tc)\nof 11.5 K reignites much interest in exploring high-temperature\nsuperconductivity in graphite intercalation compounds (GICs). Here we identify\na GIC NaC4, discovered by ab initio evolutionary structure search, as a\nsuperconductor with a computed Tc of 41.2 K at 5 GPa. This value is eight times\nhigher than that of the synthesized GIC NaC2 and possesses the highest Tc among\navailable GICs. The remarkable superconductivity of GIC NaC4 mainly arises from\nthe coupling of {\\pi} electrons in graphene with the low-frequency vibrations\ninvolving both Na and C atoms. These findings suggest that Na-GICs may hold\ngreat promise as high-Tc superconductors.\n",
        "title": "Superconductivity in graphite intercalation compounds with sodium",
        "texts": [
            "Fig. 1. (a) The calculated convex hulls for the Na-C systems at 5 and 10 GPa. The elemental reference structures are bcc-Na, graphite at 5 GPa, and diamond at 10 GPa, respectively. (b) Pressure-composition phase diagram of Na-C compounds within the pressure range from 0 to 10 GPa.",
            "Fig. 2. Crystal structures of Na-GICs at 5 GPa. (a) P21/m NaC2, (b) Cmcm NaC4, and (c) P6/mmm NaC6. For these structures, the blue and brown spheres represent Na and C atoms, respectively.",
            "Fig. 3. (a) The orbital-resolved band structures of Cmcm NaC4 at 5 GPa. (b) Projected density of states (PDOS) (the dashed line indicates EF). (c) The Fermi surfaces associated with two bands crossing EF.",
            "Fig. 4. (a) Phonon dispersion curves of Cmcm NaC4 at 5 GPa (the magnitude of λq,υ indicated by the thickness of the green curves). (b) Projected phonon DOS(PHDOS). (c) Eliashberg spectral function α2F(ω) (orange line), frequency-dependent EPC parameter λ(ω) (purple line). (d) The Fermi surface nesting function ξq along some q trajectories. (e) Pressure-depended Tc, ωlog, and λ of Cmcm NaC4."
        ],
        "imgs": [
            "$2305.00444v2-Figure1-1.png",
            "$2305.00444v2-Figure2-1.png",
            "$2305.00444v2-Figure3-1.png",
            "$2305.00444v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00445",
        "abstract": "  Owing to their rich internal structure and significant long-range\ninteractions, ultracold molecules have been widely explored as carriers of\nquantum information. Several different schemes for encoding qubits into\nmolecular states, both bare and field-dressed, have been proposed. At the same\ntime, the rich internal structure of molecules leaves many unexplored\npossibilities for qubit encodings. We show that all molecular qubit encodings\ncan be classified into four classes by the type of the effective interaction\nbetween the qubits. In the case of polar molecules, the four classes are\ndetermined by the relative magnitudes of matrix elements of the dipole moment\noperator in the single molecule basis. We exemplify our classification scheme\nby considering a new type of encoding of the effective spin-1/2 system into\nnon-adjacent rotational states (e.g., $N=0$ and $N=2$) of polar and non-polar\nmolecules with the same nuclear spin projection. Our classification scheme is\ndesigned to inform the optimal choice of molecular qubit encoding for quantum\ninformation storage and processing applications, as well as for dynamical\ngeneration of many-body entangled states and for quantum annealing.\n",
        "title": "General classification of qubit encodings in ultracold diatomic\n  molecules",
        "texts": [
            "Figure 1: Energy levels of a 1Σ molecule as functions of the effective electric field.",
            "Figure 2: Non-zero EDM matrix elements of d̂0 for a 1Σ molecule as a function of the effective electric field.",
            "Figure 3: Couplings Jz (left) and J⊥ (right) as a function of the effective electric field, using the ground rotational state and the indicated rotational states of a polar 1Σ molecule to encode the qubits.",
            "Figure 4: Non-zero quadrupole matrix elements of q̂0 as a function of the effective electric field.",
            "Figure 5: Quadrupole contribution to couplings Jz (left) and J⊥ (right) as a function of the effective electric field, using the ground rotational state and the indicated rotational states to encode the qubits."
        ],
        "imgs": [
            "$2305.00445v1-Figure1-1.png",
            "$2305.00445v1-Figure2-1.png",
            "$2305.00445v1-Figure3-1.png",
            "$2305.00445v1-Figure4-1.png",
            "$2305.00445v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00447",
        "abstract": "  Large Language Models (LLMs) have demonstrated remarkable performance across\ndiverse domains, thereby prompting researchers to explore their potential for\nuse in recommendation systems. Initial attempts have leveraged the exceptional\ncapabilities of LLMs, such as rich knowledge and strong generalization through\nIn-context Learning, which involves phrasing the recommendation task as\nprompts. Nevertheless, the performance of LLMs in recommendation tasks remains\nsuboptimal due to a substantial disparity between the training tasks for LLMs\nand recommendation tasks, as well as inadequate recommendation data during\npre-training. To bridge the gap, we consider building a Large Recommendation\nLanguage Model by tunning LLMs with recommendation data. To this end, we\npropose an efficient and effective Tuning framework for Aligning LLMs with\nRecommendation, namely TALLRec. We have demonstrated that the proposed TALLRec\nframework can significantly enhance the recommendation capabilities of LLMs in\nthe movie and book domains, even with a limited dataset of fewer than 100\nsamples. Additionally, the proposed framework is highly efficient and can be\nexecuted on a single RTX 3090 with LLaMA-7B. Furthermore, the fine-tuned LLM\nexhibits robust cross-domain generalization. Our code and data are available at\nhttps://github.com/SAI990323/TALLRec.\n",
        "title": "TALLRec: An Effective and Efficient Tuning Framework to Align Large\n  Language Model with Recommendation",
        "texts": [
            "Figure 1: Illustration of LLMs for the recommendations. Given users’ interaction history, LLMs predict whether a user will like a new item through In-context Learning. However, the representative LLMs, e.g., ChatGPT, either refuse to answer or always give positive predictions (likes) on Movie and Book recommendation tasks. If we ignore the refused answers and calculate AUC on the remaining samples, we find that LLMs perform similarly with random guessing (AUC=0.5). Refer to Section 3 for more experimental details.",
            "Figure 2: Illustration of the TALLRec framework constructed by alpaca tuning and rec-tuning two stages. During rec-tuning, we use the rec-tuning samples with instruction input and output constructed from recommendation data. Notably, we employ lightweight tuning technology to enhance the efficiency of our TALLRec framework.",
            "Figure 3: Figure (a) shows the performance comparison between LLM-based baselines (zero-shot setting) and ours TALLRec, where the TALLRec is trained on only 64 rec-tuning samples (i.e., in the 64-shot training setting). Figure (b) demonstrates the performance tendency of TALLRec’s variants and conventional sequential recommendation methods w.r.t. the number of training samples used, ranging from 1 to 256. TALLRec has three variants: “AT” for alpaca tuning only, “RT” for rec-tuning only, and “TALLRec” for the full version.",
            "Figure 4: Cross-domain generalization performance of LRLMs trained via TALLRec using Book data (TALLRec (Book)), Movie data (TALLRec (Movie)), and both (TALLRec (Both)). The left figure shows the testing results on the Movie dataset with varying numbers of rec-tuning samples, while the right figure shows the testing results on the Book dataset.",
            "Table 2: A tuning sample for rec-tuning.",
            "Table 3: Performance comparison between conventional sequential recommendation baselines and TALLRec under different few-shot training settings. The reported result is the AUC multiplied by 100, with boldface indicating the highest score. ‡: significantly better than all baselines with t-test 𝑝<0.01."
        ],
        "imgs": [
            "$2305.00447v3-Figure1-1.png",
            "$2305.00447v3-Figure2-1.png",
            "$2305.00447v3-Figure3-1.png",
            "$2305.00447v3-Figure4-1.png",
            "$2305.00447v3-Table2-1.png",
            "$2305.00447v3-Table3-1.png"
        ]
    },
    {
        "id": "2305.00449",
        "abstract": "  This thesis designs a prediction system based on matrix factorization to\npredict the classification accuracy of a specific model on a particular\ndataset. In this thesis, we conduct comprehensive empirical research on more\nthan fifty datasets that we collected from the openml website. We study the\nperformance prediction of three fundamental machine learning algorithms,\nnamely, random forest, XGBoost, and MultiLayer Perceptron(MLP). In particular,\nwe obtain the following results: 1. Predictability of fine-tuned models using\ncoarse-tuned variants. 2. Predictability of MLP using feature extraction\ntechniques. 3. Predict model performance using implicit feedback.\n",
        "title": "Predictability of Machine Learning Algorithms and Related Feature\n  Extraction Techniques",
        "texts": [
            "Figure 3.1: Schematic of Perceptron",
            "Figure 3.2: Schematic of MultiLayer Perceptron",
            "Figure 3.3: Schematic of Random Forest [37]",
            "Figure 3.6: The visualization for coordinates of different algorithms",
            "Figure 4.1: The performance of Random Forest on dataset 4538",
            "Figure 4.10: The performance of feature extraction based upon permutation importance on dataset 4538",
            "Figure 4.11: Part of increasing results for extractor with permutation importance and highest ρ values",
            "Figure 4.12: All non-increasing results of extractor with permutation importance and highest ρ values",
            "Figure 4.13: Part of increasing results of extractor with permutation importance but not highest ρ values",
            "Figure 4.16: All non-increasing results of extractor with gain-based importance and highest ρ values",
            "Figure 4.17: All increasing results of extractor with gain-based importance but not highest ρ values",
            "Figure 4.18: The performance of feature extraction based upon Spearman correlation on dataset 4538",
            "Figure 4.2: Part of results of random forest",
            "Figure 4.20: Part of increasing results for extractor with Spearman correlation and highest ρ values",
            "Figure 4.21: All non-increasing results for extractor with Spearman correlation and highest ρ values",
            "Figure 4.22: Part of increasing results for extractor with Spearman correlation but not highest ρ values",
            "Figure 4.23: The performance of PCA on dataset 4538",
            "Figure 4.25: All non-increasing results for PCA with highest ρ values",
            "Figure 4.26: Part of increasing results for PCA not having highest ρ values",
            "Figure 4.27: The performance of prediction with matrix factorization",
            "Figure 4.28: The distance between different models according to matrix factorization",
            "Figure 4.29: The detail of the distance between different datasets according to matrix factorization",
            "Figure 4.3: Part of results of random forest",
            "Figure 4.30: The overall results of distance between different dataset according to matrix factorization",
            "Figure 4.4: The performance of XGboost on dataset 4538",
            "Figure 4.5: Part of results of XGBoost",
            "Figure 4.6: Part of results of XGBoost",
            "Figure 4.7: The performance of multi-layer perceptron on dataset 4538",
            "Figure 4.8: Part of results of multi-layer perceptron",
            "Figure 4.9: Part of results of multi-layer perceptron",
            "Figure A.1: Part of results of random forest without obvious pattern",
            "Figure A.10: Part of results of multi-layer perceptron with unexpected patterns",
            "Figure A.11: Results of multi-layer perceptron without pattern",
            "Figure A.12: Part of results of multi-layer perceptron with unexpected patterns",
            "Figure A.2: Part of results of random forest without obvious pattern",
            "Figure A.3: Part of results of random forest with a pattern",
            "Figure A.4: Part of results of random forest with a pattern",
            "Figure A.5: Part of results of random forest with a pattern",
            "Figure A.7: Part of results of XGBoost without obvious pattern",
            "Figure A.8: Part of results of XGBoost without obvious pattern",
            "Figure A.9: Results of multi-layer perceptron with expected patterns",
            "Figure B.1: Increasing results for extractor with permutation importance and highest ρ values",
            "Figure B.12: All increasing results for extractor with Spearman correlation but not highest ρ values",
            "Figure B.13: All increasing results for extractor with Spearman correlation and highest ρ values",
            "Figure B.14: Non-increasing results for extractor with Spearman correlation",
            "Figure B.15: All increasing results for PCA",
            "Figure B.16: Non-increasing results for PCA",
            "Figure B.17: Non-increasing results for PCA",
            "Figure B.2: Increasing results for extractor with permutation importance but not highest ρ value",
            "Figure B.3: Part of non-increasing results for extractor with permutation importance",
            "Figure B.4: Part of non-increasing results for extractor with permutation importance",
            "Figure B.5: Non-increasing results of extractor with gain-based importance",
            "Figure B.6: Non-increasing results of extractor with gain-based importance",
            "Table 1.1: The attributes of datasets with binary classification",
            "Table 1.2: The attributes of datasets with multi classification",
            "Table 4.1: Summary of performance patterns only with datasets MLP performs best",
            "Table 4.2: Summary of performance patterns and the best classifier for each dataset excluding MLP only",
            "Table 4.3: Summary of ρ for techniques on datasets with Clustering and PCA scoring highest",
            "Table 4.4: Summary of techniques with permutation importance and gain-based importance scoring highest",
            "Table 4.5: Summary of observations",
            "Table 4.6: A matrix of all models with the highest accuracy and the most complex structure",
            "Table 4.7: A matrix of all models with the highest accuracy and the most complex structure"
        ],
        "imgs": [
            "$2305.00449v1-Figure3.1-1.png",
            "$2305.00449v1-Figure3.2-1.png",
            "$2305.00449v1-Figure3.3-1.png",
            "$2305.00449v1-Figure3.6-1.png",
            "$2305.00449v1-Figure4.1-1.png",
            "$2305.00449v1-Figure4.10-1.png",
            "$2305.00449v1-Figure4.11-1.png",
            "$2305.00449v1-Figure4.12-1.png",
            "$2305.00449v1-Figure4.13-1.png",
            "$2305.00449v1-Figure4.16-1.png",
            "$2305.00449v1-Figure4.17-1.png",
            "$2305.00449v1-Figure4.18-1.png",
            "$2305.00449v1-Figure4.2-1.png",
            "$2305.00449v1-Figure4.20-1.png",
            "$2305.00449v1-Figure4.21-1.png",
            "$2305.00449v1-Figure4.22-1.png",
            "$2305.00449v1-Figure4.23-1.png",
            "$2305.00449v1-Figure4.25-1.png",
            "$2305.00449v1-Figure4.26-1.png",
            "$2305.00449v1-Figure4.27-1.png",
            "$2305.00449v1-Figure4.28-1.png",
            "$2305.00449v1-Figure4.29-1.png",
            "$2305.00449v1-Figure4.3-1.png",
            "$2305.00449v1-Figure4.30-1.png",
            "$2305.00449v1-Figure4.4-1.png",
            "$2305.00449v1-Figure4.5-1.png",
            "$2305.00449v1-Figure4.6-1.png",
            "$2305.00449v1-Figure4.7-1.png",
            "$2305.00449v1-Figure4.8-1.png",
            "$2305.00449v1-Figure4.9-1.png",
            "$2305.00449v1-FigureA.1-1.png",
            "$2305.00449v1-FigureA.10-1.png",
            "$2305.00449v1-FigureA.11-1.png",
            "$2305.00449v1-FigureA.12-1.png",
            "$2305.00449v1-FigureA.2-1.png",
            "$2305.00449v1-FigureA.3-1.png",
            "$2305.00449v1-FigureA.4-1.png",
            "$2305.00449v1-FigureA.5-1.png",
            "$2305.00449v1-FigureA.7-1.png",
            "$2305.00449v1-FigureA.8-1.png",
            "$2305.00449v1-FigureA.9-1.png",
            "$2305.00449v1-FigureB.1-1.png",
            "$2305.00449v1-FigureB.12-1.png",
            "$2305.00449v1-FigureB.13-1.png",
            "$2305.00449v1-FigureB.14-1.png",
            "$2305.00449v1-FigureB.15-1.png",
            "$2305.00449v1-FigureB.16-1.png",
            "$2305.00449v1-FigureB.17-1.png",
            "$2305.00449v1-FigureB.2-1.png",
            "$2305.00449v1-FigureB.3-1.png",
            "$2305.00449v1-FigureB.4-1.png",
            "$2305.00449v1-FigureB.5-1.png",
            "$2305.00449v1-FigureB.6-1.png",
            "$2305.00449v1-Table1.1-1.png",
            "$2305.00449v1-Table1.2-1.png",
            "$2305.00449v1-Table4.1-1.png",
            "$2305.00449v1-Table4.2-1.png",
            "$2305.00449v1-Table4.3-1.png",
            "$2305.00449v1-Table4.4-1.png",
            "$2305.00449v1-Table4.5-1.png",
            "$2305.00449v1-Table4.6-1.png",
            "$2305.00449v1-Table4.7-1.png"
        ]
    },
    {
        "id": "2305.00454",
        "abstract": "  Transfer learning has been widely adopted for few-shot classification. Recent\nstudies reveal that obtaining good generalization representation of images on\nnovel classes is the key to improving the few-shot classification accuracy. To\naddress this need, we prove theoretically that leveraging ensemble learning on\nthe base classes can correspondingly reduce the true error in the novel\nclasses. Following this principle, a novel method named Ensemble Learning with\nMulti-Order Statistics (ELMOS) is proposed in this paper. In this method, after\nthe backbone network, we use multiple branches to create the individual\nlearners in the ensemble learning, with the goal to reduce the storage cost. We\nthen introduce different order statistics pooling in each branch to increase\nthe diversity of the individual learners. The learners are optimized with\nsupervised losses during the pre-training phase. After pre-training, features\nfrom different branches are concatenated for classifier evaluation. Extensive\nexperiments demonstrate that each branch can complement the others and our\nmethod can produce a state-of-the-art performance on multiple few-shot\nclassification benchmark datasets.\n",
        "title": "Few-shot Classification via Ensemble Learning with Multi-Order\n  Statistics",
        "texts": [
            "Figure 1: (a) The traditional methods often use different backbone networks as individuals, which significantly increases the computation and storage costs. (b) Our method takes the same backbone and equips different branches with multi-order statistics as learning individuals. They are parameter-free and trained jointly, and do not require extra model size and computation time.",
            "Figure 3: Test accuracy (%) of the classification-based (CB) loss, similarity-based (SB) loss and their combination (CB&SB) under 5-way 1-shot and 5-way 5-shot tasks on three datasets.",
            "Figure 4: Test accuracy (%) under different values of the parameter α2 in the setting of 5-way 1-shot and 5-shot on three FSC datasets.",
            "Figure 5: Test accuracy (%) under different values of the parameter α3 in the setting of 5-way 1-shot and 5-shot on three FSC datasets.",
            "Figure 6: Image reconstruction of features respectively represented by 1st-order, 2nd-order, 3rd-order statistics.",
            "Figure 7: T-SNE visualization of features on unseen samples of Baseline and our method.",
            "Table 1: Test accuracy (%) of each branch and their ensemble under 5-way 1-shot and 5-shot tasks on three datasets.",
            "Table 2: Comparison of results against state-of-the-art methods on CUB dataset.The top three results are marked in red, blue and green.",
            "Table 3: Comparison of results against state-of-the-art methods on miniImageNet, tiredImageNet, and CIFAR-FS dataset. ’-’ means the results were not provided by the authors. The top three results are marked in red, blue and green, respectively.",
            "Table 4: Comparison of results with the most related method under 5-way 1-shot and 5-shot tasks on CIFAR-FS and CUB.",
            "Table 5: Comparison of different methods under cross-domain scenario."
        ],
        "imgs": [
            "$2305.00454v1-Figure1-1.png",
            "$2305.00454v1-Figure3-1.png",
            "$2305.00454v1-Figure4-1.png",
            "$2305.00454v1-Figure5-1.png",
            "$2305.00454v1-Figure6-1.png",
            "$2305.00454v1-Figure7-1.png",
            "$2305.00454v1-Table1-1.png",
            "$2305.00454v1-Table2-1.png",
            "$2305.00454v1-Table3-1.png",
            "$2305.00454v1-Table4-1.png",
            "$2305.00454v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00456",
        "abstract": "  With the proliferation of social media, the detection of fake news has become\na critical issue that poses a significant threat to society. The dissemination\nof fake information can lead to social harm and damage the credibility of\ninformation. To address this issue, deep learning has emerged as a promising\napproach, especially with the development of natural language processing (NLP).\nThis study addresses the problem of detecting fake news on social media, which\nposes a significant challenge to society. This study proposes a new approach\nnamed GANM for fake news detection that employs NLP techniques to encode nodes\nfor news context and user content and uses three graph convolutional networks\nto extract features and aggregate users' endogenous and exogenous information.\nThe GANM employs a unique global attention mechanism with memory to learn the\nstructural homogeneity of news dissemination networks. The approach achieves\ngood results on a real dataset.\n",
        "title": "Graph Global Attention Network with Memory for Fake News Detection",
        "texts": [
            "Fig. 1 An overview illustration of GANM framework. The black arrows denote the data flow between distinct operations. The colored dashed lines denote the copy migration of tensor.",
            "Fig. 2 The performance of nine unique training processes with smooth trend, the title for each subgraph is the encoding method and the y-axis label is the model name.",
            "Fig. 3 t-SNE visualization of (a)Politifact with random parameters and (b)Gossipcop with random parameters by using GCN-GANM (BERT encoding)"
        ],
        "imgs": [
            "$2305.00456v1-Figure1-1.png",
            "$2305.00456v1-Figure2-1.png",
            "$2305.00456v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00458",
        "abstract": "  In [1], we inaugurated a new area of optimal control (OC) theory that we\ncalled \"periodic fractional OC theory,\" which was developed to find optimal\nways to periodically control a fractional dynamic system. The typical\nmathematical formulation in this area includes the class of periodic fractional\nOC problems (PFOCPs), which can be accurately solved numerically for a\nfractional order {\\alpha} in the range 0 < {\\alpha} < 1 using Fourier\ncollocation at equally spaced nodes and Fourier and Gegenbauer quadratures. In\nthis study, we extend this earlier work to cover periodic higher-order\nfractional OC problems (PHFOCPs) of any positive non-integer fractional order\n{\\alpha}.\n",
        "title": "Fourier-Gegenbauer Pseudospectral Method for Solving Periodic\n  Higher-Order Fractional Optimal Control Problems",
        "texts": [
            "Figure 1: The exact and FGPS approximate values of E L Dα t sin(t) (Columns 1–3) and their corresponding maximum absolute errors (the 4th Column) for α = 1.1 : 0.2 : 1.9, 1.99. The FGPS approximations were obtained using N = 4, L = 30, NG = 1000, and λ = 0. The exact values are shown in red color with * marker symbol, while the FGPS approximations are shown in blue colors with o marker symbol.",
            "Figures 1–4 show the excellent approximations of the derived general FGPS formulas (4) and (4) to E L Dα t sin(t) for the range α = 1.1:0.2:1.9, 1.99 using the parameter values N ∈ {4, 12, 40, 100}, L = 30,NG = 1000, and λ = 0. We observe that the graph of E L Dα t sin(t) converges to the graph of the negative sine function as α→ 2.",
            "Figure 2: The exact and FGPS approximate values of E L Dα t sin(t) (Columns 1–3) and their corresponding maximum absolute errors (the 4th Column) for α = 1.1 : 0.2 : 1.9, 1.99. The FGPS approximations were obtained using N = 12, L = 30, NG = 1000, and λ = 0. The exact values are shown in red color with * marker symbol, while the FGPS approximations are shown in blue colors with o marker symbol.",
            "Figure 3: The exact and FGPS approximate values of E L Dα t sin(t) (Columns 1–3) and their corresponding maximum absolute errors (the 4th Column) for α = 1.1 : 0.2 : 1.9, 1.99. The FGPS approximations were obtained using N = 40, L = 30, NG = 1000, and λ = 0. The exact values are shown in red color with * marker symbol, while the FGPS approximations are shown in blue colors with o marker symbol.",
            "Figure 4: The exact and FGPS approximate values of E L Dα t sin(t) (Columns 1–3) and their corresponding maximum absolute errors (the 4th Column) for α = 1.1 : 0.2 : 1.9, 1.99. The FGPS approximations were obtained using N = 100, L = 30, NG = 1000, and λ = 0. The exact values are shown in red color with * marker symbol, while the FGPS approximations are shown in blue colors with o marker symbol.",
            "Figure 5: The profiles of the approximate optimal state and control variables and the ADFEs obtained at the collocation nodes set Sπ 100 using the FGPS method together with MATLAB fmincon solver with the parameter values N = 100, α = 0.99999, and L = 30. The plots of the state and control variables were generated using 100 linearly spaced nodes in Ωπ.",
            "Figure 6: The approximate optimal performance index values against N for N = 10:10:100, α = 0.99999, and L = 30.",
            "Figure 7: The profiles of the approximate optimal state and control variables and the ADFEs obtained at the collocation nodes set Sπ 100 using the FGPS method together with MATLAB fmincon solver with the parameter values N = 100, α = 1.00001, and L = 30. The plots of the state and control variables were generated using 100 linearly spaced nodes in Ωπ.",
            "Figure 8: The evolution of the approximate optimal state and control variables y1 (left), y2 (middle), and u (right) for α = 0.9, 0.99, 0.999, 0.9999, 0.99999, 0.999999 obtained using the FGPSfmincon method with the parameter values N = 100 and L = 30. The plots were generated using 100 linearly spaced nodes in Ωπ."
        ],
        "imgs": [
            "$2305.00458v1-Figure1-1.png",
            "$2305.00458v1-Figure1–4-1.png",
            "$2305.00458v1-Figure2-1.png",
            "$2305.00458v1-Figure3-1.png",
            "$2305.00458v1-Figure4-1.png",
            "$2305.00458v1-Figure5-1.png",
            "$2305.00458v1-Figure6-1.png",
            "$2305.00458v1-Figure7-1.png",
            "$2305.00458v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00459",
        "abstract": "  Greybody factors are transmission probabilities of the Hawking radiation,\nwhich are emitted from black holes and can be obtained from the gravitational\npotential of black holes. The de Rham, Gabadadze, and Tolly (dRGT) massive\ngravity is one of the gravity theories that modified general relativity. In\nthis paper, we investigate the greybody factor from the massive scalar field in\nboth the asymptotically dS and the AdS spacetime using the WKB and the rigorous\nbound methods. We found that the greybody factor depends on the shape of the\npotential as found in quantum mechanics. The higher the potential barrier, the\nlower the amount of the grebody factor. Interestingly, for the low multipole\ncase, we found that there exists a critical mass which provides the maximum\nbound of the greybody factor. This is a crucial feature of the massive scalar\nfield on the greybody factor from the black holes in both the asymptotically dS\nand the AdS spacetime.\n",
        "title": "Greybody factors for massive scalar field emitted from black holes in\n  dRGT massive gravity",
        "texts": [
            "Fig. 1: The plot of fdS(r̃) with M̃ = 1, c2 = −0.01, αg = 1 with various βm. The dashed purple line represents fSdS(r̃) (c1 = c0 = 0).",
            "Fig. 11: Comparison of Tapp and Tb defined in equations (55) and (56), respectively, in the dS case.",
            "Fig. 14: (a) The greybody factors of the asymptotically dS black holes in the dRGT massive gravity Tb,dS,`=1 from the bound (solid line) and TWKB from the WKB method (dashed line) for c2 = −0.01, βm = 0.89, ` = 1 and m̃ = 0, 0.1 and 0.2. (b) The magnification of (a).",
            "Fig. 15: The rigorous bounds (between r̃1 and r̃2) on the greybody factors of the AdS black holes with `= 0, M̃ = 1, αg = 1. (a) c2 = 1, βm = 1.08 and m̃ = 0, 0.2 and 0.5. (b) The magnification of (a). (c) c2 = 1, m̃ = 0.2 and βm = 1.08, 1.10 and 1.12. (d) m̃ = 0.2, βm = 1.08 and c2 = 1, 1/2 and 1/3.",
            "Fig. 17: The rigorous bounds (between r̃2 and r̃3) on the greybody factors of the AdS black holes with `= 0, M̃ = 1, αg = 1. (a) and (b) c2 = 1, βm = 1.08 and m̃ = 0, 0.2 and 0.5. (c) c2 = 1, m̃ = 0.2 and βm = 1.08, 1.10 and 1.12. (d) m̃ = 0.2, βm = 1.08 and c2 = 1, 1/2 and 1/3.",
            "Fig. 3: (a) The dRGT potentials for the dS case with ` = 0, M̃ = 1, c2 = −1, αg = 1, βm = 0.8 and m = 0, 0.2 and 0.5. (b) The magnification of (a).",
            "Fig. 6: The AdS potentials with `= 0, M̃ = 1, c2 = 1, αg = 1, βm = 1.1 and m̃ = 0, 0.2 and 0.5.",
            "Fig. 7: The AdS potentials with ` = 0, M̃ = 1, αg = 1, and m̃ = 0.2. (a) c2 = 1 and βm = 1.08, 1.10 and 1.12. (b) βm = 1.1 and c2 = 1, 1/2 and 1/3.",
            "Fig. 9: (a) The rigorous bounds on the greybody factors in the dS case with ` = 0, M̃ = 1, αg = 1, c2 = −0.01, βm = 0.875 and m̃ = 0, 0.07, 0.14 and 0.21. (b) The graph of the function Ṽ/ f in the dS case with the same parameters."
        ],
        "imgs": [
            "$2305.00459v1-Figure1-1.png",
            "$2305.00459v1-Figure11-1.png",
            "$2305.00459v1-Figure14-1.png",
            "$2305.00459v1-Figure15-1.png",
            "$2305.00459v1-Figure17-1.png",
            "$2305.00459v1-Figure3-1.png",
            "$2305.00459v1-Figure6-1.png",
            "$2305.00459v1-Figure7-1.png",
            "$2305.00459v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00461",
        "abstract": "  We introduce an adaptive viscosity regularization approach for the numerical\nsolution of systems of nonlinear conservation laws with shock waves. The\napproach seeks to solve a sequence of regularized problems consisting of the\nsystem of conservation laws and an additional Helmholtz equation for the\nartificial viscosity. We propose a homotopy continuation of the regularization\nparameters to minimize the amount of artificial viscosity subject to\npositivity-preserving and smoothness constraints on the numerical solution. The\nregularization methodology is combined with a mesh adaptation strategy that\nidentifies the shock location and generates shock-aligned meshes, which allows\nto further reduce the amount of artificial dissipation and capture shocks with\nincreased accuracy. We use the hybridizable discontinuous Galerkin method to\nnumerically solve the regularized system of conservation laws and the\ncontinuous Galerkin method to solve the Helmholtz equation for the artificial\nviscosity. We show that the approach can produce approximate solutions that\nconverge to the exact solution of the Burgers' equation. Finally, we\ndemonstrate the performance of the method on inviscid transonic, supersonic,\nhypersonic flows in two dimensions. The approach is found to be accurate,\nrobust and efficient, and yields very sharp yet smooth solutions in a few\nhomotopy iterations.\n",
        "title": "An adaptive viscosity regularization approach for the numerical solution\n  of conservation laws: Application to finite element methods",
        "texts": [
            "Figure 1: The source term s as a function of the shock strength S for smax = 4 (left) and the artificial viscosity µ(η) as a function of η̄ for η̄T = 0.2 (right). Note that the derivative of g(S) is continuous at S = 0 and S = smax, whereas that of g̃(S) is discontinuous there.",
            "Figure 10: Meshes used to perform the convergence study of the numerical solution for the inviscid Burgers’ equation.",
            "Figure 11: Computational meshes for inviscid flow past NACA 0012 airfoil at M∞ = 0.8 and 1.5o angle of attack.",
            "Figure 13: Artificial viscosity (top row) and Mach number (bottom row) at different homotopy iterations on the shock-aligned mesh for inviscid flow past NACA 0012 airfoil at M∞ = 0.8 and 1.5o angle of attack.",
            "Figure 16: Profiles of density (top) and Mach number (bottom) along y = 0 at different homptopy iterations for inviscid flow past the cylinder at M∞ = 3.",
            "Figure 17: Computed artificial viscosity (top row), enthalpy (middle row), and Mach number (bottom row) at different homotopy iterations on the regular mesh for inviscid supersonic flow past the cylinder at M∞ = 3.",
            "Figure 18: Computed artificial viscosity (top row), enthalpy (middle row), and Mach number (bottom row) at different homotopy iterations on the shock-aligned mesh for inviscid supersonic flow past the cylinder at M∞ = 3.",
            "Figure 2: The computed value of σ(λn) as we gradually decrease (λn) in the homotopy continuation for the inviscid hypersonic flow past a circular cylinder at M∞ = 7 on a regular mesh: (a) ξ is chosen to be density, (b) ξ is chosen to be pressure, (c) the normalized function σ(λn)/σ(λ1) for both cases.",
            "Figure 21: Computed artificial viscosity (top row), pressure (middle row), and Mach number (bottom row) at different homotopy iterations on the shock-aligned mesh for inviscid hypersonic flow past the cylinder at M∞ = 7.",
            "Figure 22: Profiles of the Mach number along the line y = 2.6051x as a function of r = √ x2 + y2 for n = 12, 13, and 14.",
            "Figure 3: The plot of the approximate density and pressure along the horizontal line y = 0 for several values of σ(λn)/σ(λ1) for the inviscid hypersonic flow past a cylinder at M∞ = 7 on a regular mesh. The approximate density is sharper and more accurate as σ(λn)/σ(λ1) increases during the homotopy continuation. The approximate pressure is smooth for σ(λn)/σ(λ1) ≤ 7.1, mildly oscillatory for σ(λn)/σ(λ1) = 10.2, and oscillatory and negative for σ(λn)/σ(λ1) = 14.4.",
            "Figure 4: Identification of shock locations for the inviscid transonic flow past a NACA 0012 airfoil.",
            "Figure 5: Generation of a shock-aligned mesh for the NACA 0012 example.",
            "Figure 6: Shock location and shock-aligned mesh for the inviscid Burgers’ equation.",
            "Figure 7: Artificial viscosity (top) and approximate solution (bottom) for the inviscid Burgers’ equation.",
            "Figure 8: Comparison of the approximate solution and the exact solution for the inviscid Burgers’ equation. (a) Profiles of the exact and approximate solutions at different times. (b) Profiles of the approximate solution for different homotopy iterations n at t = 0.05.",
            "Table 1: Convergence rates of the numerical solution in the smooth region for the inviscid Burgers’ equation.",
            "Table 2: Convergence rates of the numerical solution for the Ringleb flow."
        ],
        "imgs": [
            "$2305.00461v2-Figure1-1.png",
            "$2305.00461v2-Figure10-1.png",
            "$2305.00461v2-Figure11-1.png",
            "$2305.00461v2-Figure13-1.png",
            "$2305.00461v2-Figure16-1.png",
            "$2305.00461v2-Figure17-1.png",
            "$2305.00461v2-Figure18-1.png",
            "$2305.00461v2-Figure2-1.png",
            "$2305.00461v2-Figure21-1.png",
            "$2305.00461v2-Figure22-1.png",
            "$2305.00461v2-Figure3-1.png",
            "$2305.00461v2-Figure4-1.png",
            "$2305.00461v2-Figure5-1.png",
            "$2305.00461v2-Figure6-1.png",
            "$2305.00461v2-Figure7-1.png",
            "$2305.00461v2-Figure8-1.png",
            "$2305.00461v2-Table1-1.png",
            "$2305.00461v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00462",
        "abstract": "  We propose a flexible framework for defining the 1-Laplacian of a hypergraph\nthat incorporates edge-dependent vertex weights. These weights are able to\nreflect varying importance of vertices within a hyperedge, thus conferring the\nhypergraph model higher expressivity than homogeneous hypergraphs. We then\nutilize the eigenvector associated with the second smallest eigenvalue of the\nhypergraph 1-Laplacian to cluster the vertices. From a theoretical standpoint\nbased on an adequately defined normalized Cheeger cut, this procedure is\nexpected to achieve higher clustering accuracy than that based on the\ntraditional Laplacian. Indeed, we confirm that this is the case using\nreal-world datasets to demonstrate the effectiveness of the proposed spectral\nclustering approach. Moreover, we show that for a special case within our\nframework, the corresponding hypergraph 1-Laplacian is equivalent to the\n1-Laplacian of a related graph, whose eigenvectors can be computed more\nefficiently, facilitating the adoption on larger datasets.\n",
        "title": "Hypergraphs with Edge-Dependent Vertex Weights: Spectral Clustering\n  based on the 1-Laplacian",
        "texts": [
            "Fig. 1. Clustering performance in two real-world datasets as a function of the parameter α, which defines the EDVWs. (a-b) Clustering error and NCC in the 20 Newsgroups dataset. (c-d) Clustering error and NCC in the Covertype dataset."
        ],
        "imgs": [
            "$2305.00462v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00464",
        "abstract": "  The complicated mesoscopic configurations of composite plate and shell\nstructures requires a huge amount of computational overhead for directly\nsimulating their mechanical problems. In this paper, a unified high-order\nmulti-scale method, which can effectively simulate the mechanical behavior and\npredict yield strength of composite plates and shells, is developed. Firstly,\nthrough the multiscale asymptotic analysis of multi-scale elastic equations in\nthe orthogonal curvilinear coordinate system, a high-order multi-scale model is\nestablished, which can uniformly and effectively analyze the mechanical\nbehavior of composite plate and shell structures. Moreover, the error\nestimation of the high-order multi-scale solutions is derived. Then, combining\nwith the material strength theory, a high-order multi-scale model for the\nstrength prediction of composite plate and shell structures is established.\nNext, based on the established high-order multi-scale model, a multi-scale\nalgorithm is developed which can not only efficiently and accurately simulate\nthe mechanical behaviors of composite plate and shell structures, but also\npredict their yield strength. Finally, the effectiveness of the established\nhigh-order multi-scale method is verified by extensive numerical experiments.\nThe numerical experimental results indicate that the high-order multi-scale\nmethod can more accurately capture the meso-scale oscillatory behaviors of\ncomposite plate and shell structures. The unified high-order multi-scale method\nestablished in this paper is not only suitable for the prediction of mechanical\nproperties of composite plate and shell structures, but also can be further\nextended to the prediction of multi-field coupling properties of composite\nplate and shell structures.\n",
        "title": "Unified high-order multi-scale method for mechanical behavior simulation\n  and strength prediction of composite plate and shell structures",
        "texts": [
            "Fig. 1. The macroscopic and mesoscopic configurations of composite plate and shell: (a) macroscopic structure of composite plate; (b) macroscopic structure of composite shell; (c) mesoscopic unit cell I; (d) mesoscopic unit cell II; (e) mesoscopic unit cell III.",
            "Fig. 2. The computational results of displacement field of composite plate, mesoscopic configuration I: (a) 𝒖𝟑 (𝟎); (b) 𝒖𝟑 (𝟏𝛆); (c) 𝒖𝟑 (𝟐𝛆); mesoscopic configuration II:",
            "Fig. 3. The computational results of displacement field of composite shell, mesoscopic configuration I: (a) 𝒖𝟐 (𝟎); (b) 𝒖𝟐 (𝟏𝛆); (c) 𝒖𝟐 (𝟐𝛆); mesoscopic configuration II:",
            "Fig. 4.Diagram of mechanical loadings on composite plate and shell: (a) macroscopic structure of composite plate; (b) macroscopic structure of composite shell.",
            "Table 1. Information of computational cost.",
            "Table 2. The predictive results of yield strengths of composite plate and shell structures.",
            "Table 3. The computational results of displacement field of composite plate and shell structures."
        ],
        "imgs": [
            "$2305.00464v1-Figure1-1.png",
            "$2305.00464v1-Figure2-1.png",
            "$2305.00464v1-Figure3-1.png",
            "$2305.00464v1-Figure4-1.png",
            "$2305.00464v1-Table1-1.png",
            "$2305.00464v1-Table2-1.png",
            "$2305.00464v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00465",
        "abstract": "  The problem of testing the equality of the generating processes of two\ncategorical time series is addressed in this work. To this aim, we propose\nthree tests relying on a dissimilarity measure between categorical processes.\nParticular versions of these tests are constructed by considering three\nspecific distances evaluating discrepancy between the marginal distributions\nand the serial dependence patterns of both processes. Proper estimates of these\ndissimilarities are an essential element of the constructed tests, which are\nbased on the bootstrap. Specifically, a parametric bootstrap method assuming\nthe true generating models and extensions of the moving blocks bootstrap and\nthe stationary bootstrap are considered. The approaches are assessed in a broad\nsimulation study including several types of categorical models with different\ndegrees of complexity. Advantages and disadvantages of each one of the methods\nare properly discussed according to their behavior under the null and the\nalternative hypothesis. The impact that some important input parameters have on\nthe results of the tests is also analyzed. An application involving biological\nsequences highlights the usefulness of the proposed techniques.\n",
        "title": "New bootstrap tests for categorical time series. A comparative study",
        "texts": [
            "Figure 1: Rejection rates as a function of b and p for procedures MBB (left panels) and SB (right panels). Scenario 1 with T = 200.",
            "Figure 2: Two-dimensional scaling plane based on distance d̂CC for the 40 protein sequences. The points inside the rectangle represent time series whose generating processes are not significantly different according to the test based on d̂CC and MBB.",
            "Table 1: Simulated rejection rates in Scenario 1.",
            "Table 2: Simulated rejection rates in Scenario 2.",
            "Table 3: Simulated rejection rates in Scenario 3.",
            "Table 4: Simulated rejection rates in Scenario 4.",
            "Table 5: Simulated rejection rates in Scenario 5."
        ],
        "imgs": [
            "$2305.00465v1-Figure1-1.png",
            "$2305.00465v1-Figure2-1.png",
            "$2305.00465v1-Table1-1.png",
            "$2305.00465v1-Table2-1.png",
            "$2305.00465v1-Table3-1.png",
            "$2305.00465v1-Table4-1.png",
            "$2305.00465v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00466",
        "abstract": "  We present a model reduction approach that extends the original empirical\ninterpolation method to enable accurate and efficient reduced basis\napproximation of parametrized nonlinear partial differential equations (PDEs).\nIn the presence of nonlinearity, the Galerkin reduced basis approximation\nremains computationally expensive due to the high complexity of evaluating the\nnonlinear terms, which depends on the dimension of the truth approximation. The\nempirical interpolation method (EIM) was proposed as a nonlinear model\nreduction technique to render the complexity of evaluating the nonlinear terms\nindependent of the dimension of the truth approximation. We introduce a\nfirst-order empirical interpolation method (FOEIM) that makes use of the\npartial derivative information to construct an inexpensive and stable\ninterpolation of the nonlinear terms. We propose two different FOEIM algorithms\nto generate interpolation points and basis functions. We apply the FOEIM to\nnonlinear elliptic PDEs and compare it to the Galerkin reduced basis\napproximation and the EIM. Numerical results are presented to demonstrate the\nperformance of the three reduced basis approaches.\n",
        "title": "Efficient and accurate nonlinear model reduction via first-order\n  empirical interpolation",
        "texts": [
            "Figure 1: Parameter sample set SN and interpolation point set TM for the Gaussian parametrized function. For the right figure, the circles represent the first 64 interpretation points, while the squares represent 64 extra interpolation points for the first-order EIM.",
            "Figure 2: Convergence of the maximum interpolation error and the Lesbegue constant as a function of N for the original empirical interpolation (EIM) and the first-order empirical interpolation (FOEIM) of the Gaussian parametrized function.",
            "Figure 3: Convergence of the average relative error in output (a) and solution (b) for the model problem of Section 3.1. The curves with M = N correspond to the original EIM, while the curves with M > N correspond to the first-order EIM.",
            "Figure 4: FE mesh and numerical solutions at two parameter points for the nonlinear heat conduction problem.",
            "Figure 5: Convergence of the average relative error in output (a) and solution (b) for the model problem of Section 4.1. The curves with M = N correspond to the original EIM, while the curves with M > N correspond to the first-order EIM."
        ],
        "imgs": [
            "$2305.00466v1-Figure1-1.png",
            "$2305.00466v1-Figure2-1.png",
            "$2305.00466v1-Figure3-1.png",
            "$2305.00466v1-Figure4-1.png",
            "$2305.00466v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00468",
        "abstract": "  This article explores the relationship between Schubert varieties and\nequivariant embeddings, using the framework of homogeneous fiber bundles over\nflag varieties. We show that the homogenous fiber bundles obtained from\nBott-Samelson-Demazure-Hansen varieties are always toroidal. Furthermore, we\nidentify the wonderful varieties among them. We give a short proof of a\nconjecture of Gao, Hodges, and Yong for deciding when a Schubert variety is\nspherical with respect to an action of a Levi subgroup. By using\nBP-decompositions, we obtain a characterization of the smooth spherical\nSchubert varieties. Among the other applications of our results are: 1) a\ncharacterization of the spherical Bott-Samelson-Demazure-Hansen varieties, 2)\nan alternative proof of the fact that, in type A, every singular Schubert\nvariety of torus complexity 1 is a spherical Schubert variety, and 3) a proof\nof the fact that, for simply laced algebraic groups of adjoint type, every\nspherical $G$-Schubert variety is locally rigid, that is to say, the first\ncohomology of its tangent sheaf vanishes.\n",
        "title": "Applications of Homogeneous Fiber Bundles to the Schubert Varieties",
        "texts": [
            "Figure 4.1: A diagram of G-equivariant quotient maps."
        ],
        "imgs": [
            "$2305.00468v2-Figure4.1-1.png"
        ]
    },
    {
        "id": "2305.00470",
        "abstract": "  This article focuses on the study of lactating sows, where the main interest\nis the influence of temperature, measured throughout the day, on the lower\nquantiles of the daily feed intake. We outline a model framework and estimation\nmethodology for quantile regression in scenarios with longitudinal data and\nfunctional covariates. The quantile regression model uses a time-varying\nregression coefficient function to quantify the association between covariates\nand the quantile level of interest, and it includes subject-specific intercepts\nto incorporate within-subject dependence. Estimation relies on spline\nrepresentations of the unknown coefficient functions, and can be carried out\nwith existing software. We introduce bootstrap procedures for bias adjustment\nand computation of standard errors. Analysis of the lactation data indicates,\namong others, that the influence of temperature increases during the lactation\nperiod.\n",
        "title": "Quantile regression for longitudinal functional data with application to\n  feed intake of lactating sows",
        "texts": [
            "Figure 1: The lactation data. Left: daily feed intake profiles over lactation days of young sows (upper panel) and of old sows (lower panel) with three randomly selected profiles (black) in each group. For some sows data are only available in a subset of the lactation period. Right: smoothed temperature curves (grey), as well as the pointwise temperature quantiles curves at quantile levels 20% (blue), 50% (green) and 80% (red) based on the whole dataset.",
            "Figure 2: Predicted quantiles corresponding to the 20% and 80% pointwise temperature profiles. Bootstrap-adjusted estimates are shown with dotted curves. The left column refers to sows at their first pregnancy, while right one refers to the older sows. Results at quantile levels τ = 0.1 and τ = 0.5 are shown in the top and bottom row, respectively. Notice that predicted quantiles at different quantile levels are plotted on different scales.",
            "Figure 3: Estimated differences in quantiles between the pointwise 20% and 80% temperature curves, both without (solid black) and with (solid orange) bias adjustment. The corresponding pointwise confidence intervals, based on the model solely or on bootstrap, are illustrated with dashed curves. The left column refers to sows at their first pregnancy, while the right column refers to the older sows. Results at levels τ = 0, 1 and τ = 0.5 are shown in the top and bottom row, respectively.",
            "Table 1: AIC and sum of effective degrees of freedom for young and old animals when adopting model (4.1) (first column), model (4.1) with β(s, t) = βA(s) (second column), model (4.2) (third column) and model (4.3) (fourth column). The smallest values of AIC are emphasized in each row."
        ],
        "imgs": [
            "$2305.00470v1-Figure1-1.png",
            "$2305.00470v1-Figure2-1.png",
            "$2305.00470v1-Figure3-1.png",
            "$2305.00470v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00472",
        "abstract": "  Emerging quantum computing technologies, such as Noisy Intermediate-Scale\nQuantum (NISQ) devices, offer potential advancements in solving mathematical\noptimization problems. However, limitations in qubit availability, noise, and\nerrors pose challenges for practical implementation. In this study, we examine\ntwo decomposition methods for Mixed-Integer Linear Programming (MILP) designed\nto reduce the original problem size and utilize available NISQ devices more\nefficiently. We concentrate on breaking down the original problem into smaller\nsubproblems, which are then solved iteratively using a combined\nquantum-classical hardware approach. We conduct a detailed analysis for the\ndecomposition of MILP with Benders and Dantzig-Wolfe methods. In our analysis,\nwe show that the number of qubits required to solve Benders is exponentially\nlarge in the worst-case, while remains constant for Dantzig-Wolfe.\nAdditionally, we leverage Dantzig-Wolfe decomposition on the use-case of\ncertifying the robustness of ReLU networks. Our experimental results\ndemonstrate that this approach can save up to 90\\% of qubits compared to\nexisting methods on quantum annealing and gate-based quantum computers.\n",
        "title": "Efficient MILP Decomposition in Quantum Computing for ReLU Network\n  Robustness",
        "texts": [
            "Fig. 1: This diagram offers an high-level overview of Benders and Dantzig-Wolfe decomposition for a MILP. We identify with (Q) the problems that are optimized with quantum hardware.",
            "Fig. 2: Average certified accuracy and runtime of various verification techniques including HQ-CRAN-DW/-BD for the initial 100 test MNIST samples on two MLP networks.",
            "Fig. 3: Comparative analysis of Benders and Dantzig-Wolfe decompositions in the HQ-CRAN algorithm using simulated and quantum annealing on a 2-Layer MLP with 20 neurons per layer.",
            "Fig. 4: Experimental analysis of HQ-CRAN-DW using quantum annealing and QAOA (Aer simulator) on the first 100 samples of the MNIST test set.",
            "TABLE I: A comparative summary of MILP decomposition methods for quantum computing, detailing the complexity of the master and subproblems (P: polynomial-time solvable, NP-hard: non-deterministic polynomial-time hard), along with the number of qubits required at the first and 2ny -th iterations. The terms ns and my represent the number of slack variables and the number of constraints involving integer variables, respectively.",
            "TABLE II: Comparison of HQ-CRAN, with Benders (BD) [13] and Dantzig-Wolfe (DW) decomposition with quantum annealing. We run each algorithm on the first 100 samples of the MNIST test set."
        ],
        "imgs": [
            "$2305.00472v2-Figure1-1.png",
            "$2305.00472v2-Figure2-1.png",
            "$2305.00472v2-Figure3-1.png",
            "$2305.00472v2-Figure4-1.png",
            "$2305.00472v2-TableI-1.png",
            "$2305.00472v2-TableII-1.png"
        ]
    },
    {
        "id": "2305.00475",
        "abstract": "  It is a common belief that for magnetic fields typical for accreting neutron\nstars in High-Mass X-ray Binaries vacuum polarization only affects the\npropagation of polarized emission in the neutron star magnetosphere. We show\nthat vacuum resonances can significantly alter the emission from the poles of\naccreting neutron stars. The effect is similar to vacuum polarization in the\natmospheres of isolated neutron stars and can result in suppression of the\ncontinuum and the cyclotron lines. It is enhanced by magnetic Comptonization in\nthe hot plasma and proximity to the electron cyclotron resonance. We present\nseveral models to illustrate the vacuum polarization effect for various\noptically thick media and discuss how the choice of polarization modes affects\nthe properties of the emergent radiation by simulating polarized energy- and\nangle-dependent radiative transfer. Polarization effects, including vacuum\npolarization, crucially alter the emission properties. Together with strongly\nangle- and energy- dependent magnetic Comptonization, they result in a complex\nspectral shape, which can be described by dips and humps on top of a\npower-law-like continuum with high-energy cutoff. These effects provide a\npossible explanation for the common necessity of additional broad Gaussian\ncomponents and two-component Comptonization models that are used to describe\nspectra of accreting X-ray pulsars. We also demonstrate the character of\ndepolarization introduced by the radiation field's propagation inside the\ninhomogeneous emission region.\n",
        "title": "Vacuum polarization alters the spectra of accreting X-ray pulsars",
        "texts": [
            "Fig. 1. Left: Coordinate system chosen to define ellipses of the polarization modes. Right: Dependency of the ellipticity of the polarization modes on the electron number density. The vacuum resonance occurs in the center of the figure. Based on Fig. 1 from Lai & Ho (2003).",
            "Fig. 2. Cross sections for magnetic Compton scattering for two different propagation angles, θ. The modes are shown left: for the case of discontinuous and right: continuous refractive indices for B ≈ 2.6 × 1012 G.",
            "Fig. 3. Flux from a homogeneous slab summed over the two polarization modes for the higher (left) and lower (right) electron number density, for B ≈ 5.2 × 1012 G. Different types of polarization modes are shown: pure plasma (“pl”, dotted), pure vacuum (“v”, thick dashes), modes and modes with continuous/discontinuous (“pl+v: cri/dri”, dashed/solid) refractive indices.",
            "Fig. 4. Emission from a highly magnetized optically thick slab for continuous and discontinuous behavior of the refractive indices, for two B-field values, left: B ∼ 1.7 × 1012 G (Ecyc = 20 keV and EV ∼ 24 keV) and right: B ∼ 5.2 × 1012 G (Ecyc = 60 keV and EV ∼ 8 keV).",
            "Fig. 5. Top: Flux from an inhomogeneous mound with kTe = 5 keV and B ∼ 3.6×1012 G (Ecyc = 40 keV) for the cases including the plasma and vacuum polarization effects for non-adiabatic,“non-ad” and adiabatic, “ad”, mode propagation (left) and the pure plasma and vacuum cases (right). The left-top panel shows the corresponding blackbody spectrum (“BB”). Bottom: The corresponding degree of polarization. The energy range accessible by the Imaging X-ray Polarimetry Explorer (IXPE) is shown by the light-blue transparent region."
        ],
        "imgs": [
            "$2305.00475v2-Figure1-1.png",
            "$2305.00475v2-Figure2-1.png",
            "$2305.00475v2-Figure3-1.png",
            "$2305.00475v2-Figure4-1.png",
            "$2305.00475v2-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00480",
        "abstract": "  In the interstellar medium (ISM), the complex organic molecules that contain\nthe thiol group ($-$SH) play an important role in the polymerization of amino\nacids. We look for SH-bearing molecules in the chemically rich solar-type\nprotostar IRAS 16293-2422. After the extensive spectral analysis using the\nlocal thermodynamic equilibrium (LTE) model, we have detected the rotational\nemission lines of trans-isomer monothioformic acid (t-HC(O)SH) towards the IRAS\n16293 B using the Atacama Large Millimeter/Submillimeter Array (ALMA). We did\nnot observe any evidence of cis-isomer monothioformic acid (c-HC(O)SH) towards\nthe IRAS 16293 B. The column density of t-HC(O)SH towards the IRAS 16293 B was\n(1.02$\\pm$0.6)$\\times$10$^{15}$ cm$^{-2}$ with an excitation temperature of\n125$\\pm$15 K. The fractional abundance of t-HC(O)SH with respect to H$_{2}$\ntowards the IRAS 16293 B is 8.50$\\times$10$^{-11}$. The column density ratio of\nt-HC(O)SH/CH$_{3}$SH towards the IRAS 16293 B is 0.185. We compare our\nestimated abundance of t-HC(O)SH towards the IRAS 16293 B with the abundance of\nt-HC(O)SH towards the galactic center quiescent cloud G+0.693-0.027 and hot\nmolecular core G31.41+0.31. After the comparison, we found that the abundance\nof t-HC(O)SH towards the IRAS 16293 B is several times of magnitude lower than\nG+0.693-0.027 and G31.41+0.31. We also discuss the possible formation mechanism\nof t-HC(O)SH in the ISM.\n",
        "title": "Detection of monothioformic acid towards the solar-type protostar IRAS\n  16293-2422",
        "texts": [
            "Figure 1. Three-dimensional molecular structure of cHC(O)SH and t-HC(O)SH. The grey atoms are carbon (C), the red atoms are oxygen (O), the white atoms are hydrogen (H), and the yellow atoms are sulfur (S) (Garcı́a de la Concepción et al., 2022).",
            "Figure 2. Millimeter-wavelength (1.274 mm) continuum emission image of IRAS 16293–2422, a solar-like protostar with two sources, IRAS 16293 A and IRAS 16293 B. The black circle is the synthesised beam of the continuum emission image. The synthesised beam size of the continuum image is 0.498′′× 0.381′′. The blue contour levels are started at 3σ, where σ is the RMS of the continuum emission image, which is 3.85 mJy.",
            "Figure 3. Detected rotational emission lines of t-HC(O)SH towards the IRAS 16293 B with different transitions. The black spectrum presents the observed millimeter-wavelength molecular spectra of IRAS 16293 B. The blue synthetic spectra present the LTE model of t-HC(O)SH, and the red spectra indicate the LTE model of other nearby molecular transitions. The green vertical lines indicate the rest frequency positions of the detected transitions of t-HC(O)SH. In the emission spectra, ‘NB’ indicate the non-blended emission lines of t-HC(O)SH.",
            "Figure 4. Integrated emission maps (moment zero maps) of t-HC(O)SH towards the IRAS 16293 B. The integrated emission maps are overlaid with the 1.274 mm continuum emission map (black contour). The contour levels are started at 3σ, where σ = 4.23 mJy beam−1. The red circle is the synthesised beam of the integrated emission maps. The synthesised beam size of all integrated emission maps is 0.546′′×0.391′′.",
            "Table 1. Summary of the LTE fitted line parameters of the t-HC(O)SH towards the IRAS 16293 B.",
            "Table 2. The upper limit column density of the other SH-bearing molecules towards IRAS 16293 B."
        ],
        "imgs": [
            "$2305.00480v1-Figure1-1.png",
            "$2305.00480v1-Figure2-1.png",
            "$2305.00480v1-Figure3-1.png",
            "$2305.00480v1-Figure4-1.png",
            "$2305.00480v1-Table1-1.png",
            "$2305.00480v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00481",
        "abstract": "  This study focuses on the microstructure's evolution upon different aging\nconditions of a high-strength low-density steel with a composition of\nFe-28Mn-9Al-1C. The steel is hot-rolled, subsequently quenched without any\nsolution treatment, and then aged under different conditions. The\nmicrostructure of the samples was studied by means of Scanning Electron\nMicroscopy, Electron Backscatter Diffraction, and Transmission Electron\nMicroscopy. The aging treatment leads to the formation of an ordered\nface-centered cubic L12 phase named k-carbide. This study aims to characterize\nthe formation and growth of these k-carbides qualitatively and quantitatively\nunder different aging conditions. Then, an effort is made to relate the\nfraction and size of this phase with the tensile properties of the steel to\ndetermine the optimal aging conditions that will lead to a good combination of\nstrength and ductility. It has been found that the k-carbides start to form\nintragranularly through concentration fluctuations of aluminum and manganese\ninside the austenite grain. Then, with the process of spinodal decomposition,\nthey grow in size coherently with the matrix. During this process, the strength\nand hardness of the steel increase while maintaining a relatively high\nelongation. The best combination of high strength and ductility was achieved at\nthe aging condition of 8 h at 550 degrees Celsius with an ultimate tensile\nstrength up to 1157 MPa and total elongation of 51%. Increasing the aging\ntemperature and time, k-carbides start to form intergranularly, lose their\ncoherency with the matrix and severely compromise the hardness and strength.\nThe shearing of the carbides during deformation is also studied.\n",
        "title": "Microstructure evolution and mechanical behavior of Fe-Mn-Al-C\n  low-density steel upon aging",
        "texts": [
            "Figure 1: BSE-SEM images of the a) NA b) 550_1 c) 550_2.5 d) 550_8 e) 650_8 samples. f) Grain size (diameter) distribution obtained from the EBSD analysis.",
            "Figure 10: TKD IPF map of the 550_8 sample deformed at 36% strain. b) the point-to-point misorientation measured on the AB line of the IPF map. c) 2nd neighbor KAM map of the same grain. d) BF TEM of the exact grain showing different diffraction conditions and strain-induced bands marked with yellow arrows. e) part of image d showing the BF and the saed pattern from which the DF of image f) was taken. The carbides are diffracting from one band at a time, confirming the misorientation observed in the TKD g) HRTEM image of a grain in the same sample with a [001] zone axis. h) A κ-carbide shown in HRTEM and i) the same carbide after the inverse FFT process, indicating that it has been sheared.",
            "Figure 2: STEM images of the a) NA, b) 550_8, c) 650_8 samples.",
            "Figure 3: a) DF TEM image of the 550_8 sample showing the randomly dispersed κ-carbides. b) SAED pattern of the [001] zone axis from which the DF of image a was obtained. The magnified (200)γ diffraction spot with the diffraction satellites is superimposed on the image. c) DF TEM image of the 650_8 sample showing the organized κ-carbide stacks. d) SAED pattern of the [001] zone axis from which the DF of image c) was obtained. The DF images are taken from the (010)κ reflections.",
            "Figure 4: a) STEM EDX analysis on the κ-carbides of the 650_8 sample; b) the chemical analysis on the line scan allows for distinguishing the carbide from the matrix.",
            "Figure 5: a) the UTS. and HV values for different aging conditions. b) Engineering stress-strain curves for the samples aged at 550 °C. c) The corresponding true stress-strain curves. d) work-hardening rate as a function of true strain with the trendlines overlapping the graph.",
            "Figure 6: a) HRTEM of the 550_8 sample. b) the same area after the inverse FFT process, after masking the reflections of the austenite matrix. c) part of the same image showing only one intragranular κ-carbide. D) same carbide after the inverse FFT process.",
            "Figure 7: a) IQ- TKD map of the 650_8 sample. b) IPF map of the same scan, showing the orientations between the κ-carbides and the neighboring grains (G1, G2, G3). c) the same map rotated 90° towards the A2 axis. d) the same map rotated 90° towards the A1 axis. e) point-to-point misorientation between the κ and G1. f) point-to-point misorientation between the κ and G3. g) BF TEM image of a κ-carbide and its neighboring grains in sample 650_8. h) SAED pattern of the carbide marked in red. i) SAED pattern of the area of the grain marked in green",
            "Figure 8: a) EDX on STEM on the grain boundary of the N.A. sample. b) EDX on STEM on the grain boundary of the 550_8 sample. c) EDX on STEM on the grain boundary of the 650_8 sample with a coarse intergranular carbide. The content of Al and Mn for points A (carbide) and B (PFZ) is also given.",
            "Figure 9: ND- IPF maps of the 550_8 sample at a) 0% strain, b) 29% strain, and c) 46% strain. d-f) 2nd neighbor KAM maps of the same scans. g) chart showing the fraction of KAMs for the 0, 29, and 46% strain samples",
            "Table 1: The chemical composition of the studied alloy, in wt.%",
            "Table 2: The aging conditions of the studied samples",
            "Table 3: The average values of the tensile properties for the studied samples."
        ],
        "imgs": [
            "$2305.00481v1-Figure1-1.png",
            "$2305.00481v1-Figure10-1.png",
            "$2305.00481v1-Figure2-1.png",
            "$2305.00481v1-Figure3-1.png",
            "$2305.00481v1-Figure4-1.png",
            "$2305.00481v1-Figure5-1.png",
            "$2305.00481v1-Figure6-1.png",
            "$2305.00481v1-Figure7-1.png",
            "$2305.00481v1-Figure8-1.png",
            "$2305.00481v1-Figure9-1.png",
            "$2305.00481v1-Table1-1.png",
            "$2305.00481v1-Table2-1.png",
            "$2305.00481v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00483",
        "abstract": "  A sensitivity study for the search for the charged lepton flavor violating\nprocess $\\tau \\to \\gamma\\mu$ at the Super $\\tau$-Charm Facility is performed\nwith a fast simulation. With the expected performance of the current detector\ndesign and an integrated luminosity of \\SI{1}{ab^{-1}} corresponding to\none-year of data taking, the sensitivity on the branching fraction (BF) of\n$\\tau \\to \\gamma\\mu$ is estimated to be at the level of \\num{e-8}. The\nsensitivity under different detector performances are also studied. With ideal\nperformance, the BF could be probed to be \\num{2.8e-8} at \\SI{90}{\\percent}\nconfidence level. The sensitivity is expected to scale with the square root of\nthe luminosity, therefore with a total luminosity of \\SI{10}{ab^{-1}}\ncorresponding to ten-year of data taking, the sensitivity could reach\n\\num{8.8e-9}, which is about one order of magnitude improvement upon the\ncurrent best upper limit.\n",
        "title": "Sensitivity study of the charged lepton flavor violating process $\\tau\n  \\to \\gamma \\mu$ at STCF",
        "texts": [
            "Fig. 7: Signal resolution under different photon position resolution performance. The left and right figure shows the invariant mass and total energy of signal photon and muon, separately. The black solid line, the red dashed line and the blue dash-dotted line shows the result under baseline, 30 % and 50 % improved photon position resolution, separately.",
            "Fig. 8: Signal resolution under different photon energy resolution performance. The left and right figure shows the invariant mass and total energy of signal photon and muon, separately. The black solid line, the red dashed line and the blue dash-dotted line shows the result under baseline, 10 % and 20 % improved photon energy resolution, separately.",
            "Table 1: The result of further event selection. The first column is the tag modes, the second column is the selection criteria, the third and fourth columns are the number of background Nbkg and signal efficiency ε before and after further selection.",
            "Table 2: Result of optimization for pion/muon separation. The first column shows the levels of pion/muon separation capability of the detector. The second and third columns show the muon identification efficiency and sensitivity on BF under different detector performance, separately.",
            "Table 3: Result of optimization for photon position resolution. The first column shows the levels of photon position resolution performance of the detector. The second and third columns show the signal efficiency and sensitivity on BF under different detector performance.",
            "Table 4: Result of optimization for photon energy resolution. The first column shows the levels of photon energy resolution performance of the detector. The second and third columns show the signal efficiency and sensitivity on BF under different detector performance."
        ],
        "imgs": [
            "$2305.00483v1-Figure7-1.png",
            "$2305.00483v1-Figure8-1.png",
            "$2305.00483v1-Table1-1.png",
            "$2305.00483v1-Table2-1.png",
            "$2305.00483v1-Table3-1.png",
            "$2305.00483v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00484",
        "abstract": "  We consider a class of high-dimensional spatial filtering problems, where the\nspatial locations of observations are unknown and driven by the partially\nobserved hidden signal. This problem is exceptionally challenging as not only\nis high-dimensional, but the model for the signal yields longer-range time\ndependencies through the observation locations. Motivated by this model we\nrevisit a lesser-known and \\emph{provably convergent} computational methodology\nfrom \\cite{berzuini, cent, martin} that uses sequential Markov Chain Monte\nCarlo (MCMC) chains. We extend this methodology for data filtering problems\nwith unknown observation locations. We benchmark our algorithms on Linear\nGaussian state space models against competing ensemble methods and demonstrate\na significant improvement in both execution speed and accuracy. Finally, we\nimplement a realistic case study on a high-dimensional rotating shallow water\nmodel (of about $10^4-10^5$ dimensions) with real and synthetic data. The data\nis provided by the National Oceanic and Atmospheric Administration (NOAA) and\ncontains observations from ocean drifters in a domain of the Atlantic Ocean\nrestricted to the longitude and latitude intervals $[-51^{\\circ},\n-41^{\\circ}]$, $[17^{\\circ}, 27^{\\circ}]$ respectively.\n",
        "title": "Sequential Markov Chain Monte Carlo for Lagrangian Data Assimilation\n  with Applications to Unknown Data Locations",
        "texts": [
            "Figure 1: Comparison of machine times of SMCMC versus ensemble methods for different state dimensions d at fixed accuracy. This is the total time spent on all simulations when the fraction of absolute errors smaller than σy/2 is approximately 70%.",
            "Figure 10: Snapshot of simulation at time = 8hrs for the SW model with observations of unknown spatial locations. We show the prior mean (reference signal), the filter mean and their difference for the rotating shallow-water HMM with observations of unknown spatial locations. The blue curves illustrate the tracks of the drifters according to the data from [15], while the red curves illustrate the mean of 50 tracks of the drifters that are moving according to the prior. The red and blue tracks are presented here only for the purpose of illustration; Algorithm 2 does not use the blue tracks but aims to estimate them.",
            "Figure 11: Snapshot of simulation at time = 20hrs for the SW model with observations of unknown spatial locations",
            "Figure 12: Snapshot of simulation at time = 26hrs for the SW model with observations of unknown spatial locations.",
            "Figure 13: Snapshot of simulation at time = 32hrs for the SW model with observations of unknown spatial locations. See Figure 14 in which the region [4×105, 7×105]× [4×105, 7×105] is zoomed-in to show the difference between the blue and red drifters’ tracks.",
            "Figure 14: This is the region [4× 105, 7× 105]× [4× 105, 7× 105] from Figure 13 which contains four drifters is zoomed-in in order to show how different can be the blue (from real data) and red (from prior) tracks.",
            "Figure 2: Comparison of machine times of SMCMC versus ensemble methods for different state dimensions d when the number of ensembles/particles and accuracy are fixed. We set N = 1000 such that 50% of the absolute errors are less than σy/2.",
            "Figure 3: The illustration depicts the process of selecting which state variables to be observed based on the drifter’s location. The red circles represent a drifter at various points in time, and the red curve indicates its track. The blue circles correspond to the nearest surrounding grid point at the times of observation.",
            "Figure 4: (Known locations example) Histogram of absolute errors: |Filter − Signal| at all state variables and at all times. The percentage of occurrence here is defined as the number of elements in the bin divided by the total number of elements d× (T + 1).",
            "Figure 5: (Unknown locations example) Histogram of absolute errors: |Filter− Prior| at all state variables and at all times. The percentage of occurrence here is defined as the number of elements in the bin divided by the total number of elements d× (T + 1).",
            "Figure 6: Snapshot of simulation at time = 8hrs for the SW model with observations of known spatial locations. We present the hidden signal, the filter mean and their difference for the rotating shallow-water HMM with observations of known locations. Red curves illustrate the tracks of drifters in the region, which are moving according to the signal.",
            "Figure 7: Snapshot of simulation at time = 20hrs for the SW model with observations of known spatial locations",
            "Figure 9: Snapshot of simulation at time = 32hrs for the SW model with observations of known spatial locations.",
            "Table 1: Comparison of SMCMC and ensemble methods for different state dimensions d."
        ],
        "imgs": [
            "$2305.00484v2-Figure1-1.png",
            "$2305.00484v2-Figure10-1.png",
            "$2305.00484v2-Figure11-1.png",
            "$2305.00484v2-Figure12-1.png",
            "$2305.00484v2-Figure13-1.png",
            "$2305.00484v2-Figure14-1.png",
            "$2305.00484v2-Figure2-1.png",
            "$2305.00484v2-Figure3-1.png",
            "$2305.00484v2-Figure4-1.png",
            "$2305.00484v2-Figure5-1.png",
            "$2305.00484v2-Figure6-1.png",
            "$2305.00484v2-Figure7-1.png",
            "$2305.00484v2-Figure9-1.png",
            "$2305.00484v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00487",
        "abstract": "  By means of a modified Lugiato-Lefever equation model, we investigate the\nnonlinear dynamics of dissipative wave structures in coherently-driven Kerr\ncavities with a parabolic potential. The potential stabilizes system dynamics,\nleading to the generation of robust dissipative solitons in the positive\ndetuning regime, and of higher-order solitons in the negative detuning regime.\nIn order to understand the underlying mechanisms which are responsible for\nthese high-order states, we decompose the field on the basis of linear\neigenmodes of the system. This permits to investigate the resulting nonlinear\nmode coupling processes. By increasing the external pumping, one observes the\nemergence of high-order breathers and chaoticons. Our modal content analysis\nreveals that breathers are dominated by modes of corresponding orders, while\nchaoticons exhibit proper chaotic dynamics. We characterize the evolution of\ndissipative structures by using bifurcation diagrams, and confirm their\nstability by combining linear stability analysis results with numerical\nsimulations. Finally, we draw phase diagrams that summarize the complex\ndynamics landscape, obtained when varying the pump, the detuning, and the\nstrength of the potential.\n",
        "title": "Nonlinear dynamics of dissipative structures in coherently-driven Kerr\n  cavities with a parabolic potential",
        "texts": [
            "Figure 1. The physical model Eq. (4) could be applied to a passive coherelty-driven cavity in (a) and to a bottle resonator in (b).",
            "Figure 2. In the left panels, we compare the field power profile |A(τ)|2 in the absence of the potential (C = 0, red δ-scan) in (a), or in the presence of the potential (C = 1, red δ-scan) in (b) and (C = 1, blue δ-scan) in (c), when varying the detuning δ. In the center and right panels, we trace the field intensity |A(τ)|2, with or without the potential, for selected values of the cavity detuning δ: green curves refer to C = 0, red curves to C = 1, red δ-scan, and blue curves to C = 1, blue δ-scan; δ = 4 in (i,ii), δ = 0 in (iii), δ = −2 in (iv), δ = −8 in (v), δ = −12 in (vi).",
            "Figure 6. Different breathers, corresponding the bifurcation diagram in Fig. 5, are plotted here for (i,ii) δ = 2.4, (iii) δ = −2, (iv) δ = −1, (v) δ = −0.5, (vi) δ = 0, (vii) δ = 0.5, when P = 3.5, C = 1. Sub-figures on the top, middle, and bottom panels, marked by (1), (2) and (3), respectively, correspond to the time evolution of power |A(τ, t)|2, total energy ˜ |A(τ, t)|2dτ and modal energies |Cn(t)|2, and to the time evolution of real and imaginary parts of the mode amplitudes Cn(t), for each δ in (i-vii).",
            "Figure 8. Bifurcation diagrams of field energy vs. detuning δ for different pump strength P in (a). Gray (pink) regions represent the stable soliton solutions of different orders (unstable solutions: breathers, chaoticons). The fold-points-connected curves (Fm,1 and Fm,2), the Hopf-points-connected curves (Hm), and the curves of chaoticon onset (Cm) at each resonance peak m in (a) are represented in the phase diagram in (b), which is the top view of (a). The solid (dashed) curve represents that the curve is at the top (lower) layer. On the one hand, increasing pumping folds the phase diagram, leading to the formation of bistable solutions (including solitons, breathers, and chaoticons). On the other hand, varying the detuning changes the solution order at different resonances surrounding each peak.",
            "Figure 9. (a) Bifurcation diagrams of field energy vs. detuning δ for different potential strength √ C in (a), when P = 3.5. (b) Phase diagram vs. detuning δ and potential strength √ C, which is the top view of (a). The notations are the same as Fig. 8. The importance of the potential in suppressing oscillatory instabilities and stabilizing DKS becomes apparent as √"
        ],
        "imgs": [
            "$2305.00487v1-Figure1-1.png",
            "$2305.00487v1-Figure2-1.png",
            "$2305.00487v1-Figure6-1.png",
            "$2305.00487v1-Figure8-1.png",
            "$2305.00487v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00489",
        "abstract": "  Focused plenoptic cameras can record spatial and angular information of the\nlight field (LF) simultaneously with higher spatial resolution relative to\ntraditional plenoptic cameras, which facilitate various applications in\ncomputer vision. However, the existing plenoptic image compression methods\npresent ineffectiveness to the captured images due to the complex\nmicro-textures generated by the microlens relay imaging and long-distance\ncorrelations among the microimages. In this paper, a lossy end-to-end learning\narchitecture is proposed to compress the focused plenoptic images efficiently.\nFirst, a data preprocessing scheme is designed according to the imaging\nprinciple to remove the sub-aperture image ineffective pixels in the recorded\nlight field and align the microimages to the rectangular grid. Then, the global\nattention module with large receptive field is proposed to capture the global\ncorrelation among the feature maps using pixel-wise vector attention computed\nin the resampling process. Also, a new image dataset consisting of 1910 focused\nplenoptic images with content and depth diversity is built to benefit training\nand testing. Extensive experimental evaluations demonstrate the effectiveness\nof the proposed approach. It outperforms intra coding of HEVC and VVC by an\naverage of 62.57% and 51.67% bitrate reduction on the 20 preprocessed focused\nplenoptic images, respectively. Also, it achieves 18.73% bitrate saving and\ngenerates perceptually pleasant reconstructions compared to the\nstate-of-the-art end-to-end image compression methods, which benefits the\napplications of focused plenoptic cameras greatly. The dataset and code are\npublicly available at https://github.com/VincentChandelier/GACN.\n",
        "title": "Learned Focused Plenoptic Image Compression with Microimage\n  Preprocessing and Global Attention",
        "texts": [
            "Fig. 1. Imaging principle of: (a) traditional plenoptic cameras; (b) focused plenoptic cameras. Red lines and blue lines represent the light rays coming from a focused object point and an unfocused object point, respectively.",
            "Fig. 10. Test flow chart for focused plenoptic image compression performance comparison following the common test conditions in MPEG lenslet video coding [5]. The sub-aperture images rendered from original plenoptic images are set as the reference to compute average distortion. The conversion and compression flow of hybrid intra codecs, learned plenoptic image compression and sub-aperture image compression methods are circled by black-dashed rectangle, green-dashed rectangle and blue-dashed rectangle, respectively.",
            "Fig. 11. RD performance evaluation of proposed network and original plenoptic image compression testing cases on (a) I01 “Cars” and (b) I15 “Matryoshka_170”.",
            "Fig. 12. RD performance evaluation of proposed network and preprocessed plenoptic image compression testing cases on (a) I01 “Cars” and (b) I15 “Matryoshka_170”.",
            "Fig. 13. RD performance evaluation of proposed network and sub-aperture-image-based compression testing cases on (a) I01 “Cars” and (b) I15 “Matryoshka_170”.",
            "Fig. 14. Visualization of the central view of reconstructed plenoptic image I01 “Cars”. Three selected areas are marked by green, blue and red rectangles respectively. The metrics are [bpp↓/PSNR↑/MS-SSIM↑].",
            "Fig. 15. Average RD performance evaluation of ablation study for global attention module on 20 test images.",
            "Fig. 2. Plenoptic images of a same scene captured by: (a) the traditional plenoptic camera; and (b) the focused plenoptic camera.",
            "Fig. 3. Preprocessing for the 256 × 256 patch of the raw plenoptic image marked in the red rectangle in Fig. 2(b) as a toy example: (a) raw plenoptic image patch; (b) devignetted patch (a); (c) pixel classification of (b), in which inter-microimage pixels, boundary incomplete microimages, and vignetting pixels are marked in black, blue, and light green, respectively. The circular region denoted in orange contains light field effective pixels. The magenta and yellow areas covering sub-aperture image effective pixels are the pixels picked by our data preprocessing scheme; and (d) the plenoptic image patch after preprocessing, in which the magenta and yellow blocks correspond to those in (c) to show the relative position.",
            "Fig. 4. Average distortion among 5 × 5 sub-aperture images with cutting size d. (a) Distortion measured with MSE. (b) Distortion measured with MS-SSIM.",
            "Fig. 5. Preprocessed plenoptic image and magnification. (a) Preprocessed plenoptic image. (b) Magnification of (a) in the green rectangle.",
            "Fig. 6. Snapshot of the categories in the dataset. Each category is presented by the central view of a plenoptic image.",
            "Fig. 7. The architecture of our proposed network with global attention module. Conv (inch, outch, kernelsize, stride) is a convolutional layer with the kernel size of kernelsize × kernelsize and a stride of stride. Global Attention (conventionalnetwork) represents the global attention module using conventionalnetwork as resampling network structure.",
            "Fig. 8. Global attention module. The feature map f and resampled feature map df are reshaped into pixels-wise vector rf and drf . The relevant latent vectors of 1df are fetched with the multi-head global attention with the query q1 derived from drf and the key k1, the value v1 derived from rf by linear layer. With 2 times global attention computing, resampling result of is obtained by reshaping output of attention 2df back to multi-dimension. The global attention module is beneficial to capture the global information in down-sampling/up-sampling operations.",
            "Fig. 9. Central views of 20 test images. (a) I01, and (b) I02, are the first frame of MPEG I-Visual test video sequences “Cars” [59] and “Matryoshka” [62], respectively; (c)-(u) are images from “FPI2k”, which are (c) I03, Box-1; (d) I04, Box_7; (e) I05, Box-28; (f) I06, Building_block_5; (g) I07, Building_block_86; (h) I08, Building_block_141; (i) I09, Calendar_9; (j) I10, Door_8; (k) I11, Indicator_6; (l) I12, Laboratory_65; (m) I13, Matryoshka_93; (n) I14, Matryoshka_169; (o) I15, Matryoshka_170; (p) I16, Plush toy_135; (q) I17, Toy car_1; (r) I18, Toy car_197; (s) I19, Toy car_502; (t) I20, Tree_29.",
            "TABLE III BD-RATE COMPARISON AMONG THE ORIGINAL AND PREPROCESSED PLENOPTIC IMAGE COMPRESSION METHODS",
            "TABLE IV BD-RATE COMPARISON FOR PROPOSED METHOD",
            "TABLE V EXECUTION TIME AND RELATIVE RATIOS OF DIFFERENT CODING METHODS AT FOUR RATES"
        ],
        "imgs": [
            "$2305.00489v1-Figure1-1.png",
            "$2305.00489v1-Figure10-1.png",
            "$2305.00489v1-Figure11-1.png",
            "$2305.00489v1-Figure12-1.png",
            "$2305.00489v1-Figure13-1.png",
            "$2305.00489v1-Figure14-1.png",
            "$2305.00489v1-Figure15-1.png",
            "$2305.00489v1-Figure2-1.png",
            "$2305.00489v1-Figure3-1.png",
            "$2305.00489v1-Figure4-1.png",
            "$2305.00489v1-Figure5-1.png",
            "$2305.00489v1-Figure6-1.png",
            "$2305.00489v1-Figure7-1.png",
            "$2305.00489v1-Figure8-1.png",
            "$2305.00489v1-Figure9-1.png",
            "$2305.00489v1-TableIII-1.png",
            "$2305.00489v1-TableIV-1.png",
            "$2305.00489v1-TableV-1.png"
        ]
    },
    {
        "id": "2305.00491",
        "abstract": "  In recent years, studies in epigenetic inheritance in biological systems as\nwell as studies on evolution in non-biological systems e.g., machine learning\nand robotics, have reopened the discussion of non-Darwinian methods of\nevolutionary optimization. In this paper, the three most prominent classical\nevolutionary strategies Lamarckian, Darwinian, and Baldwinian are implemented\nand compared in an agent-based simulation. The dynamics of optimization and\nlearning are studied in constant as well as in dynamic environments, both as\nsingle evolutionary strategy populations and as mixed evolutionary strategy\npopulations. The three different agent types are implemented as simple objects\nthat need to gather resources to replicate. The agent fitness is defined\nthrough a bitstring match between the agent and the environment and to\nreplicate each agent needs to gather sufficient resources. To make a fair\ncomparison between the three different evolutionary methods, we can assume that\nboth the ability to learn within an individual's lifetime and the learning\nprocess itself require additional resources compared to an evolutionary process\nwithout lifetime learning. When all three strategies coexist and we vary the\nreplication costs for the different strategies we find the following general\npattern: The evolutionary advantage decreases for Lamarckian and Baldwinian\nstrategies as their learning costs increase and/or as their relative\nreplication costs increase compared to the Darwinian strategies, and in most\nsituations the Baldwinian strategy performs in between the Darwinian and\nLamarckian strategies. Finally, as our investigations emphasize the superiority\nof the Lamarckian strategy in most cases with low learning cost, it is\ninteresting to note that a corresponding biological inheritance mechanism did\nnot evolve, while the Lamarckian strategy is currently extensively used in\ntechnology applications.\n",
        "title": "Dynamics of Darwinian versus Baldwinian versus Lamarckian evolution",
        "texts": [
            "Figure 10: Standard conditions with α = 0.001. With a smaller error rate, the Darwinian and Baldwinian optimization is slower, but the Darwinian population is able to reach states of higher fitness likely due to the lesser noise introduced in the population. The Baldwinian population is inhibited from reaching this state of high fitness due to the noise introduced by learning events, though given enough simulation time, the population may be able to down-regulate curiosity. Darwinian computation time = 35 seconds, Baldwinian computation time = 53 seconds, Lamarckian computation time = 55 seconds.",
            "Figure 11: Standard conditions with Rreplication = 5. At a smaller replication threshold, the Darwinian algorithm is able to search through more states. The optimization is therefore faster. The non-constant fitness of the Lamarckian population after reaching zero mean curiosity is due to the presence of several competing families with zero curiosity at t > 520. Darwinian computation time = 20 seconds, Baldwinian computation time = 26 seconds, Lamarckian computation time = 30 seconds.",
            "Figure 13: Standard conditions with Rlearning = 9. At learning cost comparable to the replication cost, the optimization of the Lamarckian population is slower than the Darwinian and Baldwinian. A selection pressure for lowering curiosity emerges in the Baldwinian population. Darwinian computation time = 15 seconds, Baldwinian computation time = 21 seconds, Lamarckian computation time = 21 seconds.",
            "Figure 16: Winning agent types as a function of relative replication cost and learning cost for mixed populations consisting of 100 Lamarckian and 100 Darwinian agents (left panel); 100 Baldwinian and 100 Darwinian agents (middle panel); 100 Lamarckian and 100 Baldwinian agents (right panel).",
            "Figure 19: Each subplot shows the winning agent types in dynamic environments described by pairs of values for the environment mutation period (τE) and the environment mutation rate (αE). Furthermore, these subplots are made for 16 different pairs of values for the relative replication cost (RLB and RBD, constrained by demanding RLB = RBD) and learning cost (Rlearning).",
            "Figure 4: Upper panel: The temporal dynamics of population mean fitness of a pure Darwinian population plotted against t. Lower left panel: Family mean fitness of agent families in the pure Darwinian population vs. t. The individual agents in the initial population are ascribed a number from 1 to N - called their family identifier - with a corresponding color in the used colormap (blue → green → yellow). This identifier is inherited by their daughter agents. Lower right panel: The number of family members in each family vs. t. It should be noted that graphs may be hidden by other graphs at small t, as families mean fitness graphs are degenerate for Darwinian populations because of the small variance in phenotypic fitness (Figure 7).",
            "Figure 5: Upper panel: The temporal dynamics of population mean fitness of a pure Lamarckian population plotted against t. Lower left panel: Family mean fitness of agent families in the pure Lamarckian population vs. t. Lower right panel: The number of family members in each family vs. t.",
            "Figure 6: Upper panel: The temporal dynamics of population mean fitness of a pure Baldwinian population plotted against t. Lower left panel: Family mean fitness of agent families in the pure Baldwinian population vs. t. Lower right panel: The number of family members in each family vs. t.",
            "Figure 7: The variance of phenotypic fitness in the populations from the simulations shown on Figures 4-6. The Lamarckian population (red) shows a very high initial increase in phenotypic variance followed by a correspondingly fast decrease, as the population has reached a mean fitness of ∼ 0.8. At t ≈ 490, the Lamarckian phenotypic variance becomes zero, as all agents in the population have optimal fitness and zero curiosity. The Darwinian population (blue) has the lowest maximal phenotypic variance; and this maximum also happens later in the dynamics than for the Lamarckian and Baldwinian populations. The Baldwinian population (purple) shows higher phenotypic variance compared to the Darwinian population at all times, as the Baldwinian agent type was designed to do.",
            "Figure 8: Standard conditions. Darwinian computation time = 14 seconds, Baldwinian computation time = 21 seconds, Lamarckian computation time = 23 seconds.",
            "Table 1: Standard conditions for simulations"
        ],
        "imgs": [
            "$2305.00491v1-Figure10-1.png",
            "$2305.00491v1-Figure11-1.png",
            "$2305.00491v1-Figure13-1.png",
            "$2305.00491v1-Figure16-1.png",
            "$2305.00491v1-Figure19-1.png",
            "$2305.00491v1-Figure4-1.png",
            "$2305.00491v1-Figure5-1.png",
            "$2305.00491v1-Figure6-1.png",
            "$2305.00491v1-Figure7-1.png",
            "$2305.00491v1-Figure8-1.png",
            "$2305.00491v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00496",
        "abstract": "  Exact solutions for non-Hermitian quantum many-body systems are rare but may\nprovide valuable insights into the interplay between Hermitian and\nnon-Hermitian components. We report our investigation of a non-Hermitian\nvariant of a p-wave Kitaev chain by introducing staggered imbalanced pair\ncreation and annihilation terms. We find that there exists a fixed line in the\nphase diagram, at which the ground state remains unchanged in the presence of\nnon-Hermitian term under the periodic boundary condition for a finite system.\nThis allows the constancy of the topological index in the process of varying\nthe balance strength at arbitrary rate, exhibiting the robustness of the\ntopology for non-Hermitian Kitaev chain under time-dependent perturbations. The\nunderlying mechanism is investigated through the equivalent quantum spin system\nobtained by the Jordan-Wigner transformation for infinite chain. In addition,\nthe exact solution shows that a resonant non-Hermitian impurity can induce a\npair of zero modes in the corresponding Majorana lattice, which asymptotically\napproach the edge modes in the thermodynamic limit, manifesting the\nbulk-boundary correspondence. Numerical simulation is performed for the quench\ndynamics for the systems with slight deviation from the fixed line to show the\nstability region in time. This work reveals the interplay between the pair\ncreation and annihilation pairing processes.\n",
        "title": "Fixed lines in a non-Hermitian Kitaev chain with spatially balanced\n  pairing processes",
        "texts": [
            "FIG. 1. (a) Schematic of a 1D Kitaev model for spinless fermion with non-Hermitian imbalanced pair terms. It consists of two sublattices A and B in black and white, respectively. Here, J is the hopping strength between two adjacent sites. ∆a is the strength of the p-wave pair creation (annihilation) on the odd (even) dimer while ∆b is the strength of the p-wave pair annihilation (creation) on the even (odd) dimer. (b) Schematic illustration of fixed lines. The fixed lines are a family of parallel lines with slope −1 in the ∆a-∆b plane. The Hamiltonians with parameters at each line share the same ground state with the same energy, which are determined only by the intercepts of the line. The intercepts of the five representative lines are −2, −1, 0 , 1 and 2. (c) Plot of the fidelity for the dynamic process in the system with different time-dependent parameters in Eq. (17). It indicates that when the time-dependent parameters only move along a fixed line, the fidelity is always equal to 1.",
            "FIG. 3. The profiles of the zero modes from Eq. 31 for Majorana lattices in Fig. 2 with N = 8. The first row is the plot for the system with the condition λ = λ− and the second row with the condition λ = λ+. The color bars indicate the amplitudes of two different sublattices. All the four patterns exhibit evident skin effect.",
            "FIG. 4. 2D color contour plots of the fidelity in Eq. (43) for the quench processes. The system parameters ∆a/∆b and µ are indicated in the panels. The unitary fidelity in (a1) and (b1) demonstrates our exact results. (a2, a3) and (b2, b3) are the cases with two different values of small µ. The deep shadows indicate the region of zero fidelity. The sharp edge indicates the sudden drops of the fidelity."
        ],
        "imgs": [
            "$2305.00496v2-Figure1-1.png",
            "$2305.00496v2-Figure3-1.png",
            "$2305.00496v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00499",
        "abstract": "  We perform Monte-Carlo measurements of two and three point functions of\ncharged operators in the critical O(2) model in 3 dimensions. Our results are\ncompatible with the predictions of the large charge superfluid effective field\ntheory. To obtain reliable measurements for large values of the charge, we\nimproved the Worm algorithm and devised a measurement scheme which mitigates\nthe uncertainties due to lattice and finite size effects.\n",
        "title": "Numerical tests of the large charge expansion",
        "texts": [
            "Figure 1: ∆(1), extracted with eq.(2.3), for α = 2 and L ∈ [16, 32]. Notice that the region where there are significant deviations from a constant value, on the left of the vertical line, gets smaller as L increases. This is expected from lattice effects. We include the previous Monte-Carlo result with error bars at 1σ, taken from Tab.I in [30], as well as the bootstrap result [36].",
            "Figure 11: Ratio in eq.(3.8). The black line is evaluation with c3/2 = 0.339(1), obtained in sec.2.",
            "Figure 12: Variance of RQ(16) as a function of Q, defined in eq. (2.1). The comparison is made at a fixed CPU time. The histograms show the distribution of RQ(16), as obtained from the measurement step described in alg. 2.",
            "Figure 13: Extrapolations of the difference between consecutive conformal dimensions to L = ∞. In blue we present our data for L = 32, 48, 64. In orange we present the linear extrapolation to L = ∞ and in red the results in [30]. In black, we present the bootstrap results [49]. In green, we present the results from [50], for Q = 1, and [51] for Q = 2, 3, 4. Not all of the results exist for all the charges.",
            "Figure 2: Here we plot both the measurements of D(Q)/Q1/2 obtained for L = 32 (107 Worm steps), as well as the results of the extrapolation to L = ∞, obtained using α = 2 in eq. (2.3). We test the leading behaviour of eq. (1.1) by demonstrating the linearity of D(Q)/Q1/2. We reproduce the previous results of [30]. As explained at the end of the section, we performed best-fits of the coefficients c3/2 and c 1 2 in eq. (1.1), restricting to charges Q ≥ Qmin for different choices of Qmin. The blue dashed curve is obtained using the coefficients extracted from the average of all the fits with Qmin = 4, . . . , 10. The orange dashed curve is the best fit obtained using only charges Q ≥ 8. Remarkably, the two lines are almost indistinguishable and almost overlap with all the data points. In the table below we list the data used in the fits presented in this section. Check app. B for a detailed discussion.",
            "Figure 3: Best-fit values of c3/2 (left) and c1/2 (right) as a function of the minimum charge included in the fit. For larger values of Qmin the error bars are larger than the plotted range. The coloured regions represent the 1σ interval quoted on (2.4).",
            "Figure 4: Difference between the data and the best-fit curves with the averaged parameters in eq. (2.4) (red) and with Qmin = 8 (blue). For large values of Q the uncertainties exceed the range displayed in the plot.",
            "Figure 5: Results for A(Q), defined in eq. 2.5. Notice the large uncertainties despite the precision of the measurements of ∆(Q).",
            "Figure 6: Difference between the value of γQ measured from Monte-Carlo and the theoretical prediction 2D(Q) + D(2Q) (see eq. (3.5)). The result is obtained from the ratio of correlation functions sampled at L = 32 and L = 64, at the same relative position. We used the values D(Q) and D(2Q) measured in the previous section for the theoretical prediction.",
            "Figure 7: Linear extrapolation of the OPE coefficient λQ,Q,−2Q to L → ∞ at fixed x and Q = 1.",
            "Figure 8: Numerical results. In regime I, the OPE coefficients extracted from the linear extrapolation are in cyan, and OPE coefficients extracted using lattice corrections are in dark blue. In regime II, both methods yield the same results. The OPE coefficient for Q = 1 is the same in both regimes. Notice that the OPE coefficient in regime I grows much faster with Q than the one in regime II; this is in qualitative agreement with the EFT predictions. The data in this plot is in the table below.",
            "Figure 9: Comparison between the numerical results for eq. (3.7) and the predicted value c3/2 = 0.34(1). The black line is the value of c3/2 obtained in sec.2, and its width is the uncertainty. The coloured full lines are the fits and the coloured regions around their uncertainty. The fits converge to the black line for larger values of Q.",
            "Table 1: Result for the fits of the OPE coefficient in regime I with different free parameters and for different values of the charges in eq. 3.1. We show the fits with both the data obtained from the linear extrapolation and with the inclusion of lattice corrections; notice the latter are more precise.",
            "Table 2: Result for the fit of the OPE coefficient in Regime II, with different parameters, in eq. (3.2).",
            "Table 3: Known conformal dimension of scalar operators in the 3d O(2) model [49]."
        ],
        "imgs": [
            "$2305.00499v3-Figure1-1.png",
            "$2305.00499v3-Figure11-1.png",
            "$2305.00499v3-Figure12-1.png",
            "$2305.00499v3-Figure13-1.png",
            "$2305.00499v3-Figure2-1.png",
            "$2305.00499v3-Figure3-1.png",
            "$2305.00499v3-Figure4-1.png",
            "$2305.00499v3-Figure5-1.png",
            "$2305.00499v3-Figure6-1.png",
            "$2305.00499v3-Figure7-1.png",
            "$2305.00499v3-Figure8-1.png",
            "$2305.00499v3-Figure9-1.png",
            "$2305.00499v3-Table1-1.png",
            "$2305.00499v3-Table2-1.png",
            "$2305.00499v3-Table3-1.png"
        ]
    },
    {
        "id": "2305.00502",
        "abstract": "  We suggest a nanoelectromechanical setup and corresponding time protocol of\nits manipulation by which we transduce quantum information from charge qubit to\nnanomechanical cat state. The setup is based on the AC Josephson effect between\nbulk superconductors and mechanically vibrating mesoscopic superconducting\nisland in the regime of the Cooper pair box. Starting with a pure state with\nquantum information initially encoded into superposition of the Cooper pair box\nstates, applying a specially tailored time protocol upon bias voltage and gate\nelectrodes, we obtain a new pure state with information finally encoded into\nsuperposition of nanomechanical coherent states constituting the cat state.\nThis performance is achieved using quantum entanglement between electrical and\nmechanical states. Nanomechanical cat states serve as a storage of quantum\ninformation, motivated by significantly longer decoherence time with respect to\nthe charge qubit states, from which the information can be transdued back to\nthe charge qubit applying the reverse time protocol.\n",
        "title": "Transduction of quantum information from charge qubit to nanomechanical\n  cat-state",
        "texts": [
            "FIG. 1. Schematic illustration of the NEM setup. The superconducting mesoscopic quantum dot (CPB) is attached to a suspended nanowire (e.g. a carbon nanotube), capable of performing the in-plane harmonic vibrations between two superconducting electrodes (S) symmetrically biased by a constant voltage Vb used to create a superconducting phase Φ(t). Electrostatic gate electrodes (G) usage is twofold: VG is used to bring the states of the quantum dot with zero and one excess Cooper pair into the CPB regime, while δV (t) is used in the time-protocol to provide a finite approximately homogeneous electric field across the central region of the junction (cross) on demand, while changing no potential (due to symmetric configuration).",
            "FIG. 2. Schematic illustration of the QI transduction protocol in the (x, p) phase space. (a) During the time interval t ∈ (0, ts) the entangled state Eq. (12) of qubit and mechanical coherent states is built applying the coherent AC Josephson effect-based dynamics coupled to mechanical oscillator while keeping electric field equal to zero. (b) During the time interval t ∈ (ts, ts + τ∗) the pure state Eq. (19) is built by switching off the bias voltage (Josephson dynamics) and applying the finite electric field E performing ”rotation”of qubit states in opposite directions, due to position-dependent (+/−) interaction, until they coincide.",
            "FIG. 3. (a) The Wigner function W (x, p, τ ) = W1(x, p, τ ) + W2(x, p, τ ), defined by Eqs. (22) and (24) under conditions (17), in the (x, p)−phase space depending on time τ ≡= t − ts = 0, 1, 2.5, 3.5, 4.5, 2π in unites of ω−1 shown in figs. a-1 to a-6 respectfully. (b)The entropy of entanglement Eq. (29) as a function of time τ (in units ω−1, T = 2π/ω is a period of oscillations) under conditions (17). The dashed horizontal line a maximal possible value of entropy ln(2). The moment τ∗ is the first moment at which the pure state is achieved, thus Sen(τ∗) = 0. The parameters used were |A+| = |A−| = 1/ √ 2, ξλN ≈ 1, θ = 2πM+π/4, M is an integer. The dashed curve in (b) is calculated for |A+| = 0.4, |A−| = 0.9165.",
            "FIG. 4. Schematic illustration of transduction process. The QI (α, β) is encoded into the charge qubit (CPB) at t = 0 while nanomechanical subsystem (NM) is in the vacuum state. During execution of the protocol it is stored in the entangled states of charge qubit and nanomechanics (CPB⊗NM). At t = ts + τ∗, the QI is transduced into the NM subsystem."
        ],
        "imgs": [
            "$2305.00502v1-Figure1-1.png",
            "$2305.00502v1-Figure2-1.png",
            "$2305.00502v1-Figure3-1.png",
            "$2305.00502v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00504",
        "abstract": "  In this paper, we propose an energy-efficient federated learning (FL)\nframework for the energy-constrained devices over cloud radio access network\n(Cloud-RAN), where each device adopts quantized neural networks (QNNs) to train\na local FL model and transmits the quantized model parameter to the remote\nradio heads (RRHs). Each RRH receives the signals from devices over the\nwireless link and forwards the signals to the server via the fronthaul link. We\nrigorously develop an energy consumption model for the local training at\ndevices through the use of QNNs and communication models over Cloud-RAN. Based\non the proposed energy consumption model, we formulate an energy minimization\nproblem that optimizes the fronthaul rate allocation, user transmit power\nallocation, and QNN precision levels while satisfying the limited fronthaul\ncapacity constraint and ensuring the convergence of the proposed FL model to a\ntarget accuracy. To solve this problem, we analyze the convergence rate and\npropose efficient algorithms based on the alternative optimization technique.\nSimulation results show that the proposed FL framework can significantly reduce\nenergy consumption compared to other conventional approaches. We draw the\nconclusion that the proposed framework holds great potential for achieving a\nsustainable and environmentally-friendly FL in Cloud-RAN.\n",
        "title": "Green Federated Learning Over Cloud-RAN with Limited Fronthual Capacity\n  and Quantized Neural Networks",
        "texts": [
            "Fig. 1. System model of the considered wireless federated learning in Clould-RAN.",
            "Fig. 2. An illustration of a two dimensional processing chip.",
            "Fig. 3. Energy power consumption due to joint optimization of user power allocation, fronthaul rate allocation and level of precision of QNN.",
            "Fig. 4. Transmit energy consumption for various user power budgets.",
            "Fig. 5. Transmit energy consumption for various fronthual rate budgets.",
            "Fig. 6. Transmit energy consumption for different target accuracies.",
            "Fig. 7. Transmit energy consumption for different level of precisions."
        ],
        "imgs": [
            "$2305.00504v1-Figure1-1.png",
            "$2305.00504v1-Figure2-1.png",
            "$2305.00504v1-Figure3-1.png",
            "$2305.00504v1-Figure4-1.png",
            "$2305.00504v1-Figure5-1.png",
            "$2305.00504v1-Figure6-1.png",
            "$2305.00504v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00506",
        "abstract": "  Approximate Bayesian Computation (ABC) is a widely applicable and popular\napproach to estimating unknown parameters of mechanistic models. As ABC\nanalyses are computationally expensive, parallelization on high-performance\ninfrastructure is often necessary. However, the existing parallelization\nstrategies leave resources unused at times and thus do not optimally leverage\nthem yet. We present look-ahead scheduling, a wall-time minimizing\nparallelization strategy for ABC Sequential Monte Carlo algorithms, which\nutilizes all available resources at practically all times by proactive sampling\nfor prospective tasks. Our strategy can be integrated in e.g. adaptive distance\nfunction and summary statistic selection schemes, which is essential in\npractice. Evaluation of the strategy on different problems and numbers of\nparallel cores reveals speed-ups of typically 10-20% and up to 50% compared to\nthe best established approach. Thus, the proposed strategy allows to\nsubstantially improve the cost and run-time efficiency of ABC methods on\nhigh-performance infrastructure.\n",
        "title": "A Wall-time Minimizing Parallelization Strategy for Approximate Bayesian\n  Computation",
        "texts": [
            "Figure 1: Illustration of core usage over run-time for static (STA), dynamic (DYN) and look-ahead (LA) scheduling for a population size N = 5 on W = 8 workers, over 3 generations (colors). The shading indicates whether a sample satisfies the acceptance criterion and is included in the final population (dark), satisfies the acceptance criterion but is discarded because enough earlier-started accepted samples exist (medium, for DYN+LA), or does not satisfy the acceptance criterion and is rejected (light). Solid lines indicate the end of a generation, dashed lines indicate the (preliminary) beginning of a generation (different from solid lines only for LA).",
            "Figure 2: Concept visualization of look-ahead scheduling (LA). As soon as no more simulations are required for generation t (green), a preliminary simulation task for generation t + 1 is formulated either based on generation t (dark purple) or t+1 (light purple). Resulting simulations are considered when evaluating the next generation (t = t+ 1), and suitable weight normalization is applied to all samples (top right). Over time, the number of workers dedicated to generation t decreases, while that for generation t+ 1 increases (bottom).",
            "Figure 3: Run-time and posterior approximation for 5 different runs of model T1 with STAT, DYN, LA Pre and LA Cur, with population size N = 100 on W = 144, 240, 432 workers.",
            "Figure 4: Results for problem T2 for different population sizes N , worker numbers W , and sleep time variances σ2. Unless otherwise specified, we used N = 1280, W = 256, and a log-normally distributed sleep time tsleep of variance σ2 = 1. To increase comparability, the εt values over nt = 8 generations were pre-defined. (A) and (B): Mean and variance of the posterior approximation πABC,εnt (θ|yobs). Box-plot over 13 repetitions. (C): Posterior mean for different sleep time variances, forW = 20. (D): Effective sample size across different sleep time variances, forN = 256 andW = 20, in which case it is likely that several generations are sampled completely from the preliminary proposal. (E): Fraction Ñ/N of accepted samples in the final population t = nt that originate from the preliminary proposal g̃nt(θ) for LA Pre and LA Cur. (F): Exemplary visualization of 1d posterior approximation marginals for single runs.",
            "Figure 5: Speed-up (1− {Wall-time LA}/{Wall-time DYN}) of LA Pre (left) and LA Cur (right) over DYN for various population sizes and numbers of workers, for a model sleep time variance of σ2 = 1.",
            "Figure 6: The run-time and posterior distributions for 2 different runs of the model (M1) with population size 1000, 500, 250 on 128 and 256 workers.",
            "Figure 7: The run-time and posterior distribution of 2 different runs of the model (M2) with population size 1000, 500, 250 on 128 and 256 workers.",
            "Table 1: Overview of application examples"
        ],
        "imgs": [
            "$2305.00506v1-Figure1-1.png",
            "$2305.00506v1-Figure2-1.png",
            "$2305.00506v1-Figure3-1.png",
            "$2305.00506v1-Figure4-1.png",
            "$2305.00506v1-Figure5-1.png",
            "$2305.00506v1-Figure6-1.png",
            "$2305.00506v1-Figure7-1.png",
            "$2305.00506v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00507",
        "abstract": "  In this study, we investigate the mass spectrum of $\\pi$ and $\\sigma$ mesons\nat finite chemical potential using the self-consistent NJL model and the\nFierz-transformed interaction Lagrangian. The model introduces an arbitrary\nparameter $\\alpha$ to reflect the weights of the Fierz-transformed interaction\nchannels. We show that when $\\alpha$ exceeds a certain threshold value, the\nchiral phase transition transforms from a first-order one to a smooth\ncrossover, which is evident from the behaviors of the chiral condensates and\nmeson masses. Additionally, at high chemical potential, the smaller the value\nof $\\alpha$, the higher the masses of the $\\pi$ and $\\sigma$ mesons become.\nMoreover, the Mott and dissociation chemical potentials both increase with the\nincrease in $\\alpha$. Thus, the meson mass emerges as a valuable experimental\nobservable for determining the value of $\\alpha$ and investigating the\nproperties of the chiral phase transition in dense QCD matter.\n",
        "title": "(pseudo)Scalar mesons in a self-consistent NJL model",
        "texts": [
            "FIG. 1: The constituent qaurk mass M as a function of the chemical potential µ at T = 0 and α = 0, 0.5, 0.925 and 1.009, respectively.",
            "FIG. 2: The pole mass of pion(left panel) and σ meson(right panel) as a function of chemical potential at T = 0 and α = 0, 0.5, 0.925 and 1.009.",
            "FIG. 3: The pole mass of σ meson, pion and twice constituent quark mass as functions of chemical potential at T = 0 and α = 0, 0.5, 0.925 and 1.009.",
            "FIG. 4: The Mott chemical potential(left panel) and the dissociation chemical potential(right panel) as a function of α.",
            "FIG. 5: The pole mass of pion(left panel) and σ meson(right panel) as a function of chemical potential at T = 100 MeV and α = 0, 0.5, 0.925 and 1.009."
        ],
        "imgs": [
            "$2305.00507v2-Figure1-1.png",
            "$2305.00507v2-Figure2-1.png",
            "$2305.00507v2-Figure3-1.png",
            "$2305.00507v2-Figure4-1.png",
            "$2305.00507v2-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00508",
        "abstract": "  We propose Structured Exploration with Achievements (SEA), a multi-stage\nreinforcement learning algorithm designed for achievement-based environments, a\nparticular type of environment with an internal achievement set. SEA first uses\noffline data to learn a representation of the known achievements with a\ndeterminant loss function, then recovers the dependency graph of the learned\nachievements with a heuristic algorithm, and finally interacts with the\nenvironment online to learn policies that master known achievements and explore\nnew ones with a controller built with the recovered dependency graph. We\nempirically demonstrate that SEA can recover the achievement structure\naccurately and improve exploration in hard domains such as Crafter that are\nprocedurally generated with high-dimensional observations like images.\n",
        "title": "Learning Achievement Structure for Structured Exploration in Domains\n  with Sparse Reward",
        "texts": [
            "Figure 1: The Crafter environment.",
            "Figure 2: Algorithm overview. SEA comprises of four parts. (1) It starts with collecting trajectories either from domain experts or previously trained agents. (2) With the collected trajectories, SEA learns the achievement representation with Eqn. 1 and builds an achievement classifier by clustering the learned representations. (3) SEA then recovers an achievement dependency graph with the classifier and the collected trajectories. (4) We train a set of sub-policies to reach each recognized achievement and an exploration policy for new achievements. A meta-controller is used to propose target achievements according to the achievement dependency graph. We use the achievement classifier to filter out the reward signal for the target achievement.",
            "Figure 3: Clustering accuracy with different data sizes. Clusters and achievements are sorted in descending order of prediction accuracy.",
            "Figure 4: Mean unlocking rate comparison in easy and hard achievement set.",
            "Figure 6: Recovered dependency graph comparison. Dashed lines represent differences.",
            "Figure 7: Comparison of mean achievement unlocking rate with a graph-based meta-controller and a random one.",
            "Figure 8: Achievement unlock rate curve for each individual task in Crafter, excluding DreamerV2.",
            "Figure 9: Achievement unlock rate curve for each individual task in Crafter, DreamerV2.",
            "Table 2: Achievement unlock rate comparison. Standard deviation shown in the parenthesis.",
            "Table 3: Crafter score5. Standard deviation shown in the parenthesis.",
            "Table 4: IMPALA hyperparameters for different experiments."
        ],
        "imgs": [
            "$2305.00508v1-Figure1-1.png",
            "$2305.00508v1-Figure2-1.png",
            "$2305.00508v1-Figure3-1.png",
            "$2305.00508v1-Figure4-1.png",
            "$2305.00508v1-Figure6-1.png",
            "$2305.00508v1-Figure7-1.png",
            "$2305.00508v1-Figure8-1.png",
            "$2305.00508v1-Figure9-1.png",
            "$2305.00508v1-Table2-1.png",
            "$2305.00508v1-Table3-1.png",
            "$2305.00508v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00510",
        "abstract": "  3D shape generation techniques leveraging deep learning have garnered\nsignificant interest from both the computer vision and architectural design\ncommunities, promising to enrich the content in the virtual environment.\nHowever, research on virtual architectural design remains limited, particularly\nregarding designer-AI collaboration and deep learning-assisted design. In our\nsurvey, we reviewed 149 related articles (81.2% of articles published between\n2019 and 2023) covering architectural design, 3D shape techniques, and virtual\nenvironments. Through scrutinizing the literature, we first identify the\nprinciples of virtual architecture and illuminate its current production\nchallenges, including datasets, multimodality, design intuition, and generative\nframeworks. We then introduce the latest approaches to designing and generating\nvirtual buildings leveraging 3D shape generation and summarize four\ncharacteristics of various approaches to virtual architecture. Based on our\nanalysis, we expound on four research agendas, including agency, communication,\nuser consideration, and integrating tools. Additionally, we highlight four\nimportant enablers of ubiquitous interaction with immersive systems in deep\nlearning-assisted architectural generation. Our work contributes to fostering\nunderstanding between designers and deep learning techniques, broadening access\nto designer-AI collaboration. We advocate for interdisciplinary efforts to\naddress this timely research topic, facilitating content designing and\ngeneration in the virtual environment.\n",
        "title": "Towards AI-Architecture Liberty: A Comprehensive Survey on Design and\n  Generation of Virtual Architecture by Deep Learning",
        "texts": [
            "Fig. 1. Applications of deep learning impact our lives in all aspects. (a) Self-drive cars; (b) AlfaGO; (c) Segmentation in the city recognition with computer vision; (d) Mirror World NFT, which shows AI dialogue character with personality and development from learning; (e) OpenCV recognizing the object types in the camera view; (f) Apple watch paired with deep learning detect atrial fibrillation with 97 % accuracy; (g) ChatGPT developed by OpenAI; (h) recommendation system in the Tiktok; (i) Smart agriculture implemented by deep learning with drones; (j) DALLE-2, one powerful painting tool empowered by machine learning; (k) D.O.U.G, a collaborative robotic arms interacted with human, learning human behaviors and gestures, performance and created by artist Soug Wen; (l) digital human body generation by 3D reconstruction technique; (m) An AI art movie created by GANs (Casey Reas); (n) BCI (Brain-computer interface).",
            "Fig. 14. Research agendas in a full process of DGMs-assisted architectural design.",
            "Fig. 3. The survey structure (Sections 2 – 4).",
            "Fig. 8. A systematic taxonomy for a review of generation approaches on virtual architecture design with DGMs.",
            "Fig. 9. The examples of generated objects in the field of computer. (a) 3D GAN [169], (b)PointFlow [173], (c) HoloGAN [125], (d)StyleSDF [131] (e)Point-E [127] (f)DreamFusion [138].",
            "Table 3. An overview of 3D generative approaches of 3D-Aware Image Synthesis. Single/multiple represents the result generated by a single image adopting a sample of single-view or multiples image adopting multipleview images. Geometry indicates whether this method allow to export to mesh. Editability indicates whether this generation process enable to edit, such as composing objects in scene. 3D-aware image synthesis perform by controllability including camera pose, position or object pose, location, relighting, and so on."
        ],
        "imgs": [
            "$2305.00510v2-Figure1-1.png",
            "$2305.00510v2-Figure14-1.png",
            "$2305.00510v2-Figure3-1.png",
            "$2305.00510v2-Figure8-1.png",
            "$2305.00510v2-Figure9-1.png",
            "$2305.00510v2-Table3-1.png"
        ]
    },
    {
        "id": "2305.00512",
        "abstract": "  Funded by the UK ExCALIBUR H\\&ES exascale programme, in early 2022 a RISC-V\ntestbed for HPC was stood up to provide free access for scientific software\ndevelopers to experiment with RISC-V for their workloads. Here we report on\nsuccesses, challenges, and lessons learnt from this activity with a view to\nbetter understanding the suitability of RISC-V for HPC and important areas to\nfocus RISC-V HPC community efforts upon.\n",
        "title": "Experiences of running an HPC RISC-V testbed",
        "texts": [
            "Figure 1: Performance comparison of two Polybench kernels between testbed hardware"
        ],
        "imgs": [
            "$2305.00512v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00513",
        "abstract": "  The present work introduces a robust way to generate attosecond pulses with\ntunable ellipticity via high-order harmonic generation by co-rotating $\\omega -\n2\\omega$ bicircular laser fields. The total electric field of the laser fields\nexhibits an absence of rotational symmetry, which leads to the generation of\nhigh harmonics of the same helicity across a broad range of spectral bandwidth.\nHigh-harmonics with the same helicity offer the opportunity to synthesize\nattosecond pulses with tunable ellipticity. The polarisation properties of the\ngenerated harmonics are robust against the variations in driving fields'\nparameters, such as wavelength, intensity ratio, and the sub-cycle phase\nbetween $\\omega-2\\omega$ fields. Our work opens an avenue to study\nchiral-sensitive light-matter ultrafast processes on their intrinsic timescale.\n",
        "title": "Tailoring polarisation of attosecond pulses via co-rotating bicircular\n  laser fields",
        "texts": [
            "FIG. 5. Temporal profile of the synthesized attosecond pulse (blue line) with its x component (magenta line), y component (yellow line), and Lissajous figure (red line) of the total electric field. Different attosecond pulses are generated by superposing the harmonics near the cutoff region of the harmonic spectra presented in the following figures: (a) Fig. 1, (b) Fig. 2(a), (c) Fig. 2(b), and (d) Fig. 2(d). The synthesized pulses have pulse duration ∼ 550−600 attoseconds, and ellipticity ∼ 0.77−0.88."
        ],
        "imgs": [
            "$2305.00513v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00514",
        "abstract": "  Most previous co-salient object detection works mainly focus on extracting\nco-salient cues via mining the consistency relations across images while\nignoring explicit exploration of background regions. In this paper, we propose\na Discriminative co-saliency and background Mining Transformer framework (DMT)\nbased on several economical multi-grained correlation modules to explicitly\nmine both co-saliency and background information and effectively model their\ndiscrimination. Specifically, we first propose a region-to-region correlation\nmodule for introducing inter-image relations to pixel-wise segmentation\nfeatures while maintaining computational efficiency. Then, we use two types of\npre-defined tokens to mine co-saliency and background information via our\nproposed contrast-induced pixel-to-token correlation and co-saliency\ntoken-to-token correlation modules. We also design a token-guided feature\nrefinement module to enhance the discriminability of the segmentation features\nunder the guidance of the learned tokens. We perform iterative mutual promotion\nfor the segmentation feature extraction and token construction. Experimental\nresults on three benchmark datasets demonstrate the effectiveness of our\nproposed method. The source code is available at:\nhttps://github.com/dragonlee258079/DMT.\n",
        "title": "Discriminative Co-Saliency and Background Mining Transformer for\n  Co-Salient Object Detection",
        "texts": [
            "Figure 1. Overall flowchart of our proposed DMT CoSOD model. Specifically, the framework consists of four components, i.e. R2R for segmentation feature generation, CtP2T and CoT2T for detection token construction, and TGFR for the segmentation feature refinement under the guidance of the tokens.",
            "Figure 2. Diagram of MHA∗ and CCA. We first generate multihead tokens T c M and T b M via MHA∗. Then, we utilize matrix multiplication of the two tokens to generate the attention weights W for modulating the token channels in CCA.",
            "Figure 3. Diagram of our proposed TGFR module. Specifically, we first distill the co-saliency and BG features under the guidance of the two tokens. Then, we fuse them back to the original segmentation feature for discriminability enhancement.",
            "Figure 4. Qualitative results of different settings of our proposed model. We show the results of progressively adding the R2R, CtP2T, CoT2T, and TGFR on the baseline.",
            "Figure 5. Visual comparison among the channels with different channel attention weights in CtP2T. We visualize some feature maps in V ∗ m(F ) for the channels with large and small channel attention (CA) in CtP2T. We visualize two channels for large and small CA, respectively.",
            "Figure 6. Visualization of some feature maps (Fea.) and predictions (Pred.) of the models with (w/) or without (w/o) using TGFR.",
            "Figure 7. Qualitative comparisons of our model with other state-of-the-art methods.",
            "Table 1. Quantitative results of different settings of our proposed model. We show the results of progressively adding R2R, CtP2T, CoT2T, and TGFR on the baseline. “Co” and “Bg” mean explicitly modeling co-saliency and BG, respectively.",
            "Table 2. Quantitative results of different settings in TGFR.",
            "Table 3. Quantitative comparison of our model with other state-of-the-art methods. We conduct the comparison on three benchmark CoSOD datasets. Red and blue denote the best and the second-best results, respectively."
        ],
        "imgs": [
            "$2305.00514v1-Figure1-1.png",
            "$2305.00514v1-Figure2-1.png",
            "$2305.00514v1-Figure3-1.png",
            "$2305.00514v1-Figure4-1.png",
            "$2305.00514v1-Figure5-1.png",
            "$2305.00514v1-Figure6-1.png",
            "$2305.00514v1-Figure7-1.png",
            "$2305.00514v1-Table1-1.png",
            "$2305.00514v1-Table2-1.png",
            "$2305.00514v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00516",
        "abstract": "  We present the adiabatic theory of dissipative solitons (DS) of complex\ncubic-quintic nonlinear Ginzburg-Landau equation (CQGLE). Solutions in the\nclosed analytical form in the spectral domain have the shape of Rayleigh-Jeans\ndistribution for a positive (normal) dispersion. The DS parametric space forms\na two-dimensional (or three-dimensional for the complex quintic nonlinearity)\nmaster diagram connecting the DS energy and a universal parameter formed by the\nratio of four real and imaginary coefficients for dissipative and\nnon-dissipative terms in CQGLE. The concept of dissipative soliton resonance\n(DSR) is formulated in terms of the master diagram, and the main signatures of\ntransition to DSR are demonstrated and experimentally verified. We show a close\nanalogy between DS and incoherent (semicoherent) solitons with an ensemble of\nquasi-particles confined by a collective potential. It allows applying the\nthermodynamical approach to DS and deriving the conditions for the DS energy\nscalability.\n",
        "title": "Dissipative Soliton Resonance: Adiabatic Theory and Thermodynamics",
        "texts": [
            "Fig. 1: The dimensionless cut-off frequency ∆′ in dependence on the (C, b)-parameters for the (+)-branch of DS on the stability threshold Σ = 0.",
            "Fig. 10: Experimental master diagram [47] demonstrating a transit to DSR regime via asymptotically constant DS spectral width ∆ and its temporal width T scaling. A spectrum becomes finger-like.",
            "Fig. 12: DS spectra (bottom axis), temporal profiles (right axis), and the corresponding Wigner function [60] (center) for E∗ =18 and C =0.24 (a) and 0.18 (b). δ =0.05, Θb = 10−10γ−1, χ =0. Inset - DS spectrum distorted by an absorption line with the dimensionless amplitude 0.0025 and the width of 1GHz [50].",
            "Fig. 13: (a) DS spectra (bottom axis), temporal profiles (right axis), and the corresponding Wigner function (center) for E∗ =54 and C =0.19 (point (c) in Fig. 8). Other parameters as in Fig. 12. (b) Multipulsing from turbulence. Laser cavity roundtrip equals z in (1). Left inset in (a): logarithm of spectral power, right inset in (b): a field autocorrelation function.",
            "Fig. 3: The Σ±-parameter dividing the (+) and (−) branches of DS in dependence on (Σ, b). Only the case of b > 0 is illustrated.",
            "Fig. 5: The dimensionless chirp Ψ(t = 0) of (+)-branch in dependence on (C, b)parameters on the stability threshold Σ = 0.",
            "Fig. 7: Experimental CPO spectra (solid lines) obtained during pulse energy scaling and corresponding dispersion curves (dashed lines): (a) bell shape spectrum at the threshold of CPO operation, (b) M-shape spectrum obtained with slightly increased average GDD and pump power values [49], (c) near finger-like spectrum after energy scaling by pump power and pulse repetition frequency in DSR [47]. TOC , Pout, Eintr, and f are the laser output mirror transmission, output power, intracavity energy, and DS repetition rate, respectively.",
            "Fig. 8: Master diagram for χ = 0. Curves related to the left vertical axis: vacuum instability border Σ = 0 (solid black); the division between (±)-branches of DS solutions (13) (solid blue); “fidelity curve” (solid magenta); one of the isogains (Σ± = 0.01, dashed-dotted green). The right vertical axes relate to the DS temporal T ′ (red dashed curve) and spectral (dotted blue curve) ∆′ widths along the stability border Σ = 0, respectively. C = αγ/βκ, E′ = E × κ √ ζ/βγ, ∆′ = ∆× √ βζ/γ, T ′ = T × (κ/ √ γζβ). Points (a), (b), and (c) refer to Figs. 12,13.",
            "Fig. 9: Master diagram for χ =-5 (1), 0.2 (2). Black solid curves are the vacuum instability thresholds, blue solid curves divide (±)-branches of DS solutions, and green dashed lines correspond to isogains Σ = 0.01. One can see as a region of DSR squeezes and shifts to the smaller C for b = 0.2 in parallel with the corresponding chirp transformation (Fig. 5)."
        ],
        "imgs": [
            "$2305.00516v2-Figure1-1.png",
            "$2305.00516v2-Figure10-1.png",
            "$2305.00516v2-Figure12-1.png",
            "$2305.00516v2-Figure13-1.png",
            "$2305.00516v2-Figure3-1.png",
            "$2305.00516v2-Figure5-1.png",
            "$2305.00516v2-Figure7-1.png",
            "$2305.00516v2-Figure8-1.png",
            "$2305.00516v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00517",
        "abstract": "  Energy Expenditure Estimation (EEE) is vital for maintaining weight, managing\nchronic diseases, achieving fitness goals, and improving overall health and\nwell-being. Gold standard measurements for energy expenditure are expensive and\ntime-consuming, hence limiting utility and adoption. Prior work has used\nwearable sensors for EEE as a workaround. Moreover, earables (ear-worn sensing\ndevices such as earbuds) have recently emerged as a sub-category of wearables\nwith unique characteristics (i.e., small form factor, high adoption) and\npositioning on the human body (i.e., robust to motion, high stability, facing\nthin skin), opening up a novel sensing opportunity. However, earables with\nmultimodal sensors have rarely been used for EEE, with data collected in\nmultiple activity types. Further, it is unknown how earable sensors perform\ncompared to standard wearable sensors worn on other body positions. In this\nstudy, using a publicly available dataset gathered from 17 participants, we\nevaluate the EEE performance using multimodal sensors of earable devices to\nshow that an MAE of 0.5 MET (RMSE = 0.67) can be achieved. Furthermore, we\ncompare the EEE performance of three commercial wearable devices with the\nearable, demonstrating competitive performance of earables\n",
        "title": "Multimodal Earable Sensing for Human Energy Expenditure Estimation",
        "texts": [
            "Fig. 1: Summary of the study protocol [14].",
            "Fig. 2: Performance Evaluation for (a) Earables, (b) Sensor Combinations, and (c) Devices.",
            "TABLE I: sensor pre-processing details"
        ],
        "imgs": [
            "$2305.00517v1-Figure1-1.png",
            "$2305.00517v1-Figure2-1.png",
            "$2305.00517v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00521",
        "abstract": "  In this paper, we present StyleLipSync, a style-based personalized lip-sync\nvideo generative model that can generate identity-agnostic lip-synchronizing\nvideo from arbitrary audio. To generate a video of arbitrary identities, we\nleverage expressive lip prior from the semantically rich latent space of a\npre-trained StyleGAN, where we can also design a video consistency with a\nlinear transformation. In contrast to the previous lip-sync methods, we\nintroduce pose-aware masking that dynamically locates the mask to improve the\nnaturalness over frames by utilizing a 3D parametric mesh predictor frame by\nframe. Moreover, we propose a few-shot lip-sync adaptation method for an\narbitrary person by introducing a sync regularizer that preserves lip-sync\ngeneralization while enhancing the person-specific visual information.\nExtensive experiments demonstrate that our model can generate accurate lip-sync\nvideos even with the zero-shot setting and enhance characteristics of an unseen\nface using a few seconds of target video through the proposed adaptation\nmethod.\n",
        "title": "StyleLipSync: Style-based Personalized Lip-sync Video Generation",
        "texts": [
            "Figure 1. Illustration of pose-aware masking.",
            "Figure 10. Visualization of SaMFs at each resolution. Please refer to the supplementary videos for visualization of the resolution less than 16× 16.",
            "Figure 11. Example of a questionnaire used in the user study.",
            "Figure 12. Detailed encoder architectures. (B,T, h,w,C) is a 5D tensor of the batch size B, the number of frames T, the height h, the width w, and the number of channels C. Similarly, (B, h,w,C) is a 4D tensor excluding the axis of the number of frames in (B,T, h,w,C). ’Conv2D-s-C′’ means a 2D convolution of 3 × 3 kernel with stride (s, s), padding (s, s), and output channels C′. ’Linear-C’ means a fully-connected layer of the output with C nodes. ’Avg.Pool2D-s’ is a 2D average pooling of s × s kernel with stride (s, s). We employ the audio encoder architecture used in [43] as our audio encoder.",
            "Figure 2. A framework of StyleLipSync. We leverage a 3D parametric mesh predictor [10, 21] to obtain pose-aware masked frames X1:T , which inherits the facial pose of input frames. Face encoder Eface maps X1:T into 2D spatial features and then fed into the decoder G through style-aware masked fusion (SaMF). Single reference image Xref and audio segments A1:T are mapped into latent space, followed by Moving-average based Latent Smoothing (MaLS). This module outputs smooth video latent codes w̃1:T ⊆ W+ that represent temporally consistent lip movement. With the guidance of SaMFs and the smooth video latent codes w̃1:T , StyleLipSync can generate temporally consistent lip-synced videos.",
            "Figure 3. Illustration of a decoder block. The encoded feature Elface(Xt) is injected into l-th decoder block through Style-aware Masked Fusion (SaMF). Only the convolution in SaMF is trainable, while the others are frozen during the training phase.",
            "Figure 5. Comparison with state-of-the-art.",
            "Figure 6. Qualitative comparison of zero-shot model.",
            "Figure 7. Experiments on the face adaptation with cross-id setting.",
            "Figure 8. Detailed architecture of the l-th moving-average based",
            "Table 1. Quantitative comparison of reconstruction on Voxceleb2 test data. The best score for each metric is in bold.",
            "Table 2. Quantitative comparison of cross-identity results for unseen face. We report CSIM [9] as the image quality metric since there is no ground truth frames for the cross-id experiments. The best score for each metric is in bold.",
            "Table 3. Ablation study on zero-shot model. The best score for each metric is in bold.",
            "Table 4. Mean Opinion score (MOS) user study results with 95% confidence interval on cross-id setting. The score ranges in 1 to 5. The best score for each metric is in bold.",
            "Table 5. Quantitative comparison of reconstruction of Voxceleb2 test data. We report CSIM [9] to support Table 1. The best score for each metric is in bold."
        ],
        "imgs": [
            "$2305.00521v1-Figure1-1.png",
            "$2305.00521v1-Figure10-1.png",
            "$2305.00521v1-Figure11-1.png",
            "$2305.00521v1-Figure12-1.png",
            "$2305.00521v1-Figure2-1.png",
            "$2305.00521v1-Figure3-1.png",
            "$2305.00521v1-Figure5-1.png",
            "$2305.00521v1-Figure6-1.png",
            "$2305.00521v1-Figure7-1.png",
            "$2305.00521v1-Figure8-1.png",
            "$2305.00521v1-Table1-1.png",
            "$2305.00521v1-Table2-1.png",
            "$2305.00521v1-Table3-1.png",
            "$2305.00521v1-Table4-1.png",
            "$2305.00521v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00522",
        "abstract": "  I present a simple algorithm for enumerating the trees generated by a Context\nFree Grammar (CFG). The algorithm uses a pairing function to form a bijection\nbetween CFG derivations and natural numbers, so that trees can be uniquely\ndecoded from counting. This provides a general way to number expressions in\nnatural logical languages, and potentially can be extended to other\ncombinatorial problems. I also show how this algorithm may be generalized to\nmore general forms of derivation, including analogs of Lempel-Ziv coding on\ntrees.\n",
        "title": "How to enumerate trees from a context-free grammar",
        "texts": [
            "Figure 1: Enumeration order of Cantor’s pairing function (left), the Rosenberg-Strong pairing function (center) and the M4(x, y) (right).",
            "Figure 3: Enumeration of the grammar in (9) using Algorithm B. Lines only show strings where Algorithm A and Algorithm B give different answers."
        ],
        "imgs": [
            "$2305.00522v1-Figure1-1.png",
            "$2305.00522v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00523",
        "abstract": "  Models of induced-gravity inflation are formulated within Supergravity\nemploying as inflaton the Higgs field which leads to a spontaneous breaking of\na U(1)_{B-L} symmetry at Mgut=2x10^16 GeV. We use a renormalizable\nsuperpotential, fixed by a U(1) R symmetry, and logarithmic or semi-logarithmic\nKahler potentials with integer prefactors which exhibit a quadratic non-minimal\ncoupling to gravity. We find inflationary solutions of Starobinsky type in\naccordance with the observations. The inflaton mass is predicted to be of the\norder of 10^13 GeV. The model can be nicely linked to MSSM offering an\nexplanation of the magnitude of the mu parameter consistently with\nphenomenological data. Also it allows for baryogenesis via non-thermal\nleptogenesis, provided that the gravitino is heavier than about 10 TeV.\n",
        "title": "Starobinsky-Type B-L Higgs Inflation Leading Beyond MSSM",
        "texts": [
            "FIGURE 1: Inflationary potential V̂IHI as a function of φ for φ > 0, cR in Eq. (4.10) and K = K1 (dark gray line) or K = K2 (light gray line) – the values of φ⋆ and φf are also indicated.",
            "TABLE 3: The required λµ values which render our models compatible with the best-fit points in the CMSSM, as found in Ref. [20], for the assumptions of Eq. (5.5), NX = 2, and K = K1 or K = K2.",
            "TABLE 4: Low energy experimental neutrino data for normal or inverted hierarchical neutrino masses."
        ],
        "imgs": [
            "$2305.00523v1-Figure1-1.png",
            "$2305.00523v1-Table3-1.png",
            "$2305.00523v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00528",
        "abstract": "  We study the problem of best-arm identification in a distributed variant of\nthe multi-armed bandit setting, with a central learner and multiple agents.\nEach agent is associated with an arm of the bandit, generating stochastic\nrewards following an unknown distribution. Further, each agent can communicate\nthe observed rewards with the learner over a bit-constrained channel. We\npropose a novel quantization scheme called Inflating Confidence for\nQuantization (ICQ) that can be applied to existing confidence-bound based\nlearning algorithms such as Successive Elimination. We analyze the performance\nof ICQ applied to Successive Elimination and show that the overall algorithm,\nnamed ICQ-SE, has the order-optimal sample complexity as that of the\n(unquantized) SE algorithm. Moreover, it requires only an exponentially sparse\nfrequency of communication between the learner and the agents, thus requiring\nconsiderably fewer bits than existing quantization schemes to successfully\nidentify the best arm. We validate the performance improvement offered by ICQ\nwith other quantization methods through numerical experiments.\n",
        "title": "ICQ: A Quantization Scheme for Best-Arm Identification Over\n  Bit-Constrained Channels",
        "texts": [
            "Figure 1: Block diagram illustrating the overall setup, shown here for the case with 3 agents, i.e., K = 3.",
            "Figure 2: Illustration of the quantization scheme when B = 3 — the blue lines given by ℓi mark the separation between the 2B equal bins, the red points denote the midpoints of these bins, and the green ‘×’s (the values to be quantized) get mapped to their nearest midpoints.",
            "Figure 3: Motivation for defining U(i, δ) as (4) – Start with µ̃j,i−1, then by the inductive hypothesis, µj should lie within U(i − 1, δ) of µ̃j,i−1 (blue interval). From (2), µ̂j,i lies within U ′(i, δ) of µj (red interval). Putting them together, µ̂j,i lies within U(i− 1, δ) + U ′(i, δ) of µ̃j,i−1.",
            "Figure 4: Figures 5a, 5b and 5c demonstrate the dependence of the performance of ICQ-SE on α. Figures 5d and 5e demonstrate the dependence on β. Figures 4a, 4b and 4c compare ICQ-SE with QuBan [12] and Fed-SEL [17] for bounded rewards while Figures 4d, 4e and 4f compare ICQ-SE with QuBan for unbounded rewards. Finally, Figures 4g, 4h and 4i compare the dependence of ICQ-SE and QuBan on the hardness of the underlying instance.",
            "Figure 5: Figures 5a, 5b and 5c demonstrate the dependence of the performance of ICQ-SE on α. Figures 5d and 5e demonstrate the dependence on β."
        ],
        "imgs": [
            "$2305.00528v1-Figure1-1.png",
            "$2305.00528v1-Figure2-1.png",
            "$2305.00528v1-Figure3-1.png",
            "$2305.00528v1-Figure4-1.png",
            "$2305.00528v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00534",
        "abstract": "  We consider unitary SQCD, a three-dimensional $\\mathcal{N}=2$ supersymmetric\nChern-Simons-matter theory consisting of one $U(N_c)_{k, k+l N_c}$ vector\nmultiplet coupled to $n_f$ fundamental and $n_a$ antifundamental chiral\nmultiplets, where $k$ and $l$ parameterise generic CS levels for\n$U(N_c)=(SU(N_c)\\times U(1))/\\mathbb{Z}_{N_c}$. We study the moduli space of\nvacua of this theory with $n_a=0$, for generic values of the parameters $N_c,\nk, l, n_f$ and with a non-zero Fayet-Ilopoulos parameter turned on. We uncover\na rich pattern of vacua including Higgs, topological and hybrid phases. This\nallows us to derive a closed-form formula for the flavoured Witten index of\nunitary SQCD for any $n_f\\neq n_a$, generalising previously known results for\neither $l=0$ or $n_f=n_a$. Finally, we analyse the vacuum structure of recently\nproposed infrared-dual gauge theories and we match vacua across the dualities,\nthus providing intricate new checks of those dualities. Incidentally, we also\ndiscuss a seemingly new level/rank duality for pure CS theories with\n$U(N)\\times U(N')$ gauge group.\n",
        "title": "On the Witten index of 3d $\\mathcal{N}=2$ unitary SQCD with general CS\n  levels",
        "texts": [
            "Table 1. Witten index for U(2)k,k+2l with nf = 4 fundamentals, for some values of k, l. The case with the minimal value IW = 6 are given in bold. The contributions from Type IV vacua when ξ > 0 are shown in red.",
            "Table 2. Moduli spaces of vacua for U(2) theory coupled with 4 fundamental multiplets and different values of the levels k and l. We include both phases of ξ, the positive and negative one.",
            "Table 3. Witten index for U(5)k,k+5l with nf = 7 fundamentals, for some values of k, l. The case with the minimal value IW = 21 are given in bold. The contributions from Type IV vacua when ξ > 0 are shown in red.",
            "Table 4. Moduli spaces of vacua for U(5)k,k+5l with nf = 7 fundamental chiral multiplets, at some values of k and l and for either sign of ξ.",
            "Table 7. Matching moduli spaces of vacua across the maximally-chiral duality with ξ > 0."
        ],
        "imgs": [
            "$2305.00534v3-Table1-1.png",
            "$2305.00534v3-Table2-1.png",
            "$2305.00534v3-Table3-1.png",
            "$2305.00534v3-Table4-1.png",
            "$2305.00534v3-Table7-1.png"
        ]
    },
    {
        "id": "2305.00535",
        "abstract": "  Graph neural networks are useful for learning problems, as well as for\ncombinatorial and graph problems such as the Subgraph Isomorphism Problem and\nthe Traveling Salesman Problem. We describe an approach for computing Steiner\nTrees by combining a graph neural network and Monte Carlo Tree Search. We first\ntrain a graph neural network that takes as input a partial solution and\nproposes a new node to be added as output. This neural network is then used in\na Monte Carlo search to compute a Steiner tree. The proposed method\nconsistently outperforms the standard 2-approximation algorithm on many\ndifferent types of graphs and often finds the optimal solution.\n",
        "title": "Nearly Optimal Steiner Trees using Graph Neural Network Assisted Monte\n  Carlo Tree Search",
        "texts": [
            "Figure 1: GNN assisted MCTS: first, train a GNN to evaluate non-terminal nodes, then use the network and heuristics to compute a Steiner tree with MCTS.",
            "Figure 3: Performance on simple graphs. Each data point represents one graph. The lower the cost the better the algorithm is. Our algorithm (MCTS) is nearly optimal and performs better than 2-approximation.",
            "Figure 4: Performance on weighted graphs. Each data point represents one graph. The lower the cost the better the algorithm is. Our algorithm (MCTS) is nearly optimal and performs better than 2-approximation.",
            "Figure 5: Performance on more weighted graphs. Each data point represents one graph. The lower the cost the better the algorithm is. Our algorithm (MCTS) is nearly optimal and performs better than 2-approximation.",
            "Figure 6: Performance on SteinLib datasets. Each data point represents one graph. The lower the cost the better the algorithm is. Our algorithm (MCTS) is nearly optimal and performs better than 2-approximation.",
            "Table 1: Average running time of different algorithms in seconds."
        ],
        "imgs": [
            "$2305.00535v1-Figure1-1.png",
            "$2305.00535v1-Figure3-1.png",
            "$2305.00535v1-Figure4-1.png",
            "$2305.00535v1-Figure5-1.png",
            "$2305.00535v1-Figure6-1.png",
            "$2305.00535v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00536",
        "abstract": "  We perform a numerical study of transport properties of a one-dimensional\nchain with couplings decaying as an inverse power $r^{-(1+\\sigma)}$ of the\nintersite distance $r$ and open boundary conditions, interacting with two heat\nreservoirs. Despite its simplicity, the model displays highly nontrivial\nfeatures in the strong long-range regime, $-1<\\sigma<0$. At weak coupling with\nthe reservoirs, the energy flux departs from the predictions of perturbative\ntheory and displays anomalous superdiffusive scaling of the heat current with\nthe chain size. We trace back this behavior to the transmission spectrum of the\nchain, which displays a self-similar structure with a characteristic\nsigma-dependent fractal dimension.\n",
        "title": "Non-equilibrium steady states of long-range coupled harmonic chains",
        "texts": [
            "FIG. 5. Panels a), b), c), d) : transmission spectra (the integrand of the heat flux expression (18)) for different values of the range exponent σ = −0.7, 0.5, 0.1, 0.5 and for a chain with N = 100. Only positive frequencies are reported. Panels e), f), g), h): rescaled cumulative function NγF (ω), for N = 80, 100, 120, 140 and σ = −0.7,−0.5,−0.1, 0.5 in panels a), b), c), d) respectively. The values of γ are taken from the blue points in Figure 4. The abrubt increase of the cumulative function in panels e) and f) at ω ≈ 1.3 is due to the dominant contribution of the first peak in panels a) and b. The subsequent, smaller, jumps are due to the contributions of the other peaks.",
            "FIG. 6. Real parts of the poles of the Green’s functions sa versus the distance of their imaginary parts from the band-edge. Leftmost panel: σ < 0, vertical axis rescaled by Nδ with δ ≈ 1 − σ. The inset in panel (a) demonstrates the different scaling the collapse for the widths of the first peaks (the first 80, 160, 320, 640, 1280 for N = 256, 512, 1024, 2048, 4096, respectively) rescaled by N . For the other values of σ, we get the same scaling for the first peaks. Rightmost panel: same for σ > 0, with vertical axis rescaled by N . Note that such scaling works for the whole spectrum in this case."
        ],
        "imgs": [
            "$2305.00536v3-Figure5-1.png",
            "$2305.00536v3-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00537",
        "abstract": "  The proliferation of machine learning (ML) has drawn unprecedented interest\nin the study of various multimedia contents such as text, image, audio and\nvideo, among others. Consequently, understanding and learning ML-based\nrepresentations have taken center stage in knowledge discovery in intelligent\nmultimedia research and applications. Nevertheless, the black-box nature of\ncontemporary ML, especially in deep neural networks (DNNs), has posed a primary\nchallenge for ML-based representation learning. To address this black-box\nproblem, the studies on interpretability of ML have attracted tremendous\ninterests in recent years. This paper presents a survey on recent advances and\nfuture prospects on interpretability of ML, with several application examples\npertinent to multimedia computing, including text-image cross-modal\nrepresentation learning, face recognition, and the recognition of objects. It\nis evidently shown that the study of interpretability of ML promises an\nimportant research direction, one which is worth further investment in.\n",
        "title": "Interpretability of Machine Learning: Recent Advances and Future\n  Prospects",
        "texts": [
            "Figure 3 The interpretability by FFNN/DL.",
            "Figure 4 A schematic of a physics-informed NN model from [82].",
            "Figure 6 A high-level overview of algorithm unrolling from [71].",
            "Figure 7 The interpretability by SGO and NN architecture.",
            "Table 1. Recognition accuracies on the Wiki database",
            "Table 2. Recognition accuracy on the ORL database",
            "Table 4. Recognition accuracy with other methods on the Caltech 256"
        ],
        "imgs": [
            "$2305.00537v1-Figure3-1.png",
            "$2305.00537v1-Figure4-1.png",
            "$2305.00537v1-Figure6-1.png",
            "$2305.00537v1-Figure7-1.png",
            "$2305.00537v1-Table1-1.png",
            "$2305.00537v1-Table2-1.png",
            "$2305.00537v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00538",
        "abstract": "  State-of-the-art congestion control algorithms for data centers alone do not\ncope well with transient congestion and high traffic bursts. To help with\nthese, we revisit the concept of direct \\emph{backward} feedback from switches\nand propose Back-to-Sender (BTS) signaling to many concurrent incast senders.\nCombining it with our novel approach to in-network caching, we achieve\nnear-source sub-RTT congestion signaling. Source Flow Control (SFC) combines\nthese two simple signaling mechanisms to instantly pause traffic sources, hence\navoiding the head-of-line blocking problem of conventional hop-by-hop flow\ncontrol. Our prototype system and scale simulations demonstrate that\nnear-source signaling can significantly reduce the message completion time of\nvarious workloads in the presence of incast, complementing existing congestion\ncontrol algorithms. Our results show that SFC can reduce the\n$99^{th}$-percentile flow completion times by $1.2-6\\times$ and the peak switch\nbuffer usage by $2-3\\times$ compared to the recent incast solutions.\n",
        "title": "SFC: Near-Source Congestion Signaling and Flow Control",
        "texts": [
            "Figure 1: Effect of different signaling + flow controlmethods without congestion control. 63-to-1 incast senders starting within a 50us time window. A dumbbell topology with unlimited switch buffer is used with 10us NIC-to-NIC RTT.",
            "Figure 13: Incast-only workload with varying incast degree, and incast synchronization interval. HPCC.",
            "Figure 15: SFC has zero impact on fairness. DCQCN+W.",
            "Figure 17: Simplified topology for the theoretical analysis.",
            "Figure 2: Effect of different FC + CC combinations, over various incast degrees. Workload: 50% network load (Hadoop traffic) + 8% incast load with 50us incast synchronization. FCT is measured only for Hadoop flows.",
            "Figure 3: Switch pipeline of SFC. Upon congestion, a BTS is",
            "Figure 4: SFC Pause Cache. Host A sends traffic 1 that encounters congestion at SW3. SW3 sends back a BTS frame",
            "Figure 5: Testbed: switch buffer usage by incast degree (no cross traffic).",
            "Figure 6: Testbed: PFC causing HoLB. Workload: Hadoop 30%; 24:1 incast.",
            "Figure 7: Hadoop workload with 50% load; 8% 128:1 incast; using HPCC for congestion control.",
            "Table 1: Evaluation parameter overview",
            "Table 2: RPC (Fig. 8) and Hadoop (Fig. 7)"
        ],
        "imgs": [
            "$2305.00538v1-Figure1-1.png",
            "$2305.00538v1-Figure13-1.png",
            "$2305.00538v1-Figure15-1.png",
            "$2305.00538v1-Figure17-1.png",
            "$2305.00538v1-Figure2-1.png",
            "$2305.00538v1-Figure3-1.png",
            "$2305.00538v1-Figure4-1.png",
            "$2305.00538v1-Figure5-1.png",
            "$2305.00538v1-Figure6-1.png",
            "$2305.00538v1-Figure7-1.png",
            "$2305.00538v1-Table1-1.png",
            "$2305.00538v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00540",
        "abstract": "  High-quality mesh generation is the foundation of accurate finite element\nanalysis. Due to the vast interior vertices search space and complex initial\nboundaries, mesh generation for complicated domains requires substantial manual\nprocessing and has long been considered the most challenging and time-consuming\nbottleneck of the entire modeling and analysis process. In this paper, we\npresent a novel computational framework named ``SRL-assisted AFM\" for meshing\nplanar geometries by combining the advancing front method with neural networks\nthat select reference vertices and update the front boundary using ``policy\nnetworks.\" These deep neural networks are trained using a unique pipeline that\ncombines supervised learning with reinforcement learning to iteratively improve\nmesh quality. First, we generate different initial boundaries by randomly\nsampling points in a square domain and connecting them sequentially. These\nboundaries are used for obtaining input meshes and extracting training datasets\nin the supervised learning module. We then iteratively improve the\nreinforcement learning model performance with reward functions designed for\nspecial requirements, such as improving the mesh quality and controlling the\nnumber and distribution of extraordinary points. Our proposed supervised\nlearning neural networks achieve an accuracy higher than 98% on predicting\ncommercial software. The final reinforcement learning neural networks\nautomatically generate high-quality quadrilateral meshes for complex planar\ndomains with sharp features and boundary layers.\n",
        "title": "SRL-Assisted AFM: Generating Planar Unstructured Quadrilateral Meshes\n  with Supervised and Reinforcement Learning-Assisted Advancing Front Method",
        "texts": [
            "Figure 1: Neural network pipeline and architecture. (a) The SRL-assisted AFM framework utilizes SL and RL neural networks to generate new vertices following the AFM scheme. (b) SL neural networks learn from ANSYS-generated quad meshes and generate a new quad on the front. (c) RL neural networks use squareness and EP penalty as the reward functions and are trained on the evolving front to maximize the reward feedback.",
            "Figure 11: The Lake Superior map with multiple holes and unbalanced seeds. (a) Final all-quad mesh. (b-c) Zoom-in pictures of the red boxes in (a).",
            "Figure 2: Meshing a planar domain with advancing front method. (a) The initial domain boundary. (b) The meshing process at 50% completeness. (c) The final mesh. (d) A zoom-in picture of the reference vertex (P0) and the front (red line) at 50% completeness.",
            "Figure 3: The judgment principle of the binary classification neural network πa when labeling the ground truth dataset. (a) Four cases (corresponds to the four updating types) when πa accepts P0 to be the reference vertex. (b) Six example cases when πa rejects P0 to be the reference vertex.",
            "Figure 4: Two special situations when a partition operation is necessary to split the domain D0. (a) Assuming that Pi is the reference vertex, the next update, which seals the line segment Pi+1Pi−2, is invalid because Pi+1Pi−2 intersects with the remaining front boundary. (b) D0 is partitioned along PiP j if the resulting two new subdomains D1,D2 both have an even number of edges. (c) D0 is partitioned along Pi−1P j if the edge numbers of both new subdomains D1,D2 are even.",
            "Figure 5: Four templates of adding the boundary layer. The quad element shares one edge (a), one vertex (b) and two adjacent edges (c, d) with the boundary. A valence-3 EP is introduced in (b, c), while two new vertices are inserted on the boundary in (d).",
            "Figure 6: The residual neural network framework [37] used in SL. (a) πa is a binary classification neural network that determines the reference vertex P0. (b) πb is a four-class classification neural network that determines the updating type. (c) We then selectively apply πc, πd or seal the edge based on πb classification results.",
            "Figure 7: SL policy neural network outputs of four held-out examples in Table 1. The local vertices P0, Pr i , P l i, i = 1, 2, 3, 4, are in black. Three close vertices Pc i , i = 1, 2, 3, are in red. EP status are listed next to the corresponding vertices. The new vertices predicted by the neural network (if any) are in blue. The new vertices from ground truth (if any) are in orange. (a) πa accepts P0 as the reference vertex. (b) πb selects updating type 2 and two existing points are connected to seal the edge. (c) πb selects updating type 1, a new point Pnew 1 is generated based on πc prediction. (d) πb selects updating type 4, two new points Pnew 1 , Pnew 2 are generated based on πd predictions.",
            "Figure 9: The knee joint cross-section. (a) Multiple meshes representing the femur (pink), femoral cartilage (orange), tibial cartilage (yellow), and tibia (cyan). (b-f) Zoom-in pictures of red boxes in (a).",
            "Table 1: Examples and statistics of SL neural network outputs with N = 10 residual blocks.",
            "Table 2: Statistics of the resulting meshes."
        ],
        "imgs": [
            "$2305.00540v1-Figure1-1.png",
            "$2305.00540v1-Figure11-1.png",
            "$2305.00540v1-Figure2-1.png",
            "$2305.00540v1-Figure3-1.png",
            "$2305.00540v1-Figure4-1.png",
            "$2305.00540v1-Figure5-1.png",
            "$2305.00540v1-Figure6-1.png",
            "$2305.00540v1-Figure7-1.png",
            "$2305.00540v1-Figure9-1.png",
            "$2305.00540v1-Table1-1.png",
            "$2305.00540v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00541",
        "abstract": "  We consider a mean-field model of firms competing \\`a la Cournot on a\ncommodity market, where the commodity price is given in terms of a power\ninverse demand function of the industry-aggregate production. Investment is\nirreversible and production capacity depreciates at a constant rate. Production\nis subject to Gaussian productivity shocks, while large non-anticipated\nmacroeconomic events driven by a two-state continuous-time Markov chain can\nchange the volatility of the shocks, as well as the price function. Firms wish\nto maximize expected discounted revenues of production, net of investment and\noperational costs. Investment decisions are based on the long-run stationary\nprice of the commodity. We prove existence, uniqueness and characterization of\nthe stationary mean-field equilibrium of the model. The equilibrium investment\nstrategy is of barrier-type and it is triggered by a couple of endogenously\ndetermined investment thresholds, one per state of the economy. We provide a\nquasi-closed form expression of the stationary density of the state and we show\nthat our model can produce Pareto distribution of firms' size. This is a\nfeature that is consistent both with observations at the aggregate level of\nindustries and at the level of a particular industry. We establish a relation\nbetween economic instability and market concentration and we show how\nmacroeconomic instability can harm firms' profitability more than productivity\nfluctuations.\n",
        "title": "A Stationary Mean-Field Equilibrium Model of Irreversible Investment in\n  a Two-Regime Economy",
        "texts": [
            "Figure 1. (a) A trajectory of the state process X; (b) E[X∞|ε∞ = 1] and E[X∞|ε∞ = 2]. Parameters: δ = 0.1, ρ = 0.08, κ = 10, c = 0.1, φ1 = 10, φ2 = 5, ζ1 = ζ2 = 1, σ1 = 0.2, σ2 = 0.15, α = 0.5, p1 = 1/10, p2 = 1/5.",
            "Figure 2. As a function of the volatility σ1 in State 1: (a) Investment thresholds a?1, a?2 and long-run equilibrium capacities Q? 1, Q? 2; (b) Ratio χ∞ and P ( X∞ ∈ (a?, a?) ) , where a? := min{a?1, a?2} and a? := max{a?1, a?2}. Parameters: δ = 0.1, ρ = 0.08, κ = 10, c = 0.1, φ1 = 10, φ2 = 10, ζ1 = ζ2 = 1, σ2 = 0.15, α = 0.5, p1 = 1/10, p2 = 1/5.",
            "Figure 4. (a) V[X∞] as a function of 1/p1; (b) V[X∞]/E[X∞] as a function of 1/p1; (c) Q̄(q) for 1/p1 = 20 (blue curve), H is the area of pink surface; (d) H as a function of 1/p1. Parameters: δ = 0.1, ρ = 0.08, κ = 10, c = 0.1, φ1 = 10, φ2 = 5, ζ1 = ζ2 = 1, σ2 = 0.2, α = 0.5, p2 = 1/5.",
            "Table 1. Elasticities of V ? at ν2 = (σ2, p2, φ2) w.r.t σ1 and φ1. Other parameters value: δ = 1/10, ρ = 0.08, κ = 10, c = 0.1, ζ1 = ζ2 = 1, p2 = 1/10."
        ],
        "imgs": [
            "$2305.00541v1-Figure1-1.png",
            "$2305.00541v1-Figure2-1.png",
            "$2305.00541v1-Figure4-1.png",
            "$2305.00541v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00543",
        "abstract": "  Neural network-based decisions tend to be overconfident, where their raw\noutcome probabilities do not align with the true decision probabilities.\nCalibration of neural networks is an essential step towards more reliable deep\nlearning frameworks. Prior metrics of calibration error primarily utilize crisp\nbin membership-based measures. This exacerbates skew in model probabilities and\nportrays an incomplete picture of calibration error. In this work, we propose a\nFuzzy Calibration Error metric (FCE) that utilizes a fuzzy binning approach to\ncalculate calibration error. This approach alleviates the impact of probability\nskew and provides a tighter estimate while measuring calibration error. We\ncompare our metric with ECE across different data populations and class\nmemberships. Our results show that FCE offers better calibration error\nestimation, especially in multi-class settings, alleviating the effects of skew\nin model confidence scores on calibration error estimation. We make our code\nand supplementary materials available at: https://github.com/bihani-g/fce\n",
        "title": "Calibration Error Estimation Using Fuzzy Binning",
        "texts": [
            "Fig. 1 Crisp binning (Top left) and fuzzy binning (Bottom left) of prediction probabilities, where the number of bins M = 3. An example of the difference in bin assignment based on p̂i in crisp vs fuzzy binning (Right).",
            "Fig. 2 Variation in calibration error estimated using ECE and FCE across different bin sizes (top to bottom) and class distributions (left vs right)",
            "Fig. 3 Variation in model overconfidence (OF) across different sample sizes",
            "Table 1 Variations in ECE and FCE across different fine-tuning settings. Here, ∆ calculates the average difference in estimated calibration error when binning is performed using fewer bins (M ∈ [2..7]) versus more bins (M ∈ [8..15])."
        ],
        "imgs": [
            "$2305.00543v2-Figure1-1.png",
            "$2305.00543v2-Figure2-1.png",
            "$2305.00543v2-Figure3-1.png",
            "$2305.00543v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00546",
        "abstract": "  Webpages change over time, and web archives hold copies of historical\nversions of webpages. Users of web archives, such as journalists, want to find\nand view changes on webpages over time. However, the current search interfaces\nfor web archives do not support this task. For the web archives that include a\nfull-text search feature, multiple versions of the same webpage that match the\nsearch query are shown individually without enumerating changes, or are grouped\ntogether in a way that hides changes. We present a change text search engine\nthat allows users to find changes in webpages. We describe the implementation\nof the search engine backend and frontend, including a tool that allows users\nto view the changes between two webpage versions in context as an animation. We\nevaluate the search engine with U.S. federal environmental webpages that\nchanged between 2016 and 2020. The change text search results page can clearly\nshow when terms and phrases were added or removed from webpages. The inverted\nindex can also be queried to identify salient and frequently deleted terms in a\ncorpus.\n",
        "title": "Making Changes in Webpages Discoverable: A Change-Text Search Interface\n  for Web Archives",
        "texts": [
            "Fig. 1. Two examples of web archive URI lookup of https://www.niehs.nih.gov/health/topics/agents/index.cfm. URI lookup does not allow the user to search by page text.",
            "Fig. 10. Out of about 40,000 seed URI-Rs in the EDGI data set, approximately 11,000 have successful (200) HTTP status codes in both 2016 and 2020. We found an additional 3,500 mementos from multiple web archives with successful status codes.",
            "Fig. 11. In SolrWayback, multiple versions of the same page are shown in the search results without any indication of how they are different. In the change text search engine results page, the versions of the page https://www.niehs.nih.gov/health/topics/agents/index.cfm that match the addition and deletion of the query term “pollution\" are indicated clearly.",
            "Fig. 2. None of these three web archive search interfaces group the versions to show the change in the page over time.",
            "Fig. 4. The Internet Archive’s Wayback Machine Changes tool shows users the differences between two captures. It only works for captures at this one web archive, and there is no way to search the changes to find the dates and times.",
            "Fig. 6. The architecture of the change text search engine. Level 1 consists of document acquisition. Level 2 consists of the documents and indices. Level 3 consists of the user interface.",
            "Fig. 7. Change text search interface. 1, 2, and 4: individual replay links to page mementos; 3: the diff between the pre and post deletion versions; 5: content lifespan calculation; 6: the link to the sliding diff viewer across all indexed versions of the page; 7: the link to the deletion animation",
            "Fig. 8. The sliding difference viewer shows the term ‘scientific’ was deleted from the page https://www.niehs.nih.gov/health/topics/agents/index.cfm in 2017, along with the context of the deletion.",
            "Fig. 9. The animation shows the deletion of the phrase “endangered species\" on the page http://www.fws.gov/ENDANGERED/permits/index.html.",
            "Table 1. Web archives with mementos in the first half of 2016 and 2020 for the 3,563 pages in the new pairing set with 200-to-200 status codes, as shown in the top right of Figure 10b.",
            "Table 2. Categorization of top 100 deleted terms in the 1,000 paired memento index sample."
        ],
        "imgs": [
            "$2305.00546v1-Figure1-1.png",
            "$2305.00546v1-Figure10-1.png",
            "$2305.00546v1-Figure11-1.png",
            "$2305.00546v1-Figure2-1.png",
            "$2305.00546v1-Figure4-1.png",
            "$2305.00546v1-Figure6-1.png",
            "$2305.00546v1-Figure7-1.png",
            "$2305.00546v1-Figure8-1.png",
            "$2305.00546v1-Figure9-1.png",
            "$2305.00546v1-Table1-1.png",
            "$2305.00546v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00548",
        "abstract": "  The extension of mixed quantum/classical theory (MQCT) to describe\ncollisional energy transfer is developed for symmetric-top-rotor + linear-rotor\nsystem type and is applied to $ \\rm ND_3 + \\rm D_2 $. State-to-state transition\ncross sections are computed in a broad energy range for all possible processes:\nwhen both $ \\rm ND_3$ and $ \\rm D_2$ molecules are excited or both are\nquenched, when one is excited while the other is quenched and vice versa, when\n$ \\rm ND_3 $ state changes its parity while $ \\rm D_2 $ is excited or quenched,\nand when $ \\rm ND_3 $ is excited or quenched while $ \\rm D_2 $ remains in the\nsame state, ground or excited. In all these processes the results of MQCT are\nfound to approximately satisfy the principle of microscopic reversibility. For\na set of sixteen state-to-state transitions available from literature for\ncollision energy $ \\rm 800 cm^{-1} $ the values of cross sections predicted by\nMQCT are within 8% of accurate full-quantum results. A useful time-dependent\ninsight is obtained by monitoring the evolution of state populations along MQCT\ntrajectories. It is shown that, if before the collision, $ \\rm D_2 $ is in its\nground state, the excitation of to $ \\rm ND_3 $ rotational states proceeds\nthrough a two-step mechanism in which the kinetic energy of molecule-molecule\ncollision is first used to excite $ \\rm D_2 $ and only then is transferred to\nthe excited rotational states of to $ \\rm ND_3 $. It is found that both\npotential coupling and Coriolis coupling play important roles in $ \\rm ND_3 +\n\\rm D_2 $collisions.\n",
        "title": "Mixed Quantum/Classical Theory for Rotational Energy Exchange in\n  Symmetric-Top-Rotor + Linear-Rotor Collisions and a Case Study of $ \\rm ND_3\n  + \\rm D_2$ System",
        "texts": [
            "Figure 1: The test of microscopic reversibility for transitions between several rotational states of ND3 + D2 system, labeled as (𝑗 ±𝑗 ). Cross sections are plotted as a function of collision energy. The data obtained by “direct” MQCT calculations are shown by solid lines, whereas dashed lines represent the results of \"reverse\" calculations. Red color is used for quenching processes, black color is for excitation processes. Blue symbol indicates full-quantum results of Ref. [40] The value of energy difference is given for each transition.",
            "Figure 2: Opacity functions for several transitions between the rotational states of ND3 + D2 system, labeled as (𝑗 ±𝑗 ). Transition probabilities are plotted as a function of collision impact parameter. Collision energy is 800 cm-1. In the upper two rows of frames, the opacity functions are given for all individual (𝑗, 𝑚)-components of the initial state. In the lower row of frames, the opacity functions are averaged over the initial (𝑗, 𝑚)-states, divided by degeneracy of the final state, and the results for excitation and quenching are plotted together, in order to check microscopic reversibility.",
            "Figure 3: Evolution of state populations in ND3 and D2 along one typical MQCT trajectory at collision energy of 800 cm-1. The impact parameter is 𝑏 = 5.58 Bohr, which corresponds to the orbital angular momentum quantum number ℓ = 35. The initial states are ND3 (1 ) and D2 (𝑗 = 0). The total population of D2 (𝑗 = 2) is shown by dashed purple line. The final ND3 + D2 (𝑗 = 0) states are labeled and are indicated by color. A vertical dashed line indicates the moment of closest approach of two molecules.",
            "Figure 4: Evolution of state populations in ND3 and D2 along one typical MQCT trajectory at collision energy of 800 cm-1. The impact parameter is 𝑏 = 5.0 Bohr, which corresponds to the orbital angular momentum quantum number ℓ = 35. The initial states are ND3(1 ) and D2(𝑗 = 2). The total population of D2(𝑗 = 2) except elastic (1 2) is shown by dashed purple line. The final ND3 + D2(𝑗 = 0) states are labeled and are indicated by color. A vertical dashed line indicates the moment of closest approach of two molecules.",
            "Figure 5: Evolution of state populations in ND3 and D2 along one typical MQCT trajectory at collision energy of 800 cm-1. The impact parameter is 𝑏 = 0, which corresponds to the orbital angular momentum quantum number ℓ = 0. The initial states are ND3 (2 ) and D2 (𝑗 = 2). The total population of D2(𝑗 = 2) except elastic (2 2) is shown by dashed purple line. The final ND3 + D2(𝑗 = 0) states are labeled and are indicated by color. A vertical dashed line indicates the moment of closest approach of two molecules.",
            "Figure 6: Cross sections for excitation of ND3(𝑗±) states from its ground state (1 ) in collisions with D2. In these processes the excitation of ND3 occurs in coincidence with excitation (0 → 2, upper frame) or quenching (2 → 0, lower frame) of the rotational states of D2. Our MQCT results and the full-quantum results of Ref. [40] are shown in blue and red colors, respectively. Transitions labels by asterisk are analyzed in detail in Fig. 2."
        ],
        "imgs": [
            "$2305.00548v1-Figure1-1.png",
            "$2305.00548v1-Figure2-1.png",
            "$2305.00548v1-Figure3-1.png",
            "$2305.00548v1-Figure4-1.png",
            "$2305.00548v1-Figure5-1.png",
            "$2305.00548v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00549",
        "abstract": "  Recently the superconducting diode effect (SDE) has attracted a lot of\nattention due to new possibilities in the field of superconducting electronics.\nOne of the possible realizations of the SDE is the implementation in\nsuperconducting hybrid structures. In this case the SDE is achieved by means of\nthe proximity effect. However, the optimal conditions for the SDE quality\nfactor in hybrid devices remain unclear. In this study we consider the\nSuperconductor/Ferromagnet/Topological insulator (S/F/TI) hybrid device and\ninvestigate the diode quality factor at different parameters of the hybrid\nstructure. Consequently, we reveal important parameters that have crucial\nimpact on the magnitude of the SDE quality factor.\n",
        "title": "Phase diagrams of the superconducting diode effect in topological hybrid\n  structures",
        "texts": [
            "FIG. 3. Phase diagram of the diode efficiency η plotted on the axes ds − df . The parameters of the calculation: γ = 0.5, γB = 0.3, T = 0.25Tcs, H = 0.3.",
            "FIG. 4. Phase diagram of the diode efficiency η as a function of the interface parameters γ − γB . The parameters of the calculation: T = 0.1Tcs, ds = 1.2ξ, df = ξ,H = 0.3"
        ],
        "imgs": [
            "$2305.00549v1-Figure3-1.png",
            "$2305.00549v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00550",
        "abstract": "  Machine Learning (ML) has become a valuable asset to solve many real-world\ntasks. For Network Intrusion Detection (NID), however, scientific advances in\nML are still seen with skepticism by practitioners. This disconnection is due\nto the intrinsically limited scope of research papers, many of which primarily\naim to demonstrate new methods ``outperforming'' prior work -- oftentimes\noverlooking the practical implications for deploying the proposed solutions in\nreal systems. Unfortunately, the value of ML for NID depends on a plethora of\nfactors, such as hardware, that are often neglected in scientific literature.\n  This paper aims to reduce the practitioners' skepticism towards ML for NID by\n\"changing\" the evaluation methodology adopted in research. After elucidating\nwhich \"factors\" influence the operational deployment of ML in NID, we propose\nthe notion of \"pragmatic assessment\", which enable practitioners to gauge the\nreal value of ML methods for NID. Then, we show that the state-of-research\nhardly allows one to estimate the value of ML for NID. As a constructive step\nforward, we carry out a pragmatic assessment. We re-assess existing ML methods\nfor NID, focusing on the classification of malicious network traffic, and\nconsider: hundreds of configuration settings; diverse adversarial scenarios;\nand four hardware platforms. Our large and reproducible evaluations enable\nestimating the quality of ML for NID. We also validate our claims through a\nuser-study with security practitioners.\n",
        "title": "SoK: Pragmatic Assessment of Machine Learning for Network Intrusion\n  Detection",
        "texts": [
            "Fig. 1: Typical deployment scenario of a NIDS.",
            "Fig. 10: An ML pipeline representing a detector by cascading a 2- and Mclass classifier. The Binary classifier first analyzes a sample, predicting whether such sample is benign or malicious. If the sample is malicious, then it is forwarded to a M-class classifier that determines the specific malicious class (out of M possible classes).",
            "Fig. 11: Exemplary design of a ‘redundant’ ensemble of ML models for NID (used in [175]). Each classifier is trained on a specific attack (out of M); however, each classifier receives only samples that are either benign, or belong to the specific attack that the classifier can recognize.",
            "Fig. 12: Design of the ML pipelines entailed in our considered ML-NIDS.",
            "Fig. 2: Architecture of an ML-NIDS.",
            "Fig. 3: Typical ML workflow adopted in research.",
            "Fig. 4: The business perspective of ML-NIDS.",
            "Fig. 7: Detection of unknown attacks.",
            "Fig. 8: Robustness to adversarial attacks.",
            "Fig. 9: Runtime (on the high-end platform).",
            "TABLE 1: Viewpoint of practitioners on our set of factors.",
            "TABLE 10: GTCS. Results against adversarial (original tpr and adversarial tpr) and unknown attacks (the tpr is the average on the ‘unknown’ attacks, while the fpr is due to training on a new T that does not have the ‘unknown’ class.).",
            "TABLE 11: NB15 binary classification results (fpr and tpr) against ‘known’ attacks seen during the training stage (closed world).",
            "TABLE 12: NB15. Results against adversarial (original tpr and adversarial tpr) and unknown attacks (the tpr is the average on the ‘unknown’ attacks, while the fpr is due to training on a new T that does not have the ‘unknown’ class.).",
            "TABLE 13: UF-NB15 binary classification results (fpr and tpr) against ‘known’ attacks seen during the training stage (closed world).",
            "TABLE 14: UF-NB15. Results against adversarial (original tpr and adversarial tpr) and unknown attacks (the tpr is the average on the ‘unknown’ attacks, while the fpr is due to training on a new T that does not have the ‘unknown’ class.).",
            "TABLE 15: CICIDS17 binary classification results (fpr and tpr) against ‘known’ attacks seen during the training stage (closed world).",
            "TABLE 16: CICIDS17. Results against adversarial (original tpr and adversarial tpr) and unknown attacks (the tpr is the average on the ‘unknown’ attacks, while the fpr is due to training on a new T that does not have the ‘unknown’ class.).",
            "TABLE 17: CTU13 Multi-classification results. Cells report the (average) Accuracy (and std. dev.) computed exclusively on the malicious samples.",
            "TABLE 18: GTCS Multi-classification results. Cells report the (average) Accuracy (and std. dev.) computed exclusively on the malicious samples.",
            "TABLE 19: NB15 Multi-classification results. Cells report the (average) Accuracy (and std. dev.) computed exclusively on the malicious samples.",
            "TABLE 2: State-of-the-Art: papers published since 2017 in top cybersecurity conferences that consider applications of ML linked with NID.",
            "TABLE 20: UF-NB15 Multi-classification results. Cells report the (average) Accuracy (and std. dev.) computed exclusively on the malicious samples.",
            "TABLE 21: CICIDS17 Multi-classification results. Cells report the (average) Accuracy (and std. dev.) computed exclusively on the malicious samples.",
            "TABLE 22: CTU13 Runtime (in seconds) for training the ML-NIDS on the high-end platform..",
            "TABLE 23: GTCS: Runtime (in seconds) for training the ML-NIDS on the high-end platform..",
            "TABLE 24: NB15: Runtime (in seconds) for training the ML-NIDS on the high-end platform..",
            "TABLE 25: UF-NB15: Runtime (in seconds) for training the ML-NIDS on the high-end platform..",
            "TABLE 26: CICIDS17: Runtime (in seconds) for training the ML-NIDS on the high-end platform..",
            "TABLE 3: Practitioners’ opinion on the results displayed in Table 2.",
            "TABLE 31: CICIDS17: Runtime (in seconds) for testing (on E) the ML-NIDS on the high-end platform..",
            "TABLE 32: Runtime (training and testing) on the other platforms (for the GTCS dataset).",
            "TABLE 4: Summary of the datasets of our experimental evaluation.",
            "TABLE 5: State-of-the-Art (2022): papers published in top cybersecurity conferences that consider applications of ML linked with NID.",
            "TABLE 6: Distribution of samples for each Dataset.",
            "TABLE 7: CTU13 binary classification results (fpr and tpr) against ‘known’ attacks seen during the training stage (closed world).",
            "TABLE 8: CTU13. Results against adversarial (original tpr and adversarial tpr) and unknown attacks (the tpr is the average on the ‘unknown’ attacks, while the fpr is due to training on a new T that does not have the ‘unknown’ class.).",
            "TABLE 9: GTCS binary classification results (fpr and tpr) against ‘known’ attacks seen during the training stage (closed world)."
        ],
        "imgs": [
            "$2305.00550v1-Figure1-1.png",
            "$2305.00550v1-Figure10-1.png",
            "$2305.00550v1-Figure11-1.png",
            "$2305.00550v1-Figure12-1.png",
            "$2305.00550v1-Figure2-1.png",
            "$2305.00550v1-Figure3-1.png",
            "$2305.00550v1-Figure4-1.png",
            "$2305.00550v1-Figure7-1.png",
            "$2305.00550v1-Figure8-1.png",
            "$2305.00550v1-Figure9-1.png",
            "$2305.00550v1-Table1-1.png",
            "$2305.00550v1-Table10-1.png",
            "$2305.00550v1-Table11-1.png",
            "$2305.00550v1-Table12-1.png",
            "$2305.00550v1-Table13-1.png",
            "$2305.00550v1-Table14-1.png",
            "$2305.00550v1-Table15-1.png",
            "$2305.00550v1-Table16-1.png",
            "$2305.00550v1-Table17-1.png",
            "$2305.00550v1-Table18-1.png",
            "$2305.00550v1-Table19-1.png",
            "$2305.00550v1-Table2-1.png",
            "$2305.00550v1-Table20-1.png",
            "$2305.00550v1-Table21-1.png",
            "$2305.00550v1-Table22-1.png",
            "$2305.00550v1-Table23-1.png",
            "$2305.00550v1-Table24-1.png",
            "$2305.00550v1-Table25-1.png",
            "$2305.00550v1-Table26-1.png",
            "$2305.00550v1-Table3-1.png",
            "$2305.00550v1-Table31-1.png",
            "$2305.00550v1-Table32-1.png",
            "$2305.00550v1-Table4-1.png",
            "$2305.00550v1-Table5-1.png",
            "$2305.00550v1-Table6-1.png",
            "$2305.00550v1-Table7-1.png",
            "$2305.00550v1-Table8-1.png",
            "$2305.00550v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00552",
        "abstract": "  In low-resource computing contexts, such as smartphones and other tiny\ndevices, Both deep learning and machine learning are being used in a lot of\nidentification systems. as authentication techniques. The transparent,\ncontactless, and non-invasive nature of these face recognition technologies\ndriven by AI has led to their meteoric rise in popularity in recent years.\nWhile they are mostly successful, there are still methods to get inside without\npermission by utilising things like pictures, masks, glasses, etc. In this\nresearch, we present an alternate authentication process that makes use of both\nfacial recognition and the individual's distinctive temporal facial feature\nmotions while they speak a password. Because the suggested methodology allows\nfor a password to be specified in any language, it is not limited by language.\nThe suggested model attained an accuracy of 96.1% when tested on the\nindustry-standard MIRACL-VC1 dataset, demonstrating its efficacy as a reliable\nand powerful solution. In addition to being data-efficient, the suggested\ntechnique shows promising outcomes with as little as 10 positive video examples\nfor training the model. The effectiveness of the network's training is further\nproved via comparisons with other combined facial recognition and lip reading\nmodels.\n",
        "title": "Deep Learning-based Spatio Temporal Facial Feature Visual Speech\n  Recognition",
        "texts": [
            "Fig. 1. Proposed Architecture built on VGGFace",
            "Fig. 2. Data Preprocessing Pipeline",
            "Fig. 3. Proposed Architecture built on LSTM Network",
            "Fig. 4. Variations in future extraction",
            "Fig. 5. Learning Curves of Training and Validation Accuracy and Loss for 30 Epochs and its Confusion Matrix",
            "TABLE III PERFORMANCE OF PROPOSED METHODOLOGY",
            "TABLE IV ERROR CLASSIFICATION GRANULARITY (MIRACLVC1 DATASET)"
        ],
        "imgs": [
            "$2305.00552v1-Figure1-1.png",
            "$2305.00552v1-Figure2-1.png",
            "$2305.00552v1-Figure3-1.png",
            "$2305.00552v1-Figure4-1.png",
            "$2305.00552v1-Figure5-1.png",
            "$2305.00552v1-TableIII-1.png",
            "$2305.00552v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00554",
        "abstract": "  Blockchain systems often rely on rationality assumptions for their security,\nexpecting that nodes are motivated to maximize their profits. These systems\nthus design their protocols to incentivize nodes to execute the honest protocol\nbut fail to consider out-of-band collusion. Existing works analyzing\nrationality assumptions are limited in their scope, either by focusing on a\nspecific protocol or relying on non-existing financial instruments. We propose\na general rational attack on rationality by leveraging an external channel that\nincentivizes nodes to collude against the honest protocol. Our approach\ninvolves an attacker creating an out-of-band bribery smart contract to motivate\nnodes to double-spend their transactions in exchange for shares in the\nattacker's profits. We provide a game theory model to prove that any rational\nnode is incentivized to follow the malicious protocol. We discuss our approach\nto attacking the Bitcoin and Ethereum blockchains, demonstrating that\nirrational behavior can be rational in real-world blockchain systems when\nanalyzing rationality in a larger ecosystem. We conclude that rational\nassumptions only appear to make the system more secure and offer a false sense\nof security under the flawed analysis.\n",
        "title": "Breaking Blockchain Rationality with Out-of-Band Collusion",
        "texts": [
            "Fig. 1: In a real-world blockchain system, given an honest protocol Ph, the magnate can always construct a malicious protocol Pm with a higher total reward by double-spending transactions through reverting a confirmed block."
        ],
        "imgs": [
            "$2305.00554v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00556",
        "abstract": "  Visual reconstruction algorithms are an interpretive tool that map brain\nactivity to pixels. Past reconstruction algorithms employed brute-force search\nthrough a massive library to select candidate images that, when passed through\nan encoding model, accurately predict brain activity. Here, we use conditional\ngenerative diffusion models to extend and improve this search-based strategy.\nWe decode a semantic descriptor from human brain activity (7T fMRI) in voxels\nacross most of visual cortex, then use a diffusion model to sample a small\nlibrary of images conditioned on this descriptor. We pass each sample through\nan encoding model, select the images that best predict brain activity, and then\nuse these images to seed another library. We show that this process converges\non high-quality reconstructions by refining low-level image details while\npreserving semantic content across iterations. Interestingly, the\ntime-to-convergence differs systematically across visual cortex, suggesting a\nsuccinct new way to measure the diversity of representations across visual\nbrain areas.\n",
        "title": "Reconstructing seen images from human brain activity via guided\n  stochastic search",
        "texts": [
            "Figure 1: Pipeline diagram for our method: the top half demonstrates the Training stage for our models, and the bottom half depicts the Inference Stage that deploys our stochastic search procedure.",
            "Figure 2: Qualitative comparison of our method against a CLIP decoding-only method, and brute-force search through a library of COCO images. (T.-Y. Lin et al., 2015)",
            "Figure 4: Correlation of predicted and actual brain activity (“score”) for the top image at each iteration for different ROIs (curves). Inset: the number of iterations for each ROI to cross score for ground truth image (dashed lines).",
            "Table 1: Quantitative comparison of methods. PixCorr: pixelwise correlation metric. SSIM: structural similarity index measure. CLIP: two-way identification experiment comparing CLIP from reconstruction to CLIP from ground truth target and a random reconstruction of the same type."
        ],
        "imgs": [
            "$2305.00556v2-Figure1-1.png",
            "$2305.00556v2-Figure2-1.png",
            "$2305.00556v2-Figure4-1.png",
            "$2305.00556v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00557",
        "abstract": "  Interacting systems are ubiquitous in nature and engineering, ranging from\nparticle dynamics in physics to functionally connected brain regions. These\ninteracting systems can be modeled by graphs where edges correspond to the\ninteractions between interactive entities. Revealing interaction laws is of\nfundamental importance but also particularly challenging due to underlying\nconfigurational complexities. The associated challenges become exacerbated for\nheterogeneous systems that are prevalent in reality, where multiple interaction\ntypes coexist simultaneously and relational inference is required. Here, we\npropose a novel probabilistic method for relational inference, which possesses\ntwo distinctive characteristics compared to existing methods. First, it infers\nthe interaction types of different edges collectively by explicitly encoding\nthe correlation among incoming interactions with a joint distribution, and\nsecond, it allows handling systems with variable topological structure over\ntime. We evaluate the proposed methodology across several benchmark datasets\nand demonstrate that it outperforms existing methods in accurately inferring\ninteraction types. We further show that when combined with known constraints,\nit allows us, for example, to discover physics-consistent interaction laws of\nparticle systems. Overall the proposed model is data-efficient and\ngeneralizable to large systems when trained on smaller ones. The developed\nmethodology constitutes a key element for understanding interacting systems and\nmay find application in graph structure learning.\n",
        "title": "Collective Relational Inference for learning heterogeneous interactions",
        "texts": [
            "Figure 1: Comparison between (A) existing probabilistic approaches [9, 13, 14] and (B) our proposed method CRI for relational inference. Previous approaches predict the interaction type of different edges independently (e.g., the incoming edges of v1). CRI takes the subgraph of each particle (e.g., S(1)) as an entity. We learn the joint distribution of interaction type for all edges in the subgraph, allowing for modeling their collective influence on particle states.",
            "Figure 2: Framework of CRI. The proposed CRI, shown in the gray area, takes particle states at every time step and predicts accelerations. Dashed squares represent different objects (e.g., the particle system at a given time step, the graphical representation of the particle system, etc.). Solid squares correspond to different operators. For simplicity, a case with only two different types of interactions is shown but the proposed method is general. (A) The particle system over time. At every time step, each particle is described by its position and velocity, and the time-invariant property, e.g., mass. (B) All possible realizations denoted by the random variable z(1) for the subgraph S(1). (C) The subgraph S(1) at time t. (D) The subgraph S(1) with different realizations at time t, which are the input of the generative model. (E) The predicted acceleration of v1 of different realizations. (F) The final predicted acceleration which is the expectation over the estimated probability z(1). (G) The ground-truth acceleration which is computed from particle states between two consecutive time steps.",
            "Figure 3: Framework of Evolving-CRI. (A) The particle system at various moments in time. Particles may interact with different neighbors at different time steps. The interaction radius of particle 3 (orange) is indicated by a black circle. At each time step, the feature vector xti of each particle vi contains its position and velocity, and the time-invariant property, e.g., mass. (B) At each time step, we update the estimation of the posterior distributions of the interaction type for edges appearing at this time step, using Eq. 11. (C) The estimated posteriors after observing the system across all time steps. (D) Example subgraph S(3) at time t. (E) The example subgraph with different realizations of edge types at time t, which is the input for the generative model. (F) The predicted acceleration, which is the expectation over the inferred posterior distribution in (C). (G) The ground-truth acceleration computed from particle states between two consecutive time steps.",
            "Figure 4: Test performances for the spring and charge experiments. Mean and standard derivation are computed from five independent experiments. (left column) Accuracy of the interaction type inference. (center column) MAE of pairwise force. NRI and MPM cannot infer pairwise force. (right column) MAE of state (position and velocity combined) after 10 simulation steps.",
            "Figure 5: Concept of Evolving-CRI to learn the heterogeneous interactions in crystallization problems. (left) System evolution during crystallization. Yellow and red colors indicate two different kinds of particles with heterogeneous interactions. (right) Schematic of Evolving-CRI consisting of an inference module and a generative module. Evolving-CRI is trained to predict the ground-truth acceleration. After training, the heterogeneous interactions are implicitly learnt.",
            "Figure 6: Performances of Evolving-CRI on the crystallization problem with an evolving graph topology. (A1-A3) Interpolation and (B1-B3) extrapolation results of Evolving-CRI. Mean and standard derivation are computed from five independent experiments. (A1 and B1) Accuracy in inferring the interaction type. (A2 and B2) Mean Absolute Error in particle acceleration. (A3 and B3) Mean Absolute Error in pairwise interaction. NRI and MPM cannot explicitly predict the pairwise force.",
            "Figure 7: Framework of Var-CRI. (A) The particle system over time. At each time step, the feature xti of each particle contains its position and velocity, and the time-invariant property, e.g., mass. (B) We partition the incoming edges of v3 into two disjoint groups and infer the probabilities q∗(ζ3,1) and q∗(ζ3,2). (C) The subgraph S(3) at time t. (D) The subgraph S(3) with different realizations of its two groups at time t, which are the input of the generative module. (E) The predicted acceleration of v3 at time t which is the expectation over q∗(ζ3,1) and q∗(ζ3,2). (F) The ground-truth acceleration computed by looking at particle states at two consecutive time steps.",
            "Table 2: The neural network architecture and the Gaussian variance of CRI, Var-CRI and EvolvingCRI in different experiments.",
            "Table 3: Detailed results of different methods on Spring N5K2 (Sec. 3.1.1). The mean and the standard deviation are computed from five experiments.",
            "Table 4: Detailed results on Spring N10K2 (Sec. 3.1.2). The mean and the standard deviation are computed from five experiments.",
            "Table 5: Detailed results on the generalization experiment in Sec. 3.1.3. The model is trained and selected on the training and validation dataset of Spring N5K2, and tested on Spring N10K2. The mean and the standard deviation are computed from five experiments.",
            "Table 6: Detailed results on Spring N5K4 (Sec. 3.1.4). The mean and the standard deviation are computed from five experiments.",
            "Table 7: Detailed results on Charge N5K2 in Sec. 3.1.5. NRI and MPM use the CNN reducer in their encoder, which is the default setting for the charge data in the original paper. The mean and the standard deviation are computed from five experiments.",
            "Table 8: Interpolation performance on learning heterogeneous interactions in the crystallization simulation in Sec. 3.2. The mean and the standard deviation are computed from five experiments.",
            "Table 9: Extrapolation performance on learning heterogeneous interactions in the crystallization simulation in Sec. 3.2. The mean and the standard deviation are computed from five experiments."
        ],
        "imgs": [
            "$2305.00557v1-Figure1-1.png",
            "$2305.00557v1-Figure2-1.png",
            "$2305.00557v1-Figure3-1.png",
            "$2305.00557v1-Figure4-1.png",
            "$2305.00557v1-Figure5-1.png",
            "$2305.00557v1-Figure6-1.png",
            "$2305.00557v1-Figure7-1.png",
            "$2305.00557v1-Table2-1.png",
            "$2305.00557v1-Table3-1.png",
            "$2305.00557v1-Table4-1.png",
            "$2305.00557v1-Table5-1.png",
            "$2305.00557v1-Table6-1.png",
            "$2305.00557v1-Table7-1.png",
            "$2305.00557v1-Table8-1.png",
            "$2305.00557v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00558",
        "abstract": "  The phenomenon of the deconfinement -- the spectacular drop of the\ncolorelectric string tension at the critical temperature $T_c$ -- is studied\nwithin the method of field correlators (FCM) taking into account directly the\ncontribution of the gluon condensate into the hadronic free energy. Using the\nresulting expressions for the free energy as a sum of the gluon condensate (the\nvacuum energy) and the hadronic pressure one obtains the possibility to\ncalculate the deconfinement temperature $T_c$ and the temperature behavior of\nthe string tension $\\sigma_E(T)$ and the gluonic condensate $G_2(T)$ below\n$T_c$. The connection between the string tension and the quark condensate found\nin the framework of FCM allows the predict also the latter as a function of $T$\n. These results are compared to the known lattice data of $T_c$, $\\sigma_E(T)$,\n$\\langle \\bar{q}q \\rangle(T)$ for hadronic media with different $n_f$ and $m_q$\nand in the external magnetic field $eB$. The good agreement of the results of\nthis approach with lattice data is demonstrated.\n",
        "title": "Theory of the deconfinement process in QCD",
        "texts": [
            "Figure 1: Comparison of the lattice data for the ratio σ(T )/σ(0) from [33] – dotted line, with our result from eq.(26) – solid line, and lattice data from [34] – dots.",
            "Figure 2: The ratio sigma(T)/sigma(0) according to eqs.(24),(25) for different values of the hadron mass – mπ –solid line, mρ – long dashed line, mJ/ψ – dashed line and the same ratio from lattice data of [33]-dotted line fully covered by the pion curve.",
            "Figure 3: The behavior of the quark condensate as a function of temperature T:the dotted line – the simple form of eq.(30), the solid line corresponds to the string tension in the pionic hadron gas to the power 4/3, dots-lattice data from [74].",
            "Table 1: Transition temperature Tc for massless quarks, nf = 0, 2, 3 (the upper part), and for different nonzero mq and nf (the lower part) in comparison with lattice data.",
            "Table 2: Quark mass dependence of transition temperature with |〈q̄q〉| = (0.13 GeV)3 in comparison with the lattice data from [61].",
            "Table 3: The temperature dependence of the quark condensate ratioKq(T ) = Σ(T )",
            "Table 4: The average light quark condensate as a function of temperature T in our equation (30) vs lattice data from [75]."
        ],
        "imgs": [
            "$2305.00558v2-Figure1-1.png",
            "$2305.00558v2-Figure2-1.png",
            "$2305.00558v2-Figure3-1.png",
            "$2305.00558v2-Table1-1.png",
            "$2305.00558v2-Table2-1.png",
            "$2305.00558v2-Table3-1.png",
            "$2305.00558v2-Table4-1.png"
        ]
    },
    {
        "id": "2305.00559",
        "abstract": "  We present a tool for modelling and reasoning with knowledge from various\ndiverse (and possibly conflicting) viewpoints. The theoretical underpinnings\nare provided by enhancing base logics by standpoints according to a recently\nintroduced formalism that we also recall. The tool works by translating the\nstandpoint-enhanced version of the description logic SROIQ to its plain (i.e.\nclassical) version. Existing reasoners can then be directly used to provide\nautomated support for reasoning about diverse standpoints.\n",
        "title": "Automated reasoning support for Standpoint-OWL 2",
        "texts": [
            "Table 1 “Plain” SROIQ role, concept expressions, RIAs and TBox axioms. 𝐶 ≡ 𝐷 abbreviates 𝐶 ⊑ 𝐷, 𝐷 ⊑ 𝐶 . 2. Background"
        ],
        "imgs": [
            "$2305.00559v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00561",
        "abstract": "  Motion planning of autonomous agents in partially known environments with\nincomplete information is a challenging problem, particularly for complex\ntasks. This paper proposes a model-free reinforcement learning approach to\naddress this problem. We formulate motion planning as a probabilistic-labeled\npartially observable Markov decision process (PL-POMDP) problem and use linear\ntemporal logic (LTL) to express the complex task. The LTL formula is then\nconverted to a limit-deterministic generalized B\\\"uchi automaton (LDGBA). The\nproblem is redefined as finding an optimal policy on the product of PL-POMDP\nwith LDGBA based on model-checking techniques to satisfy the complex task. We\nimplement deep Q learning with long short-term memory (LSTM) to process the\nobservation history and task recognition. Our contributions include the\nproposed method, the utilization of LTL and LDGBA, and the LSTM-enhanced deep Q\nlearning. We demonstrate the applicability of the proposed method by conducting\nsimulations in various environments, including grid worlds, a virtual office,\nand a multi-agent warehouse. The simulation results demonstrate that our\nproposed method effectively addresses environment, action, and observation\nuncertainties. This indicates its potential for real-world applications,\nincluding the control of unmanned aerial vehicles (UAVs).\n",
        "title": "Model-free Motion Planning of Autonomous Agents for Complex Tasks in\n  Partially Observable Environments",
        "texts": [
            "Fig. 1 Q network architecture.",
            "Fig. 11 A generated path for Task in φ2 of dynamic event with labeling uncertainty: (1) If it is fully aware of the task (q state sequence): (a) The path on q0. (b) The path on q1. (c) The path back on q0. (2) If it is not aware of the task (label sequence): (d) The path on q0. (e) The path on q1. (f) The path back on q0.",
            "Fig. 12 A generated path for Task in φ2 of static event: (1) If it is fully aware of the task (q state sequence): (a) The path on q0. (b) The path on q1. (c) The path back on q0. (2) If it is not aware of the task (label sequence): (d) The path on q0. (e) The path on q1. (f) The path back on q0.",
            "Fig. 13 Comparison of the reward evolution for task φ2.",
            "Fig. 16 Generated paths for the TurtleBot to accomplish tasks if it can observe surroundings in all four directions: (a) Task 1. (b) Task 2.",
            "Fig. 18 The paths for the agent to accomplish the assigned tasks for a single round when the agent can observe only one direction: (a) Task 1. (b) Task 2.",
            "Fig. 2 A 10 x 10 grid world",
            "Fig. 20 Q network architectures for a MARL problem.",
            "Fig. 21 The accumulated rewards of the MARL case.",
            "Fig. 22 The paths generated for the red and yellow agents to accomplish the assigned task.",
            "Fig. 3 The comparison of accumulated rewards by using Q networks with LSTM, CNN, and DNN.",
            "Fig. 4 A path generated from the derived policy.",
            "Fig. 5 The architecture of Q networks taking ot and qt as input.",
            "Fig. 7 The LDGBA of φ1.",
            "Fig. 8 The averaged accumulated rewards of task φ1.",
            "Fig. 9 A single round path of task φ1: (a) The path on q0. (b) The path on q1."
        ],
        "imgs": [
            "$2305.00561v1-Figure1-1.png",
            "$2305.00561v1-Figure11-1.png",
            "$2305.00561v1-Figure12-1.png",
            "$2305.00561v1-Figure13-1.png",
            "$2305.00561v1-Figure16-1.png",
            "$2305.00561v1-Figure18-1.png",
            "$2305.00561v1-Figure2-1.png",
            "$2305.00561v1-Figure20-1.png",
            "$2305.00561v1-Figure21-1.png",
            "$2305.00561v1-Figure22-1.png",
            "$2305.00561v1-Figure3-1.png",
            "$2305.00561v1-Figure4-1.png",
            "$2305.00561v1-Figure5-1.png",
            "$2305.00561v1-Figure7-1.png",
            "$2305.00561v1-Figure8-1.png",
            "$2305.00561v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00562",
        "abstract": "  Diffusion-based models have shown the merits of generating high-quality\nvisual data while preserving better diversity in recent studies. However, such\nobservation is only justified with curated data distribution, where the data\nsamples are nicely pre-processed to be uniformly distributed in terms of their\nlabels. In practice, a long-tailed data distribution appears more common and\nhow diffusion models perform on such class-imbalanced data remains unknown. In\nthis work, we first investigate this problem and observe significant\ndegradation in both diversity and fidelity when the diffusion model is trained\non datasets with class-imbalanced distributions. Especially in tail classes,\nthe generations largely lose diversity and we observe severe mode-collapse\nissues. To tackle this problem, we set from the hypothesis that the data\ndistribution is not class-balanced, and propose Class-Balancing Diffusion\nModels (CBDM) that are trained with a distribution adjustment regularizer as a\nsolution. Experiments show that images generated by CBDM exhibit higher\ndiversity and quality in both quantitative and qualitative ways. Our method\nbenchmarked the generation results on CIFAR100/CIFAR100LT dataset and shows\noutstanding performance on the downstream recognition task.\n",
        "title": "Class-Balancing Diffusion Models",
        "texts": [
            "Figure 1. Generation degrades along with class frequency. Semantics of generated images become less recognizable when class frequency decreases, while the FID score increases significantly.",
            "Figure 10. (a) DDPM(left)/CBDM(right) comparison when denoising a same noised image in CelebA-5. (b) An exemplar about the fidelity and diversity control guided by strength ω and regularization weight τ for generators trained on the CUB dataset.",
            "Figure 11. Comparison of image generation results on body class (62) between different label set. Image generated by DDPM is also shown for comparison.",
            "Figure 12. CFG/TCFG comparison with an embedded ω",
            "Figure 2. Algorithm (left) and generation (right) visualization. In the left figure, we show that an extra regularization loss gLr proportional to the diffusion step t is added during training. This loss function pushes the sampling distribution (curves on the surface) to wider region while preventing it to be excessively distorted compared to the ground truth distribution (gradient color on the background).",
            "Figure 3. Comparison of image generation on heavily taildistributed (94) and mild tail-distributed (62) classes between DDPM and CBDM.",
            "Figure 4. FID improvement per class compared to DDPM. The curve is smoothened by a moving average of 5 unit.",
            "Figure 5. FID/IS score under different regularization weight τ",
            "Figure 6. FID/IS score under different guidance strength ω",
            "Figure 7. Image fidelity and diversity controlled by guidance strength ω and regularization weight τ .",
            "Figure 8. Image generation visualization for the CIFAR100LT dataset",
            "Figure 9. Image generation visualization for the CIFAR10LT dataset",
            "Table 1. CBDM performance on different datasets. In the table, the first three columns are diversity-related, and we mark the best results in bold. As the comparison between CBDM and DDPM is more straightforward, we mark the performance gain in parentheses next to the CBDM results, using blue and red to indicate improvements and degradation respectively.",
            "Table 2. CBDM performance for 3 mechanisms under different regularization sampling set Y . Column PT indicates the dataset used in (pre)training, column FT indicates the dataset used for fine-tuning. The rows where Y marked as “-“ represent the results with DDPM, and rows where FT marked as “-“ represent the results of CBDM trained from scratch. Three diversity-preferred metrics and the best results are in bold for emphasis.",
            "Table 3. Comparision with long-tailed SoTAs on CIFAR. Following their setting, all methods are evaluated with 10k generated images and ground truth images are from their validation dataset. The publish year of every baselines are marked in next to the citation.",
            "Table 4. Recognition results of different training data. All configurations are evaluated on the testing set of normal CIFAR100. Gains based on CIFAR100LT dataset is noted in blue.",
            "Table 5. CBDM performance using different backbones on CIFAR100LT dataset. Three diversity-biased metrics.",
            "Table 6. Sampling with 100 DDIM steps on CIFAR100 and CIFAR100LT. The difference compared with those using DDPM steps are reported below each result.",
            "Table 7. CBDM performance on high-resolution datasets. Here, CB-DDPM refers to the DDPM model fine-tuned by our method, ω refers to the guidance strength and τ refers to the weight of the regularization term. We note than the fine-tuning is applied on CUB and ImageNet-LT due to the limited calculation budget.",
            "Table 8. Influence of ϕ to model performance"
        ],
        "imgs": [
            "$2305.00562v1-Figure1-1.png",
            "$2305.00562v1-Figure10-1.png",
            "$2305.00562v1-Figure11-1.png",
            "$2305.00562v1-Figure12-1.png",
            "$2305.00562v1-Figure2-1.png",
            "$2305.00562v1-Figure3-1.png",
            "$2305.00562v1-Figure4-1.png",
            "$2305.00562v1-Figure5-1.png",
            "$2305.00562v1-Figure6-1.png",
            "$2305.00562v1-Figure7-1.png",
            "$2305.00562v1-Figure8-1.png",
            "$2305.00562v1-Figure9-1.png",
            "$2305.00562v1-Table1-1.png",
            "$2305.00562v1-Table2-1.png",
            "$2305.00562v1-Table3-1.png",
            "$2305.00562v1-Table4-1.png",
            "$2305.00562v1-Table5-1.png",
            "$2305.00562v1-Table6-1.png",
            "$2305.00562v1-Table7-1.png",
            "$2305.00562v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00564",
        "abstract": "  The quantum master equation (QME), used to describe the Markov process of\ninteraction between atoms and field, has a number of significant drawbacks. It\nis extremely memory intensive, and also inapplicable to the case of long-term\nmemory in the environment. An iterative algorithm for modeling the dynamics of\nan atomic system in the extended Tavis-Cummings model in terms of a pure state\nis proposed. The correctness of this algorithm is shown on the example of the\ninteraction of an atomic system with the environment through the exchange of\nphotons with the preservation of coherence. This algorithm is applicable to a\nwide class of processes associated with photonic machinery, in particular, to\nchemical reactions.\n",
        "title": "Description of the non-Markovian dynamics of atoms in terms of a pure\n  state",
        "texts": [
            "Table 1: Comparison table of two algorithms."
        ],
        "imgs": [
            "$2305.00564v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00565",
        "abstract": "  For many examples of couples $(\\mu,\\nu)$ of probability measures on the real\nline in the convex order, we observe numerically that the Hobson and Neuberger\nmartingale coupling, which maximizes for $\\rho=1$ the integral of $|y-x|^\\rho$\nwith respect to any martingale coupling between $\\mu$ and $\\nu$, is still a\nmaximizer for $\\rho\\in(0,2)$ and a minimizer for $\\rho>2$. We investigate the\ntheoretical validity of this numerical observation and give rather restrictive\nsufficient conditions for the property to hold. We also exhibit couples\n$(\\mu,\\nu)$ such that it does not hold. The support of the Hobson and Neuberger\ncoupling is known to satisfy some monotonicity property which we call\nnon-decreasing. We check that the non-decreasing property is preserved for\nmaximizers when $\\rho\\in(0,1]$. In general, there exist distinct non-decreasing\nmartingale couplings, and we find some decomposition of $\\nu$ which is in\none-to-one correspondence with martingale couplings non-decreasing in a\ngeneralized sense.\n",
        "title": "Non-decreasing martingale couplings",
        "texts": [
            "Figure 2: The function ρ 7→ αρ (with αρ computed by a root finding algorithm)."
        ],
        "imgs": [
            "$2305.00565v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00567",
        "abstract": "  The goal of multi-objective reinforcement learning (MORL) is to learn\npolicies that simultaneously optimize multiple competing objectives. In\npractice, an agent's preferences over the objectives may not be known apriori,\nand hence, we require policies that can generalize to arbitrary preferences at\ntest time. In this work, we propose a new data-driven setup for offline MORL,\nwhere we wish to learn a preference-agnostic policy agent using only a finite\ndataset of offline demonstrations of other agents and their preferences. The\nkey contributions of this work are two-fold. First, we introduce D4MORL,\n(D)atasets for MORL that are specifically designed for offline settings. It\ncontains 1.8 million annotated demonstrations obtained by rolling out reference\npolicies that optimize for randomly sampled preferences on 6 MuJoCo\nenvironments with 2-3 objectives each. Second, we propose Pareto-Efficient\nDecision Agents (PEDA), a family of offline MORL algorithms that builds and\nextends Decision Transformers via a novel preference-and-return-conditioned\npolicy. Empirically, we show that PEDA closely approximates the behavioral\npolicy on the D4MORL benchmark and provides an excellent approximation of the\nPareto-front with appropriate conditioning, as measured by the hypervolume and\nsparsity metrics.\n",
        "title": "Scaling Pareto-Efficient Decision Making Via Offline Multi-Objective RL",
        "texts": [
            "Figure 1: Illustration of the Hypervolume and Sparsity Metrics. Only undominated solutions (i.e., the Pareto set) are used for calculating the evaluation metrics.",
            "Figure 3: Illustration of the preference distributions for 3 objectives. Entropy is estimated on 50K preference samples using the Vasicek estimator in Scipy (Vasicek, 1976, Virtanen et al., 2020).",
            "Figure 4: We show that MODT(P) and MORVS(P) can be good approximator to the Pareto front. There are relatively more dominated points in MO-Hopper and MO-Walker2d colored in red.",
            "Figure 5: We show that MORVS(P) Model can follow the given target reward that is within the dataset’s minimum and maximum record. The plots are for all the two-objective environments. In addition, MO-Hopper and MO-Walker2d present to be the most challenging environments for PEDA variants, featuring more dominated solutions than other environments.",
            "Figure 6: RTG fitted through linear regression (lr) models stay closer to the dataset distribution. Furthermore, linear regression models can also efficiently generalize to unseen preferences during test time.",
            "Figure 7: Pareto Visualization for all PEDA variants and baselines on High-H datasets. Notice that MO-Hopper and MO-Walker2d are more challenging and have significantly more dominated points for all variants. In other environments, however, the PEDA variants produce better results while other baselines fail at higher chances. Since BC without preference is completely single objective, we don’t show the result here.",
            "Table 1: Hypervolume performance on High-H-Expert dataset. PEDA variants MODT(P) and MORVS(P) always approach the expert behavioral policy. (B: Behavioral policy)",
            "Table 2: Hypervolume performance on High-H-Amateur dataset. PEDA variants still approach or even exceed the behavioral policy even when a considerable portion of data is suboptimal. MODT(P) and MORVS(P) still present to be the strongest models and outperform other baselines. (B: Behavioral policy)",
            "Table 3: Sparsity (Ó) performance on High-H-Expert dataset. MODT(P) and MORVS(P) have a lower density. BC(P) also has a competitive sparsity in smaller environments such as Swimmer.",
            "Table 4: Sparsity (Ó) performance on High-H-Amateur dataset. We can see that all models still have a similar or stronger sparsity performance when trained on amateur datasets. Furthermore, MORVS(P) still presents the strongest performance. While BC(P) has strong performance in MOHopper-3obj and MO-Swimmer, it also fails to give a dense solution in other environments and has a higher standard error.",
            "Table 5: A comprehensive view of the dataset. All datasets have a 500 maximum step per trajectory, and 50K trajectories are collected under each setting. As indicated by average step per trajectory, we can see Amateur trajectories are always shorter or same as Expert, thus leading to a lower return.",
            "Table 6: We ablate how well PEDA variants perform and generalize under a different preference distribution in the MO-HalfCheetah environment. We can see that PEDA can still perform well when trained under the partially-clustered Med-H dataset. However, performance drops when it is trained under the entirely clustered Low-H dataset. (B: Behavioral Policy)",
            "Table 7: We ablate the importance of using multi-dimensional rtgs instead of a one-dimensional rtgs by taking the weighted sum of objectives on the MO-HalfCheetah environment. We see multiobjective rtgs provide a variance reduction for MORVS(P) and hypervolume performance improvement in other models. (B: Behavioral Policy)"
        ],
        "imgs": [
            "$2305.00567v1-Figure1-1.png",
            "$2305.00567v1-Figure3-1.png",
            "$2305.00567v1-Figure4-1.png",
            "$2305.00567v1-Figure5-1.png",
            "$2305.00567v1-Figure6-1.png",
            "$2305.00567v1-Figure7-1.png",
            "$2305.00567v1-Table1-1.png",
            "$2305.00567v1-Table2-1.png",
            "$2305.00567v1-Table3-1.png",
            "$2305.00567v1-Table4-1.png",
            "$2305.00567v1-Table5-1.png",
            "$2305.00567v1-Table6-1.png",
            "$2305.00567v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00572",
        "abstract": "  Adaptable, low-cost, coils designed by carefully selecting the arrangements\nand geometries of simple primitive units are used to generate magnetic fields\nfor diverse applications. These extend from magnetic resonance and fundamental\nphysics experiments to active shielding of quantum devices including\nmagnetometers, interferometers, clocks, and computers. However, finding optimal\narrangements and geometries of multiple primitive structures is time-intensive\nand it is challenging to account for additional constraints, e.g. optical\naccess, during the design process. Here, we demonstrate a general method to\nfind these optimal arrangements. We encode specific symmetries into sets of\nloops, saddles, and cylindrical ellipses and then solve exactly for the\nmagnetic field harmonics generated by each set. By combining these analytic\nsolutions using computer algebra, we can use numerical techniques to\nefficiently map the landscape of parameters and geometries which the coils must\nsatisfy. Sets of solutions may be found which generate desired target fields\naccurately while accounting for complexity and size restrictions. We\ndemonstrate this approach by employing simple configurations of loops, saddles,\nand cylindrical ellipses to design target linear field gradients and compare\ntheir performance with designs obtained using conventional methods. A case\nstudy is presented where three optimized arrangements of loops, designed to\ngenerate a uniform axial field, a linear axial field gradient, and a quadratic\naxial field gradient, respectively, are hand-wound around a low-cost,\n3D-printed coil former. These coils are used to null the background in a\ntypical laboratory environment, reducing the magnitude of the axial field along\nthe central half of the former's axis from $\\left(7.8\\pm0.3\\right)$ $\\mu$T\n(mean $\\pm$ st. dev.) to $\\left(0.11\\pm0.04\\right)$ $\\mu$T.\n",
        "title": "Designing optimal loop, saddle, and ellipse-based magnetic coils by\n  spherical harmonic mapping",
        "texts": [
            "Fig. 10: (a) Initial seeds (green scatter) for the FindRoot function in Mathematica in the search space of optimal normalized separations, χci, for i∈[1 : Nloops], to design the set of Nloops = 3 axially antisymmetric loop pairs presented Fig. 3b. (b) Contour of solutions in the search space of χci that null the field harmonics of undesired orders n = [4, 6] and degree m = 0. Coloring corresponds to the magnitude of the ratio of the weighted sum of the magnitudes of the target field harmonic generated by the set of loop pairs, F2,0, to that of the leading-order error field harmonic generated by the set of loop pairs, F8,0. The optimal solution (arrow) maximizes this ratio.",
            "Fig. 13: Schematics of Nloops axially symmetric loop pairs (red arrows indicate current flow direction) of radius ρc at axial positions z′ = ±dci for i ∈ [1 : Nloops]. (a) Nloops = 2 pairs of loops with dci = [0.4537, 0.9454]ρc and turn ratios 3 : 1 (black, blue, respectively, with higher turn ratios in bold lines) (b) Nloops = 2 pairs of loops with dci = [0.3775, 0.9020]ρc and turn ratios −1 : 2, labelled as (a).",
            "Fig. 14: Magnitude of the normalized axial magnetic field (color scales right), Bz = Bz/B0, where B0 is the magnetic field gradient strength specified in Table II, in the xz-plane generated by the coils in Fig. 13a and Fig. 13b, corresponding to (a) and (b), respectively, where the coils are of radius ρc. White contours enclose the regions where (a) Bz and (b) d2Bz/dz 2 deviate from perfect uniformity and curvature, respectively, by less than 1% and 10%, respectively (dot-dashed curves).",
            "Fig. 3: Schematics of Nloops axially antisymmetric loop pairs (red arrows indicate current flow direction) of radius ρc at axial positions z′ = ±dci for i ∈ [1 : Nloops]. (a) Nloops = 1 pair of loops with dc1 = (√ 3/2 ) ρc (black). (b) Nloops = 3 pairs of loops with dci = [0.5544, 0.6748, 0.8660]ρc and turn ratios 1 : −2 : 2 (black, blue, and brown, respectively, with higher turn ratios in bold lines).",
            "Fig. 4: Magnitude of the normalized axial magnetic field (color scales right), Bz = Bz/B0, where B0 is the magnetic field gradient strength specified in Table I, in the xz-plane generated by the coils in Fig. 3a and Fig. 3b, corresponding to (a) and (b), respectively, where the coils are of radius ρc. White contours enclose the regions where dBz/dz deviates from perfect linearity by less than 1% (dot-dashed curves).",
            "Fig. 5: Schematics of Narcs axially symmetric sets of arcs (red arrows indicate current flow direction) with one-fold azimuthal symmetry of radius ρc at axial positions z′ = ±dci for i ∈ [1 : Narcs] which are connected to make double saddles. (a) Narcs = 2 sets of arcs (black) which extend azimuthally over 2ϕc1 = 2π/3 and are at axial positions dci = [0.404, 2.56]ρc. The sets of arcs are connected in series to make double saddles. (b) Narcs = 4 sets of arcs, each of which contains two nested azimuthal extensions, 2ϕc1 = 7π/15 and 2ϕc2 = 13π/15, at axial positions dci = [0.2995, 0.4170, 0.6550, 2.5522]ρc, where the first and second (black) and the third and fourth (blue) sets of arcs are connected in series to make double saddles with the same turn ratios.",
            "Fig. 6: Magnitude of the normalized transverse magnetic field (color scales right), Bx = Bx/B0, where B0 is the magnetic field gradient strength specified in Table I, in the xz-plane generated by the coils in Fig. 5a and Fig. 5b, corresponding to (a) and (b), respectively, where the coils are of radius ρc. White contours enclose the regions where dBx/dz deviates from perfect linearity by less than 1% (dot-dashed curves).",
            "Fig. 7: Schematics of Nellipses axially symmetric sets of ellipses (red arrows indicate current flow direction) with one-fold azimuthal symmetry of radius ρc at axial positions z′ = ±dci for i ∈ [1 : Nellipses]. (a) Nellipses = 1 set of ellipses with dc1 = 1.25ρc and which extend by a maximum axial distance ec1 = ρc (black). (b) Nellipses = 2 sets of ellipses with dci = [0.6842, 0.7493]ρc which extend by maximum axial distances eci = [0.2842, 0.4036]ρc and have opposite current ratios, 1 : −1 (black and blue, respectively).",
            "Fig. 8: Magnitude of the normalized transverse magnetic field (color scales right), Bx = Bx/B0, where B0 is the magnetic field gradient strength specified in Table I, in the xz-plane generated by the coils in Fig. 7a and Fig. 7b, corresponding to (a) and (b), respectively, where the coils are of radius ρc. White contours enclose the regions where dBx/dz deviates from perfect linearity by less than 1% (dot-dashed curves).",
            "Fig. 9: The algorithm used to determine optimal sets of normalized coil separations, χc. The inputs are: a target field harmonic, Bn,m, of order n and degree m; turn ratios of primitive groups, Ii; and constraints on the values of χc. The weighted magnitudes of field harmonics, Fn,m, are used to search the parameter space for solutions on the contours where the set of leading-order harmonics are nulled. These solutions are ranked and the optimal solution is returned.",
            "TABLE I: Properties of the standard coils in Figs. 3a, 5a and 7a, designed using the methodology presented in Romeo and Hoult [35], and the optimized equivalents in Figs. 3b, 5b and 7b designed in this work for a coil radius of ρc = 10 cm. The following coil properties are listed: target field harmonic, Bn,m of order n and degree m; the maximum axial dimension, max (dimc), where dimc = dc in the loops and saddles cases, dimc = dc + ec in the ellipses case, dc is the separation of the coil units from the origin, and ec is the axial extent of the ellipses from their centre; the total length of wire in the coil, l, including repeated units with multiple turn ratios; the magnetic field gradient strength, B0, i.e. dBz/dz for B2,0 and dBx/dz for B2,1 along the z-axis at the centre of the coil, per unit current, I; the inductance, L; and the size of the central volume where the target field gradient is generated with less than 1% deviation from target relative to that generated by the standard coil, V1%. The inductance is approximated numerically from the total magnetic energy [48] using COMSOL Multiphysics®, assuming that the wire tracks are filamentary.",
            "TABLE II: Properties of the optimized coils in Fig. 13, here given for a coil radius of ρc = 10 cm and labelled as Table I. The magnetic field strength, B0, is the value of Bz for B1,0 and d2Bz/dz 2 for B3,0 and is evaluated at the centre of the coil per unit current, I ."
        ],
        "imgs": [
            "$2305.00572v2-Figure10-1.png",
            "$2305.00572v2-Figure13-1.png",
            "$2305.00572v2-Figure14-1.png",
            "$2305.00572v2-Figure3-1.png",
            "$2305.00572v2-Figure4-1.png",
            "$2305.00572v2-Figure5-1.png",
            "$2305.00572v2-Figure6-1.png",
            "$2305.00572v2-Figure7-1.png",
            "$2305.00572v2-Figure8-1.png",
            "$2305.00572v2-Figure9-1.png",
            "$2305.00572v2-TableI-1.png",
            "$2305.00572v2-TableII-1.png"
        ]
    },
    {
        "id": "2305.00575",
        "abstract": "  The Callan-Harvey mechanism in 2+1 D Jackiw-Rebbi model is revisited. We\nanalyzed Callan-Harvey anomaly inflow in the massive Chern insulator (quantum\nanomalous Hall system) subject to external electric field. In addition to the\nconventional current flowing from the bulk to edge due to parity anomaly, we\nconsidered the dissipation of the edge charge due to interaction with external\nbosonic bath in 2+1 D and due to external bath of photons in 3+1 D. In the case\nof 2+1 D bosonic bath, we found the new stationary state, which is defined by\nthe balance between Callan-Harvey current and the outgoing flow caused by the\ndissipation processes. In the case of 3+1 D photon bath, we found a critical\nelectric field, below which this balance state can be achieved, but above which\nthere is no such a balance. Furthermore, we estimated the photon-mediated\ntransition rate between 2+1 D bulk and 1+1 D topological edge state of the\norder of one ns$^{-1}$ (nanosecond) at the room temperature.\n",
        "title": "Dissipative Callan-Harvey mechanism in 2+1 D Dirac system: The fate of\n  edge states along a domain wall",
        "texts": [
            "FIG. 1: The setup of the system. As explained in the main text of Sec.1, the fermion mass changes sign at x = 0, and therefore the Chern number is 1/2 at the x > 0 region and −1/2 at the x < 0 region. In the presence of an uniform electric field in the y-direction (green arrows), the Hall currents (blue arrows) in the two regions flow in opposite directions. Therefore, there will be charge accumulation at the edge. The red arrows denote the edge current.",
            "FIG. 2: The energy spectra for electron systems and the edge-to-bulk transition processes. The blue and black lines describe the unoccupied and occupied states, respectively. Zigzag lines represent ingoing or outgoing photons. (a) A semi-infinite electron system with one edge or domain wall. There is only one chiral mode, whose occupied states are depicted by the straight blue line. The red arrow depicts the leading-order excitation process, which absorbs one photon. The green arrows are related to the second-order relaxation process, which includes an absorption of a low-energy photon (green zigzag line) and an emission of a high-energy photon (blue zigzag line). (b) The schematic diagram of transitions in a finite-sized system with two edges. The two straight blue lines represent the occupied edge states. The red and purple arrows denote the absorption and emission processes, while the red and purple zigzag lines denote the ingoing and outgoing photons, respectively.",
            "FIG. 3: (a)The black curve (marked by label 1) shows the momentum dependence of the excitation rate Γ1(ke)/e 2 of the edge state |ke >. It is computed according to Eq.24, with v/c = 0.01. The horizontal axis is ke/(m0v). The black curve (marked by label 2) is the the distribution function R(ke)/R(0) in the saturation state, i.e. Eq.26, with the electric field Ey = 2 × 10−5em0v related to the red dotted line in Fig.(b). (b) The saturation momentum K∗e obtained from Eq. 25 as a function of electric filed Ey, in the step-function approximation for the edge-state occupancy.",
            "FIG. 4: (a)The black curve (marked by label 1) is the excitation rate Γ1(ke), as a function of momentum ke, Eq.31. ns is nanosecond. The parameters are given as follows: the bulk gap ∆ = 2m0v 2 = 0.1eV, Fermi velocity v = 0.01c and the temperature kBT = ∆/4. The red curve (marked by label 2) is the the occupation function R(ke)/R(0) in the saturation state, with Ey = 0.75V/m. It is obtained from Eq.26, with the Γ1(ke) function given by Eq.31. (b) The saturation momentum K∗e in the step-function assumption for the edge occupation, v.s. electric filed Ey. One observes that there is a critical electric field, around 1.5V/m, above which the value of K∗e diverges."
        ],
        "imgs": [
            "$2305.00575v1-Figure1-1.png",
            "$2305.00575v1-Figure2-1.png",
            "$2305.00575v1-Figure3-1.png",
            "$2305.00575v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00579",
        "abstract": "  In this work, we consider the problem of autonomous racing with multiple\nagents where agents must interact closely and influence each other to compete.\nWe model interactions among agents through a game-theoretical framework and\npropose an efficient algorithm for tractably solving the resulting game in real\ntime. More specifically, we capture interactions among multiple agents through\na constrained dynamic game. We show that the resulting dynamic game is an\ninstance of a simple-to-analyze class of games. Namely, we show that our racing\ngame is an instance of a constrained dynamic potential game. An important and\nappealing property of dynamic potential games is that a generalized Nash\nequilibrium of the underlying game can be computed by solving a single\nconstrained optimal control problem instead of multiple coupled constrained\noptimal control problems. Leveraging this property, we show that the problem of\nautonomous racing is greatly simplified and develop RAPID (autonomous\nmulti-agent RAcing using constrained PotentIal Dynamic games), a racing\nalgorithm that can be solved tractably in real-time. Through simulation\nstudies, we demonstrate that our algorithm outperforms the state-of-the-art\napproach. We further show the real-time capabilities of our algorithm in\nhardware experiments.\n",
        "title": "RAPID: Autonomous Multi-Agent Racing using Constrained Potential Dynamic\n  Games",
        "texts": [
            "Fig. 1: Visualizations of two of the hardware experiments using two Crazyflies. As it can be seen in the left figure, even when the ego drone starts behind, it overtakes the opponent and ultimately blocks the opponent to avoid being overtaken. On the right, it can be seen that when the ego drone starts ahead of the opponent, it generates blocking behavior twice to avoid being overtaken. No collisions occurred in the hardware experiments and the ego-drone won the race in both instances.",
            "Fig. 2: Experiment snapshots of the race among three quadrotors. Green color is used to represent the ego quadrotor which uses our trajectory planner RAPID and exhibits an overtaking maneuver around the two quadrotors that use reactive MPC. The top row consists of top views that are plotted with the actual hardware experiment data. The second row shows the snapshots of the actual hardware experiment. For visualization purposes, the approximated boundaries of the track are marked by the white lines on the second row. We see that the ego (green) is trying to block the agent marked with the blue color. Videos can be found at: https://youtu.be/85PYCj6vUd4.",
            "Fig. 4: The ego (plotted with green color) pushes the baseline (plotted with blue color) against the boundary.",
            "TABLE I: Simulation Results for the Customized Track",
            "TABLE II: Mean Solve Time (in seconds) Comparisons for Different Numbers of Agents.",
            "TABLE III: Results for Two-agent Hardware Experiments. Our method was able to overtake 10 times out of the 10 trials when it started behind. And it was able to defend its leading position 8 times out of the 10 trials when it started ahead.",
            "TABLE IV: Results for Three-agents Hardware Experiments"
        ],
        "imgs": [
            "$2305.00579v1-Figure1-1.png",
            "$2305.00579v1-Figure2-1.png",
            "$2305.00579v1-Figure4-1.png",
            "$2305.00579v1-TableI-1.png",
            "$2305.00579v1-TableII-1.png",
            "$2305.00579v1-TableIII-1.png",
            "$2305.00579v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00581",
        "abstract": "  Despite the success of Transformer models in vision and language tasks, they\noften learn knowledge from enormous data implicitly and cannot utilize\nstructured input data directly. On the other hand, structured learning\napproaches such as graph neural networks (GNNs) that integrate prior\ninformation can barely compete with Transformer models. In this work, we aim to\nbenefit from both worlds and propose a novel Multimodal Graph Transformer for\nquestion answering tasks that requires performing reasoning across multiple\nmodalities. We introduce a graph-involved plug-and-play quasi-attention\nmechanism to incorporate multimodal graph information, acquired from text and\nvisual data, to the vanilla self-attention as effective prior. In particular,\nwe construct the text graph, dense region graph, and semantic graph to generate\nadjacency matrices, and then compose them with input vision and language\nfeatures to perform downstream reasoning. Such a way of regularizing\nself-attention with graph information significantly improves the inferring\nability and helps align features from different modalities. We validate the\neffectiveness of Multimodal Graph Transformer over its Transformer baselines on\nGQA, VQAv2, and MultiModalQA datasets.\n",
        "title": "Multimodal Graph Transformer for Multimodal Question Answering",
        "texts": [
            "Figure 1: Overview of Multimodal Graph Transformer. It takes visual features, text features, and their corresponding generated graphs as inputs. The generated graph is first converted to an adjacency matrix to induce the mask matrix G. The modified quasi-attention score in the Transformer is computed to infer the answer. In the formular, G is the graph-induced matrix constructed by concatenating adjacency matrices both from the vision and the language end. Ĝ is the trainable bias. The input features from different modalities are fused along with graph info to perform downstream reasoning.",
            "Figure 2: The figure illustrates the overall framework of our Multimodal Graph Transformer. The input from different modalities are processed and transformed into corresponding graphs, which are then converted into masks and combined with their features to be fed into Transformers for downstream reasoning. In detail, semantic graphs are created through scene graph generation methods, dense region graphs are extracted as densely connected graphs, and text graphs are generated through parsing.",
            "Figure 3: The naive demonstration of converting a semantic graph into an adjacency matrix. Cells in blue means ‘0’s for that element in the graph matrix, while white ones means ‘-inf’s. We employ the matrix as the mask when computing the quasi-attention.",
            "Figure 4: A naive demonstration of adding the graphinduced mask while computing the quasi-attention when the inputs are from two modalities. The visual mask is the mask converted from the dense region graph and the text mask is converted from the text graph. The cross-modal mask, which is always set as an all-zero matrix, is imposed to encourage the model to learn the cross-attention between the image features and text features, thus facilitating the alignment across them.",
            "Figure 6: Examples from the GQA dataset for visual reasoning and compositional question answering.",
            "Figure 7: Examples from the VQA v2 dataset for Visual Question Answering.",
            "Table 1: Accuracy (%) comparison of different methods on the VQA task. Ours has the second best performance and is comparable to state-of-the-art methods. After applying our proposed quasi-attention mechanism and exploiting the use of graphs, there is also a 2% improvement of overall accuracy on the LXMERT baseline, suggesting the generalization ability of our method.",
            "Table 2: EM (%) and F1 (%) of Multimodal Graph Transformer and its Transformer baseline on questions in MultiModalQA that require reasoning over multiple modalities. We also quote the results from the MultiModalQA (Talmor et al., 2021) paper. Incorporating graph information into the Multimodal Graph Transformer can boost about 2% F1 and 4% EM performance.",
            "Table 4: Comparison of VQA datasets"
        ],
        "imgs": [
            "$2305.00581v1-Figure1-1.png",
            "$2305.00581v1-Figure2-1.png",
            "$2305.00581v1-Figure3-1.png",
            "$2305.00581v1-Figure4-1.png",
            "$2305.00581v1-Figure6-1.png",
            "$2305.00581v1-Figure7-1.png",
            "$2305.00581v1-Table1-1.png",
            "$2305.00581v1-Table2-1.png",
            "$2305.00581v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00584",
        "abstract": "  RISC-V is an emerging technology, with applications ranging from embedded\ndevices to high-performance servers. Therefore, more and more security-critical\nworkloads will be conducted with code that is compiled for RISC-V. Well-known\nmicroarchitectural side-channel attacks against established platforms like x86\napply to RISC-V CPUs as well. As RISC-V does not mandate any hardware-based\nside-channel countermeasures, a piece of code compiled for a generic RISC-V CPU\nin a cloud server cannot make safe assumptions about the microarchitecture on\nwhich it is running. Existing tools for aiding software-level precautions by\nchecking side-channel vulnerabilities on source code or x86 binaries are not\ncompatible with RISC-V machine code.\n  In this work, we study the requirements and goals of architecture-specific\nleakage analysis for RISC-V and illustrate how to achieve these goals with the\nhelp of fast and precise dynamic binary analysis. We implement all necessary\nbuilding blocks for finding side-channel leakages on RISC-V, while relying on\nexisting mature solutions when possible. Our leakage analysis builds upon the\nmodular side-channel analysis framework Microwalk, that examines execution\ntraces for leakage through secret-dependent memory accesses or branches. To\nprovide suitable traces, we port the ARM dynamic binary instrumentation tool\nMAMBO to RISC-V. Our port named MAMBO-V can instrument arbitrary binaries which\nuse the 64-bit general purpose instruction set. We evaluate our toolchain on\nseveral cryptographic libraries with RISC-V support and identify multiple\nexploitable leakages.\n",
        "title": "MAMBO-V: Dynamic Side-Channel Leakage Analysis on RISC-V",
        "texts": [
            "Fig. 1: RISC–V side-channel analysis overview. MAMBO–V instruments a RISC–V library and generates execution traces, which are subsequently analyzed using Microwalk. The resulting analysis report then helps the developer to find and fix the identified leakages.",
            "Fig. 2: Exemplary instrumentation of a lock-acquire-loop: The instrumentation may insert unconstrained instructions (marked in blue) into the atomic sequence, e.g., add a function call with parameters to trace a conditional branch instruction. In order to set the argument registers, the original register contents have to be written to the stack using an unconstrained store instruction.",
            "Fig. 3: Microwalk pipeline with a new trace generation module based on MAMBO–V. Each trace generation module may emit either source-based or binary execution traces, which are then preprocessed into a common trace format that can be parsed by all analysis modules.",
            "Table 1: Result of leakage analysis of several cryptographic libraries on RISC– V. “Tr. CPU” shows the CPU time for generating the raw traces and “An. CPU” the CPU time for trace preprocessing and analysis. The columns “# Lkgs.” and “# Uniq.” show the total and unique number of detected leaking code lines. Target Type Tr. CPU An. CPU # Lkgs. # Uniq."
        ],
        "imgs": [
            "$2305.00584v2-Figure1-1.png",
            "$2305.00584v2-Figure2-1.png",
            "$2305.00584v2-Figure3-1.png",
            "$2305.00584v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00585",
        "abstract": "  During his state visit to China in April 2023, Brazilian President Lula\nproposed the creation of a trade currency supported by the BRICS countries.\nUsing the United Nations Comtrade database, providing the frame of the world\ntrade network associated to 194 UN countries during the decade 2010 - 2020, we\nstudy a mathematical model of influence battle of three currencies, namely, the\nUS dollar, the euro, and such a hypothetical BRICS currency. In this model, a\ncountry trade preference for one of the three currencies is determined by a\nmultiplicative factor based on trade flows between countries and their relative\nweights in the global international trade. The three currency seed groups are\nformed by 9 eurozone countries for the euro, 5 Anglo-Saxon countries for the US\ndollar and the 5 BRICS countries for the new proposed currency. The countries\nbelonging to these 3 currency seed groups trade only with their own associated\ncurrency whereas the other countries choose their preferred trade currency as a\nfunction of the trade relations with their commercial partners. The trade\ncurrency preferences of countries are determined on the basis of a Monte Carlo\nmodeling of Ising type interactions in magnetic spin systems commonly used to\nmodel opinion formation in social networks. We adapt here these models to the\nworld trade network analysis. The results obtained from our mathematical\nmodeling of the structure of the global trade network show that as early as\n2012 about 58 percent of countries would have preferred to trade with the BRICS\ncurrency, 23 percent with the euro and 19 percent with the US dollar. Our\nresults announce favorable prospects for a dominance of the BRICS currency in\ninternational trade, if only trade relations are taken into account, whereas\npolitical and other aspects are neglected.\n",
        "title": "Prospects of BRICS currency dominance in international trade",
        "texts": [
            "Figure 2 Distribution of the countries’ trade currency ternary scores (ZUSD, ZEUR, ZBRI) for 2010 (top panel) and 2019 (bottom panel). A country is represented by a circle. Colors are associated to TCPs, blue for USD, gold for EUR, and red for BRI. The ZUSD coordinate is read along the dashed blue horizontal lines, the ZEUR coordinate along the gold dashed oblique lines, and the ZBRI coordinate along the red dashed oblique lines."
        ],
        "imgs": [
            "$2305.00585v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00586",
        "abstract": "  Pre-trained language models can be surprisingly adept at tasks they were not\nexplicitly trained on, but how they implement these capabilities is poorly\nunderstood. In this paper, we investigate the basic mathematical abilities\noften acquired by pre-trained language models. Concretely, we use mechanistic\ninterpretability techniques to explain the (limited) mathematical abilities of\nGPT-2 small. As a case study, we examine its ability to take in sentences such\nas \"The war lasted from the year 1732 to the year 17\", and predict valid\ntwo-digit end years (years > 32). We first identify a circuit, a small subset\nof GPT-2 small's computational graph that computes this task's output. Then, we\nexplain the role of each circuit component, showing that GPT-2 small's final\nmulti-layer perceptrons boost the probability of end years greater than the\nstart year. Finally, we find related tasks that activate our circuit. Our\nresults suggest that GPT-2 small computes greater-than using a complex but\ngeneral mechanism that activates across diverse contexts.\n",
        "title": "How does GPT-2 compute greater-than?: Interpreting mathematical\n  abilities in a pre-trained language model",
        "texts": [
            "Figure 1: Year-span prediction example (XX=17 and YY=32) with sample (in)valid output years.",
            "Figure 11: Iterative path patching results through attention heads’ value vectors",
            "Figure 12: Iterative path patching results for MLPs 0-3",
            "Figure 13: (Left) Full circuit diagram. Note that grouped MLPs are interconnected; attention heads are not. (Right) Probability heatmap for the patched full circuit.",
            "Figure 16: Path Patching Step 3: MLP 10",
            "Figure 19: Neuron contributions for each MLP 10 neuron in the top 4-11. Neurons ordered by importance, left-to-right, top-to-bottom. Blue indicates that the neuron upweights a certain predicted year, given a starting year YY, while red indicates downweighting.",
            "Figure 2: Left: Probability heatmap of GPT-2 for year-span prediction. Y-axis: the sentence’s start year (YY). X-axis: the two-digit output year candidate. (X,Y): Mean probability assigned by GPT-2 to output year X given input year Y. Right: GPT-2’s average output distribution when YY=41",
            "Figure 20: Neuron contributions of the top-100 (left) and 200 (right) neurons in MLP 10. Blue indicates that the neuron upweights a certain predicted year, given a starting year YY, while red indicates downweighting.",
            "Figure 21: Direct effects of top-3 MLP 10 Neurons",
            "Figure 22: Summed and patched direct effects of top-10 MLP 10 Neurons",
            "Figure 23: Probability heatmaps for (left to right) “1799, 1753, 1733, 1701, 16YY, 16”, “1695, 1697, 1699, 1701, 1703, 17”, and “17YY is smaller than 17”.",
            "Figure 24: Probability heatmaps for (left to right) “The <noun> started in the year 17YY and ended in the year 17”, “The <noun> happened in 17YY. Some years later, it is now the year 17”, and “1599, 1607, 1633, 1679, 17YY, 17”.",
            "Figure 27: Probability heatmaps for “The <noun> ended in the year 17YY and started in the year 17” (left) and “The <noun> lasted from the year 7YY BC to the year 7” (right).",
            "Figure 3: A. The computational graph of GPT-2, run on our normal dataset. B: GPT-2, where the (MLP 10, logits) path is patched to receive 01-input. C. GPT-2, where the (Attn 10, MLP 10, logits) and (Attn 10, MLP 10, MLP 11, logits) paths receive 01-input. Nodes receiving normal input have blue output; nodes receiving 01-input have red output; nodes receiving both have purple output.",
            "Figure 4: Iterative path-patching (IPP) heatmaps. Y-axis: layer of the component. X-axis: attention head number, or MLP. (X,Y): Change in probability difference induced by patching the corresponding component. A: Heatmap for the path ((X,Y), logits). B: Heatmaps for MLPs 8-11.",
            "Figure 5: Left: Diagram of the year-span prediction circuit. Center: Diagram showing which GPT-2 components receive our standard dataset vs. our 01-dataset in the circuit evaluation experiment. Right: The probability heatmap (as in Figure 2) for the patched model.",
            "Figure 6: (Left) Attention patterns for attention heads a7.h11 and a8.h10. <bos> is GPT-2’s start of sentence token, <|endoftext|>. (Right) Logit lens of a7.h11 and a8.h10. Axes as in Figure 2; blue indicates that the module upweights the output year, and red, that it downweights the year.",
            "Figure 8: PCA of MLP 8’s input, a7.h10’s and a7.h8’s output, and the static year embeddings. Each point corresponds to one datapoint’s representation, and is labeled with and colored by the its YY.",
            "Figure 9: Left: The logit lens of the 3 MLP 10 neurons most important to year-span prediction. Right: The logit lens of the top-10 MLP 10 neurons. Blue indicates that the neuron upweights logits at the given input year (y-axis), output year (x-axis) combination, while red indicates downweighting."
        ],
        "imgs": [
            "$2305.00586v3-Figure1-1.png",
            "$2305.00586v3-Figure11-1.png",
            "$2305.00586v3-Figure12-1.png",
            "$2305.00586v3-Figure13-1.png",
            "$2305.00586v3-Figure16-1.png",
            "$2305.00586v3-Figure19-1.png",
            "$2305.00586v3-Figure2-1.png",
            "$2305.00586v3-Figure20-1.png",
            "$2305.00586v3-Figure21-1.png",
            "$2305.00586v3-Figure22-1.png",
            "$2305.00586v3-Figure23-1.png",
            "$2305.00586v3-Figure24-1.png",
            "$2305.00586v3-Figure27-1.png",
            "$2305.00586v3-Figure3-1.png",
            "$2305.00586v3-Figure4-1.png",
            "$2305.00586v3-Figure5-1.png",
            "$2305.00586v3-Figure6-1.png",
            "$2305.00586v3-Figure8-1.png",
            "$2305.00586v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00588",
        "abstract": "  We introduce finite mixtures of Ising models as a novel approach to study\nmultivariate patterns of associations of binary variables. Our proposed models\ncombine the strengths of Ising models and multivariate Bernoulli mixture\nmodels. We examine conditions required for the identifiability of Ising mixture\nmodels, and develop a Bayesian framework for fitting them. Through simulation\nexperiments and real data examples, we show that Ising mixture models lead to\nmeaningful results for sparse binary contingency tables.\n",
        "title": "Bayesian Finite Mixtures of Ising Models",
        "texts": [
            "Figure 1: A directed acyclic graph to illustrate the associations between parameters in our model specification.",
            "Figure 2: Significant pairwise associations determined by Whittaker (1990) (left panel) and the Bayesian Ising model we proposed (right panel). Each association is shown as an edge between vertices associated with variables it involves. The labels of the edges indicate the estimated posterior means of their indicators.",
            "Figure 3: Significant pairwise associations determined by the Bayesian Ising mixture model. The 28 associations in the first component are presented in the left panel, while the 22 associations in the right component are shown in the right panel. Each association is shown as an edge between vertices associated with variables it involves. The labels of the edges indicate the estimated posterior means of their indicators.",
            "Figure 4: Significant pairwise associations determined by the forward stepwise function based on BIC in the R package gRim (Højsgaard et al., 2012) (left panel) and the Bayesian Ising model (right panel) in the NLTCS data. Pairwise associations are shown as edges between vertices associated with variables they involve. The labels of the edges indicate the estimated posterior means of their indicators.",
            "Figure 5: Significant pairwise associations determined by the Bayesian Ising mixture model with two components in the NLTCS data. Each association is shown as an edge between vertices associated with variables it involves. There are 18 associations in the first component (shown in the left panel), and 19 associations in the second component (shown in the right panel). The labels of the edges indicate the estimated posterior means of their indicators.",
            "Table 1: Estimated posterior mean of γ in Ising models under Design A, B, and Setting 1 and 2. Under both designs, the importance sampling standard errors are approximately 0.0001 for Setting 1 and 0.1 for Setting 2.",
            "Table 2: Estimated posterior mean of γ in the Ising model and of γ(1),γ(2) in the Ising mixture model with two components under Design C and Design D.",
            "Table 3: Rochdale data from Whittaker (1990). The cells counts appear row by row in lexicographical order with the levels of variable 8 varying fastest and the levels of variable 1 varying slowest.",
            "Table 4: Expected cell counts for the top 10 largest counts cells for the Rochdale data (left panel) and the NLTCS data (right panel). Cells are identified through their sequence of level indicators with 0 as no and 1 as yes.",
            "Table 5: Estimated posterior means of the association indicators in the Ising model and the Ising mixture model with two components for the Rochdale data.",
            "Table 6: The NLTCS data. This 16 by 16 tables shows all the possible combination of the 8 binary variables. The cells counts appear row by row in lexicographical order with Variable 8 varying fastest and Variable 1 varying slowest.",
            "Table 7: The posterior means of γ(1) and γ(2) inferred by two-component Ising mixture models for the NLTCS data. The number of component in the normal mixture sampling distribution is J = 5. The posterior mean of the weight of the first component, i.e. E(w(1) | n), is 0.4.",
            "Table 8: Examples of Ising mixture models with singular information matrices."
        ],
        "imgs": [
            "$2305.00588v1-Figure1-1.png",
            "$2305.00588v1-Figure2-1.png",
            "$2305.00588v1-Figure3-1.png",
            "$2305.00588v1-Figure4-1.png",
            "$2305.00588v1-Figure5-1.png",
            "$2305.00588v1-Table1-1.png",
            "$2305.00588v1-Table2-1.png",
            "$2305.00588v1-Table3-1.png",
            "$2305.00588v1-Table4-1.png",
            "$2305.00588v1-Table5-1.png",
            "$2305.00588v1-Table6-1.png",
            "$2305.00588v1-Table7-1.png",
            "$2305.00588v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00590",
        "abstract": "  We investigate the spatial dynamics of two disease epidemics reaching a\nthree-species cyclic model. Regardless of their species, all individuals are\nsusceptible to being infected with two different pathogens, which spread\nthrough person-to-person contact. The occurrence of coinfection leads to a\nsynergistic increase in the risk of hosts dying due to complications from\neither disease. Our stochastic simulations show that departed areas inhabited\nby hosts of a single pathogen arise from random initial conditions. The\nsingle-disease spatial domains are bordered by interfaces of coinfected hosts\nwhose dynamics are curvature-driven. Our findings show that the coarsening\ndynamics of the interface network are controlled by the fluctuations of\ncoinfection waves invading the single-disease territories. As the coinfection\nmortality grows, the dynamics of the interface network attain the scaling\nregime. We discover that organisms' infection risk is maximised if the\ncoinfection increases the death due to disease in $30\\%$, and minimised as the\nnetwork dynamics reach the scaling regime, with species populations being\nmaximum. Our conclusions may help ecologists understand the dynamics of\nepidemics and their impact on the stability of ecosystems.\n",
        "title": "Spatial dynamics of synergistic coinfection in rock-paper-scissors\n  models",
        "texts": [
            "Figure 1: Snapshots of the rock-paper-scissors model with two disease epidemics. Figures 1a to 1e show the organism’s configuration at the initial conditions and after 600, 1200, 4000, and 9600 generations; pink, dark purple, and light purple dots show individuals of species 1, 2, and 3, respectively; green dots depict empty spaces. Red and dark blue dots in Figs. 1f to 1j show the respective spatial distribution of individuals infected with virus 1 and 2; yellow dots show the coinfected organisms while light blue dots are healthy individuals and empty spaces. Figures 1k to 1o highlight the interfaces of coinfected organisms in yellow, the spatial positions depicted in dark green are empty, occupied by single-disease or healthy individuals.",
            "Figure 2: Dynamics of species densities in the simulation shown in Fig. 1. The green line shows how the species density of individuals of species 1 varies with time, irrespective of being healthy or sick. The red, dark blue, and yellow lines depict the temporal dependence of the density of organisms of species 1 infected with virus 1, virus 2 and coinfected, respectively.",
            "Figure 3: Snapshots of simulations of a single interface of coinfected individuals for various coinfection mortality catalyst factors. Figures 3a, 3f, and 3k shows the initial prepared organisms’ organisation, spatial disease distribution and absence of coinfected; the colours follow the same scheme in Fig. 1. The spatial configuration after 800 generations appears in Figs. 3b, 3g and 3l for γ = 1.25; the results for γ = 1.5 are shown in Figs. 3c, 3h and 3m. For higher κ, the interface fluctuations reduces, as shown in Figs. 3d, 3i and 3n for γ = 1.75, and Figs. 3e, 3j and 3o for γ = 2.0.",
            "Figure 4: Scaling exponent in terms of the coinfection catalysed mortality. The orange dots show the λ computed using the function I? ∝ tλ, where I? is the number of coinfected individuals. The outcomes were averaged from 100 simulations running in lattices with 3002 grid sites for a timespan of 10000 generations; the error bars indicate the standard deviation. The dashed purple line shows the best fit of the numerical results.",
            "Figure 5: Organisms’ infection risk as a function of the coinfection mortality catalysed factor. The results were averaged from sets of 100 simulations running in lattices with 5002 grid sites, running until t = 5000 generations. The error bars show the standard deviation.",
            "Figure 6: Density of individuals of a single species in terms of the coinfection mortality catalysed factor. The outcomes were obtained by averaging the data from sets of 100 simulations running in lattices with 5002 grid sites, running until t = 5000 generations; the error bars show the standard deviation."
        ],
        "imgs": [
            "$2305.00590v1-Figure1-1.png",
            "$2305.00590v1-Figure2-1.png",
            "$2305.00590v1-Figure3-1.png",
            "$2305.00590v1-Figure4-1.png",
            "$2305.00590v1-Figure5-1.png",
            "$2305.00590v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00597",
        "abstract": "  The ability to automatically learn movements and behaviors of increasing\ncomplexity is a long-term goal in autonomous systems. Indeed, this is a very\ncomplex problem that involves understanding how knowledge is acquired and\nreused by humans as well as proposing mechanisms that allow artificial agents\nto reuse previous knowledge. Inspired by Jean Piaget's theory's first three\nsensorimotor substages, this work presents a cognitive agent based on CONAIM\n(Conscious Attention-Based Integrated Model) that can learn procedures\nincrementally. Throughout the paper, we show the cognitive functions required\nin each substage and how adding new functions helps address tasks previously\nunsolved by the agent. Experiments were conducted with a humanoid robot in a\nsimulated environment modeled with the Cognitive Systems Toolkit (CST)\nperforming an object tracking task. The system is modeled using a single\nprocedural learning mechanism based on Reinforcement Learning. The increasing\nagent's cognitive complexity is managed by adding new terms to the reward\nfunction for each learning phase. Results show that this approach is capable of\nsolving complex tasks incrementally.\n",
        "title": "Incremental procedural and sensorimotor learning in cognitive humanoid\n  robots",
        "texts": [
            "Fig. 1. Simulation environment. From Left to Right. a) Marta robot equipped with an RGB-D camera; b) Environment with distributed colored blocks and a Pioneer P3DX robot acting as a distractor. Marta’s view of the scene is shown at left. (c) Agent’s degrees of freedom. Motors used in red. (d) Division of the agent’s visual space for the virtual actuator (named as ”eye”, ”look” or ”fovea”).",
            "Fig. 10. 1st Substage. Sensory data obtained in validation Experiment B. Left to right: (a) Overview of the scene in the simulator CoppeliaSim (t = 40s); (b) Marta’s camera view (t = 40s); (c) Salience Map (t = 43s); (d) Winner of the attentional cycle (t = 43s); (e) Agents and objects’ positions in scene.",
            "Fig. 11. 2nd Substage. Sensory data obtained in the 1st episode of Procedural Learning. Left to right. (a) Overview of the scene in the simulator CoppeliaSim (t = 1s); (b) Marta’s camera view (t = 1s); (c) Salience Map (t = 3s); (d) Winner of the attentional cycle (t = 3s); (e) Agents and objects’ positions in scene.",
            "Fig. 12. 2nd Substage. Sensory data obtained in Experiment A. Left to right. (a) Overview of the scene in the simulator CoppeliaSim (t = 1s); (b) Marta’s camera view (t = 1s); (c) Salience Map (t = 3s); (d) Winner of attentional cycle (t = 3s); (e) Agents and objects’ positions in scene.",
            "Fig. 13. 3rd Substage. Sensory data obtained in the 1st episode of Procedural Learning. Left to right. (a) Overview of the scene in the simulator CoppeliaSim (t = 1s); (b) Marta’s camera view (t = 1s); (c) Salience Map (t = 3s); (d) Winner of attentional cycle (t = 3s); (e) Agents and objects’ positions in scene.",
            "Fig. 14. 3rd Substage. Sensory data obtained in validation experiment A. Left to right. (a) Overview of the scene in the simulator CoppeliaSim (t = 1s); (b) Marta’s camera view (t = 1s); (c) Salience Map (t = 3s); (d) Winner of the attentional cycle (t = 3s); (e) Agents and objects’ positions in scene.",
            "Fig. 2. Schematic model of the cognitive-attentive system adopted. a) Full view; b) Details of the Cognitive System in 1st Substage, with some of the modules (MO,VO,MV,G, t, top-down) disabled (painted in grey); c) Details of the Cognitive System in 2nd Substage and 3rd Substage.",
            "Fig. 3. Implementation scheme of the CONAIM+CST architecture with the robot Marta that receives attentional stimuli bottom-up and top-down.",
            "Fig. 4. Possible actions for the cognitive robot in experiments for 1st Substage, 2nd Substage and 3rd Substage. Motor actions (Am): 1. No-action; 2-5. Move neck pitch/yaw actuators with low discretization or Move neck pitch/yaw actuators with high discretization; Virtual actions (Av): 8-10. Move virtual actuators (eyes) to particular image zones; Attentional actions (Aa): 11-14. Move neck pitch/yaw actuators towards the attentional stimulus; Top-down Attentional Actions: 15. Emphasize stimuli of a particular color; 16. Emphasize stimuli at a particular distance; 17. Emphasize stimuli in a particular region of the space.",
            "Fig. 5. Reinforcement for the cognitive robot depends on the current state (si) and previous action. Reinforcement for motor actions (Rma): The system is positively reinforced if the direction the robot’s head moved matches the emergence of a visual stimulus; The system receives no reinforcement if there is no such space-time synchronicity; The system is strongly negatively reinforced if the robot loses its balance; Reinforcement for virtual actions (Rva): The system is positively reinforced if the direction in which the virtual actuator (eye) moved matches the emergence of a visual stimulus; The system receives no reinforcement if there is no such spatial-temporal synchronicity.",
            "Fig. 6. System dynamics in 1st Substage. t1: The robot sensors sample the environment; t2: The attentional system generates the saliency map (L1); t3: The working memory (MW) identifies this new state of the world (S1) based on (L1). The recall function (RP) is called to look for for any procedure in MP that could be applicable to the current state S1; t4: Such procedure is not found in MP; t5: The decision maker (D) informs that the robot do not know what to do in the current state; t6: The decision maker (D) decides to start a new QTable associated to this state (S1) in MP; t7: The new QTable is created with random values, enabling the cognitive robot to learn more about this state; t8: The recall function RP returns the possible actions associated to this state and their Q values; t9: current state S1 and possible actions are sent to the decision maker (D); t10: The decision maker (D) chooses the next action between a random action and the best action for the current state (Qmax) according to an ε-greedy policy. In this example, the action to move the robot’s head to the right (A2) was selected; t11: A new salience map (L2) is generated by the attentional system; t12: The working memory (MW) identifies the new state (S2) based on (L2); t13: The decision maker (D) evaluates the current state (S2) and the previous action performed (A2). Since there is a synchronicity between the robot’s head-resulting position and the external stimulus, a positive reinforcement RS1A2 increases the Q value for the action A2 in the state S1; t14: The Q value is sent to the QTable; t15: The QTable is updated; t16: A new recall RL looks for the possible actions for the current state S2; t17: The possible actions are found in MP; t18: The decision maker (D) is informed about the current state S2 and the possible actions; t19: The decision maker (D) decides by the action A4 (move the head bellow).",
            "Fig. 7. Top: Resulting reward (left) per episode and number of actions (right) for each learning experiment for all substages when incremental learning is in course. Bottom: Resulting reward (left) per episode and number of actions (right) for each learning experiment for all substages with no incremental learning.",
            "Fig. 8. 1st Substage. Sensory data obtained in the 1st episode of Procedural Learning. Left to Right: (a) Overview of the scene in CoppeliaSim (t = 1s); (b) Marta’s camera view (t = 1s); (c) Salience Map (t = 3s); (d) Winner of the attentional cycle (t = 3s); (e) Agents and objects’ positions in scene.",
            "Fig. 9. 1st Substage. Sensory data obtained in validation Experiment A. Left to right: (a) Overview of the scene in CoppeliaSim (t = 40s); (b) Marta’s camera view (t = 40s); (c) Salience Map (t = 43s); (d) Winner of the attentional cycle (t = 43s); (e) Agents and objects’ positions in scene.",
            "TABLE I SUBSET OF EXPERIMENTS AND EXPECTED RESULTS FOR A COGNITIVE ROBOT SENSORIMOTOR LEARNING IN A VISUAL OBJECT TRACKING TASK. ADAPTED FROM [6].",
            "TABLE II OVERVIEW OF THE APPROACH: SCHEMAS, VISION RESOLUTION, ACTIONS AND RESOLUTIONS, COGNITIVE SYSTEM AND REWARD STRATEGY ADOPTED IN EACH SUBSTAGE IN THE EXPERIMENTS.",
            "TABLE III DETAILS OF THE EXPERIMENTS: SUBSTAGES, VISION RESOLUTION, MEMORIES, ACTIONS, COGNITIVE FUNCTIONS AND REWARD STRATEGY."
        ],
        "imgs": [
            "$2305.00597v1-Figure1-1.png",
            "$2305.00597v1-Figure10-1.png",
            "$2305.00597v1-Figure11-1.png",
            "$2305.00597v1-Figure12-1.png",
            "$2305.00597v1-Figure13-1.png",
            "$2305.00597v1-Figure14-1.png",
            "$2305.00597v1-Figure2-1.png",
            "$2305.00597v1-Figure3-1.png",
            "$2305.00597v1-Figure4-1.png",
            "$2305.00597v1-Figure5-1.png",
            "$2305.00597v1-Figure6-1.png",
            "$2305.00597v1-Figure7-1.png",
            "$2305.00597v1-Figure8-1.png",
            "$2305.00597v1-Figure9-1.png",
            "$2305.00597v1-TableI-1.png",
            "$2305.00597v1-TableII-1.png",
            "$2305.00597v1-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00599",
        "abstract": "  We propose a discrete latent distribution for Generative Adversarial Networks\n(GANs). Instead of drawing latent vectors from a continuous prior, we sample\nfrom a finite set of learnable latents. However, a direct parametrization of\nsuch a distribution leads to an intractable linear increase in memory in order\nto ensure sufficient sample diversity. We address this key issue by taking\ninspiration from the encoding of information in biological organisms. Instead\nof learning a separate latent vector for each sample, we split the latent space\ninto a set of genes. For each gene, we train a small bank of gene variants.\nThus, by independently sampling a variant for each gene and combining them into\nthe final latent vector, our approach can represent a vast number of unique\nlatent samples from a compact set of learnable parameters. Interestingly, our\ngene-inspired latent encoding allows for new and intuitive approaches to\nlatent-space exploration, enabling conditional sampling from our\nunconditionally trained model. Moreover, our approach preserves\nstate-of-the-art photo-realism while achieving better disentanglement than the\nwidely-used StyleMapping network.\n",
        "title": "StyleGenes: Discrete and Efficient Latent Distributions for GANs",
        "texts": [
            "Figure 1: We propose StyleGenes: a biologically inspired discrete latent distribution for GANs. Our Genome (a) is an ordered set of smaller codebooks, we call genes. Each gene contains a collection of embeddings, its variants. For each gene, we select a variant and concatenate them to produce our latent code. We train for and perform unconditional image synthesis (b) by randomly sampling a variant for each gene. Analyzing our discrete Genome let us associate genes with specific attributes. We leverage this information to conditionally generate from our unconditionally trained model, without retraining or training any additional modules (c). Although our latent distribution is discrete, the learned style space offers emergent continuous properties, ensuring smooth interpolation between samples (d).",
            "Figure 10: Unconditional generation on Metfaces. All images were produced by gene sequences selected at random and without cherry-picking.",
            "Figure 11: Image Inversion with latent code optimization. While projecting specific faces to our discrete latent space cannot guarantee good results. Optimizing in our underlying continuous space is able to produce projection samples of high quality and fidelity. In the three last columns we find the closest variants of each gene to the real projected vector, using different distance functions: Manhattan distance, Euclidean distance and Cosine Similarity. We use this us an intermediate step for our genome inversion, explained in the experiments section of the main paper.",
            "Figure 12: The code for StyleGenes. For StyleGAN-based architectures we use our Genome to substitute the StyleMapping Network. For the FastGAN generator we use it in the stead of the gaussian sampling",
            "Figure 13: Attributes’ absolute standard scores. We are presenting a clearer version of Figure 2 of the main paper. One can easily see that for most attributes only specific genes produce high variability. These are the genes we sample more frequently in our conditional generation approach. Most genes are only utilized for small changes in the images on their own, but combining them can create diverse outputs. Please zoom for a more detailed view.",
            "Figure 14: Attribute Correlation. One motivation behind the design of the mapping network is to forbid the sampling of invalid combinations, that are not present in the original dataset. By using pretrained classifiers, we show that the correlation between the certain attributes is similar between real FFHQ images and those produced by both the mapping network and our discrete sampling method.",
            "Figure 2: Which genes affect which attribute? The polar plot shows which genes affect which CelebA attributes the most. Each color represents a different attribute. The labels indicate the gene that exhibits the highest variability in this attribute. Most attributes are affected only by a handful of genes. We observe that specific genes affect pertinent attributes. For instance, genes 66 and 38 affect gender and hair color, while gene 85 the mouth-related features. We show how randomly changing a specific gene’s variants produces different alterations to the images on the right. Changing the variants of genes 0 and 14, which do not exhibit importance for any attribute, leads to minute changes. Most genes fall into this category.",
            "Figure 3: Interpolation and Inversion. Our latents are trained in a discrete fashion, but have real values. Thus, it is possible to interpolate between them. Our network can generate realistic results from codes outside of the genome’s values. Inspired by this feature, we extend PTI [35] to add real images in our genome.",
            "Figure 4: We can observe how the density of the discrete latent distribution is changing through training. The variants’ values are learned through the adversarial game to produce images, along with the synthesis network. that match the real distribution.",
            "Figure 5: Unconditional Generation on FFHQ 1024 × 1024 [19] using StyleGenes along with a StyleGan2 synthesis network. All images were produced by gene sequences selected at random and without cherry-picking.",
            "Figure 6: Unconditional Generation on Metfaces [17] using StyleGenes along with a StyleGan3 synthesis network. All images were produced by gene sequences selected at random and without cherry-picking.",
            "Figure 7: 3D-aware Generation on Cats [17] using StyleGenes along with a EG3D [5] synthesis network. All images were produced by gene sequences selected at random and without cherry-picking.",
            "Figure 8: Unconditional generation on FFHQ. All images were produced by gene sequences selected at random and without cherry-picking.",
            "Figure 9: Unconditional generation on AFHQv2. All images were produced by gene sequences selected at random and without cherry-picking.",
            "Table 1: A: Evaluation of our discrete sampling approach, StyleGenes, by substituting the StyleGAN2’s StyleMapping network or FastGAN’s Gaussian sampling for ProjectedGAN. We achieve similar or better FID to the continuous case. B: Ablation on different configurations of the genome and our baseline. Increasing the number of the embeddings in our codebook, the # Variants, increases the performance by increasing the number of parameters we are using. We can also lower the FID by breaking the latent code into more genes of smaller lengths. This increases the number of unique codes we can sample from our genome without increasing the memory/parameters.",
            "Table 2: We measure disentanglement by our ability to predict an attribute’s presence in a generated image from its latent code. StyleGenes’ codes are much easier to associate to attributes than the StyleMapping’s ones.",
            "Table 3: VQ-methods are quantized and not self-learned (different losses, encoder). They learn local descriptors spatially aligned in a grid and require multiple different codes for semantically rich and diverse images. Contrary, we use a single global code, avoiding a parameter explosion with our Genome. We don’t require an autoregressive sampler (e.g. transformer), and thus are faster.",
            "Table 4: Conditional Generation We train our method unconditionally, by sampling uniformly the variants for each gene position. With our analysis we can conditionally sample the variants to generate a desired attribute, without retraining our unconditional model. We can control a FID-accuracy trade-off using the temperature. Lower values decrease variability but increase accuracy. In contrast to our method, the conditional StyleGAN baseline is limited to the attributes it was trained with. For inference they need to provide values for every attribute, and thus, to generate an image with a specific attribute, we sample the rest randomly or use the real dataset’s conditional frequencies.",
            "Table 5: Using our discriminator as a heuristic, we compute the expected value of realness for each variant. We use these values to substitute the most fake variants with duplicates of the most real ones. The number on the top of each columns shows how many variants are pruned. Our pruning approach can decrease the FID. Pruning too much, however, decreases the size of the genome and can increase the score. We report the FID computed with 50k images, averaged over five runs."
        ],
        "imgs": [
            "$2305.00599v1-Figure1-1.png",
            "$2305.00599v1-Figure10-1.png",
            "$2305.00599v1-Figure11-1.png",
            "$2305.00599v1-Figure12-1.png",
            "$2305.00599v1-Figure13-1.png",
            "$2305.00599v1-Figure14-1.png",
            "$2305.00599v1-Figure2-1.png",
            "$2305.00599v1-Figure3-1.png",
            "$2305.00599v1-Figure4-1.png",
            "$2305.00599v1-Figure5-1.png",
            "$2305.00599v1-Figure6-1.png",
            "$2305.00599v1-Figure7-1.png",
            "$2305.00599v1-Figure8-1.png",
            "$2305.00599v1-Figure9-1.png",
            "$2305.00599v1-Table1-1.png",
            "$2305.00599v1-Table2-1.png",
            "$2305.00599v1-Table3-1.png",
            "$2305.00599v1-Table4-1.png",
            "$2305.00599v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00602",
        "abstract": "  We use the SIMBA galaxy formation simulation suite to explore anisotropies in\nthe properties of circumgalactic gas that result from accretion and feedback\nprocesses. We particularly focus on the impact of bipolar active galactic\nnuclei (AGN) jet feedback as implemented in SIMBA, which quenches galaxies and\nhas a dramatic effect on large-scale gas properties. We show that jet feedback\nat low redshifts is most common in the stellar mass range $(1-5)\\times\n10^{10}M_\\odot$, so we focus on galaxies with active jets in this mass range.\nIn comparison to runs without jet feedback, jets cause lower densities and\nhigher temperatures along the galaxy minor axis (SIMBA jet direction) at radii\n>=$0.5r_{200c}-4r_{200c}$ and beyond. This effect is less apparent at higher or\nlower stellar masses, and is strongest within green valley galaxies. The\nmetallicity also shows strong anisotropy out to large scales, driven by star\nformation feedback. We find substantially stronger anisotropy at\n<=$0.5r_{200c}$, but this also exists in runs with no explicit feedback,\nsuggesting that it is due to anisotropic accretion. Finally, we explore\nanisotropy in the bulk radial motion of the gas, finding that both star\nformation and AGN wind feedback contribute to pushing the gas outwards along\nthe minor axis at <=1 Mpc, but AGN jet feedback further causes bulk outflow\nalong the minor axis out to several Mpc, which drives quenching via gas\nstarvation. These results provide observational signatures for the operation of\nAGN feedback in galaxy quenching.\n",
        "title": "Feedback-driven anisotropy in the circumgalactic medium for quenching\n  galaxies in the SIMBA simulations",
        "texts": [
            "Figure 1. Star formation rate vs stellar mass relation for all central galaxies (the main sample) in the Simba-100 run at 𝑧 = 1.0 (top), 0.5 (middle) and 0.0 (bottom). The colourbar shows the jet-active ratio at different redshifts (as defined in §2.3). Contours present the number distribution of main sample galaxies with 𝑀∗ ⩾ 109.9. This lower 𝑀∗ cut is empirically chosen so that the contours overlap with the colourmap. Regions of star forming (SF), green valley (GV) and quenched (Q) galaxies are demarcated by the white dashed lines, which are the selection criteria adopted by Belfiore et al. (2018) (see text for details). Vertical dashed lines divide the galaxies into three stellar mass bins that will be considered in further analysis below. It is noticeable that at all redshifts, ‘jet-active’ galaxies are the most populous within the GV region between 𝑀∗ = 1010𝑀⊙ and 5 × 1010𝑀⊙ .",
            "Figure 10. Gas total mass-weighted radial velocity as a function of galactocentric distance in 3D, using different types of ‘jet-active’ central galaxies at 𝑧 = 0.0 within 𝑀∗ = (1 − 5) × 1010𝑀⊙ (left) and 𝑀∗ = 5 − 10 × 1010𝑀⊙ (right). Measurements are performed within the same cone regions as those for Figure 9. Shaded regions represent the bootstrap error. Galaxy types are distinguished by colours, using the same colour scheme as in Figure 3. In both panels, the ratio of quantities along the minor and major axes is shown as an inset in order to highlight the differences.",
            "Figure 11. Redshift evolution of feedback activity. Progenitors are traced back to 𝑧 = 1.0 for 𝑀∗ = (1 − 5) × 1010𝑀⊙ quenched galaxies at 𝑧 = 0.0, where progenitors are defined as having the most stellar particles in common. A one-to-one matching is performed within the same stellar mass range with accretion rate > 0 across snapshots. Top: the histogram of star formation rate evolved with redshifts and the redshift evolution of 𝑇mw, Σgas quadrupole curves as a function of galactocentric distance. Only results from 𝑧 = 0.0 (red solid), 0.5 (green solid) and 1.0 (blue solid) are shown here for illustration. An inset within each panel zooms into the central region with 𝑟 ≲ 0.5𝑟200𝑐 . Bottom: The edge-on 𝑇mw stacked maps at different redshifts for visual inspection. It is clear that the progenitors of quenched galaxies undergo stronger AGN feedback at earlier times.",
            "Figure 12. The edge-on 𝑇mw stacked maps for 𝑧 = 1.0 progenitors without kinetic-jet mode. It is clear that the star formation and radiative feedback alone are not strong enough to expel gas out to large distances.",
            "Figure 2. Anisotropy of the CGM properties for ‘jet-active’ central galaxies at 𝑧 = 0.0 (edge-on view). Galaxies are selected from the Simba-50-‘allphys’ model with stellar mass between 1× 1010 𝑀⊙ and 5× 1010 𝑀⊙ . There are 377 galaxies in total and the averaged host halo mass is ⟨log10 (𝑀200𝑐 ) ⟩ = 12.04. Top row: mass-weighted temperature map (𝑇mw, left) and gas column density map (Σgas, right). Bottom row: thermal SZ 𝑦 map (SZ−𝑦, left) and dark matter column density map (Σdm, right). Maps are are normalised with respect to the azimuthal average. Minor axes of galaxies are aligned along the inner disk momentum directions (jet directions in this case), as well as all particles within a cubic region of ±4𝑟200𝑐 . Note that the topmost and leftmost coordinates are in units of cMpc for comparison. On each panel, the small window in the upper right corner zooms into the central square region with size 𝑟200𝑐 .",
            "Figure 3. Comparison of mass-weighted gas temperature (𝑇mw), gas column density (Σgas), mass-weighted gas metallicity (𝑍mw) and thermal SZ−𝑦 (𝑦) quadrupole curves for different galaxy types (SF: blue, GV: green, Q: red), as a function of projected galactocentric distance. This aims to characterise the angular dependence of the CGM properties. Results are obtained for Simba-100 ‘jet-active’ central galaxies at 𝑧 = 0.0 within a low stellar mass bin (𝑀∗ = (1 − 5) × 1010𝑀⊙ , solid lines) and intermediate mass bin (𝑀∗ = 5 − 10 × 1010𝑀⊙ , dotted lines). For comparison, results for all SF central galaxies with accretion rate > 0.0 within the lowest stellar mass bin are shown as cyan solid lines. Shaded regions show the bootstrap errors. For clarity, we omit the error regions around the curves obtained from the intermediate mass bin. In the top row, an inset within each panel zooms into the central region with 𝑟 ≲ 0.5𝑟200𝑐 .",
            "Figure 4. Upper row: mass-weighted temperature (𝑇mw), gas column density (Σgas),and metallicity (𝑍mw) quadrupole curves as a function of galactocentric distance for the Simba-100 ‘jet-active’ galaxies at 𝑧 = 0.0. This compares the results obtained from the edge-on projected maps within four stellar mass bins. Shaded regions show the bootstrap errors. In each panel, an inset zooms into the central region with 𝑟 ≲ 0.5𝑟200𝑐 .Lower row: quadrupole values for different CGM properties evaluated at various galactocentric distances. The symbols represent the galaxy-population stacked average within a given mass bin and the shaded regions show the bootstrap errors. Only the quadrupoles measured from the edge-on view are shown here for illustration. Halo masses and stellar masses are both labelled on the same plot for comparison. For Simba galaxies, the CGM presents the most significant anisotropic features at log10 (𝑀∗/𝑀⊙ ) ∼ 10.5 − 11.0 or log10 (𝑀200𝑐/𝑀⊙ ) ∼ 12.2 − 12.5.",
            "Figure 5. The same as Figure 2 but here showing Simba-50-‘nojet’ (top row) and Simba-50-‘nofb’ (bottom row) model results for comparison. Host haloes across models are matched by their halo masses. The averaged halo mass is ⟨log10 (𝑀200𝑐 ) ⟩ = 11.95 for the Simba-50-‘nojet’ model and 11.90 for the Simba-50-‘nofb’ model.",
            "Figure 6. Quadrupole of mass-weighted temperature (𝑇mw, top left), gas column density map (Σgas, top right), the thermal SZ map (𝑦, bottom left) and the dark matter column density map (ΣDM, bottom right), measured across Simba-50 model variants as a function of projected galactocentric distance. Results measured from both edge-on (solid lines) and face-on (dotted lines) projections are presented here. Shaded regions show the bootstrap errors. In the top row, an inset within each panel zooms into the central region with 𝑟 ≲ 0.5𝑟200𝑐 .",
            "Figure 7. Anisotropy of the mass-weighted metallicity (𝑍mw) for ‘jet-active’ central galaxies at 𝑧 = 0.0 in different Simba-50 models (𝑀∗ = 1 − 5 × 1010 𝑀⊙). Only the edge-on projection is shown. Maps are normalised with respect to the azimuthal average. Galaxies as well as their surrounding particle fields are rotated and stacked with the same approach as in Figure 2. On each panel, the small window in the upper right corner zooms in to the central square region with a size of 𝑟200𝑐 .",
            "Figure 8. 𝑍mw quadrupole measurement as a function of galactocentric distance in different Simba models. For clarity, only results from the edgeon projection are shown. Shaded regions show the bootstrap errors. An inset panel zooms into the central region with 𝑟 ≲ 0.5𝑟200𝑐 .",
            "Figure 9. Total mass-weighted radial velocity for gas component (left) and dark matter component (middle) as a function of galactocentric distance in 3D, using ‘jet-active’ central galaxies with 𝑀∗ = (1 − 5) × 1010𝑀⊙ at 𝑧 = 0.0. Measurements are performed within a 3D cone with an opening angle of ±45◦ around the axis. Dashed lines show the results from the cone aligned with minor axis, while the solid lines show the average curves from cones along the 𝑋-axis and the 𝑌 -axis on the galaxy major plane. In the left panel, the ratio of quantities along the minor and major axes is shown as an inset in order to highlight the differences. Shaded regions represent the bootstrap errors. Models are distinguished by colours with the same colour scheme as in Figure 7. Black dotted line: Hubble flow for comparison. To highlight the effective region of each AGN variants, the ratios between the gas and dark matter curves of each model are given in the rightmost panel for comparison.",
            "Table 1. Feedback descriptions for different Simba-50 runs. Note that the Simba-100 fiducial run employs the same ‘allphs’ model as the Simba-50 run."
        ],
        "imgs": [
            "$2305.00602v2-Figure1-1.png",
            "$2305.00602v2-Figure10-1.png",
            "$2305.00602v2-Figure11-1.png",
            "$2305.00602v2-Figure12-1.png",
            "$2305.00602v2-Figure2-1.png",
            "$2305.00602v2-Figure3-1.png",
            "$2305.00602v2-Figure4-1.png",
            "$2305.00602v2-Figure5-1.png",
            "$2305.00602v2-Figure6-1.png",
            "$2305.00602v2-Figure7-1.png",
            "$2305.00602v2-Figure8-1.png",
            "$2305.00602v2-Figure9-1.png",
            "$2305.00602v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00604",
        "abstract": "  We present ISAAC (Input-baSed ApproximAte Curvature), a novel method that\nconditions the gradient using selected second-order information and has an\nasymptotically vanishing computational overhead, assuming a batch size smaller\nthan the number of neurons. We show that it is possible to compute a good\nconditioner based on only the input to a respective layer without a substantial\ncomputational overhead. The proposed method allows effective training even in\nsmall-batch stochastic regimes, which makes it competitive to first-order as\nwell as second-order methods.\n",
        "title": "ISAAC Newton: Input-based Approximate Curvature for Newton's Method",
        "texts": [
            "Figure 1: Logarithmic training loss (top) and test accuracy (bottom) on the MNIST classification task. The axes are the regularization parameters λg and λa in logarithmic scale with base 10. Training with a 5-layer ReLU activated network with 100 (left, a, e), 400 (center, b, c, f, g), and 1 600 (right, d, h) neurons per layer. The optimizer is SGD except for (c, g) where the optimizer is SGD with momentum. The top-left sector is ζ , the top-right column is ζ∗, and the bottom-right corner is ∇ (gradient descent). For each experiment and each of the three sectors, we use one learning rate, i.e., ζ , ζ∗, ∇ have their own learning rate to make a fair comparison between the methods; within each sector the learning rate is constant. We can observe that in the limit of λg →∞ (i.e., in the limit to the right) the performance remains good, showing the utility of ζ∗.",
            "Figure 2: Training loss of the MNIST auto-encoder trained with gradient descent, K-FAC, ζ , and ζ∗. Comparing the performance per real-time (left) and per number of update steps (right). Runtimes are for a CPU core.",
            "Figure 3: Training an auto-encoder on MNIST (left) and FashionMNIST (right). The model is the same as used by Botev et al. [18], i.e., it is a ReLU-activated 6-layer fully connected model with dimensions 784-1000-500- 30-500-1000-784. Displayed is the logarithmic training loss.",
            "Figure 4: Training a 5-layer ReLU network with 400 neurons per layer on the MNIST classification task (as in Figure 1) but with the Adam optimizer [19].",
            "Figure 5: Training on the MNIST classification task using ζ∗ only in selected layers. Runtimes are for CPU.",
            "Figure 6: ResNet-18 trained on CIFAR-10 with image augmentation and a cosine learning rate schedule. To ablate the optimizer, two additional settings are added, specifically, without weight decay and without momentum. Results are averaged over 5 runs and the standard deviation is indicated with the colored areas.",
            "Figure 7: Training loss of the MNIST auto-encoder trained with gradient descent, K-FAC, ζ , ζ∗, as well as SGD w/ momentum, SGD with a 10× larger batch size (600), K-FAC with a 10× larger batch size (600), and Adam. Comparing the performance per real-time (left) and per number of epochs (right). We display both the training loss (top) as well as the test loss (bottom) Runtimes are for a CPU core.",
            "Figure 8: Test accuracy for training on the MNIST classification task using ζ∗ only in selected layers. Runtimes are for CPU.",
            "Figure 9: Reproduction of the experiments in Figure 1 but with the Fisher-based natural gradient formulation from Remark 4. For a description of the experimental settings, see the caption of Figure 1. We observe that, for large λg, the behavior is similar to Figure 1, which is expected as they are the same in the limit of λg → ∞. Further, we observe that (in this case of the Fisher-based ζ ) not only in the limit of λg →∞ but also in the limit of λa →∞ good performance can be achieved. Moreover, in this specific experiment, λa →∞ has slightly better optimal performance compared to λg →∞, but λa →∞ is more sensitive to changes in λg compared to the sensitivity of the case of λg →∞ wrt. changes in λa. This phenomenon was also (to a lesser extent) visible in the experiments of Figure 1. We would like to remark that the case of λg →∞ (i.e., ζ?) is computationally more efficient compared to λa →∞.",
            "Table 1: BERT results for fine-tuning pre-trained BERT-Base (B-B) and BERT-Mini (B-M) models on the COLA, MRPC, and STSB text classification tasks. Larger values are better for all metrics. MCC is the Matthews correlation. Results averaged over 10 runs.",
            "Table 2: Runtimes and memory requirements for different models. Runtime is the training time per epoch on MNIST at a batch size of 60, i.e., for 1 000 training steps. The K-FAC implementation is from the backpack library [15]. The GPU is an Nvidia A6000."
        ],
        "imgs": [
            "$2305.00604v1-Figure1-1.png",
            "$2305.00604v1-Figure2-1.png",
            "$2305.00604v1-Figure3-1.png",
            "$2305.00604v1-Figure4-1.png",
            "$2305.00604v1-Figure5-1.png",
            "$2305.00604v1-Figure6-1.png",
            "$2305.00604v1-Figure7-1.png",
            "$2305.00604v1-Figure8-1.png",
            "$2305.00604v1-Figure9-1.png",
            "$2305.00604v1-Table1-1.png",
            "$2305.00604v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00606",
        "abstract": "  Natural Language Processing (NLP) research has made great advancements in\nrecent years with major breakthroughs that have established new benchmarks.\nHowever, these advances have mainly benefited a certain group of languages\ncommonly referred to as resource-rich such as English and French. Majority of\nother languages with weaker resources are then left behind which is the case\nfor most African languages including Wolof. In this work, we present a parallel\nWolof/French corpus of 123,000 sentences on which we conducted experiments on\nmachine translation models based on Recurrent Neural Networks (RNN) in\ndifferent data configurations. We noted performance gains with the models\ntrained on subworded data as well as those trained on the French-English\nlanguage pair compared to those trained on the French-Wolof pair under the same\nexperimental conditions.\n",
        "title": "Low-Resourced Machine Translation for Senegalese Wolof Language",
        "texts": [
            "Fig. 1. Data collection pipeline",
            "Fig. 2. Performance evolution of Fr→Wo NMT models on subworded and nonsubworded data in the same data size configurations",
            "Fig. 3. Performance evolution of Fr→En NMT models on subworded and nonsubworded data in the same data size configurations",
            "Fig. 4. Performance evolution of Fr→Wo and Fr→En NMT models on raw data in the same data size configurations",
            "Fig. 5. Performance evolution of Fr→Wo and Fr→En NMT models on subworded data in the same data size configurations",
            "Table 1. French Wolof Experimentation",
            "Table 2. French English Experimentation"
        ],
        "imgs": [
            "$2305.00606v1-Figure1-1.png",
            "$2305.00606v1-Figure2-1.png",
            "$2305.00606v1-Figure3-1.png",
            "$2305.00606v1-Figure4-1.png",
            "$2305.00606v1-Figure5-1.png",
            "$2305.00606v1-Table1-1.png",
            "$2305.00606v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00607",
        "abstract": "  Due to the lack of temporal annotation, current Weakly-supervised Temporal\nAction Localization (WTAL) methods are generally stuck into over-complete or\nincomplete localization. In this paper, we aim to leverage the text information\nto boost WTAL from two aspects, i.e., (a) the discriminative objective to\nenlarge the inter-class difference, thus reducing the over-complete; (b) the\ngenerative objective to enhance the intra-class integrity, thus finding more\ncomplete temporal boundaries. For the discriminative objective, we propose a\nText-Segment Mining (TSM) mechanism, which constructs a text description based\non the action class label, and regards the text as the query to mine all\nclass-related segments. Without the temporal annotation of actions, TSM\ncompares the text query with the entire videos across the dataset to mine the\nbest matching segments while ignoring irrelevant ones. Due to the shared\nsub-actions in different categories of videos, merely applying TSM is too\nstrict to neglect the semantic-related segments, which results in incomplete\nlocalization. We further introduce a generative objective named Video-text\nLanguage Completion (VLC), which focuses on all semantic-related segments from\nvideos to complete the text sentence. We achieve the state-of-the-art\nperformance on THUMOS14 and ActivityNet1.3. Surprisingly, we also find our\nproposed method can be seamlessly applied to existing methods, and improve\ntheir performances with a clear margin. The code is available at\nhttps://github.com/lgzlIlIlI/Boosting-WTAL.\n",
        "title": "Boosting Weakly-Supervised Temporal Action Localization with Text\n  Information",
        "texts": [
            "Figure 1. Comparison of our proposed framework with current WTAL methods. (a) Common failures in existing WTAL methods. (b) Existing WTAL model’s pipeline. (c) The proposed framework with text-segment mining and video-text language completion, where the depth of color represents the degree of correlation between segments and texts.",
            "Figure 2. Illustration of the proposed framework. In this work, the text-segment mining objective uses the action label texts as a query to mine semantically related segments in the video to achieve action localization. In addition, the language completion objective aims to focus on the areas related to the action label texts in the video as comprehensively as possible to complete the masked keywords, and alleviate the localization errors caused by the excessive attention of the matching strategy to the most relevant segments in a self-supervised manner.",
            "Figure 3. Two prediction examples on THUMOS14 dataset.",
            "Table 1. Experimental results of different methods in THUMOS14 dataset.",
            "Table 2. Experimental results of different methods in ActivityNet1.3 dataset.",
            "Table 3. Effectiveness of each component on THUMOS14 datasets.",
            "Table 4. Comparisons with different prompts in classification model on THUMOS14 dataset.",
            "Table 5. Comparisons with types of consistency constraint loss on THUMOS14 dataset.",
            "Table 6. Comparisons with different types of language reconstructors in the video-text language completion model on THUMOS14 dataset.",
            "Table 7. Comparisons with different prompts in completion model on THUMOS14 dataset.",
            "Table 8. Integrating our framework to existing methods on THUMOS14 dataset."
        ],
        "imgs": [
            "$2305.00607v1-Figure1-1.png",
            "$2305.00607v1-Figure2-1.png",
            "$2305.00607v1-Figure3-1.png",
            "$2305.00607v1-Table1-1.png",
            "$2305.00607v1-Table2-1.png",
            "$2305.00607v1-Table3-1.png",
            "$2305.00607v1-Table4-1.png",
            "$2305.00607v1-Table5-1.png",
            "$2305.00607v1-Table6-1.png",
            "$2305.00607v1-Table7-1.png",
            "$2305.00607v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00608",
        "abstract": "  We study the properties of differentiable neural networks activated by\nrectified power unit (RePU) functions. We show that the partial derivatives of\nRePU neural networks can be represented by RePUs mixed-activated networks and\nderive upper bounds for the complexity of the function class of derivatives of\nRePUs networks. We establish error bounds for simultaneously approximating\n$C^s$ smooth functions and their derivatives using RePU-activated deep neural\nnetworks. Furthermore, we derive improved approximation error bounds when data\nhas an approximate low-dimensional support, demonstrating the ability of RePU\nnetworks to mitigate the curse of dimensionality. To illustrate the usefulness\nof our results, we consider a deep score matching estimator (DSME) and propose\na penalized deep isotonic regression (PDIR) using RePU networks. We establish\nnon-asymptotic excess risk bounds for DSME and PDIR under the assumption that\nthe target functions belong to a class of $C^s$ smooth functions. We also show\nthat PDIR achieves the minimax optimal convergence rate and has a robustness\nproperty in the sense it is consistent with vanishing penalty parameters even\nwhen the monotonicity assumption is not satisfied. Furthermore, if the data\ndistribution is supported on an approximate low-dimensional manifold, we show\nthat DSME and PDIR can mitigate the curse of dimensionality.\n",
        "title": "Differentiable Neural Networks with RePU Activation: with Applications\n  to Score Estimation and Isotonic Regression",
        "texts": [
            "Fig 1: Examples of PDIR estimates. In all figures, the data points are depicted as grey dots, the underlying regression functions are plotted as solid black curves, and PDIR estimates with different level of penalty parameter λ are plotted as colored curves. In the top two figures, data are generated from models with monotonic regression functions. In the bottom left figure, the target function is a constant. In the bottom right figure, the model is misspecified, in which the underlying regression function is not monotonic. Small values of λ can lead to non-monotonic estimated functions.",
            "TABLE 1 Comparison of approximation results of RePU neural networks on a function with smoothness order β > 0, within the accuracy ε. ReQU σ2 and ReCU σ3 are special instances of RePU σp for p≥ 2. The Sobolev norm W s,p of a function f refers to the mean value of Lp norm of all partial derivatives of f for p > 0 and W s,∞ refers to the maximum value of L∞ norm of all the partial derivatives of f . The Hölder normHs is the W s,∞ when s is a non-negative integer.",
            "TABLE 2 Comparison among ReLU, Sigmoid and RePU activation functions."
        ],
        "imgs": [
            "$2305.00608v1-Figure1-1.png",
            "$2305.00608v1-Table1-1.png",
            "$2305.00608v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00609",
        "abstract": "  Recent studies provide evidence that social constructivist pedagogical\nmethods such as active learning, interactive engagement, and inquiry-based\nlearning, while pedagogically more effective, can enable inequities in the\nclassroom. By conducting a quantitative empirical examination of\ngender-inequitable group dynamics in two inquiry-based physics labs, we extend\nresults of previous work. Using a survey on group work preferences and video\nrecordings of lab sessions, we find similar patterns of gendered role-taking\nnoted in prior studies. These results are not reducible to differences in\nstudents' preferences. We find that an intervention which employed partner\nagreement forms, with the goal of reducing inequities, had a positive impact on\nstudents' engagement with equipment during a first-semester lab course. Our\nwork will inform implementation of more effective interventions in the future\nand emphasizes challenges faced by instructors who are dedicated to both\nresearch-based pedagogical practices and efforts to promote diversity, equity,\nand inclusion in their classrooms.\n",
        "title": "Group Dynamics in Inquiry-based Labs: Gender Inequities and the Efficacy\n  of Partner Agreements",
        "texts": [
            "FIG. 1. Pedagogical practices considered in this work depicted within their respective theoretical frameworks. For each pedagogical practice, arrows indicate known link to sustained inequities (solid line) and plausible links to less inequities (dashed lines).",
            "FIG. 2. Expected fraction of men and women that preferred a given role controlling for course, track, and the interaction of course and track. Errors bars represent 95% confidence intervals. The asterisks denote statistical significance where ∗ indicates p < 0.05, ∗∗ indicates p < 0.01, and ∗∗∗ indicates p < 0.001. Students could select as many or as few roles as they wanted.",
            "FIG. 3. Expected fraction of men and women that preferred a given method of role distribution controlling for course, track, and the interaction of course and track. Errors bars represent 95% confidence intervals. The asterisks denote statistical significance where ∗ indicates p < 0.05, ∗∗ indicates p < 0.01, and ∗∗∗ indicates p < 0.001. Students could select only one answer.",
            "FIG. 4. Expected fraction of men and women that preferred a given leadership style controlling for course, track, and the interaction of course and track. Errors bars represent 95% confidence intervals. The asterisks denote statistical significance where ∗ indicates p < 0.05, ∗∗ indicates p < 0.01, and ∗∗∗ indicates p < 0.001. Students could select only one answer.",
            "FIG. 5. Results from multilevel regression in (a) Physics I Lab and (b) Physics II Lab for ‘Equipment’ group fraction. These results are controlling for group size and random effects. The base term for each course is the group fraction of men in the control section who did not indicate a preference for equipment. The error bars represent the standard error of the regression coefficients. The asterisks denote statistical significance where ∗ indicates p < 0.05, ∗∗ indicates p < 0.01, and ∗∗∗ indicates p < 0.001. The full model output can be found in Appendix D.",
            "FIG. 6. Results from multilevel regression in (a) Physics I Lab and (b) Physics II Lab for ‘Laptop’, ‘Calculator’, and ‘Paper’ group fraction. These results are controlling for group size and random effects. The base term for each course is the group fraction of men in the control section who did not indicate a preference for notes or analysis. The error bars represent the standard error of the regression coefficients. There were no statistically significant differences. The full model output can be found in Appendix D.",
            "FIG. 7. Visual check for the assumption of linearity for hierarchical linear modeling. These plots show the residuals vs. the fitted values for a) ‘Equipment’ group fraction in Physics I Lab, b) ‘Equipment’ group fraction in Physics II Lab, c) ‘Laptop,’ ‘Calculator,’ and ‘Paper’ group fraction in Physics I Lab, and d) ‘Laptop,’ ‘Calculator,’ and ‘Paper’ group fraction in Physics II Lab.",
            "FIG. 8. Visual check for the assumption of normality for hierarchical linear modeling. These plots show the residuals vs. the fitted values for a) ‘Equipment’ group fraction in Physics I Lab, b) ‘Equipment’ group fraction in Physics II Lab, c) ‘Laptop,’ ‘Calculator,’ and ‘Paper’ group fraction in Physics I Lab, and d) ‘Laptop,’ ‘Calculator,’ and ‘Paper’ group fraction in Physics II Lab.",
            "TABLE I. Self-reported, anonymous results from a survey of student demographic information: gender (including nonbinary/other options), racial/ethnic identity [57], and parents’ highest level of education [58] across courses (≈ 70% response rate). Racial/ethnic groups were not considered mutually exclusive. Counts may not equal the total as students may not have answered all background questions or preferred to not disclose.",
            "TABLE II. Coding scheme used for video observations. The ‘Laptop,’ ‘Calculator,’ and ‘Paper’ codes were later collapsed.",
            "TABLE III. Student and observation demographic data from the four lab sections which were recorded. Student demographic data indicates the number of men and women in each section. An observation describes one student in one lab period, thus, observation demographic data indicates the number of men and women in each session across the semester. For example, we have 8 unique students that are men in the Physics I Lab control section; we have 61 observations of these 8 unique students across the full semester due to absences.a",
            "TABLE V. Number of men and women enrolled in each course and track for Physics I Lab and Physics II Lab.",
            "TABLE X. Results from linear regression for ‘Laptop,’ ‘Calculator,’ and ‘Paper’ group fraction. The table shows the regression coefficient, standard error, and p-value (in parentheses). The variance explained by these models for both fixed and random effects (fixed effects only) is 54% (12%) for Physics I Lab and 61% (6%) for Physics II Lab."
        ],
        "imgs": [
            "$2305.00609v2-Figure1-1.png",
            "$2305.00609v2-Figure2-1.png",
            "$2305.00609v2-Figure3-1.png",
            "$2305.00609v2-Figure4-1.png",
            "$2305.00609v2-Figure5-1.png",
            "$2305.00609v2-Figure6-1.png",
            "$2305.00609v2-Figure7-1.png",
            "$2305.00609v2-Figure8-1.png",
            "$2305.00609v2-TableI-1.png",
            "$2305.00609v2-TableII-1.png",
            "$2305.00609v2-TableIII-1.png",
            "$2305.00609v2-TableV-1.png",
            "$2305.00609v2-TableX-1.png"
        ]
    },
    {
        "id": "2305.00614",
        "abstract": "  We explain recent LHCb measurements of the lepton universality ratios,\n$R_{D^{(*)}}^{\\tau/\\ell}\\equiv \\frac{\\mathcal{B}(\\bar B \\to D^{(*)+} \\tau^-\n\\bar\\nu_\\tau)} {\\mathcal{B}(\\bar B \\to D^{(*)+}\\ell^- \\bar\\nu_\\ell)}$ and\n${R(\\Lambda_c^+)}^{\\tau/\\ell} \\equiv \\frac{\\mathcal{B}(\\Lambda_b \\to\n\\Lambda_c^+ \\tau^- \\bar{\\nu}_{\\tau})}{\\mathcal{B}(\\Lambda_b \\to \\Lambda_c^+\n\\ell^- \\bar{\\nu}_{\\ell})}$ with $\\ell=\\mu$, via new physics that affects\n$R_D^{\\tau/\\ell}$ and $R(\\Lambda_c^+)^{\\tau/\\ell}$ but not\n$R_{D^*}^{\\tau/\\ell}$. The scalar operator in the effective theory for new\nphysics is indicated. We find that the forward-backward asymmetry and $\\tau$\npolarization in $\\bar{B} \\to D^+ \\tau^{-} \\bar{\\nu}_{\\tau}$ and $\\Lambda_b \\to\n\\Lambda_c^+ \\tau^- \\bar{\\nu}_{\\tau}$ decays are significantly affected by the\nscalar interaction. We construct a simple two Higgs doublet model as a\nrealization of our scenario and consider lepton universality in semileptonic\ncharm and top decays, radiative $B$ decay, $B$-mixing, and $Z \\to b \\bar b$.\n",
        "title": "Hint of a new scalar interaction in LHCb data?",
        "texts": [
            "FIG. 1. Left: The 1σ allowed parameter space for complex gS . The best fit point is marked by the star. Right: SM and NP predictions for two observables. The star corresponds to the best fit point. The values measured by LHCb are shown for comparison.",
            "TABLE I. Best fit parameters which are identical for both real gS and complex gS .",
            "TABLE II. SM and NP predictions for various observables. For NP, the best fit predictions are same for both real and complex gS . The SM predictions are based on the lattice form factor results but no other experimental input."
        ],
        "imgs": [
            "$2305.00614v2-Figure1-1.png",
            "$2305.00614v2-TableI-1.png",
            "$2305.00614v2-TableII-1.png"
        ]
    },
    {
        "id": "2305.00615",
        "abstract": "  In this paper we give an algorithm for streaming $k$-edit approximate pattern\nmatching which uses space $\\widetilde{O}(k^2)$ and time $\\widetilde{O}(k^2)$\nper arriving symbol. This improves substantially on the recent algorithm of\nKociumaka, Porat and Starikovskaya (2022) which uses space $\\widetilde{O}(k^5)$\nand time $\\widetilde{O}(k^8)$ per arriving symbol. In the $k$-edit approximate\npattern matching problem we get a pattern $P$ and text $T$ and we want to\nidentify all substrings of the text $T$ that are at edit distance at most $k$\nfrom $P$. In the streaming version of this problem both the pattern and the\ntext arrive in a streaming fashion symbol by symbol and after each symbol of\nthe text we need to report whether there is a current suffix of the text with\nedit distance at most $k$ from $P$. We measure the total space needed by the\nalgorithm and time needed per arriving symbol.\n",
        "title": "Streaming $k$-edit approximate pattern matching via string decomposition",
        "texts": [
            "Figure 1: The alignment of text and pattern grammars after arrival of some text symbol. The pattern P is represented by grammars GP 1 , . . . , G P r . Grammars GP 1 , . . . , G P r−R are encoded by Enc and sent to the CKP-match algorithm as its pattern. The current text T is represented by the sequence of grammars GT 1 , . . . , G T s , G a 1, . . . , G a t . Grammars GT 1 , . . . , G T s are encoded and committed to the CKP-match algorithm as its text. Grammars Ga 1, . . . , G a t are active grammars of the text, and might change as more symbols are added to the text."
        ],
        "imgs": [
            "$2305.00615v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00616",
        "abstract": "  We investigate and ascertain the ideal inputs to any finite-time\nthermodynamic process. We demonstrate that the expectation values of entropy\nflow, heat, and work can all be determined via Hermitian observables of the\ninitial state. These Hermitian operators encapsulate the breadth of behavior\nand the ideal inputs for common thermodynamic objectives. We show how to\nconstruct these Hermitian operators from measurements of thermodynamic output\nfrom a finite number of effectively arbitrary inputs. Behavior of a small\nnumber of test inputs thus determines the full range of thermodynamic behavior\nfrom all inputs. For any process, entropy flow, heat, and work can all be\nextremized by pure input states -- eigenstates of the respective operators. In\ncontrast, the input states that minimize entropy production or maximize the\nchange in free energy are non-pure mixed states obtained from the operators as\nthe solution of a convex optimization problem. To attain these, we provide an\neasily implementable gradient descent method on the manifold of density\nmatrices, where an analytic solution yields a valid direction of descent at\neach iterative step. Ideal inputs within a limited domain, and their associated\nthermodynamic operators, are obtained with less effort. This allows analysis of\nideal thermodynamic inputs within quantum subspaces of infinite-dimensional\nquantum systems; it also allows analysis of ideal inputs in the classical\nlimit. Our examples illustrate the diversity of 'ideal' inputs: Distinct\ninitial states minimize entropy production, extremize the change in free\nenergy, and maximize work extraction.\n",
        "title": "Thermodynamically ideal quantum-state inputs to any device",
        "texts": [
            "FIG. 1. Diversity of ideal inputs for a finite-time qubit-reset process, displayed on and in the Bloch sphere. The states extremizing heat, work, and energy-change all lie on the surface of the Bloch sphere, in the direction of a maximal eigenstate of the corresponding thermodynamic operators. The entire surface of the Bloch sphere maximizes entropy gain. Minimal entropy production and maximal free energy gain are achieved by non-trivial mixed-state inputs. The change in entropy is minimized by the fully-mixed input. Entropy production is maximized by the same pure-state input that maximizes heat exhaustion. The greatest loss of free energy occurs for the same pure-state input that loses the most energy.",
            "FIG. 2. Tracking the behavior of four inputs is enough to bound the behavior of all other inputs to a qubit process. Here we show the the range of expectation values for exhausted heat and entropy production throughout a finite-time qubit-reset process. The expectation values from four random inputs are shown as dashed lines. This allows construction of the thermodynamic operator Q throughout time. (top) Maximal and minimal heat, corresponding to extremal eigenvalues of Q, shown as thick red solid lines; (bottom) Maximal and minimal entropy production, obtained from gradient descent/ascent, shown as thick red solid lines. These extrema bound the behavior of all other inputs, including the behavior of 100 other random initial conditions shown as thin gray solid lines.",
            "FIG. 4. Spatial probability density pv(x/λth) = limδx→0 λth δx |〈x, x + δx|v〉|2 for the eigenstates |v〉 of the expected-work operator W, offset by the corresponding work eigenvalue w, such that W |v〉 = w |v〉.",
            "FIG. 5. Bottom panels: Snapshots of spatial evolution of the ideal input to the work-extraction protocol, along with the resulting trajectory of expected work. Upper panels: Snapshots of spatial evolution of a random input to the protocol, along with the resulting trajectory of expected work. Top and bottom panels show spatial probability density of the state in thick solid blue, compared to the probability density for the instantaneous equilibrium state in thin dashed green; the instantaneous potential-energy landscape, which starts and ends as a symmetric double well, is shown in thin solid gray. The two long middle panels show the time evolution of the expected work from each of these two initial states."
        ],
        "imgs": [
            "$2305.00616v1-Figure1-1.png",
            "$2305.00616v1-Figure2-1.png",
            "$2305.00616v1-Figure4-1.png",
            "$2305.00616v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00618",
        "abstract": "  This paper introduces a novel simulation tool for analyzing and training\nneural network models tailored for compute-in-memory hardware. The tool\nleverages physics-based device models to enable the design of neural network\nmodels and their parameters that are more hardware-accurate. The initial study\nfocused on modeling a CMOS-based floating-gate transistor and memristor device\nusing measurement data from a fabricated device. Additionally, the tool\nincorporates hardware constraints, such as the dynamic range of data\nconverters, and allows users to specify circuit-level constraints. A case study\nusing the MNIST dataset and LeNet-5 architecture demonstrates the tool's\ncapability to estimate area, power, and accuracy. The results showcase the\npotential of the proposed tool to optimize neural network models for\ncompute-in-memory hardware.\n",
        "title": "Modeling and Analysis of Analog Non-Volatile Devices for\n  Compute-In-Memory Applications",
        "texts": [
            "Fig. 1: Overview of the simulation platform based on measured non-volatile devices.",
            "Fig. 2: Measurement of the ReRAM device fabricated by using atomic layer deposition (ALD) and electron-beam (e-beam) evaporation on the left. Characterization of FG device fabricated in 65nm CMOS process on the right.",
            "Fig. 3: Overall Architecture for performing inference using the non-volatile memory. The DACs encode the inputs as an analog voltage, the memory elements output a current based on the DAC line voltage and stored value, the DTA outputs the difference in current as a voltage (with a fixed gain), and finally, the ADC converts the voltage back into a digital value as the output.",
            "Fig. 4: Current measurements at 0.1 V with ReRAM device programmed at different states. [13]",
            "TABLE I: LeNet-5 Training Results"
        ],
        "imgs": [
            "$2305.00618v1-Figure1-1.png",
            "$2305.00618v1-Figure2-1.png",
            "$2305.00618v1-Figure3-1.png",
            "$2305.00618v1-Figure4-1.png",
            "$2305.00618v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00619",
        "abstract": "  In the context of mobile sensing environments, various sensors on mobile\ndevices continually generate a vast amount of data. Analyzing this\never-increasing data presents several challenges, including limited access to\nannotated data and a constantly changing environment. Recent advancements in\nself-supervised learning have been utilized as a pre-training step to enhance\nthe performance of conventional supervised models to address the absence of\nlabelled datasets. This research examines the impact of using a self-supervised\nrepresentation learning model for time series classification tasks in which\ndata is incrementally available. We proposed and evaluated a workflow in which\na model learns to extract informative features using a corpus of unlabeled time\nseries data and then conducts classification on labelled data using features\nextracted by the model. We analyzed the effect of varying the size,\ndistribution, and source of the unlabeled data on the final classification\nperformance across four public datasets, including various types of sensors in\ndiverse applications.\n",
        "title": "Self-supervised Activity Representation Learning with Incremental Data:\n  An Empirical Study",
        "texts": [
            "Fig. 1. Overview of the workflow. Unlabelled time series data were used to train an encoder model in a pre-training phase, which is then used in a downstream phase to extract features from labelled data and served as input to the downstream classifier.",
            "Fig. 2. Incremental pre-train data settings for UCIHAR. In instanceincremental, models were trained for various proportions of instances. In class incremental, models were trained for various number of classes.",
            "Fig. 3. Workflow of the UEA dataset investigation. Full training data were split into random subsets with size according to the number of classes in a dataset, and also single class subsets. These were used to pre-train encoder models, and compared with model trained based on no and full pre-training data.",
            "Fig. 4. Instance-incremental setup for UCIHAR dataset. Performance has been improved over the first 25% of training data but plateaued afterwards.",
            "Fig. 5. Class-incremental setup for UCIHAR dataset. Performance increased over the first two classes used for pre-training and plateaued afterwards.",
            "TABLE I ACCURACY ACHIEVED BY DIFFERENT BASELINES W/O PRETRAINING PHASE ACROSS THREE HAR DATASETS. OUR PROPOSED SSL-BASED FRAMEWORK CONSISTENTLY REACHES HIGH ACCURACY.",
            "TABLE II ACCURACY ON 30 UEA DATASETS IN DIFFERENT SCENARIOS."
        ],
        "imgs": [
            "$2305.00619v1-Figure1-1.png",
            "$2305.00619v1-Figure2-1.png",
            "$2305.00619v1-Figure3-1.png",
            "$2305.00619v1-Figure4-1.png",
            "$2305.00619v1-Figure5-1.png",
            "$2305.00619v1-TableI-1.png",
            "$2305.00619v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00621",
        "abstract": "  Survival analysis is the problem of estimating probability distributions for\nfuture event times, which can be seen as a problem in uncertainty\nquantification. Although there are fundamental theories on strictly proper\nscoring rules for uncertainty quantification, little is known about those for\nsurvival analysis. In this paper, we investigate extensions of four major\nstrictly proper scoring rules for survival analysis and we prove that these\nextensions are proper under certain conditions, which arise from the\ndiscretization of the estimation of probability distributions. We also compare\nthe estimation performances of these extended scoring rules by using real\ndatasets, and the extensions of the logarithmic score and the Brier score\nperformed the best.\n",
        "title": "Proper Scoring Rules for Survival Analysis",
        "texts": [
            "Figure 1. Two types of discretization of probability distribution F̂ (t) with B = 5.",
            "Figure 2. Illustration of computation of weight wi = (F (ζi+1)− F (c))/(1− F (c)) for scoring rule SCen−log.",
            "Figure 3. Illustration of computations of weight wi = (F (ζ) − F (c))/(1− F (c)) for scoring rule SCen−Binary−Brier.",
            "Figure 4. Prediction performance (lower is better) comparison on three datasets with SCen−log−simple, KM-calibration, and D-calibration.",
            "Table 1. Prediction performances of DeepHit (lower is better) with various α for B = 32.",
            "Table 2. Comparison between two extensions of logarithmic score for B = 8.",
            "Table 3. Comparison between two extensions of logarithmic score for B = 16.",
            "Table 4. Comparison between two extensions of logarithmic score for B = 32."
        ],
        "imgs": [
            "$2305.00621v3-Figure1-1.png",
            "$2305.00621v3-Figure2-1.png",
            "$2305.00621v3-Figure3-1.png",
            "$2305.00621v3-Figure4-1.png",
            "$2305.00621v3-Table1-1.png",
            "$2305.00621v3-Table2-1.png",
            "$2305.00621v3-Table3-1.png",
            "$2305.00621v3-Table4-1.png"
        ]
    },
    {
        "id": "2305.00626",
        "abstract": "  Let $F(n,k)$ be a hypergeometric function that may be expressed so that $n$\nappears within initial arguments of inverted Pochhammer symbols, as in factors\nof the form $\\frac{1}{(n)_{k}}$. Only in exceptional cases is $F(n, k)$ such\nthat Zeilberger's algorithm produces a two-term recursion for $\\sum_{k =\n0}^{\\infty} F(n, k)$ obtained via the telescoping of the right-hand side of a\ndifference equation of the form $p_{1}(n) F(n + r, k) + p_{2}(n) F(n, k) = G(n,\nk+1) - G(n, k)$ for fixed $r \\in \\mathbb{N}$ and polynomials $p_{1}$ and\n$p_{2}$. Building on the work of Wilf, we apply a series acceleration technique\nbased on two-term hypergeometric recursions derived via Zeilberger's algorithm.\nFast converging series previously given by Ramanujan, Guillera, Chu and Zhang,\nChu, Lupa\\c{s}, and Amdeberhan are special cases of hypergeometric transforms\nintroduced in our article.\n",
        "title": "On two-term hypergeometric recursions with free lower parameters",
        "texts": [
            "Table 1. Organization of Section 4, based on the acceleration method described in Section 3. We are letting Catalan’s constant be denoted as G = 1− 1 32 + 1 52 − · · · , and we let Apéry’s constant be denoted as ζ(3) = 1 + 1 23 + 1 33 + · · · ."
        ],
        "imgs": [
            "$2305.00626v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00627",
        "abstract": "  Accurate extraction of mitral valve shape from clinical tomographic images\nacquired in patients has proven useful for planning surgical and interventional\nmitral valve treatments. However, manual extraction of the mitral valve shape\nis laborious, and the existing automatic extraction methods have not been\nsufficiently accurate. In this paper, we propose a fully automated method of\nextracting mitral valve shape from computed tomography (CT) images for the all\nphases of the cardiac cycle. This method extracts the mitral valve shape based\non DenseNet using both the original CT image and the existence probability maps\nof the mitral valve area inferred by U-Net as input. A total of 1585 CT images\nfrom 204 patients with various cardiac diseases including mitral regurgitation\n(MR) were collected and manually annotated for mitral valve region. The\nproposed method was trained and evaluated by 10-fold cross validation using the\ncollected data and was compared with the method without the existence\nprobability maps. The mean error of shape extraction error in the proposed\nmethod is 0.88 mm, which is an improvement of 0.32 mm compared with the method\nwithout the existence probability maps.\n",
        "title": "CNN-based fully automatic mitral valve extraction using CT images and\n  existence probability maps",
        "texts": [
            "Fig. 1 Input CT image and ground truth of Mitral Valve",
            "Fig. 2 Flowchart of our method",
            "Fig. 3 Probability map inference model architecture (U-Net)",
            "Fig. 4 Comparison of inferred meshes cross-section with and without probability maps. The mesh consists of grid points connected by lines, with the anterior leaflet in red and the posterior leaflet in blue. Arrows in the figure indicate areas where errors in the mesh shape are large. (a) MR case. (b) Normal case.",
            "Fig. 5 Mitral valve mesh extracted by shape extraction model with probability maps. The anterior leaflet of the mitral valve is shown in pink and the posterior leaflet in green. (a)MR case. (b) Normal case.",
            "Fig. 6 Comparison of inferred meshes cross-section with and without probability maps with greater improvement at the posterior leaflet. The mesh consists of grid points connected by lines, with the anterior leaflet in red and the posterior leaflet in blue. Arrows in the figure indicate areas where errors in the mesh shape are large.",
            "Table 3 shows that the accuracy of extraction of posterior leaflet was lower than that of the anterior leaflet. This may be because the posterior leaflet is often located near the heart"
        ],
        "imgs": [
            "$2305.00627v1-Figure1-1.png",
            "$2305.00627v1-Figure2-1.png",
            "$2305.00627v1-Figure3-1.png",
            "$2305.00627v1-Figure4-1.png",
            "$2305.00627v1-Figure5-1.png",
            "$2305.00627v1-Figure6-1.png",
            "$2305.00627v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00628",
        "abstract": "  We develop an efficient numerical approach for simulating the high-power\ndispersive readout in circuit quantum electrodynamics. In the numerical\nsimulations of the high-power readout, a large-amplitude coherent state induced\nin a cavity is an obstacle because many Fock states are required to describe\nsuch a state. We remove the large-amplitude coherent state from the numerical\nsimulations by simulating the dynamics in a frame where the amplitude of the\ncoherent state is almost absent. Using the developed method, we numerically\nsimulate the high-power dispersive readout of the two-level system and the\ntransmon. Our proposed method succeeds in producing reasonable behaviors of the\nhigh-power dispersive readout which can be deduced from the photon-number\ndependence of the cavity frequency: The high-power dispersive readout works in\nthe two-level-system case while it does not work in the transmon case.\n",
        "title": "Efficient numerical approach for the simulations of high-power\n  dispersive readout with time-dependent unitary transformation",
        "texts": [
            "FIG. 10. Parametric plot of the transmon occupation number versus the cavity photon number during the dynamics with input-field amplitudes E/ωc = 6.0×10−3, 7.0×10−3, and 8.0× 10−3. Red dotted line represents the transmon occupation number as a function of the cavity photon number obtained from the labeled eigenstates |g̃, ñ⟩. An initial state is |g̃, 0̃⟩. The highest occupation number Nmax is set to 40 in the cases with E/ωc = 6.0 × 10−3 and 8.0 × 10−3 and 60 in the case with E/ωc = 7.0× 10−3. The other parameters are the same as those in Fig. 8.",
            "FIG. 3. Time evolution of the absolute amplitude of the coherent state generated in the cavity in the transformed frame. The displacement α(t) is set to Q(t). The parameters and the initial state are the same with those in Fig. 2.",
            "FIG. 4. (a),(d) Time evolution of the cavity photon number for different input-field amplitudes. Here, nc is the critical photon number given by (ωq − ωc) 2/4g2. The resonant frequency ωq and the coupling g are the same as those in Fig. 2. (b), (e) Time evolution of the real part of the cavity amplitude in the rotating frame at the drive frequency starting. (c), (f) Time evolution of the absolute amplitude of the coherent state in the transformed frame. Initial states are (a-c) |g̃, 0̃⟩ and (d-f) |ẽ, 0̃⟩. The highest occupation number Nmax is set to 30 in the cases with E/ωc = 7.0 × 10−3 and 2.5 × 10−2. For the cases with E/ωc = 6.0× 10−2, we set Nmax to 50.",
            "FIG. 7. Time evolution of the cavity photon number of the cavity under a monochromatic drive Ee−iωdt in the transmon case. Initially, |ψini⟩qc is set to |g̃, 0̃⟩. The parameters used in the simulation are (EC/h̄ωc, EJ/h̄ωc, g/ωc, κ/ωc, Ng, ωd/ωc) = (5.0 × 10−2, 1.6, 3.0 × 10−2, 1.619 × 10−3, 0.0, 1.0015). The amplitude of input field E is set to 3.0× 10−3ωc.",
            "FIG. 8. (a),(d) Time evolution of the cavity photon number for different input-field amplitudes in the transmon cases. (b),(e) Time evolution of the real part of the cavity amplitude in the rotating frame at the drive frequency. (c), (f) Time evolution of the absolute amplitude of the coherent state in the transformed frame starting. Initial states are (a-c) |g̃, 0̃⟩ and (d-f) |ẽ, 0̃⟩. The parameters of the system are the same with those in Fig. 7. The highest occupation number Nmax is set to 20 in the cases with E/ωc = 1.4 × 10−2 and 2.0 × 10−2, 30 in the case with E/ωc = 6.0 × 10−3, 60 in the case with E/ωc = 7.0 × 10−3, and 100 in the cases with E/ωc = 1.5× 10−2 and 2.4× 10−2.",
            "FIG. 9. Parametric plot of the transmon occupation number versus the cavity photon number during the dynamics shown in Fig. 8. Initial states are (a)|g̃, 0̃⟩ and (b) |ẽ, 0̃⟩. Red dotted lines represent the transmon occupation numbers as a function of the cavity photon number obtained from the labeled eigenstates |g̃, ñ⟩ and |ẽ, ñ⟩."
        ],
        "imgs": [
            "$2305.00628v2-Figure10-1.png",
            "$2305.00628v2-Figure3-1.png",
            "$2305.00628v2-Figure4-1.png",
            "$2305.00628v2-Figure7-1.png",
            "$2305.00628v2-Figure8-1.png",
            "$2305.00628v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00629",
        "abstract": "  We study a distributed method called SAB-TV, which employs gradient tracking\nto collaboratively minimize the sum of smooth and strongly-convex local cost\nfunctions for networked agents communicating over a time-varying directed\ngraph. Each agent, assumed to have access to a stochastic first-order oracle\nfor obtaining an unbiased estimate of the gradient of its local cost function,\nmaintains an auxiliary variable to asymptotically track the stochastic gradient\nof the global cost. The optimal decision and gradient tracking are updated over\ntime through limited information exchange with local neighbors using row- and\ncolumn-stochastic weights, guaranteeing both consensus and optimality. With a\nsufficiently small constant step-size, we demonstrate that, in expectation,\nSAB-TV converges linearly to a neighborhood of the optimal solution. Numerical\nsimulations illustrate the effectiveness of the proposed algorithm.\n",
        "title": "Distributed Stochastic Optimization with Gradient Tracking over\n  Time-Varying Directed Networks",
        "texts": [
            "Fig. 1: Samples from MNIST dataset and the heatmap of coefficients calculated using the SAB–TV algorithm.",
            "Fig. 2: Residual (Left) and Test Accuracy (Right) ."
        ],
        "imgs": [
            "$2305.00629v1-Figure1-1.png",
            "$2305.00629v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00631",
        "abstract": "  In this paper, we investigate existence and stability of solitary waves to\nthe rotation-Camassa-Holm equation which can be considered as a model in the\nshallow water for the long-crested waves propagating near the equator with\neffect of the Coriolis force due to the Earths rotation. We prove existence of\nsolitary waves by performing a phase plane analysis. Moreover, utilizing the\napproach proposed by Grillakis-Shatah-Strauss, we prove stability of solitary\nwaves.\n",
        "title": "Existence and stability of solitary waves to the rotation-Camassa-Holm\n  equation",
        "texts": [
            "Figure 2.2: Solitary wave profiles with two different speeds."
        ],
        "imgs": [
            "$2305.00631v1-Figure2.2-1.png"
        ]
    },
    {
        "id": "2305.00635",
        "abstract": "  In this paper, we present a self-prior-based mesh inpainting framework that\nrequires only an incomplete mesh as input, without the need for any training\ndatasets. Additionally, our method maintains the polygonal mesh format\nthroughout the inpainting process without converting the shape format to an\nintermediate one, such as a voxel grid, a point cloud, or an implicit function,\nwhich are typically considered easier for deep neural networks to process. To\nachieve this goal, we introduce two graph convolutional networks (GCNs):\nsingle-resolution GCN (SGCN) and multi-resolution GCN (MGCN), both trained in a\nself-supervised manner. Our approach refines a watertight mesh obtained from\nthe initial hole filling to generate a complete output mesh. Specifically, we\ntrain the GCNs to deform an oversmoothed version of the input mesh into the\nexpected complete shape. The deformation is described by vertex displacements,\nand the GCNs are supervised to obtain accurate displacements at vertices in\nreal holes. To this end, we specify several connected regions of the mesh as\nfake holes, thereby generating meshes with various sets of fake holes. The\ncorrect displacements of vertices are known in these fake holes, thus enabling\ntraining GCNs with loss functions that assess the accuracy of vertex\ndisplacements. We demonstrate that our method outperforms traditional\ndataset-independent approaches and exhibits greater robustness compared with\nother deep-learning-based methods for shapes that infrequently appear in shape\ndatasets. Our code and test data are available at\nhttps://github.com/astaka-pe/SeMIGCN.\n",
        "title": "Learning Self-Prior for Mesh Inpainting Using Self-Supervised Graph\n  Convolutional Networks",
        "texts": [
            "Fig. 10: Visual comparison of inpainting performance for real scans provided by the Stanford 3D Repository [61].",
            "Fig. 11: Inpainting results for real scans distributed by the AIM@SHAPE Shape Repository [62].",
            "Fig. 12: Inpainting results for a real scan obtained by an optical 3D scanner (GOM ATOS Core 135).",
            "Fig. 13: Comparison of output meshes obtained with different network architectures.",
            "Fig. 14: Comparison of the speed of Epos convergence across different network architectures.",
            "Fig. 15: Comparison of output meshes at different resolutions. While the outputs after the refinement step appear nearly identical, there are subtle differences in the shapes of areas that were initially holes (best viewed on screen).",
            "Fig. 6: Self-supervision of the proposed GCN, where the GCN predicts the displacement of each vertex to reproduce the inpainted shape from the oversmoothed shape. We train the GCN in a self-supervised manner to predict the vertex displacements by filling zeros to the displacements at real and fake holes (colored pink and orange, respectively).",
            "Fig. 8: Comparison of results between MeshFix (i.e., our baseline), our method, and Point2Mesh [24].",
            "TABLE 1: Weights for Loss Terms",
            "TABLE 2: Quantitative Comparison of Inpainting Performance Using the Average Error Distance εhole in Units of 10−3",
            "TABLE 3: Inpainting Performance Comparison Across Different Network Architectures",
            "TABLE 4: Comparison of Running Times for Loss Convergence Across Different Network Architectures",
            "TABLE 5: Ablation Study for MGCN’s Losses",
            "TABLE 6: Effect of Fake Hole Size",
            "TABLE 7: Effect of Probability of Fake Hole Occurrence"
        ],
        "imgs": [
            "$2305.00635v1-Figure10-1.png",
            "$2305.00635v1-Figure11-1.png",
            "$2305.00635v1-Figure12-1.png",
            "$2305.00635v1-Figure13-1.png",
            "$2305.00635v1-Figure14-1.png",
            "$2305.00635v1-Figure15-1.png",
            "$2305.00635v1-Figure6-1.png",
            "$2305.00635v1-Figure8-1.png",
            "$2305.00635v1-Table1-1.png",
            "$2305.00635v1-Table2-1.png",
            "$2305.00635v1-Table3-1.png",
            "$2305.00635v1-Table4-1.png",
            "$2305.00635v1-Table5-1.png",
            "$2305.00635v1-Table6-1.png",
            "$2305.00635v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00636",
        "abstract": "  Significance testing based on p-values has been implicated in the\nreproducibility crisis in scientific research, with one of the proposals being\nto eliminate them in favor of Bayesian analyses. Defenders of the p-values have\ncountered that it is the improper use and errors in interpretation, rather than\nthe p-values themselves that are to blame. Similar exchanges about the role of\np-values have occurred with some regularity every 10 to 15 years since their\nformal introduction in statistical practice. The apparent contradiction between\nthe repeated failures in interpretation and continuous use of p-values suggest\nthat there is an inferential value in the computation of these values. In this\nwork we propose to attach a radical Bayesian interpretation to the number\ncomputed and reported as a p-value for the Generalized Linear Model, which has\nbeen the workhorse of applied statistical work. We introduce a decision\nanalytic framework for thresholding posterior tail areas (pi-values) which for\nany given Bayesian analysis will have a direct correspondence to p-values in\nnon-Bayesian approaches. Pi-values are non-controversial, posterior probability\nsummaries of treatment effects. A predictive probability argument is made to\njustify the exploration of the stochastic variation (replication probability)\nof p and pi-values and culminates into a concrete proposal for the synthesis of\nLikelihood and Bayesian approaches to data analyses that aim for\nreproducibility. We illustrate these concepts using the results of recent\nrandomized controlled trials in cardiometabolic and kidney diseases and provide\nR code for the implementation of the proposed methodology.\n",
        "title": "The Letter Pi : Bayesian interpretation of p-values, Reproducibility and\n  Considerations for Replication in the Generalized Linear Model",
        "texts": [
            "Figure 1 x2 Comparison of priors that test and priors that explore for a single parameter.",
            "Figure 2 Twice the tail area probabilities (π-values, in log10 scale) for the standardized normal distribution and the student t (St) distribution for different values of the degrees of freedom (individual panels) and values of the Wald statistic (Z-value). The dashed horizontal line corresponds to the 0.05 threshold.",
            "Figure 3 Volumetric slice plot of the critical threshold against the fractional gain, loss and opportunity cost. The figure shows slices of the four-dimensional space 𝜋𝑐𝑟𝑖𝑡 , 𝜖, 𝜖 ′ , 𝑐",
            "Figure 4 (A) Relation between the predictive π-value in the replicate dataset and the π-value in the initial experiment (-log10 scale) for the predictive distribution and the expected values of the of the RPD computed in the log10 and untransformed scale. The vertical lines from left to right correspond to conventional levels of statistical significance, 0.05, 0.01, 0.001 (B) Replication probability density for different initial p values (vertical line corresponds to p=0.05) (C) Standard deviation vs mean of the RPD in the log10 scale (D) Standard deviation vs mean of the RPD in the untransformed scale. In (C) and (D) the dotted line is the line of identity",
            "Figure 6 Likelihoods in the CREDENCE and DAPA-CKD trials for the primary (1o) outcome and Diabetic Ketoacidosis (DKA). X-axis : intercept of the Poisson model, y-axis treatment of SGLT2i therapy",
            "Figure 7 Posterior probabilities for the treatment effect of SGLT2i in the CREDENCE and DAPA-CKD trials for the primary kidney specific outcome and Diabetic Ketoacidosis (DKA). Gaussian Approximation is based on the material in Sections 2-3 and coincides with the maximum likelihood distribution, Flat Prior = MCMC analysis under the constant prior, EM=Expectation Maximization.",
            "Figure 8 Replication analysis of treatment effect in the SGLT2 kidney outcome trials. Top row , histograms of the predictive distribution of the treatment in the exact translated and replicated trials, approximate predictive density (Eq. 35) and non parametric kernel density estimates of replicated Bayesian analyses under two different priors. Middle row: histogram of observed p-values in the replicated trials, approximate predictive density of p and π-values (Eq. 37) and π-values obtained in replicate Bayesian analyses (MCMC – based on the NUTS sampler) using the schema in Eq. 36. For the Bayesian analysis, posterior samples from in replicated study were fit to a finite Gaussian mixture model and the parameters of the letter were used to calculate tail area probabilities. Bottom row cumulative density function of the p and π value based in Eq. 37. The vertical dashed lined in the two rows indicate the threshold of p=0.05.",
            "Table 1 Unnormalized densities for priors that test or explore, according to the hyperprior for the variance parameter",
            "Table 2 Decision table for a pure analyst with utility function 𝑈𝑎𝑛(𝑥), initial capital 𝐶 and symmetric gain or loss of 𝛼 after having obtained data 𝒚",
            "Table 3 Decision table for a client of statistical analyses with utility function 𝑈𝑐𝑜(𝑥), initial capital 𝑀, asymmetric gains and losses and a relative opportunity cost c. The fractional gain (𝜖) is restricted to be positive, while the relative loss (𝜖′) and opportunity cost are restricted to lie in the interval (0,1)",
            "Table 4 Decision table for a pure analyst with utility function 𝑈𝑎𝑛(𝑥), initial capital 𝐶 and symmetric gain or loss of 𝛼 after having obtained data 𝒚",
            "Table 5 Primary outcome and Diabetic Ketoacidosis (DKA) events in the CREDENCE (Canagliflozin) and DAPA-CKD (dapagliflozin) kidney outcome trials of Sodium Glucose Cotransporter Two inhibitors (SGLT2i). Table shows the hazard ratio reported in the trials, number of events and event rates (not reported in the DAPA-CKD trial for the DKA outcome)",
            "Table 6 Analysis of the primary outcome and Diabetic Ketoacidosis (DKA) in the CREDENCE (Canagliflozin) and DAPA-CKD (dapagliflozin) kidney outcome trials of Sodium Glucose Cotransporter Two inhibitors (SGLT2i). Table shows the point estimate and its standard error for the maximum likelihood method (which is also the approximate posterior for quadratic log-likelihoods) and Bayesian analysis under the flat and Student-t informative priors estimated by the NUTS sampler. Also shown in an approximate Bayesian analysis based on Expectation Maximization (EM) for the Student-t prior.",
            "Table 7 Analysis of the primary outcome and Diabetic Ketoacidosis (DKA) in the CREDENCE (Canagliflozin) and DAPA-CKD (dapagliflozin) kidney outcome trials of Sodium Glucose Cotransporter Two inhibitors (SGLT2i). Table shows the π-value for the maximum likelihood method (which is also the approximate π-value) and π-values from Bayesian analysis under the flat and Student-t informative priors estimated by the NUTS sampler. Also shown in an approximate Bayesian analysis based on Expectation Maximization (EM) for the Student-t prior."
        ],
        "imgs": [
            "$2305.00636v1-Figure1-1.png",
            "$2305.00636v1-Figure2-1.png",
            "$2305.00636v1-Figure3-1.png",
            "$2305.00636v1-Figure4-1.png",
            "$2305.00636v1-Figure6-1.png",
            "$2305.00636v1-Figure7-1.png",
            "$2305.00636v1-Figure8-1.png",
            "$2305.00636v1-Table1-1.png",
            "$2305.00636v1-Table2-1.png",
            "$2305.00636v1-Table3-1.png",
            "$2305.00636v1-Table4-1.png",
            "$2305.00636v1-Table5-1.png",
            "$2305.00636v1-Table6-1.png",
            "$2305.00636v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00638",
        "abstract": "  The minimal length of closed geodesics among all finite-type hyperbolic\nsurfaces with self-intersection number $k$ is $2\\cosh^{-1}(2k+1)$ for $k$\nsufficiently large, i.e. $k>10^{13350}$ by arXiv:2210.12966. In the present\npaper we will give an another proof independent of it and improve the lower\nbound $k>10^{13350}$ to $k>1750$.\n",
        "title": "Nonsimple closed geodesics with given intersection number on hyperbolic\n  surfaces",
        "texts": [
            "Figure 7: A corkscrew geodesic: the blue curve in the figure"
        ],
        "imgs": [
            "$2305.00638v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00639",
        "abstract": "  The term \"digital twin\" (DT) has become a key theme of the cyber-physical\nsystems (CPSs) area, while remaining vaguely defined as a virtual replica of an\nentity. This article identifies DT characteristics essential for enhancing CPS\nsecurity and discusses indicators to evaluate them.\n",
        "title": "Security-Enhancing Digital Twins: Characteristics, Indicators, and\n  Future Perspectives",
        "texts": [
            "Figure 1. Schematic structure of an automated industrial mixing process as an example of a CPS and its corresponding DT. Note: A concrete DT implementation may comprise a mix of the elements presented (depending on the security use case of interest) and the labels used in the illustration only indicate the general scope (e.g., control logic, SCADA software, and HMI software are all subsumed under “program logic”). Furthermore, real systems and peripheral devices may also be connected to the DT to address certain constraints such as emulator limitations.",
            "Figure 2. Characteristics of security-enhancing digital twins.",
            "Figure 3. Example of a synchronization session (assuming a discrete approximation of time, where T = {0, . . . , r} and tk ∈ T ). SEDTi is synchronized over the time span ts to te and follows the states of the respective real system, which is part of a CPS, with delay ∆ti = 2 time intervals. The synchronization session starts at t0 and ends at t10, with one outof-sync region in between (3 time intervals). pij and qij are the start and end of SEDTi being out of sync (relative to the time scale of the CPS)."
        ],
        "imgs": [
            "$2305.00639v3-Figure1-1.png",
            "$2305.00639v3-Figure2-1.png",
            "$2305.00639v3-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00644",
        "abstract": "  We introduce the concept of Procedural Content Generation via Knowledge\nTransformation (PCG-KT), a new lens and framework for characterizing PCG\nmethods and approaches in which content generation is enabled by the process of\nknowledge transformation -- transforming knowledge derived from one domain in\norder to apply it in another. Our work is motivated by a substantial number of\nrecent PCG works that focus on generating novel content via repurposing derived\nknowledge. Such works have involved, for example, performing transfer learning\non models trained on one game's content to adapt to another game's content, as\nwell as recombining different generative distributions to blend the content of\ntwo or more games. Such approaches arose in part due to limitations in PCG via\nMachine Learning (PCGML) such as producing generative models for games lacking\ntraining data and generating content for entirely new games. In this paper, we\ncategorize such approaches under this new lens of PCG-KT by offering a\ndefinition and framework for describing such methods and surveying existing\nworks using this framework. Finally, we conclude by highlighting open problems\nand directions for future research in this area.\n",
        "title": "Procedural Content Generation via Knowledge Transformation (PCG-KT)",
        "texts": [
            "Fig. 1: Example of our framework applied to an example from [9]. Initial Kid Icarus level data (raw knowledge G1) is used to derive a Markov level design model (extracted knowledge K1) via a derivation function (D). This knowledge is passed as input through a transformation function (T ), which uses a mapping and a Mario level to derive a Markov level design model for Super Mario Bros. levels (transformed knowledge K2), which can be used to output novel content.",
            "Fig. 14: Recommendation process for Pitako. Reproduced with permission from [71]. In this context, all sprites are associated with a game behavior e.g. shooter, chaser, random move, etc. In a), users provide a sprite to the game engine. In b), Pitako ranks the best sprite matches from other games (red circles) through data mining association (using confidence as a sorting criteria). In c), users have access to the ranks. In d), after inspecting the ranks, users select a new sprite. In e), users can inspect the two sprites in action—the one they provided and the one suggested by the system, imported from another game.",
            "Fig. 3: Example interpolation between Mega Man and Metroid. Reproduced with permission from [17]",
            "Fig. 4: Example output of a blended level design model.",
            "Fig. 5: Original game jumps (solid) vs generated jumps (dashdotted) extracted from blended domains. Reproduced with permission from [56].",
            "Fig. 6: Segments generated by conditioning on blend labels (shown below the 3rd row), using an original segment from Super Mario Bros. (SMB) (1st row), Kid Icarus (KI) (2nd) and Mega Man (MM) (3rd). First, second and third elements of the label correspond to SMB, KI and MM respectively. Bordered segments are originals. Reproduced with permission from [19]",
            "Fig. 8: Examples of the different final models and an output level for the different combinational creativity approaches when combining “castle” and “aboveground” Super Mario Bros. levels. Reproduced with permission from [35].",
            "TABLE I: The PCG-KT framework applied to three techniques: game blending, conceptual expansion and domain transfer.",
            "TABLE II: Summary of the PCG-KT works discussed in Section V."
        ],
        "imgs": [
            "$2305.00644v1-Figure1-1.png",
            "$2305.00644v1-Figure14-1.png",
            "$2305.00644v1-Figure3-1.png",
            "$2305.00644v1-Figure4-1.png",
            "$2305.00644v1-Figure5-1.png",
            "$2305.00644v1-Figure6-1.png",
            "$2305.00644v1-Figure8-1.png",
            "$2305.00644v1-TableI-1.png",
            "$2305.00644v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00647",
        "abstract": "  In big bang nucleosynthesis (BBN), the deuterium-tritium (DT) fusion\nreaction, D(T,n)$\\alpha$, enhanced by the 3/2$^+$ resonance, is responsible for\n99% of primordial $^4$He. This has been known for decades and has been well\ndocumented in the scientific literature. However, following the tradition\nadopted by authors of learned articles, it was stated in a matter-of-fact\nmanner and not emphasized; for most people, it has remained unknown. This\nhelium became a source for the subsequent creation of $\\geq$25% of the carbon\nand other heavier elements and, thus, a substantial fraction of our human\nbodies. (To be more precise than $\\geq$25% will require future simulation\nstudies on stellar nucleosynthesis.)\n  Also, without this resonance, controlled fusion energy would be beyond reach.\nFor example, for inertial confinement fusion (ICF), laser energy delivery for\nthe National Ignition Facility (NIF) would have to be approximately 70 times\nlarger for ignition.\n  Because the resonance enhances the DT fusion cross section a hundredfold, we\npropose that the 3/2$^+$ $^5$He excited state be referred to as the \"Bretscher\nstate\" in honor of the Manhattan Project scientist who discovered it, in\nanalogy with the well-known 7.6 MeV \"Hoyle state\" in $^{12}$C that allows for\nthe resonant 3$\\alpha$ formation.\n",
        "title": "DT fusion through the $^5$He $3/2+$ \"Bretscher state\" accounts for $\\ge\n  25\\%$ of our existence via nucleosynthesis and for the possibility of fusion\n  energy",
        "texts": [
            "Figure 4: An extract from Bretscher and French’s paper LA-582,2 February 15, 1946, providing the first identification of the DT resonance."
        ],
        "imgs": [
            "$2305.00647v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00648",
        "abstract": "  We study the effects of marginally spinful electron-electron interactions on\nthe low-energy instabilities and favorable phase transitions in a\ntwo-dimensional (2D) spin-$1/2$ semimetal that owns a quadratic band crossing\npoint (QBCP) parabolically touched by the upper and lower bands. In the\nframework of a renormalization group procedure, all sorts of interactions are\ntreated on the equal footing to derive the coupled energy-dependent evolutions\nof all interaction couplings that govern the low-energy properties. Deciphering\nthe essential physical information of such flows, we at first find that the\ntendencies of interaction parameters fall into three categories including Limit\ncase, Special case, and General case based on the initial conditions. In\naddition, the 2D QBCP system is attracted to several distinct kinds of fixed\npoints (FPs) in the interaction-parameter space, namely\n$\\mathrm{FP}_1^{+}$/$\\mathrm{FP}_2^{-}$, $\\mathrm{FP}_1^{\\pm}$/\n$\\mathrm{FP}_2^{\\pm}$/$\\mathrm{FP}_3^{\\pm}$, and\n$\\mathrm{FP}_1^{\\pm}/\\mathrm{FP}_3^{\\pm}/\\mathrm{FP}_{41,42,43}^{\\pm}$ with the\nsubscripts characterizing the features of FPs for the Limit, Special, and\nGeneral cases, respectively. Furthermore, as approaching these FPs, we\ndemonstrate that the spinful fermion-fermion interactions can induce a number\nof favorable instabilities accompanied by certain phase transitions.\nSpecifically, the quantum anomalous Hall (QAH), quantum spin Hall (QSH), and\nnematic (Nem.) site(bond) states are dominant for $\\mathrm{FP}_{1}^{\\pm}$,\n$\\mathrm{FP}_{2}^{\\pm}$, and $\\mathrm{FP}_{3}^{\\pm}$, respectively. Rather, QSH\nbecomes anisotropic nearby $\\mathrm{FP}_{41,42,43}^{\\pm}$ with one component\nleading and the others subleading. Besides, Nem.site(bond), chiral\nsuperconductivity, and nematic-spin-nematic (NSN.) site(bond) are subleading\ncandidates around these FPs.\n",
        "title": "Favorable phase transitions induced by spinful electron-electron\n  interactions in two-dimensional semimetal with a quadratic band crossing\n  point",
        "texts": [
            "FIG. 5. (Color online) Choosing (λ00, λ01, λ10, λ11, λ20, λ21) from six classes for an example instance (the basic results are similar for other choices) and showing the competition among different fixed points by tuning the magnitudes of three parameters: (a) λ11, λ21, and λ20 with t > 0 and the initial parameters (Class − i) = (10−3, 10−3, 10−3, 10−x, 10−y, 10−z), (b) λ00, λ10, and λ01 with t > 0 and the initial parameters (Class − i) = (10−x, 10−y, 10−z, 10−3, 10−3, 10−3), (c) λ11, λ21, and λ20 with t < 0 and the initial parameters (Class − i) = (10−3, 10−3, 10−3, 10−x, 10−y, 10−z), and (d) λ00, λ10, and λ01 with t < 0 and the initial parameters (Class− i) = (10−x, 10−y, 10−z, 10−3, 10−3, 10−3), where x, y, z serve as the magnitudes of the related parameters, as well as blue, red, and green correspond to the FP± 1 , FP± 2 , and FP± 3 , respectively.",
            "FIG. 7. (Color online) Competition among different fixed points with varying the magnitude of a single interaction parameter(horizontal axis) and fixing the others: (a) t > 0 and (b) t < 0, where the vertical axis characterizes the possibility for fixed points, as well as yellow, red, and green correspond to the FP± 1 , FP± 3 , and FP± 4 (FP± 41, FP± 42, or FP± 43), respectively.",
            "FIG. 8. (Color online) Energy-dependent susceptibilities of all candidate instabilities presented in Table I as approaching (a) FP+ 1 and (b) FP− 2 , respectively. The subscripts (x, y, z) serve as the distinct components of corresponding states.",
            "FIG. 9. (Color online) Stabilities of (a) the leading phases at t > 0, (b) the subleading phases at t > 0, and (c) the subleading phase at t < 0 nearby the fixed points in the Special case measured by the percentages with variation of initial conditions.",
            "TABLE II. Collections of the leading (blue) and subleading (red) phases as approaching the corresponding fixed points for both t > 0 and t < 0 situations. Hereby, L, S, and G cases are abbreviations for the Limit, Special, and General cases, respectively."
        ],
        "imgs": [
            "$2305.00648v1-Figure5-1.png",
            "$2305.00648v1-Figure7-1.png",
            "$2305.00648v1-Figure8-1.png",
            "$2305.00648v1-Figure9-1.png",
            "$2305.00648v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00650",
        "abstract": "  Deep neural networks often rely on spurious correlations to make predictions,\nwhich hinders generalization beyond training environments. For instance, models\nthat associate cats with bed backgrounds can fail to predict the existence of\ncats in other environments without beds. Mitigating spurious correlations is\ncrucial in building trustworthy models. However, the existing works lack\ntransparency to offer insights into the mitigation process. In this work, we\npropose an interpretable framework, Discover and Cure (DISC), to tackle the\nissue. With human-interpretable concepts, DISC iteratively 1) discovers\nunstable concepts across different environments as spurious attributes, then 2)\nintervenes on the training data using the discovered concepts to reduce\nspurious correlation. Across systematic experiments, DISC provides superior\ngeneralization ability and interpretability than the existing approaches.\nSpecifically, it outperforms the state-of-the-art methods on an object\nrecognition task and a skin-lesion classification task by 7.5% and 9.6%,\nrespectively. Additionally, we offer theoretical analysis and guarantees to\nunderstand the benefits of models trained by DISC. Code and data are available\nat https://github.com/Wuyxin/DISC.\n",
        "title": "Discover and Cure: Concept-aware Mitigation of Spurious Correlation",
        "texts": [
            "Figure 10. Comparison of clustering and group assignments on Waterbirds.",
            "Figure 2. DISC Framework on MetaShift dataset. DISC starts with clustering to construct data environments [G1, G2] that separates spurious attributes (we use 2 clusters per class to demonstrate). At t-th iteration, DISC computes the concept sensitivity and discovers (wrinkle, bed) and (bench, tree) as the spurious concepts of “cat” and “dog”, respectively. In the cure step, it mixes up the selected subset, e.g., dog images, with images of spurious concepts, e.g., “bed”, to remove the spurious correlation with an augmented dataset.",
            "Figure 3. Alignment of spurious attributes and spurious concepts.",
            "Figure 4. Training dynamics on ISIC. (a) Individual concept sensitivity vs. epoch. (b) Test AUROC and (c) The average concept sensitive of DISC and ERM during training.",
            "Figure 5. The concept sensitivity of spurious concepts on landbird class on Waterbirds at the beginning and the end of training.",
            "Figure 6. Visualization on the clustering and group assignments.",
            "Figure 7. Examples of concept images in the concept bank.",
            "Figure 8. Different interpretations on Waterbirds explaining “why the images are predicted as land birds?” . (a) Grad-CAM visualization. (b) The word score generated by Jain et al. (2022). (c) The averaged concept scores when generating counterfactuals using CCE (Abid et al., 2022). (d) The concept sensitivity of spurious concepts on landbird class before the after the DISC training.",
            "Figure 9. Worst Group Accuracy and Silhouette score w.r.t. number of clusters per class. For the ISIC dataset, we report the sensitivity result on one of the train-test splits.",
            "Table 1. Overall experimental results. The best results are bold and the second best results are underlined.",
            "Table 2. Experimental results of the ablation models.",
            "Table 4. A comprehensive concept list of the concept bank in this work.",
            "Table 5. Selected concept categories for each dataset",
            "Table 6. Hyper-parameters of DISC during training.",
            "Table 7. Comparison between interpretations of DISC and the existing methods.",
            "Table 8. All experimental results of the ablation of model design choices."
        ],
        "imgs": [
            "$2305.00650v1-Figure10-1.png",
            "$2305.00650v1-Figure2-1.png",
            "$2305.00650v1-Figure3-1.png",
            "$2305.00650v1-Figure4-1.png",
            "$2305.00650v1-Figure5-1.png",
            "$2305.00650v1-Figure6-1.png",
            "$2305.00650v1-Figure7-1.png",
            "$2305.00650v1-Figure8-1.png",
            "$2305.00650v1-Figure9-1.png",
            "$2305.00650v1-Table1-1.png",
            "$2305.00650v1-Table2-1.png",
            "$2305.00650v1-Table4-1.png",
            "$2305.00650v1-Table5-1.png",
            "$2305.00650v1-Table6-1.png",
            "$2305.00650v1-Table7-1.png",
            "$2305.00650v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00651",
        "abstract": "  Comprehensive studies are made on the six-state clock universality of two\nmodels using several approaches. We apply the machine-learning technique of\nphase classification to the antiferromagnetic (AF) three-state Potts model on\nthe square lattice with ferromagnetic next-nearest-neighbor (NNN) coupling and\nthe triangular AF Ising model with anisotropic NNN coupling to study two\nBerezinskii-Kosterlitz-Thouless transitions. We also use the Monte Carlo\nsimulation paying attention to the ratio of correlation functions of different\ndistances for these two models. The obtained results are compared with those of\nthe previous studies using the level-spectroscopy method. We directly show the\nsix-state clock universality for totally different systems with the\nmachine-learning study.\n",
        "title": "Comprehensive studies on the universality of BKT transitions --\n  Machine-learning study, Monte Carlo simulation, and Level-spectroscopy method",
        "texts": [
            "Figure 1. The schematic representation of Hamiltonian (2) on the triangular lattice [18]. The NN couplings are denoted by straight lines, whereas the anisotropic NNN couplings in two of the three directions are denoted by dotted lines.",
            "Figure 11. Helicity modulus (a) and correlation ratio (b) for XY model on the triangular lattice. The system sizes are 48, 72, 96, 144, and 192. In the plot of helicity modulus, we give the straight line (2/π)T . In the inset the FSS plots are given, where",
            "Figure 12. Helicity modulus (a) and correlation ratio (b) for the six-state clock model on the triangular lattice. The system sizes are 48, 72, 96, 144, and 192. In the plot of helicity modulus, we give the straight line (2/π)T . In the inset the FSS plots are given, where X(c, T ) = L/ exp(c1,2/ √ |T − T1,2|). For the helicity modulus, only the FSS for the high-temperature side is given.",
            "Figure 13. The output layer averaged over a test set as a function of T for the triangular lattice six-state clock model. The system sizes are L = 24, 36, and 48. The samples of T within the ranges 0.76 ≤ T ≤ 1.04, 1.21 ≤ T ≤ 1.31 and 1.52 ≤ T ≤ 1.8 are used for training data.",
            "Figure 2. The output layer for the AF three-state Potts model with F NNN coupling for r = 0.2 (a), r = 0.4 (b), and r = 0.8 (c), using the training data of the F six-state clock model. The system sizes are L = 32, 48, and 64.",
            "Figure 3. The output layer averaged over a test set as a function of T for the 2D sixstate clock model on the square lattice. The system sizes are L = 32, 48, and 64. The samples of T within the ranges 0.4 ≤ T ≤ 0.64, 0.78 ≤ T ≤ 0.82 and 0.96 ≤ T ≤ 1.2 are used for training data.",
            "Figure 4. The plot of the correlation ratio R(T ) for the AF three-state Potts model on the square lattice with F NNN coupling. In the inset, the FSS plots are given,",
            "Figure 6. The output layer for the triangular AF Ising model with anisotropic NNN coupling for r = 0.2 (a), r = 0.4 (b), and r = 0.8 (c), using the training data of the F six-state clock model. The system sizes are L = 24, 36, and 48.",
            "Figure 7. The plot of the correlation ratio R(T ) for the triangular AF Ising model with anisotropic NNN coupling. In the inset, the FSS plots are given, where"
        ],
        "imgs": [
            "$2305.00651v1-Figure1-1.png",
            "$2305.00651v1-Figure11-1.png",
            "$2305.00651v1-Figure12-1.png",
            "$2305.00651v1-Figure13-1.png",
            "$2305.00651v1-Figure2-1.png",
            "$2305.00651v1-Figure3-1.png",
            "$2305.00651v1-Figure4-1.png",
            "$2305.00651v1-Figure6-1.png",
            "$2305.00651v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00654",
        "abstract": "  Representation learning and exploration are among the key challenges for any\ndeep reinforcement learning agent. In this work, we provide a singular value\ndecomposition based method that can be used to obtain representations that\npreserve the underlying transition structure in the domain. Perhaps\ninterestingly, we show that these representations also capture the relative\nfrequency of state visitations, thereby providing an estimate for pseudo-counts\nfor free. To scale this decomposition method to large-scale domains, we provide\nan algorithm that never requires building the transition matrix, can make use\nof deep networks, and also permits mini-batch training. Further, we draw\ninspiration from predictive state representations and extend our decomposition\nmethod to partially observable environments. With experiments on multi-task\nsettings with partially observable domains, we show that the proposed method\ncan not only learn useful representation on DM-Lab-30 environments (that have\ninputs involving language instructions, pixel images, and rewards, among\nothers) but it can also be effective at hard exploration tasks in DM-Hard-8\nenvironments.\n",
        "title": "Representations and Exploration for Deep Reinforcement Learning using\n  Singular Value Decomposition",
        "texts": [
            "Figure 1. Consider top-k SVD decomposition of Pπ ≈ UkV′k, where V′k := ΣkVk > ∈ Rk×|S|. After decomposition, we consider the rows of Uk ∈ R|S|×k to be the k |S| dimensional representation for the states. Intuitively, if two states have similar next state transition distributions (teal rows Pπ [i] and Pπ [j]) then their representations (orange rows Uk[i] and Uk[j]) would also be similar. Notice that rows in Uk can be thought of as coefficients for combining the common basis vectors V′k to best estimate rows of Pπ (i.e., Pπ [i] ≈ Uk[i]V ′ k, and Pπ [j] ≈ Uk[j]V ′ k). Therefore, if Pπ [i] ≈ Pπ [j], then Uk[i]V ′ k ≈ Uk[j]V ′ k.",
            "Figure 10. This plot is analogous to Figure 2(D) and Figure 3(D) and extends the visualization technique to the POMDP setting. The ground truth state visitation is the same as in Figure 2(A). Top-left Bonuses constructed using learned representations of the history when p = 0.0. Top-right Bonuses constructed using learned representations of the history when p = 0.3. Bottom-left Bonuses constructed using learned representations of the history when p = 0.6. Bottom-right Bonuses constructed using learned representations of the history when p = 0.9. Legend: Brighter color indicates higher value bonus. Colors for each of the true state s is computed based on the average of bonuses from all (partial) histories that have s as the true underlying state at the end of their sequence of observations.",
            "Figure 11. Beliefs for a given trial under the POMDP setting with p = 0.0.",
            "Figure 12. Beliefs for a given trial under the POMDP setting with p = 0.3.",
            "Figure 13. Beliefs for a given trial under the POMDP setting with p = 0.6.",
            "Figure 14. Beliefs for a given trial under the POMDP setting with p = 0.9. Top-rows illustrate the snapshots of the observations that were given to the agent at timesteps t = {0, 25, 50, 75, 100, 125, 150, 175, 200}. The bottom rows denote the belief decoded from the representation of the history till timestep t. See text for more details. Legend: All plots on this page share the same legend. For the bottom rows, the deeper red color indicates a higher degree of belief. For the top row, the red color indicates the location of the agent. Higher p indicates a higher degree of partial-observability and thus more frames have the agent missing.",
            "Figure 15. Human normalized scores aggregated across all the 30 tasks on DMLab30 using 3 seeds",
            "Figure 16. Parameter Study: De-Rex Representation. Sensitivity on weighting the SVD loss in the representation (wloss) and the dimension of the SVD decomposition (d)",
            "Figure 17. Parameter Study: Lapacian Decomposition Representation. Sensitivity on weighting the decomposition loss in the representation (wloss) and the dimension of the SVD decomposition (d)",
            "Figure 18. Individual learning curves for De-Rex Representation, Laplacian decomposition, and the VMPO baseline methods on the DMLab30 tasks.",
            "Figure 2. (A) State visitation frequency in the data collected using a random policy. (B) Reference colors for the states in the 4rooms. (C) 2D Representations learned from 121-dimension tabular representation. (D) Bonus constructed using the learned representations. Legend: values are normalized between 0 and 1 and a darker color represents a lower value.",
            "Figure 3. (A) State visitation frequency in the data collected using a random policy. (B) Example of the domain image used as the state. (C) 2D representations learned from images (30x30x3) corresponding to the states. Reference colors for the states are the same as that used in Figure 2 (B). (D) Bonus constructed using the learned representations. Legend: values are normalized between 0 and 1 and a darker color represents a lower value.",
            "Figure 4. A low-rank system-dynamics matrix (adapted from the work by Singh et al. (2012)). Intuitively, row U[i] provides a good representation for history hi because it contains all the information that is sufficient to infer the outcome probability of all the futures (tests), given hi.",
            "Figure 5. Similar to Figure 2 and 3, we provide plots in Figure 9 (in Appendix D) to assess the quality of the learned distributions. However, it is not particularly informative for representations in higher dimensions. Therefore, as an alternative, we learned a classification model (using a single-layer neural network) that aims to classify the true underlying state at the end of the observation sequence of a given (partial) history using the representation of that (partial) history. This provides us with a proxy for how well can the learned representations be used as to decode beliefs over the underlying true state. Top-row illustrates the snapshots of the observations that were provided to the agent at timesteps t = {0, 25, 50, 75, 100, 125, 150, 175, 200} (notice the agent missing in some frames). The bottom rows denote the belief decoded from the representation of the history till timestep t. See text for more details. Legend: For the bottom row, the deeper red color indicates a higher degree of belief. For the top row, the red color indicates the location of the agent.",
            "Figure 6. Per-game comparison of (a) De-Rex representation vs. VMPO baseline and (b) Laplacian representation vs. VMPO baseline. We compare the final human normalized scores (i.e., average of the last 2% of the total 2 · 1010 training steps). Each score is averaged over three seeds.",
            "Figure 7. Learning curves for each task on the DM-Hard-8 suite (Gulcehre et al., 2019) in the multi-task setup. The shaded area corresponds to the minimum and maximum across three seeds. High variance in these environments is due to extremely sparse rewards (e.g., only at the end of completing a sequence of complex tasks the agent is able to get any reward). Because of this, if the agent is able to explore well enough it solves the task, or else it fails completely.",
            "Figure 8. Recall that observation Ot contains the previous action At−1. Let F1(Oi) be the embedding for the observation at timestep i. Let the belief state bt = F2 (F1(O0),F1(O1), ...,F1(Ot)) obtained using a forward LSTM. Let F3 be a reverse LSTM, such that b′t = F3(F1(OT ),F1(OT−1), ...,F1(Ot)). Then fθ1(ht) ∈ Rk in (15) is defined to be fθ1(bt), and gθ2(τt) is defined to be gθ2(b ′ t+1).",
            "Figure 9. This plot is analogous to Figure 2(B) and Figure 2(C) and extends the visualization technique to the POMDP setting. We plot the representations for all possible (partial) histories in the data collected Top-Left Ground truth color to represent the underlying true state s. Top-row Illustration of the learned three-dimensional representations for the histories in the 4-rooms (POMDP) setting where p = 0.0. To view 3D representations, we plot slices (XY, XZ, YZ) of the axes. Bottom-row Illustration of the learned three-dimensional representations for the histories in the 4-rooms (POMDP) setting where p = 0.3. To view 3D representations, we plot slices (XY, XZ, YZ) of the axes. Legend: (Partial) histories that have s as the true underlying state at the end of their sequence of observations have their representations share the same color as the reference color for s. Therefore, as there are multiple histories that end at a given state, for a single color of the true state there are multiple learned representations with the same color.",
            "Table 1. Hyper-parameters for De-Rex Representation for DMLab30",
            "Table 2. Hyper-parameters for De-Rex Exploration for DMHard-8"
        ],
        "imgs": [
            "$2305.00654v2-Figure1-1.png",
            "$2305.00654v2-Figure10-1.png",
            "$2305.00654v2-Figure11-1.png",
            "$2305.00654v2-Figure12-1.png",
            "$2305.00654v2-Figure13-1.png",
            "$2305.00654v2-Figure14-1.png",
            "$2305.00654v2-Figure15-1.png",
            "$2305.00654v2-Figure16-1.png",
            "$2305.00654v2-Figure17-1.png",
            "$2305.00654v2-Figure18-1.png",
            "$2305.00654v2-Figure2-1.png",
            "$2305.00654v2-Figure3-1.png",
            "$2305.00654v2-Figure4-1.png",
            "$2305.00654v2-Figure5-1.png",
            "$2305.00654v2-Figure6-1.png",
            "$2305.00654v2-Figure7-1.png",
            "$2305.00654v2-Figure8-1.png",
            "$2305.00654v2-Figure9-1.png",
            "$2305.00654v2-Table1-1.png",
            "$2305.00654v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00662",
        "abstract": "  We investigate the eigenstate thermalization in terms of a Hermitian operator\nand the complex eigenkets that follows Gaussian ensemble distribution. With the\nnon-Hermitian open bipartite system, there are, however, some global\nrestrictions such that the elements share some of the properties of Gaussian\northogonal ensemble in diagonal and off-diagonal perspective. Such global\nrestrictions enforce that one of the subsystem contains a nullspace with\nnon-defective degeneracies (the primary subsystem), and the another full-ranked\nsubsystem (the secondary subsystem). For the primary subsystem, the mixed\ndensities in Hermitian and non-Hermitian basis exhibits global fluctuation and\nunidirectional (non-Hermitian skin effect) fluctuation, respectively. The\nformer is due to the global restrictions of the whole system which plays teh\nrole of environmental disorder, while the latter is due to the nonlocal\nsymmetries which is allowed in the restricted Hilbert space.\n  We also investigate the integrablity-chaos transition with independent\nperturbations in terms of the Berry autocorrelation in semicalssical limit,\nwhere there is a phase space spanned by the momentum-like projection and the\nrange of local wave function.\n",
        "title": "Eigenstate thermalization in an open bipartite quantum system and the\n  semiclassical method base on correlations of adjacent local states in phase\n  space",
        "texts": [
            "Figure 1: The eye-notations in left-side represent the estimation for the expectation of Hamiltonian (observable) h = ψm,1ψ ∗ m′,1ψm,2ψ ∗ m′,2, which mix the two symmetry sectors that are classified by two eigenvalues λ1 and λ2. (e) A more interlaced pattern as a result of the selected parameter set: For upper and lower panels we restrict ψm,1ψ∗ m′,1 = ψm,2ψ∗ m′,2 = 0 and ψm,1ψ∗ m′,2 = ψm,2ψ∗ m′,1 = 0 as indicated by the black lines with cross. In both these two cases, the transverse correlation plays the main role, i.e., the asymptotical degeneration between nonintegrable eigenstates. Also, these two cases share the almost same spectral (the only difference is that there is a small sink in the spectral of imaginary part of eigenvalues for the latter case). While the spetrals for the real part of eigenvalues all reflect the thermalization (N ∼ (0, 10.03962) and N ∼ (1.77636 × 10−15, 16.91982) for the two cases, repectively).",
            "Figure 11: Variances of the complete thermalized case and uncompletely thermalized case with different sample range determined by the (power of) system size L. We set K = 1 here. The line in (a)-(d) are 1 3LK 2, 13L 3K2, (ϕg − 1)LK2, (ϕg − 1)L3K2, respectively. The vertical dashed lines labels the prime numbers.",
            "Figure 12: (Left) Schematic diagram for the phase space where I(p,q) is a classical action. (Right) The segments for the method CALP where k is the variable in centroid here.",
            "Figure 14: Level statistic of GOE.",
            "Figure 16: Level statistic of GUE.",
            "Figure 17: The products of eigenvectors of different eigenvalues, where the diagonal (off-diagonal) positions representing the products between the same (different) speices. (a) ψ∗ iℓ,1ψjℓ′,1 + ψ∗ iℓ,2ψjℓ′,2, (b) ψ ∗ iℓ,1ψjℓ′,1, (c) ψ∗ iℓ,2ψjℓ′,2, (d) ψ ∗ iℓ,1ψjℓ′,2, (e) ψ ∗ iℓ,2ψjℓ′,1, (f) (ψ ∗ iℓ,1+ψ ∗ iℓ,2)(ψjℓ′,1+ψjℓ′,2) = ψ∗ iℓ,1ψjℓ′,1+ψ ∗ iℓ,2ψjℓ′,2+ψ ∗ iℓ,1ψjℓ′,2+ ψ∗ iℓ,2ψjℓ′,1, .",
            "Figure 18: (a) Diagonal elements of H. (b) Eigenvalues of H and O, which correspond to integrable eigenstates. (c) Elements in Hℓℓ′ with ℓ′ = 3, 8. (d) Variance of matrix A with sample dimension ds reduced to onedimensional form according to the first principal component. The red dot corresponds to the ds = 1 where the variance is exactly H2 ℓℓ = 0.04 without any error.",
            "Figure 19: (a) ψ∗ iℓ,1ψiℓ′,1 +ψ∗ iℓ,2ψiℓ′,2;(b) ψ ∗ jℓ,1ψjℓ′,1 +ψ∗ jℓ,2ψjℓ′,2; The panels (c) and (d) are the difference and summation of panels (a) and (b), respectively.",
            "Figure 20: (a) Eigenvectors in sparse structure results in large difference between distinct species, and thus leads to maximal rank and each one of the corresponding nondegenerated eigenstates corresponds to a good quantum number. (b) The eigenvector set with the fluctuation part being removed, in constrast to (a). This results in lower energy difference between unperturbed (integrable) eigenstates and perturbed (nonintegrable) eigenstates.",
            "Figure 3: (a)-(b) Real part and imaginary part of the approximated GOE matrix where the parameters of product variables are determined in terms of the second and fourth moments of GOE. (c)-(d) ((e)-(f)) show the real (imaginary) part of eigenvalues and its distribution. For lower D, we use the smoothed histogram diagram to reflect the probability density distribution. The distributions of real part and imaginary part of element follow N (5.55112 × 10−17, 0.237598) and N (−1.38778 × 10−17, 0.0813476), respectively. While the standard GOE follows N (0, 0.15625).",
            "Figure 4: The same with Fig.3 but for D = 6. The distributions of real part and imaginary part of element follow N (0, 0.904249) and N (1.23358 × 10−16, 0.839433), respectively. While the standard GOE follows N (0, 0.0648148).",
            "Figure 5: The same with Fig.3 but for D = 8. The distributions of real part and imaginary part of element follow N (1.11022 × 10−16, 4.09099) and N (5.55112 × 10−17, 4.05583), respectively. While the standard GOE follows N (0, 0.0351563).",
            "Figure 6: (a)-(c) show the results for D = 4, where the entries distribution follows N (−0.0709444, 0.1623832). (d)-(f) show the results for D = 8, where the distribution of elements of H follows N (−0.0709444, 0.1623832). (g)-(i) show the results for D = 14, where the distribution of elements of H follows N (−0.0530054, 0.08465552). Comparing to the method that identifying the parameters by considering the second the fourth moments of Gaussian variables ψm,i, as shown in Fig.3, the method that matching the diagonal elements of the corresponding singular matrix is more efficient as it only require to solve D/2 parameters. The eigenvalue distribution is also different from that in Fig.3 and Fig.2, where the probability density distribution (the spectral) for the eigenvalues becomes asymmetry, and a three-peak pattern appears in the spectral with the increase of D. For a comparasion, we note that for standard GOE the distributions follow N (0, 0.15625), N (0, 0.0351563), and N (0, 0.022), for D = 4, 8, 10, respectively. (j)The ratios R1 and R2 for these three sizes.",
            "Figure 7: The same with Fig.6 where (a)-(c), (d)-(f), (g)-(h) correspond to D = 20, 30, 34, respectively. With the increase of D, R2 exponentially increase while R1 approaches to one with logarithmically slow speed, e.g., for D = 20, R2 = 1239.18,R1 = 1.43874.",
            "Figure 8: (a,b) Spectrum for the |ψiℓ,1(2)|2 and |ψiℓ,1(2)|4, respectively. (c,d)Inverse participation ratio (IPR) and normalized participation ratio (NPR) for all eigenstates sampled from ψiℓ,1(2), respectively, for integrable case. (e,f)The same with (c,d) but for nonintegrable case.",
            "Figure 9: The first column shows the variance of local observable Ô1 with different sample ranges. The second column shows ratio of variances of nearby system sizes Ln"
        ],
        "imgs": [
            "$2305.00662v3-Figure1-1.png",
            "$2305.00662v3-Figure11-1.png",
            "$2305.00662v3-Figure12-1.png",
            "$2305.00662v3-Figure14-1.png",
            "$2305.00662v3-Figure16-1.png",
            "$2305.00662v3-Figure17-1.png",
            "$2305.00662v3-Figure18-1.png",
            "$2305.00662v3-Figure19-1.png",
            "$2305.00662v3-Figure20-1.png",
            "$2305.00662v3-Figure3-1.png",
            "$2305.00662v3-Figure4-1.png",
            "$2305.00662v3-Figure5-1.png",
            "$2305.00662v3-Figure6-1.png",
            "$2305.00662v3-Figure7-1.png",
            "$2305.00662v3-Figure8-1.png",
            "$2305.00662v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00663",
        "abstract": "  Researchers commonly believe that neural networks model a high-dimensional\nspace but cannot give a clear definition of this space. What is this space?\nWhat is its dimension? And does it has finite dimensions? In this paper, we\ndevelop a plausible theory on interpreting neural networks in terms of the role\nof activation functions in neural networks and define a high-dimensional (more\nprecisely, an infinite-dimensional) space that neural networks including\ndeep-learning networks could create. We show that the activation function acts\nas a magnifying function that maps the low-dimensional linear space into an\ninfinite-dimensional space, which can distinctly identify the polynomial\napproximation of any multivariate continuous function of the variable values\nbeing the same features of the given dataset. Given a dataset with each example\nof $d$ features $f_1$, $f_2$, $\\cdots$, $f_d$, we believe that neural networks\nmodel a special space with infinite dimensions, each of which is a monomial\n$$\\prod_{i_1, i_2, \\cdots, i_d} f_1^{i_1} f_2^{i_2} \\cdots f_d^{i_d}$$ for some\nnon-negative integers ${i_1, i_2, \\cdots, i_d} \\in\n\\mathbb{Z}_{0}^{+}=\\{0,1,2,3,\\ldots\\} $. We term such an infinite-dimensional\nspace a $\\textit{ Super Space (SS)}$. We see such a dimension as the minimum\ninformation unit. Every neuron node previously through an activation layer in\nneural networks is a $\\textit{ Super Plane (SP) }$, which is actually a\npolynomial of infinite degree. This $\\textit{ Super Space }$ is something like\na coordinate system, in which every multivalue function can be represented by a\n$\\textit{ Super Plane }$. We also show that training NNs could at least be\nreduced to solving a system of nonlinear equations. %solve sets of nonlinear\nequations\n",
        "title": "Activation Functions Not To Active: A Plausible Theory on Interpreting\n  Neural Networks",
        "texts": [
            "Figure 1: The function of an activation function is just like that of a nozzle",
            "Figure 3: An Alternative to the NN for regression",
            "Table 1: A fake dataset for a toy example of classification"
        ],
        "imgs": [
            "$2305.00663v2-Figure1-1.png",
            "$2305.00663v2-Figure3-1.png",
            "$2305.00663v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00664",
        "abstract": "  Non-IID transfer learning on graphs is crucial in many high-stakes domains.\nThe majority of existing works assume stationary distribution for both source\nand target domains. However, real-world graphs are intrinsically dynamic,\npresenting challenges in terms of domain evolution and dynamic discrepancy\nbetween source and target domains. To bridge the gap, we shift the problem to\nthe dynamic setting and pose the question: given the label-rich source graphs\nand the label-scarce target graphs both observed in previous T timestamps, how\ncan we effectively characterize the evolving domain discrepancy and optimize\nthe generalization performance of the target domain at the incoming T+1\ntimestamp? To answer it, we propose a generalization bound for dynamic non-IID\ntransfer learning on graphs, which implies the generalization performance is\ndominated by domain evolution and domain discrepancy between source and target\ngraphs. Inspired by the theoretical results, we introduce a novel generic\nframework named EvoluNet. It leverages a transformer-based temporal encoding\nmodule to model temporal information of the evolving domains and then uses a\ndynamic domain unification module to efficiently learn domain-invariant\nrepresentations across the source and target domains. Finally, EvoluNet\noutperforms the state-of-the-art models by up to 12.1%, demonstrating its\neffectiveness in transferring knowledge from dynamic source graphs to dynamic\ntarget graphs.\n",
        "title": "EvoluNet: Advancing Dynamic Non-IID Transfer Learning on Graphs",
        "texts": [
            "Figure 1: An illustrative example of dynamic transfer learning across book review network and IMDb review network. As an example, IMDb launched a new series in 2022, The Lord of the Rings: The Rings of Power, while the original book of this series has been published for decades. It is very natural to transfer knowledge from the information-rich source domain (book review network) to the information-scarce target domain (IMDb review network) across time in order to solve the target task (IMDb review prediction) at G (𝑇+1)",
            "Figure 2: The proposed DyTrans framework.",
            "Figure 3: An illustrative example of why multi-resolution temporal encoding is important.",
            "Figure 4: Hyper-parameter analysis on Benchmark 2 with respect to 𝑑𝑢 and 𝑑 .",
            "Table 1: Symbols and notations.",
            "Table 3: Comparison of different methods in node classification task using 5 labeled samples per class (AUC). The first four models are Classical GNN models and the next four are Temporal GNNs, we show their fine-tuned results on the target domain. The remaining two models are for transfer learning, we show results of knowledge transfer from source to target domain.",
            "Table 4: Ablation study (AUC ± 95% confidence intervals)."
        ],
        "imgs": [
            "$2305.00664v4-Figure1-1.png",
            "$2305.00664v4-Figure2-1.png",
            "$2305.00664v4-Figure3-1.png",
            "$2305.00664v4-Figure4-1.png",
            "$2305.00664v4-Table1-1.png",
            "$2305.00664v4-Table3-1.png",
            "$2305.00664v4-Table4-1.png"
        ]
    },
    {
        "id": "2305.00665",
        "abstract": "  We study the inclusive decay widths of singly heavy baryons with the improved\nbag model in which the unwanted center-of-mass motion is removed. Additional\ninsight is gained by comparing the charmed and bottom baryons. We discuss the\nrunning of the baryon matrix elements and compare the results with the\nnon-relativistic quark model (NRQM). While the calculated two-quark operator\nelements are compatible with the literature, those of the four-quark ones\ndeviate largely. In particular, the heavy quark limit holds reasonably well in\nthe bag model for four-quark operator matrix elements but is badly broken in\nthe NRQM. We predict $1-\\tau(\\Omega_b)/ \\tau(\\Lambda_b^0) = (8.34\\pm2.22)\\%$ in\naccordance with the current experimental value of $(11.5^{+12.2}_{-11.6})\\%$\nand compatible with $(13.2\\pm 4.7)\\%$ obtained in the NRQM. We find an\nexcellent agreement between theory and experiment for the lifetimes of bottom\nbaryons. We confirm that $\\Omega_c^0$ could live longer than $\\Lambda_c^+$\nafter the dimension-7 four-quark operators are taken into account. We recommend\nto measure some semileptonic inclusive branching fractions in the forthcoming\nexperiments to discern different approaches. For example, we obtain ${\\cal BF}\n(\\Xi_c^+ \\to X e^+ \\nu_e) = (8.57\\pm 0.49)\\% $ and ${\\cal BF} (\\Omega_c^0 \\to X\ne^+ \\nu_e) = (1.88\\pm 1.69)\\% $ in sharp contrast to ${\\cal BF} (\\Xi_c^+ \\to X\ne^+ \\nu_e) = (12.74^{+2.54}_{-2.45})\\% $ and ${\\cal BF} (\\Omega_c^0 \\to X e^+\n\\nu_e) = (7.59^{+2.49}_{-2.24})\\% $ found in the NRQM.\n",
        "title": "Study of singly heavy baryon lifetimes",
        "texts": [
            "FIG. 1: The leading-order Feynman diagram for C3, where the ⊗ represents the insertion of the effective Hamiltonian for Q→ q1q2q3.",
            "FIG. 2: The topological diagrams for the spectator effects: (a) W -exchange, (b) destructive (constructive) Pauli interference and (c) constructive (destructive) Pauli interference at the dimension-6 (dimension-7) level. There is no 4-point vertices between the W bosons and quarks in the diagrams (b) and (c).",
            "TABLE I: Evolution of the charmed baryon lifetimes measured in units of fs.",
            "TABLE III: The parameters λ1 and λ2 calculated in the bag model in units of GeV2.",
            "TABLE IV: The two-quark operator matrix elements, where µ2 G,π and ρ3D are in units of 10−1GeV2 and 10−2GeV3, respectively. The parameters of µ2 G and ρ3D are evaluated at the hadronic scale µH in the BM. Here, the numbers in the parentheses are the uncertainties counting backward in digits, for example, 4.42(24) = 4.42 ± 0.24. The values of the NRQM are quoted from Refs. [23, 24].",
            "TABLE V: The matrix elements of the four-quark operators in units of 10−3 GeV3 with qI = u, d evaluated at the hadronic scale µH . The results of the NRQM are quoted from Refs. [23] and [24] for charm and beauty baryons, respectively.",
            "TABLE VI: Results for the lifetimes of heavy baryons, where the decay widths and lifetimes are in units of 10−12 (10−13) GeV and 10−13s (10−12s ), respectively, for Bc (Bb). Uncertainties arising from mQ, µH , I q BQ and the deviation of full QCD from HQET are denoted by the subscripts m, µ, 4 and s, respectively. The NLO values of Γ7 are taken to be the same as the ones at the LO.",
            "TABLE VII: Comparison of our results with Ref. [23] obtained in the pole mass scheme for charmed baryons and Ref. [24] in the kinetic mass scheme for bottom baryons, of which the uncertainties are added quadratically. The baryon matrix elements in Refs. [23, 24] are evaluated using the NRQM. Experimental results are quoted from Ref. [1] and Table I. The lifetimes are in units of 10−13s for Bc and 10−12s for Bb."
        ],
        "imgs": [
            "$2305.00665v2-Figure1-1.png",
            "$2305.00665v2-Figure2-1.png",
            "$2305.00665v2-TableI-1.png",
            "$2305.00665v2-TableIII-1.png",
            "$2305.00665v2-TableIV-1.png",
            "$2305.00665v2-TableV-1.png",
            "$2305.00665v2-TableVI-1.png",
            "$2305.00665v2-TableVII-1.png"
        ]
    },
    {
        "id": "2305.00666",
        "abstract": "  In recent years, remarkable results have been achieved in self-supervised\naction recognition using skeleton sequences with contrastive learning. It has\nbeen observed that the semantic distinction of human action features is often\nrepresented by local body parts, such as legs or hands, which are advantageous\nfor skeleton-based action recognition. This paper proposes an attention-based\ncontrastive learning framework for skeleton representation learning, called\nSkeAttnCLR, which integrates local similarity and global features for\nskeleton-based action representations. To achieve this, a multi-head attention\nmask module is employed to learn the soft attention mask features from the\nskeletons, suppressing non-salient local features while accentuating local\nsalient features, thereby bringing similar local features closer in the feature\nspace. Additionally, ample contrastive pairs are generated by expanding\ncontrastive pairs based on salient and non-salient features with global\nfeatures, which guide the network to learn the semantic representations of the\nentire skeleton. Therefore, with the attention mask mechanism, SkeAttnCLR\nlearns local features under different data augmentation views. The experiment\nresults demonstrate that the inclusion of local feature similarity\nsignificantly enhances skeleton-based action representation. Our proposed\nSkeAttnCLR outperforms state-of-the-art methods on NTURGB+D, NTU120-RGB+D, and\nPKU-MMD datasets.\n",
        "title": "Part Aware Contrastive Learning for Self-Supervised Action Recognition",
        "texts": [
            "Figure 1: The motivation of our method. Although input skeletons (a) belong to the same movement category, there exists a significant gap between their skeleton sequences in feature space in (b). However, by considering local feature similarity, as shown by the red points in (c), the distance between two actions of the same semantic category becomes shorter in feature space. Therefore, we aim to extend local similarity-based contrastive learning to complement global contrastive learning, in order to bring samples with similar local features closer in feature space. Through the attention mechanism, the local similarity is discriminated and the network focuses on the changes in human action parts, such as leg movements (as highlighted in red). This approach is expected to be more conducive to learning local representations that are beneficial for accurate action recognition.",
            "Figure 4: (a) The normal dot product in the calculation of LInfo . (b) and (c) show the attention affected dot product in the calculation of Ls and Lns.",
            "Figure 5: The t-SNE visualization results using the NTU-60 dataset with xsub settings. (a), (b), and (c) indicate the visualizations of SkeAttnCLR in joint, bone, and motion separately. (d), (e), and (f) show the visualization results of the baseline (SkeletonCLR).",
            "Figure 6: The t-SNE visualization results using the NTU-60 dataset with xview settings. (a), (b), and (c) indicate the visualizations of SkeAttnCLR in joint, bone, and motion separately. (d), (e), and (f) show the visualization results of the baseline (SkeletonCLR).",
            "Table 1: Linear evaluation comparisons with the baseline using the same backbone, where J, M, and B indicate joint, motion, and bone, 3S means three streams fusion, ∗ indicates that results obtained with our settings.",
            "Table 10: Norm data augmentation settings.",
            "Table 11: Data mixing augmentation settings.",
            "Table 12: Parameters setting for ST-GCN.",
            "Table 13: Parameters setting for BIGRU.",
            "Table 14: Parameters setting for Transformer (DSTA).",
            "Table 15: Hyperparameter λ experiments on NTU-60 dataset.",
            "Table 16: Ablation experiments with parameters µ on NTU-60 dataset.",
            "Table 17: Abliation study for multi-head self-attention on NTU-60 dataset.",
            "Table 18: Experiment result of transfer learning by NTU60 to PKU on Joint level.",
            "Table 2: Linear evaluation comparisons with different backbones on NTU-60 dataset. J, M, and B indicate joint, motion, and bone.",
            "Table 3: Linear evaluation comparisons with other methods using the same backbone, J indicates joint, 3S means three streams fusion.",
            "Table 4: KNN evaluation results on NTU-RGB+D dataset.",
            "Table 5: Semi-supervised evaluation results.",
            "Table 6: Fully finetune evaluation results, J means joint, 3S indicates three streams.",
            "Table 7: Ablation study of loss function designs on NTU-60 dataset Joint level.",
            "Table 8: Parameters setting for contrastive learning framework.",
            "Table 9: SGD optimizer settings."
        ],
        "imgs": [
            "$2305.00666v2-Figure1-1.png",
            "$2305.00666v2-Figure4-1.png",
            "$2305.00666v2-Figure5-1.png",
            "$2305.00666v2-Figure6-1.png",
            "$2305.00666v2-Table1-1.png",
            "$2305.00666v2-Table10-1.png",
            "$2305.00666v2-Table11-1.png",
            "$2305.00666v2-Table12-1.png",
            "$2305.00666v2-Table13-1.png",
            "$2305.00666v2-Table14-1.png",
            "$2305.00666v2-Table15-1.png",
            "$2305.00666v2-Table16-1.png",
            "$2305.00666v2-Table17-1.png",
            "$2305.00666v2-Table18-1.png",
            "$2305.00666v2-Table2-1.png",
            "$2305.00666v2-Table3-1.png",
            "$2305.00666v2-Table4-1.png",
            "$2305.00666v2-Table5-1.png",
            "$2305.00666v2-Table6-1.png",
            "$2305.00666v2-Table7-1.png",
            "$2305.00666v2-Table8-1.png",
            "$2305.00666v2-Table9-1.png"
        ]
    },
    {
        "id": "2305.00667",
        "abstract": "  The reconfigurable intelligent surface (RIS) is a promising technology that\nenables wireless communication systems to achieve improved performance by\nintelligently manipulating wireless channels. In this paper, we consider the\nsum-rate maximization problem in a downlink multi-user\nmulti-input-single-output (MISO) channel via space-division multiple access\n(SDMA). Two major challenges of this problem are the high dimensionality due to\nthe large number of RIS elements and the difficulty to obtain the full channel\nstate information (CSI), which is assumed known in many algorithms proposed in\nthe literature. Instead, we propose a hybrid machine learning approach using\nthe weighted minimum mean squared error (WMMSE) precoder at the base station\n(BS) and a dedicated neural network (NN) architecture, RISnet, for RIS\nconfiguration. The RISnet has a good scalability to optimize 1296 RIS elements\nand requires partial CSI of only 16 RIS elements as input. We show it achieves\na high performance with low requirement for channel estimation for geometric\nchannel models obtained with ray-tracing simulation. The unsupervised learning\nlets the RISnet find an optimized RIS configuration by itself. Numerical\nresults show that a trained model configures the RIS with low computational\neffort, considerably outperforms the baselines, and can work with discrete\nphase shifts.\n",
        "title": "RISnet: A Scalable Approach for Reconfigurable Intelligent Surface\n  Optimization with Partial CSI",
        "texts": [
            "Figure 2. Information processing of layers in RISnet.",
            "Figure 3. Application of 9 filters to expand from one anchor RIS element to 9 RIS elements, where f5 is the channel feature of RIS element 5. Indices of user and layer are omitted for simplicity since the expansion is for RIS elements.",
            "Figure 4. Expansion of considered RIS elements. Blue: anchor RIS elements. Lower left corner: example of the expansion to extend the anchor RIS elements from the blue element to the adjacent elements (light blue elements in Subfigure (a) and all elements in Subfigure (b)).",
            "Figure 6. Training results with different spatial correlation between RIS elements.",
            "Figure 7. Test results with different spatial correlation between RIS elements and settings (Det. = deterministic ray-tracing model, I.i.d. = i.i.d. complex Gaussian channel gain)."
        ],
        "imgs": [
            "$2305.00667v2-Figure2-1.png",
            "$2305.00667v2-Figure3-1.png",
            "$2305.00667v2-Figure4-1.png",
            "$2305.00667v2-Figure6-1.png",
            "$2305.00667v2-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00668",
        "abstract": "  We report a theoretical derivation of the Cabibbo-Kobayashi-Maskawa (CKM)\nmatrix parameters and the accompanying mixing angles. These results are arrived\nat from the exceptional Jordan algebra applied to quark states, and from\nexpressing flavor eigenstates (i.e. left-chiral states) as superposition of\nmass eigenstates (i.e. the right-chiral states) weighted by square-root of\nmass. Flavor mixing for quarks is mediated by the square-root mass eigenstates,\nand the mass ratios used have been derived in earlier work from a left-right\nsymmetric extension of the standard model. This permits a construction of the\nCKM matrix from first principles. There exist only four normed division\nalgebras, they can be listed as follows - the real numbers $\\mathbb{R}$, the\ncomplex numbers $\\mathbb{C}$, the quaternions $\\mathbb{H}$ and the octonions\n$\\mathbb{O}$. The first three algebras are fairly well known; however,\noctonions as algebra are less studied. Recent research has pointed towards the\nimportance of octonions in the study of high energy physics. Clifford algebras\nand the standard model are being studied closely. The main advantage of this\napproach is that the spinor representations of the fundamental fermions can be\nconstructed easily here as the left ideals of the algebra. Also the action of\nvarious Spin Groups on these representations too can be studied easily. In this\nwork, we build on some recent advances in the field and try to determine the\nCKM angles from an algebraic framework. We obtain the mixing angle values as\n$\\theta_{12}=11.093^o, \\theta_{13}=0.172^o, \\theta_{23}=4.054^o$. In\ncomparison, the corresponding experimentally measured values for these angles\nare $13.04^o \\pm 0.05^o, 0.201^o \\pm 0.011^o, 2.38^o \\pm 0.06^o $. The\nagreement of theory with experiment is likely to improve when running of quark\nmasses is taken into account.\n",
        "title": "CKM matrix parameters from the exceptional Jordan algebra",
        "texts": [
            "Table 1: Forces and force carriers",
            "Table 2: (a)Up-Isospin particles ; (b)Down-Isospin Particles .",
            "Table 5: Particles as the representations of the Exterior Algebra.[20]"
        ],
        "imgs": [
            "$2305.00668v1-Table1-1.png",
            "$2305.00668v1-Table2-1.png",
            "$2305.00668v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00671",
        "abstract": "  The lightweight MLP-based decoder has become increasingly promising for\nsemantic segmentation. However, the channel-wise MLP cannot expand the\nreceptive fields, lacking the context modeling capacity, which is critical to\nsemantic segmentation. In this paper, we propose a parametric-free patch rotate\noperation to reorganize the pixels spatially. It first divides the feature map\ninto multiple groups and then rotates the patches within each group. Based on\nthe proposed patch rotate operation, we design a novel segmentation network,\nnamed PRSeg, which includes an off-the-shelf backbone and a lightweight Patch\nRotate MLP decoder containing multiple Dynamic Patch Rotate Blocks\n(DPR-Blocks). In each DPR-Block, the fully connected layer is performed\nfollowing a Patch Rotate Module (PRM) to exchange spatial information between\npixels. Specifically, in PRM, the feature map is first split into the reserved\npart and rotated part along the channel dimension according to the predicted\nprobability of the Dynamic Channel Selection Module (DCSM), and our proposed\npatch rotate operation is only performed on the rotated part. Extensive\nexperiments on ADE20K, Cityscapes and COCO-Stuff 10K datasets prove the\neffectiveness of our approach. We expect that our PRSeg can promote the\ndevelopment of MLP-based decoder in semantic segmentation.\n",
        "title": "PRSeg: A Lightweight Patch Rotate MLP Decoder for Semantic Segmentation",
        "texts": [
            "Fig. 1: Model performance vs. model efficiency on the ADE20K validation set. Results are presented for single models with multi-scale inference. Through the MLP decoder, PRSeg achieves a new state-of-the-art 54.16% mIoU while being more efficient than previous methods.",
            "Fig. 2: The overall architecture of our single-scale Patch Rotate MLP decoder (PRSeg-S). Its core design is the DPR-Block, which consists of a Dynamic Channel Selection Module (DCSM), a Patch Rotate Module (PRM) and a channel-wise Fully Connected (FC) layer.",
            "Fig. 3: The overall architecture of our multi-scale Patch Rotate MLP decoder (PRSeg-M), which is a multi-scale extension of PRSeg-S with parallel branches , each of which is composed of several DPR-Blocks.",
            "Fig. 4: Qualitative visualization of SegFormer (top) and our PRSeg-M (bottom). The examples are chosen from ADE20K dataset. Compared to SegFormer, our PRSeg-M reduces long-range context fusion errors as highlighted in white box.",
            "Fig. 5: (a) Comparisons with different channel selection manners. (b) Effect of group size in rotate operation. (c) Effect of the ratio of rotated channels. (d) Effect of the weight of regulation loss in total loss function.",
            "TABLE I: Detailed training settings for each dataset with different backbone models. The “Common” item shows the settings shared for all the backbones.",
            "TABLE II: Comparison with the state-of-the-art methods on the ADE20K dataset. “SS” and “MS” indicate single-scale inference and multi-scale inference, respectively.",
            "TABLE III: Comparison with the state-of-the-art methods on the Cityscapes validation set.",
            "TABLE IV: Comparison with the state-of-the-art methods on the COCO-Stuff 10K dataset.",
            "TABLE IX: Ablation study on the number of blocks. A block consists of a Dynamic Channel Selection Module (DCSM), a Patch Rotate Module (PRM) and a channel-wise Fully Connected (FC) layer. The following results are obtained on ADE20K with a decoder of dimension 512.",
            "TABLE V: Analysis of FPS. Except for SegFormer and PRSeg-M, which use straight architecture ResNet-50 (dilation=8) as their backbone, all other methods adopt the pyramidal architecture ResNet-50.",
            "TABLE VI: SegFormer-ResNet-50 multi-scale inference performance on ADE20K dataset.",
            "TABLE VII: Ablation study on the effect of each component in our DPR-Block.",
            "TABLE VIII: Ablation study on patch rotation strategy in our Rotate Operation."
        ],
        "imgs": [
            "$2305.00671v1-Figure1-1.png",
            "$2305.00671v1-Figure2-1.png",
            "$2305.00671v1-Figure3-1.png",
            "$2305.00671v1-Figure4-1.png",
            "$2305.00671v1-Figure5-1.png",
            "$2305.00671v1-TableI-1.png",
            "$2305.00671v1-TableII-1.png",
            "$2305.00671v1-TableIII-1.png",
            "$2305.00671v1-TableIV-1.png",
            "$2305.00671v1-TableIX-1.png",
            "$2305.00671v1-TableV-1.png",
            "$2305.00671v1-TableVI-1.png",
            "$2305.00671v1-TableVII-1.png",
            "$2305.00671v1-TableVIII-1.png"
        ]
    },
    {
        "id": "2305.00672",
        "abstract": "  The magnetic anisotropy and magnetic interactions at the interface between Fe\nand NiO(001) were investigated. Depending on the growth conditions of the\nNiO(001) layers and the post-annealing temperature, the preferential\nmagnetization direction of the ultrathin Fe layer grown on a NiO(001) layer\nchanged from in-plane to a direction perpendicular to the film plane. The\nlattice constant of the NiO(001) layers parallel to the growth direction\nincreased with O$_2$ flow rate, while that parallel to the in-plane were locked\nonto the MgO(001) substrate regardless of the growth conditions of the NiO\nlayers. Moreover, perpendicular magnetization was observed only when the NiO\nlayer was grown with O$_2$ flow rates higher than 2.0 sccm corresponding to\noxygen-rich NiO. X-ray magnetic circular dichroism measurements revealed an\nenhancement in anisotropic orbital magnetic moments similar to the origin of\nperpendicular magnetic anisotropy at the Fe/MgO(001) interface. The interfacial\nmagnetic anisotropy energies were 0.93 and 1.02 mJ/m$^2$ at room temperature\nand at 100 K, respectively, indicating less temperature dependence. In\ncontrast, the coercivity $H_c$ exhibited a significant temperature dependence.\nAlthough no signature of exchange bias or unidirectional loop shift was\nobserved, $H_c$ was strongly dependent on the NiO layer thickness, indicating\nthat the exchange interaction at the interface between the ferromagnetic and\nantiferromagnetic layers was not negligible, despite the NiO(001) being a\nspin-compensated surface.\n",
        "title": "Perpendicular magnetic anisotropy of an ultrathin Fe layer grown on\n  NiO(001)",
        "texts": [
            "FIG. 1. (a) and (b) Stacking structures of Cr(2 nm)/Fe/NiO/MgO(001) substrates with wedge-shaped thickness gradients. (c) Hall pattern and wiring arrangement. The current path is parallel to the gradient direction of the wedge.",
            "FIG. 2. (a) 2θ/ω-XRD patterns of NiO(001) films grown under various different O2 flow rates. The asterisks indicate 002 peaks of NiO. (b) Typical RHEED pattern of NiO(001). (c) O2 flow rate dependence of the lattice constants along the growth direction (cNiO) determined by 2θ/ωXRD measurements. (d) RSMs around the 113 diffraction of NiO/MgO(001) films grown at O2 flow rates of 0.5 sccm (left) and 6 sccm (right). The numbers shown on the right side in (a) and (d) indicate the oxygen flow rates during deposition.",
            "FIG. 3. Out-of-plane MH loops of Cr/Fe/NiO(001) multilayers at room temperature; (a) O2 flow dependence range of 0.5 to 6.0 sccm with Tanneal =500◦C and (b)Tanneal dependence range of 250 to 550◦C with O2 flow rate of 2.0 sccm."
        ],
        "imgs": [
            "$2305.00672v1-Figure1-1.png",
            "$2305.00672v1-Figure2-1.png",
            "$2305.00672v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00673",
        "abstract": "  In semi-supervised medical image segmentation, there exist empirical mismatch\nproblems between labeled and unlabeled data distribution. The knowledge learned\nfrom the labeled data may be largely discarded if treating labeled and\nunlabeled data separately or in an inconsistent manner. We propose a\nstraightforward method for alleviating the problem - copy-pasting labeled and\nunlabeled data bidirectionally, in a simple Mean Teacher architecture. The\nmethod encourages unlabeled data to learn comprehensive common semantics from\nthe labeled data in both inward and outward directions. More importantly, the\nconsistent learning procedure for labeled and unlabeled data can largely reduce\nthe empirical distribution gap. In detail, we copy-paste a random crop from a\nlabeled image (foreground) onto an unlabeled image (background) and an\nunlabeled image (foreground) onto a labeled image (background), respectively.\nThe two mixed images are fed into a Student network and supervised by the mixed\nsupervisory signals of pseudo-labels and ground-truth. We reveal that the\nsimple mechanism of copy-pasting bidirectionally between labeled and unlabeled\ndata is good enough and the experiments show solid gains (e.g., over 21% Dice\nimprovement on ACDC dataset with 5% labeled data) compared with other\nstate-of-the-arts on various semi-supervised medical image segmentation\ndatasets. Code is available at https://github.com/DeepMed-Lab-ECNU/BCP}.\n",
        "title": "Bidirectional Copy-Paste for Semi-Supervised Medical Image Segmentation",
        "texts": [
            "Figure 1. Illustration of the mismatch problem under semisupervised leaning setting. Assume the training set is drawn from a latent distribution in (a). But the empirical distributions of small amount of labeled data and a large amount of unlabeled data are (b) and (c), respectively. It’s hard to use few labeled data to construct the precise distribution of the whole dataset. (d) By using our BCP, the empirical distributions of labeled and unlabeled features are aligned. (e) But other methods such as SSNet [35] or cross unlabeled data copy-paste cannot address the empirical distribution mismatch issue. All distributions are kernel density estimations of voxels belonging to myocardium class in ACDC [2].",
            "Figure 2. Dice scores for unlabeled and labeled training data of different models on LA dataset [39]. A much smaller performance gap is observed in our method.",
            "Figure 3. Overview of our bidirectional copy-paste framework in Mean Teacher architecture, drawn with 2D inputs for better visualization. The inputs to Student network are generated by mixing two labeled and two unlabeled images in the proposed bidirectional copy-paste manner. Then, to provide the supervisory signal to the Student network, we combine the ground-truths and the pseudo-labels generated by the Teacher network into one supervisory signal via the same bidirectional copy-paste, to enable strong supervision from ground-truths help the weak supervision from pseudo-label.",
            "Figure 4. Visualizations of several semi-supervised segmentation methods with 10% labeled data and ground truth on LA dataset (best viewed by zoom-in on screen).",
            "Figure 5. Kernel dense estimations of different methods, trained on 10% labeled ACDC dataset. Top to bottom are kernel dense estimations of features belong to three different class of ACDC: right ventricle, myocardium and left ventricle. Baseline: Only labeled data are used to train the network. CP, In and Out are same as Table 4. It can be seen that our BCP could make the features of labeled data and unlabeled data align better. Furthermore, the outstanding performance of our method compared with In and Out demonstrates the necessity of bidirectional copy-paste.",
            "Figure 6. Different masking strategies. (a): random mask; (b): zero-centered mask; (c): contact mask.",
            "Table 1. Comparisons with state-of-the-art semi-supervised segmentation methods on LA dataset. Improvements compared with the second best results are highlighted.",
            "Table 10. Ablation on ACDC dataset with 5% labeled data, α = 0.5 across all experiments. nms: Post-processing the pseudolabels for unlabeled data. Pre-Train: Initialized from a pre-trained model with copy-paste on labeled data.",
            "Table 2. Comparisons with state-of-the-art semi-supervised segmentation methods on the Pancreas-NIH dataset.",
            "Table 3. Comparisons with state-of-the-art semi-supervised segmentation methods on the ACDC dataset.",
            "Table 4. Ablation study of the copy-paste directions. In: inward copy-paste (foreground: unlabeled, background: labeled). Out: outward copy-paste (foreground: labeled, background: unlabeled). CP: direct copy-paste (background & foreground: labeled & labeled and unlabeled & unlabeled).",
            "Table 5. Ablation study of interpolation strategies on LA dataset. Mixup: We imitate the framework of GuidedMix-Net [25], which is proposed for semi-supervised segmentation of natural images. FG-CutMix: We crop images of the whole training batch into 4×4 patches and then combine them randomly to generate new images.",
            "Table 6. Results with three masking strategies on LA dataset.",
            "Table 7. Ablation study of β on LA dataset.",
            "Table 8. Ablation study of the weights α in the loss function.",
            "Table 9. Ablation study of pre-training strategy on LA dataset. random: Initialized randomly. w/o CP: Initialized from a pretrained model trained on labeled data without copy-paste."
        ],
        "imgs": [
            "$2305.00673v1-Figure1-1.png",
            "$2305.00673v1-Figure2-1.png",
            "$2305.00673v1-Figure3-1.png",
            "$2305.00673v1-Figure4-1.png",
            "$2305.00673v1-Figure5-1.png",
            "$2305.00673v1-Figure6-1.png",
            "$2305.00673v1-Table1-1.png",
            "$2305.00673v1-Table10-1.png",
            "$2305.00673v1-Table2-1.png",
            "$2305.00673v1-Table3-1.png",
            "$2305.00673v1-Table4-1.png",
            "$2305.00673v1-Table5-1.png",
            "$2305.00673v1-Table6-1.png",
            "$2305.00673v1-Table7-1.png",
            "$2305.00673v1-Table8-1.png",
            "$2305.00673v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00674",
        "abstract": "  The jamming transition is a nonequilibrium critical phenomenon, which governs\ncharacteristic mechanical properties of jammed soft materials, such as pastes,\nemulsions, and granular matters. Both experiments and theory of jammed soft\nmaterials have revealed that the complex modulus measured by conventional\nmacrorheology exhibits a characteristic frequency dependence. Microrheology is\na new type of method to obtain the complex modulus, which transforms the\nmicroscopic motion of probes to the complex modulus through the generalized\nStokes relation (GSR). Although microrheology has been applied to jammed soft\nmaterials, its theoretical understanding is limited. In particular, the\nvalidity of the GSR near the jamming transition is far from obvious since there\nis a diverging length scale $l_c$, which characterizes the heterogeneous\nresponse of jammed particles. Here, we study the microrheology of jammed\nparticles by theory and numerical simulation. First, we develop a linear\nresponse formalism to calculate the response function of the probe particle,\nwhich is transformed to the complex modulus via the GSR. Then, we apply our\nformalism to a numerical model of jammed particles and find that the storage\nand loss modulus follow characteristic scaling laws near the jamming\ntransition. Importantly, the observed scaling law coincides with that in\nmacrorheology, which indicates that the GSR holds even near the jamming\ntransition. We rationalize this equivalence by asymptotic analysis of the\nobtained formalism and numerical analysis on the displacement field of jammed\nparticles under a local perturbation.\n",
        "title": "Microrheology near jamming",
        "texts": [
            "Figure 1. The storage modulus (filled symbols) and loss modulus (open symbols) calculated via (a,b) microrheology and (c) macrorheology are presented. We prepare 20 independent packings and the moduli are averaged over these different samples. The solid and dashed lines represent √ ω and ω scaling respectively. The complex modulus is rescaled by P 1 2 , and the frequency is rescaled by P . All of them show a very good collapse with rescaled variables. (d) The complex moduli of micro- and macrorheology at P = 10−2, 10−5 are presented in the same plot. This plot shows that not only the scaling but also the magnitudes of the modulus are almost the same in the different measurements.",
            "Figure 2. (a) The off-diagonal part of the displacement field ṼO(r) = VO(r)/VO,el(r), where VO(r) is the numerically obtained result and VO,el(r) is the prediction of elastic theory. For small r, ṼO(r) is larger than the prediction of elastic theory. For large r, its value converges to 1, which indicates the validity of elastic theory at a certain length scale lc. Note that because of the finite size effect, ṼO(r) becomes significantly smaller than the prediction of elastic theory for r lc. (b) Same as (a), but the horizontal axis is rescaled as r/P−1/4. The collapse confirms the presence of the diverging length scale lc ∝ P−1/4 above which elastic theory works."
        ],
        "imgs": [
            "$2305.00674v1-Figure1-1.png",
            "$2305.00674v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00675",
        "abstract": "  Although lane detection methods have shown impressive performance in\nreal-world scenarios, most of methods require post-processing which is not\nrobust enough. Therefore, end-to-end detectors like DEtection TRansformer(DETR)\nhave been introduced in lane detection.However, one-to-one label assignment in\nDETR can degrade the training efficiency due to label semantic conflicts.\nBesides, positional query in DETR is unable to provide explicit positional\nprior, making it difficult to be optimized. In this paper, we present the\nOne-to-Several Transformer(O2SFormer). We first propose the one-to-several\nlabel assignment, which combines one-to-many and one-to-one label assignment to\nsolve label semantic conflicts while keeping end-to-end detection. To overcome\nthe difficulty in optimizing one-to-one assignment. We further propose the\nlayer-wise soft label which dynamically adjusts the positive weight of positive\nlane anchors in different decoder layers. Finally, we design the dynamic\nanchor-based positional query to explore positional prior by incorporating lane\nanchors into positional query. Experimental results show that O2SFormer with\nResNet50 backbone achieves 77.83% F1 score on CULane dataset, outperforming\nexisting Transformer-based and CNN-based detectors. Futhermore, O2SFormer\nconverges 12.5x faster than DETR for the ResNet18 backbone.\n",
        "title": "End-to-End Lane detection with One-to-Several Transformer",
        "texts": [
            "Figure 6: Viusalization results on CULane.",
            "Table 3: Results of number of lane anchors.",
            "Table 4: Performances of different one-to-many label assignments."
        ],
        "imgs": [
            "$2305.00675v4-Figure6-1.png",
            "$2305.00675v4-Table3-1.png",
            "$2305.00675v4-Table4-1.png"
        ]
    },
    {
        "id": "2305.00676",
        "abstract": "  High-speed autonomous driving in off-road environments has immense potential\nfor various applications, but it also presents challenges due to the complexity\nof vehicle-terrain interactions. In such environments, it is crucial for the\nvehicle to predict its motion and adjust its controls proactively in response\nto environmental changes, such as variations in terrain elevation. To this end,\nwe propose a method for learning terrain-aware kinodynamic model which is\nconditioned on both proprioceptive and exteroceptive information. The proposed\nmodel generates reliable predictions of 6-degree-of-freedom motion and can even\nestimate contact interactions without requiring ground truth force data during\ntraining. This enables the design of a safe and robust model predictive\ncontroller through appropriate cost function design which penalizes sampled\ntrajectories with unstable motion, unsafe interactions, and high levels of\nuncertainty derived from the model. We demonstrate the effectiveness of our\napproach through experiments on a simulated off-road track, showing that our\nproposed model-controller pair outperforms the baseline and ensures robust\nhigh-speed driving performance without control failure.\n",
        "title": "Learning Terrain-Aware Kinodynamic Model for Autonomous Off-Road Rally\n  Driving With Model Predictive Path Integral Control",
        "texts": [
            "Fig. 1. Sampled trajectories and the optimal trajectory from the MPPI controller. Our terrain-aware kinodynamic model is capable of predicting the effect of terrain geometry on vehicle motion. The controller penalizes trajectories with unsafe vehicle motions and contact interactions, as well as high levels of uncertainty, allowing for the execution of aggressive maneuvers with enhanced safety. The penalized trajectories are depicted in red.",
            "Fig. 2. An overview diagram of our method of learning terrain-aware kinodynamic model for autonomous high-speed off-road driving using MPPI controller.",
            "Fig. 3. Multi-step prediction errors for the values (a) z, (b) ϕ, and (c) θ. Each line represents the mean, and the shaded region represents 1/5 of the standard deviation for visual clarity.",
            "Fig. 4. Ground truth trajectory and predicted trajectories generated by multi-step prediction of (a) 2D and (b) Ours for one example trial.",
            "Fig. 5. Visualization of (a) vertical force Fz , (b) roll moment Mx, and (c) pitch moment My derived by using the predictions from 2D and Ours.",
            "Fig. 6. (a) The back view, and (b) the side view of actual vehicle trajectory while crossing a cracked region. (c) The sampled trajectories of the MPPI right before the vehicle crosses the crack and the computed optimal trajectory in that time step. Intriguingly, it is estimated that trajectories with low speeds at which cannot be crossed are subjected to a significant impact on the vehicle’s rear wheels by the terrain, resulting in a loss of stability (colored in red).",
            "TABLE I THE DESIGN SPECIFICATIONS OF EACH MODEL. WE ABBREVIATED THE DETERMINISTIC/PROBABILISTIC MODEL AS D/P, RESPECTIVELY."
        ],
        "imgs": [
            "$2305.00676v2-Figure1-1.png",
            "$2305.00676v2-Figure2-1.png",
            "$2305.00676v2-Figure3-1.png",
            "$2305.00676v2-Figure4-1.png",
            "$2305.00676v2-Figure5-1.png",
            "$2305.00676v2-Figure6-1.png",
            "$2305.00676v2-TableI-1.png"
        ]
    },
    {
        "id": "2305.00678",
        "abstract": "  Medical image segmentation is a fundamental task in the community of medical\nimage analysis. In this paper, a novel network architecture, referred to as\nConvolution, Transformer, and Operator (CTO), is proposed. CTO employs a\ncombination of Convolutional Neural Networks (CNNs), Vision Transformer (ViT),\nand an explicit boundary detection operator to achieve high recognition\naccuracy while maintaining an optimal balance between accuracy and efficiency.\nThe proposed CTO follows the standard encoder-decoder segmentation paradigm,\nwhere the encoder network incorporates a popular CNN backbone for capturing\nlocal semantic information, and a lightweight ViT assistant for integrating\nlong-range dependencies. To enhance the learning capacity on boundary, a\nboundary-guided decoder network is proposed that uses a boundary mask obtained\nfrom a dedicated boundary detection operator as explicit supervision to guide\nthe decoding learning process. The performance of the proposed method is\nevaluated on six challenging medical image segmentation datasets, demonstrating\nthat CTO achieves state-of-the-art accuracy with a competitive model\ncomplexity.\n",
        "title": "Rethinking Boundary Detection in Deep Learning Models for Medical Image\n  Segmentation",
        "texts": [
            "Fig. 1. Illustration of our CTO, which follows an encoder-decoder paradigm, where the encoder network consists of a mainstream CNNs and an assistant ViT. The decoder network employs a boundary detection operator to guide its learning process.",
            "Fig. 2. Visualizations on CoNIC [17] (top two rows) and LiTS17 [4] (buttom two rows). The red boxes highlight the main difference of each method.",
            "Table 1. Comparisons with other methods on ISIC [19,11] & PH2 [31].",
            "Table 2. Comparisons with other methods on CoNIC [17] and LiTS17 [4].",
            "Table 3. Comparisons with other methods on BTCV [24].",
            "Table 4. Ablation study results on ISIC 2018 [11]. * means the component achieves significant performance improvement with p < 0.05 via paired t-test."
        ],
        "imgs": [
            "$2305.00678v1-Figure1-1.png",
            "$2305.00678v1-Figure2-1.png",
            "$2305.00678v1-Table1-1.png",
            "$2305.00678v1-Table2-1.png",
            "$2305.00678v1-Table3-1.png",
            "$2305.00678v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00680",
        "abstract": "  Estimating the information transmission capability of a quantum channel\nremains one of the fundamental problems in quantum information processing. In\ncontrast to classical channels, the information-carrying capability of quantum\nchannels is contextual. One of the most significant manifestations of this is\nthe superadditivity of the channel capacity: the capacity of two quantum\nchannels used together can be larger than the sum of the individual capacities.\nHere, we present a one-parameter family of channels for which as the parameter\nincreases its one-way quantum and private capacities increase while its two-way\ncapacities decrease. We also exhibit a one-parameter family of states with\nanalogous behavior with respect to the one- and two-way distillable\nentanglement and secret key. Our constructions demonstrate that noise is\ncontext dependent in quantum communication.\n",
        "title": "Noise is resource-contextual in quantum communication",
        "texts": [
            "Figure 1: Noise resource-contextuality: capacity of a family of channels for transmitting quantum information as a function of the noise parameter λ. The top scenario corresponds to the capacity in the absence of feedback (one-way capacity) and the bottom scenario corresponds to the capacity with feedback (two-way capacity). Intuitively, one would expect both capacities to be quantitatively different but have similar qualitative behavior; that is, either both increase or both decrease as a function of the noise parameter. Here we show that the very meaning of noise can depend on the resources. We exhibit families of channels for which as the two-way capacity decreases, the one-way capacity increases. Increasing λ represents noise for two-way communications while decreasing λ represents noise for one-way communications.",
            "Figure 3: One- vs two-way capacity of Nλ, p as a function of λ when p(λ) = 4λ − 1. In the range λ ∈ [0.25, 0.3125] the one-way quantum (and private) capacity monotonically increases while the two-way quantum (and private) capacity decreases.",
            "Figure 6: One- vs two-way capacity of the wiretap channels Nλ, p as a function of p when λ(p) = p/(2 log(6/p)). In the range p ∈ [0.8687, 1] the one-way capacity monotonically increases while the two-way capacity decreases."
        ],
        "imgs": [
            "$2305.00680v3-Figure1-1.png",
            "$2305.00680v3-Figure3-1.png",
            "$2305.00680v3-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00682",
        "abstract": "  In this work we revisit power law, $\\frac{1}{M^2}R^\\beta$, inflation to find\nthe deviations from $R^2$ inflation allowed by current CMB and LSS\nobservations. We compute the power spectra for scalar and tensor perturbations\nnumerically and perform MCMC analysis to put constraints on parameters $M$ and\n$\\beta$ from Planck-2018, BICEP3 and other LSS observations. We consider\ngeneral reheating scenario and also vary the number of e-foldings during\ninflation, $N_{pivot}$, along with the other parameters. We find $\\beta =\n1.966^{+0.035}_{-0.042}$, $M= \\left(3.31^{+5}_{-2}\\right)\\times 10^{-5}$ and\n$N_{pivot} = 41^{+10}_{-10}$ with $95\\%\\, C.\\, L.$. This indicates that the\ncurrent observations allow deviation from Starobinsky inflation. The scalar\nspectral index, $n_s$, and tensor-to-scalar ratio, $r$, derived from these\nparameters, are consistent with the Planck and BICEP3 observations.\n",
        "title": "Observational constraints on power law Starobinsky inflation",
        "texts": [
            "FIG. 2: Marginalized constraints on the potential parameters and Npivot using Planck-2018, BICEP3 and BAO data",
            "FIG. 3: Joint 68% C.L., and 95% C.L. constraints on parameters of potential and Npivot using Planck-2018, BICEP3 and BAO data",
            "FIG. 4: Joint 68% C.L., and 95% C.L. constraints on potential parameter M and Npivot from Planck-2018, BICEP3 and BAO data",
            "FIG. 5: Joint 68% C.L., and 95% C.L. constraints on ns and r from Planck-2018, BICEP3 and BAO data",
            "TABLE I: Priors on model parameters",
            "TABLE II: Planck-2018, BICEP3 and BAO constraints on parameters of potential, r and ns."
        ],
        "imgs": [
            "$2305.00682v1-Figure2-1.png",
            "$2305.00682v1-Figure3-1.png",
            "$2305.00682v1-Figure4-1.png",
            "$2305.00682v1-Figure5-1.png",
            "$2305.00682v1-TableI-1.png",
            "$2305.00682v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00685",
        "abstract": "  We study the dissociation of $\\psi (3770)$, $\\psi (4040)$, $\\psi (4160)$, and\n$\\psi (4415)$ mesons in collisions with nucleons, which takes place in\nhigh-energy proton-nucleus collisions. Quark interchange between a nucleon and\na $c\\bar c$ meson leads to the dissociation of the $c\\bar c$ meson. We consider\nthe reactions: $pR \\to \\Lambda_c^+ \\bar{D}^0$, $pR \\to \\Lambda_c^+\n\\bar{D}^{*0}$, $pR \\to \\Sigma_c^{++} D^-$, $pR \\to \\Sigma_c^{++} D^{*-}$, $pR\n\\to \\Sigma_c^{+} \\bar{D}^0$, $pR \\to \\Sigma_c^{+} \\bar{D}^{*0}$, $pR \\to\n\\Sigma_c^{*++} D^-$, $pR \\to \\Sigma_c^{*++} D^{*-}$, $pR \\to \\Sigma_c^{*+}\n\\bar{D}^0$, and $pR \\to \\Sigma_c^{*+} \\bar{D}^{*0}$, where $R$ stands for $\\psi\n(3770)$, $\\psi (4040)$, $\\psi (4160)$, or $\\psi (4415)$. A reaction of a\nneutron and a $c\\bar c$ meson corresponds to a reaction of a proton and the\n$c\\bar c$ meson by replacing the up quark with the down quark and vice versa.\nTransition-amplitude formulas are derived from the $S$-matrix element.\nUnpolarized cross sections are calculated with the transition amplitudes for\nscattering in the prior form and in the post form. The cross sections relate to\nnodes in the radial wave functions of $\\psi (3770)$, $\\psi (4040)$, $\\psi\n(4160)$, and $\\psi (4415)$ mesons.\n",
        "title": "Dissociation cross sections of $\\psi (3770)$, $\\psi (4040)$, $\\psi\n  (4160)$, and $\\psi (4415)$ mesons with nucleons",
        "texts": [
            "Table 1: Values of the parameters. a1 and a2 are in units of millibarns; b1 and b2 are in units of GeV; c1 and c2 are dimensionless."
        ],
        "imgs": [
            "$2305.00685v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00686",
        "abstract": "  Three - dimensional static and spinning black hole solutions of the\nEinstein-Klein-Gordon system are obtained for a particular scalar field\nconfiguration. At large distances, and for small scalar field, the solutions\nreduce to the BTZ black hole. The scalar field dresses the black hole with\nsecondary scalar hair, since the scalar charge is related to the conserved\nblack hole mass and is not an independent charge. A self interacting potential\nis included, containing a mass term that is above the Breitenlohner-Freedman\nbound in three dimensions. Independence of the scalar potential from the\nconserved black hole charges, imposes fixed mass and angular momentum to scalar\ncharge ratios. The thermodynamic properties as well as the energy conditions of\nthe black hole are analysed.\n",
        "title": "Black Holes with Scalar Hair in Three Dimensions",
        "texts": [
            "FIG. 1. The potential V (r) and V ′(r)/φ′(r) for M = −Λ = 1, while changing the scalar charge A.",
            "FIG. 2. Left: h(r) versus r forM = ` = 1, while changing the scalar charge A. Right: r+ as a function of A, while changing the mass of the black hole for ` = 1.",
            "FIG. 4. The energy density ρ, the radial pressure pr and the radial pressure ρ+ pr for M = ` = 1 while changing the scalar charge A.",
            "FIG. 5. The temperature of the black hole for ` = 1 as a function of M, while changing the scalar charge.",
            "FIG. 7. b(r) and gtt(r) having set ` = A = 1, J = 2, while varying the mass parameter.",
            "FIG. 8. The temperature T, the entropy S and the heat capacity C as functions of the black hole mass"
        ],
        "imgs": [
            "$2305.00686v1-Figure1-1.png",
            "$2305.00686v1-Figure2-1.png",
            "$2305.00686v1-Figure4-1.png",
            "$2305.00686v1-Figure5-1.png",
            "$2305.00686v1-Figure7-1.png",
            "$2305.00686v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00689",
        "abstract": "  In this paper, we prove a lower bound on the soundness of quantum locally\ntestable codes under the distance balancing construction of Evra et al.\narXiv:2004.07935 [quant-ph]. Our technical contribution is that the new\nsoundness of the quantum code is at least the old soundness divided by the\nclassical code length (up to a constant factor). This allows us to use any\nclassical code with independent checks when distance balancing, where\npreviously only the repetition code had been considered for qLTCs. By using a\ngood classical LDPC code, we are able to grow the dimension of the hypersphere\nproduct codes arXiv:1608.05089 [quant-ph] and the hemicubic codes\narXiv:1911.03069 [quant-ph] while maintaining their distance and locality, but\nat the expense of soundness. From this, and also by distance balancing a chain\ncomplex of Cross et al. arXiv:2209.11405 [cs.IT], we obtain quantum locally\ntestable codes of new parameters.\n",
        "title": "General Distance Balancing for Quantum Locally Testable Codes",
        "texts": [
            "Table 1: Parameters resulting from the distance balancing of the chain complex Q with, first, the usual parity-check matrix for the repetition code of length l, and second, the modified parity-check matrix for the same code, as shown in [4]. Notice that distance and dimension are the same between the two - they must be because these quantities are properties of codespaces, and are therefore the same if we go to a different parity-check matrix for the same code. Soundness and locality, on the other hand, do depend on parity-check matrices themselves, and so may differ. We comment also that [4] refers to ‘check weight’ (maximum number of qubits involved in a check) and ‘qubit degree’ (maximum number of checks in which a qubit is involved) where here, for simplicity, we use only the word ‘locality’, which may be defined as the maximum of the two.",
            "Table 2: Columns 2 and 3 contain the parameters of the hypersphere product and hemicubic codes, while columns 4 and 5 contain the general parameters that we obtain by applying the above construction to each of them using a good classical LDPC code of length t.",
            "Table 3: Example parameters arising from applying the above construction to the hemicubic codes - with a logarithmic (t = √ log(n)) and then a polynomial (t = nα) classical code length. One could also apply the construction to the hypersphere product codes to obtain a very slightly improved locality, at the expense of a slightly decreased soundness.",
            "Table 4: The parameters resulting from distance balancing the complex Q with the repetition code of length l (column 2) and a good classical LDPC code of length t (column 3). A logarithmic-length example of these parameters may be found in column 4."
        ],
        "imgs": [
            "$2305.00689v1-Table1-1.png",
            "$2305.00689v1-Table2-1.png",
            "$2305.00689v1-Table3-1.png",
            "$2305.00689v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00691",
        "abstract": "  Cameras digitize real-world scenes as pixel intensity values with a limited\nvalue range given by the available bits per pixel (bpp). High Dynamic Range\n(HDR) cameras capture those luminance values in higher resolution through an\nincrease in the number of bpp. Most displays, however, are limited to 8 bpp.\nNaive HDR compression methods lead to a loss of the rich information contained\nin those HDR images. In this paper, tone mapping algorithms for thermal\ninfrared images with 16 bpp are investigated that can preserve this\ninformation. An optimized multi-scale Retinex algorithm sets the baseline. This\nalgorithm is then approximated with a deep learning approach based on the\npopular U-Net architecture. The remaining noise in the images after tone\nmapping is reduced implicitly by utilizing a self-supervised deep learning\napproach that can be jointly trained with the tone mapping approach in a\nmulti-task learning scheme. Further discussions are provided on denoising and\ndeflickering for thermal infrared video enhancement in the context of tone\nmapping. Extensive experiments on the public FLIR ADAS Dataset prove the\neffectiveness of our proposed method in comparison with the state-of-the-art.\n",
        "title": "Joint tone mapping and denoising of thermal infrared images via\n  multi-scale Retinex and multi-task learning",
        "texts": [
            "Figure 1. Comparison between näıve linear downscaling, CLAHE, and the optimized multi-scale Retinex-based reference TMO used in this paper. The example image is taken from the public FLIR ADAS Dataset12.",
            "Figure 10. Qualitative comparison between the state-of-the-art, our optimized MSR and our final deep learning-based approach. The example images confirm the measures in Table 5: the FLIR algorithm (upper left) has the best TMQI followed by our learned MSR. The noise reduction between the optimized and the learned MSR (bottom center and right) is clearly visible in zoom view.",
            "Figure 2. Qualitative comparison between the different TMOs providing the current baseline.",
            "Figure 3. Comparison between different methods for histogram equalization. The processed images are shown in the upper row and the related histograms in the lower row.",
            "Figure 4. Comparison between the MSR algorithm with and without deflickering through histogram matching. The example images are taken from the FLIR ADAS Dataset video subset.",
            "Figure 5. Average image intensity value over time throughout the FLIR video dataset tone mapped with the MSR algorithm with different combinations of CLAHE, sigma clipping and histogram matching. Both, sigma clipping and histogram matching smooth the average image intensity over time and thus perform deflickering.",
            "Figure 6. Comparison between the results of the deep learning-based approximation. The idea is to mimic the performance of reference TMOs based on traditional computer vision by deep neural networks. The example images show that the two tested neural network architectures CAN and U-Net can successfully mimic the reference TMOs. Interestingly, CAN performs better when mimicking the FLIR TMO, while U-Net performs better when mimicking the optimized MSR.",
            "Figure 7. Results of the frame-to-frame denoising approach on the FLIR test set and the FLIR train set. From left to right: reference image without denoising from FLIR test set, the same image after frame-to-frame denoising, reference image without denoising from FLIR train set, the same image after frame-to-frame denoising.",
            "Figure 8. Comparison between different self-supervised denoising approaches. While frame-to-frame denoising34 introduces image blur and Noisier2Noise35 loses image details, the Noisy-As-Clean9 approach provides the best denoising performance.",
            "Figure 9. Comparison between the self-supervised Noisy-As-Clean denoising approach9 used as post-processing, or learned jointly together with tone mapping.",
            "Table 1. Quantitative evaluation comparing different TMOs to form the current baseline. FLIR12 Realtime TMO16 CGF5 MSR6",
            "Table 2. Comparison between the state-of-the-art TMOs and the baseline MSR algorithm with different optimizations. The proposed optimized MSR performs best among the Retinex-based algorithms especially for the TMQI measure.",
            "Table 3. Comparison between the FLIR TMO, our optimized MSR and our deep learning-based approximation using the CAN and the U-Net architecture. Both methods can be approximated according to the measures. Mimicking the optimized MSR works slightly better according to the TMQI.",
            "Table 4. Quantitative evaluation of the self-supervised denoising method and denoising with deflickering. The considered denoising approach is first evaluated as post-processing after the approximation of tone mapping. Then, joint training is done with implicit denoising and deflickering. We use Noisy-As-Clean as denoising method in the joint training. Joint TMO+denoising+deflickering performs best according to the measures.",
            "Table 5. Comparison between the state-of-the-art, our optimized MSR and our deep learning-based approach with joint denoising and deflickering called learned MSR. The performance improvement compared to the baseline MSR6 is notable in multiple measures with the TMQI and the noise visibility being the most important ones. The other Retinex-based approach CGF is outperformed, too."
        ],
        "imgs": [
            "$2305.00691v1-Figure1-1.png",
            "$2305.00691v1-Figure10-1.png",
            "$2305.00691v1-Figure2-1.png",
            "$2305.00691v1-Figure3-1.png",
            "$2305.00691v1-Figure4-1.png",
            "$2305.00691v1-Figure5-1.png",
            "$2305.00691v1-Figure6-1.png",
            "$2305.00691v1-Figure7-1.png",
            "$2305.00691v1-Figure8-1.png",
            "$2305.00691v1-Figure9-1.png",
            "$2305.00691v1-Table1-1.png",
            "$2305.00691v1-Table2-1.png",
            "$2305.00691v1-Table3-1.png",
            "$2305.00691v1-Table4-1.png",
            "$2305.00691v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00692",
        "abstract": "  Nonorthogonal multiple access (NOMA) with multi-antenna base station (BS) is\na promising technology for next-generation wireless communication, which has\nhigh potential in performance and user fairness. Since the performance of NOMA\ndepends on the channel conditions, we can combine NOMA and reconfigurable\nintelligent surface (RIS), which is a large and passive antenna array and can\noptimize the wireless channel. However, the high dimensionality makes the RIS\noptimization a complicated problem. In this work, we propose a machine learning\napproach to solve the problem of joint optimization of precoding and RIS\nconfiguration. We apply the RIS to realize the quasi-degradation of the\nchannel, which allows for optimal precoding in closed form. The neural network\narchitecture RISnet is used, which is designed dedicatedly for RIS\noptimization. The proposed solution is superior to the works in the literature\nin terms of performance and computation time.\n",
        "title": "Non-Orthogonal Multiple Access Assisted by Reconfigurable Intelligent\n  Surface Using Unsupervised Machine Learning",
        "texts": [
            "Fig. 2. Information processing of one layer in the RISnet.",
            "Fig. 3. Training of the RISnet with N = 1024.",
            "TABLE I SETTING AND PARAMETER VALUES"
        ],
        "imgs": [
            "$2305.00692v3-Figure2-1.png",
            "$2305.00692v3-Figure3-1.png",
            "$2305.00692v3-TableI-1.png"
        ]
    },
    {
        "id": "2305.00693",
        "abstract": "  The probability of a given candidate winning a future election is worked out\nin closed form as a function of (i) the current support rates for each\ncandidate, (ii) the relative positioning of the candidates within the political\nspectrum, (iii) the time left to the election, and (iv) the rate at which noisy\ninformation is revealed to the electorate from now to the election day, when\nthere are three or more candidates. It is shown, in particular, that the\noptimal strategy for controlling information can be intricate and nontrivial,\nin contrast to a two-candidate race. A surprising finding is that for a\ncandidate taking the centre ground in an electoral competition among a\npolarised electorate, certain strategies are fatal in that the resulting\nwinning probability for that candidate vanishes identically.\n",
        "title": "Three candidate election strategy",
        "texts": [
            "FIG. 1: Winning likelihood. The probability that candidate zero will win the election in eighteen months (T = 1.5), as a function of the current support rate p for the candidate. The realised likelihood of winning a future election is always higher than today’s poll if p > 1 2 ; and conversely lower than the poll if p < 1 2 . How much the winning probability deviates from the current poll depends on how much information is revealed over the next eighteen months. Here, two examples are shown, corresponding to the values σ = 0.2 (in purple) and σ = 1.2 (in red).",
            "FIG. 2: Winning probabilities as functions of (p1, p2). The probabilities of winning a future election to take place in one year time (T = 1), when the information flow rate is set at σ = 1, are plotted here for the parameter choice (x1, x2, x3) = (1, 2, 3). The forms of the probabilities for candidate 1 (left panel, in red) and candidate 3 (right panel, in blue) are entirely symmetric. However, the behaviour of the probability for candidate 2 (centre panel, in purple) is slightly different in that there is a region in the parameter space (p1, p2) of the current support rates for which the probability of candidate 2 winning is identically zero. We will have more to say about this in the next section.",
            "FIG. 3: Dynamical behaviours of the poll statistics {πit} and the corresponding winning probabilities. Sample paths for the support rates (π1t, π2t, π3t) for the three candidates are shown on the left panels. The corresponding winning probability processes for each candidate are shown on the right panels. The parameters are chosen as (x1, x2, x3) = (1, 2, 3) for the values of the random variable X, (p1, p2, p3) = (0.38, 0.26, 0.36) for the current support level so that the electorates are slightly polarised, and T = 1 year for the time left to the election day. The top two panels correspond to the value σ = 0.25 for the information flow rate. In this case, the probability for the second candidate to win the election is identically zero. For a comparison, the corresponding results for the choice σ = 1 are plotted in the bottom two panels, in which the second candidate narrowly secures a victory.",
            "FIG. 4: Winning probabilities as functions of σ. The probability of winning an election in one year time (T = 1), as a function of the information flow rate σ, is shown for the three candidates, labelled according to x1 = 1, x2 = 2, and x3 = 3. The current poll statistics are taken to be p1 = 0.38 for the first candidate on the left (red), p2 = 0.26 for the second candidate taking the centre ground (purple), and p3 = 0.36 for the third candidate on the right (blue).",
            "FIG. 5: Gains in winning probabilities as functions of σ. If the political positioning (x1, x2, x3) = (1, 2, 3) considered in Figure 4 is shifted, how would that affect the winning probabilities? Here, the difference of the resulting winning probabilities to the one in Figure 4 is shown for three different cases: (x1, x2, x3) = (0.1, 2, 3.9) (left panel), (x1, x2, x3) = (1, 2, 3.9) (central panel), and (x1, x2, x3) = (1.5, 2, 3.9) (right panel). Other parameters are kept unchanged (p1 = 0.38, p2 = 0.26, p3 = 0.36, and T = 1). If the difference is negative, then clearly the shift is disadvantageous. The result shows that among a polarised electorate, if the candidate on the left of the political spectrum leans further to the left and the candidate on the right leans further to the right, then this is generally disadvantageous for both. However, if the competition is dominated by noise (small σ values), then the candidate on the right can benefit by leaning further to the right.",
            "FIG. 6: Maximum attainable support rates πkT (ξ∗k) for the five candidates. For a range of values for the information flow rate σ, the maximum values of {πkT } on the election day are shown by the dots, interpolated by lines to make the comparison easy. The current support rates {pk} are given by the bottom values (in purple). In the left panel the five candidates are all assumed to have an equal support rate of 20%, whereas they are chosen at random in the central and right panels. The results shows how the maximum attainable support rates for different candidates vary rather dramatically, depending on the existence of candidates having different political leanings and their associated current support rates. The parameters are chosen to be (x1, x2, x3, x4, x5) = (1, 2, 3, 4, 5) for the positioning of the candidates and T = 1 year for time left to the election."
        ],
        "imgs": [
            "$2305.00693v2-Figure1-1.png",
            "$2305.00693v2-Figure2-1.png",
            "$2305.00693v2-Figure3-1.png",
            "$2305.00693v2-Figure4-1.png",
            "$2305.00693v2-Figure5-1.png",
            "$2305.00693v2-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00694",
        "abstract": "  Piecewise deterministic Markov processes (PDMPs) are a type of\ncontinuous-time Markov process that combine deterministic flows with jumps.\nRecently, PDMPs have garnered attention within the Monte Carlo community as a\npotential alternative to traditional Markov chain Monte Carlo (MCMC) methods.\nThe Zig-Zag sampler and the Bouncy Particle Sampler are commonly used examples\nof the PDMP methodology which have also yielded impressive theoretical\nproperties, but little is known about their robustness to extreme dependence or\nanisotropy of the target density. It turns out that PDMPs may suffer from poor\nmixing due to anisotropy and this paper investigates this effect in detail in\nthe stylised but important Gaussian case. To this end, we employ a multi-scale\nanalysis framework in this paper. Our results show that when the Gaussian\ntarget distribution has two scales, of order $1$ and $\\epsilon$, the\ncomputational cost of the Bouncy Particle Sampler is of order $\\epsilon^{-1}$,\nand the computational cost of the Zig-Zag sampler is $\\epsilon^{-2}$. In\ncomparison, the cost of the traditional MCMC methods such as RWM is of order\n$\\epsilon^{-2}$, at least when the dimensionality of the small component is\nmore than $1$. Therefore, there is a robustness advantage to using PDMPs in\nthis context.\n",
        "title": "Scaling of Piecewise Deterministic Monte Carlo for Anisotropic Targets",
        "texts": [
            "Figure 1: Paths of y1 for θ “ 0 (left), θ “ π{6 (centre), and θ “ π{4 (right), and y1 (1st row), y2 (2nd row) and v1, v2 (3rd and 4th rows) of the Zig-Zag sampler where ε “ 0.01.",
            "Figure 2: The value of the diffusion coefficient Ω “ Ωpθq for θ P r0, 2πq for the Zig-Zag sampler. The function takes `8 when θ “ nπ{4, n “ 0, 1, . . . , 7 corresponding to the dotted lines.",
            "Figure 3: Numerical validation of the theoretical value Ω “ Ωpθq in the range θ P p0, π{4q. This is achieved by statistical estimation of the diffusion coefficient for a grid of values for θ, interpreting the process yε1ptq as a diffusion. This is for ε “ 0.001 and a trajectory with time horizon T “ 2.0.",
            "Figure 4: Numerical experiment illustrating how the py1ptq, v1ptq, |v2|ptqq statistics of a BPS trajectory (in blue) converge to the fluid limit (in red) given by (2.7).",
            "Figure 5: Paths of v2 (left) and y2 (right) for the Bouncy particle sampler for ε “ 0.01.",
            "Figure 6: Typical path of the process yLptq.",
            "Figure 8: Relation among ωn, τn and θn when α “ β “ 1."
        ],
        "imgs": [
            "$2305.00694v1-Figure1-1.png",
            "$2305.00694v1-Figure2-1.png",
            "$2305.00694v1-Figure3-1.png",
            "$2305.00694v1-Figure4-1.png",
            "$2305.00694v1-Figure5-1.png",
            "$2305.00694v1-Figure6-1.png",
            "$2305.00694v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00695",
        "abstract": "  One of the main reasons that cause seniors to face accessibility barriers\nwhen trying to use software applications is that the age-related user interface\n(UI) needs of seniors (e.g., physical and cognitive limitations) are not\nproperly addressed in software user interfaces. The existing literature\nproposes model-driven engineering based UI adaptations as a prominent solution\nfor this phenomenon. But in our exploration into the domain, we identified that\nthe existing work lacks comprehensiveness when it comes to integrating\naccessibility into software modelling tools and methods when compared to a\nwell-recognised accessibility standard such as the Web Content Accessibility\nGuidelines (WCAG). Thus in this paper, we outline a research roadmap that aims\nto use WCAG as a reference framework to design domain-specific languages that\nmodel the diverse accessibility scenarios of senior users via user context\ninformation and UI adaptation rules modelling so that they meet the\naccessibility standards specified in WCAG.\n",
        "title": "Addressing Age-Related Accessibility Needs of Senior Users Through\n  Model-Driven Engineering",
        "texts": [
            "Fig. 1. A UI adaptation scenario for seniors with low-vision where a non-adapted UI (A) is being design-time (B)/run-time (C) adapted with UI modifications to contrast ratio, text-size, multi-modality (text-to-speech and speech-to-text)",
            "Fig. 2. The research roadmap",
            "TABLE I MAJOR ACCESSIBILITY FEATURE GAPS IN SECTION III"
        ],
        "imgs": [
            "$2305.00695v2-Figure1-1.png",
            "$2305.00695v2-Figure2-1.png",
            "$2305.00695v2-TableI-1.png"
        ]
    },
    {
        "id": "2305.00697",
        "abstract": "  A load-independent constant current (CC) - constant voltage (CV) output is an\nimportant requirement of inductive power transfer (IPT) systems for electric\nvehicle charging applications. Zero phase angle (ZPA) is also a desirable\nfeature, to ensure a lower power rating requirement for the switching\nconverter. CC and CV output along with ZPA can be achieved by using a suitable\ncompensation topology. Equation manipulation techniques can be used for\ndesigning the compensation topology. But, it can be mathematically intensive\nespecially for higher order topologies. To overcome this problem, resonant-tank\nbased approaches are adopted in several works to achieve CC and CV conditions.\nHowever, equation-based approaches are depended upon either wholly or partly\nfor realizing ZPA. This approach can be tedious and lacks physical insight. The\nproposed method extends resonant tank approach to achieve ZPA also, besides CC\nand CV. The need for a separate method to achieve ZPA is eliminated. Further,\nit simplifies the process in arriving at the constraints that ensure ZPA. As a\nsample validation, the proposed method is applied to a S-SP compensation\ntopology. The CC-ZPA and CV-ZPA constraints for the S-SP topology are shown to\nbe in line with the ones arrived at using an existing equation-based impedance\napproach. The simplicity of the proposed method can be observed from the sample\nvalidation.\n",
        "title": "A Resonant Tank Based Approach for Realizing ZPA in Inductive Power\n  Transfer Systems",
        "texts": [
            "Fig. 1. Basic resonant tanks and their properties [1]",
            "Fig. 2. Unified model for an arbitrary compensation topology [4]",
            "Fig. 3. A S-SP topology and its resonant conditions in CC and CV modes. Red boxes indicate elements to be resonated for achieving CC or CV and blue boxes indicate the ones to be resonated for ZPA.",
            "Fig. 5. The unified model of S-SP topology used in [4]"
        ],
        "imgs": [
            "$2305.00697v1-Figure1-1.png",
            "$2305.00697v1-Figure2-1.png",
            "$2305.00697v1-Figure3-1.png",
            "$2305.00697v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00699",
        "abstract": "  We present results of a systematic study of the capture process through the\nbarrier penetration model. The nucleus-nucleus interaction potential is\ncalculated using the double-folding model (DFM) with the M3Y Paris NN forces.\nThe nucleon densities entering the model are generated from the experimental\nthree-parameter Fermi charge densities. The DFM has been extended to the case\nof deformed target nuclei. It is shown that the density-dependent M3Y NN forces\nwith the finite range exchange part can be mimicked successfully by the\nzero-range density-independent forces. The latter option significantly reduces\nthe required computer time. For the nucleon densities and target nuclei\ndeformations we employ the values from the commonly used data bases. Thus, we\ndo not vary any parameters to reach a better agreement with the data. The\nresulting cross-sections are compared with data for 20 reactions with the\nproduct of the charge numbers Z_P*Z_T ranging from 216 up to 2576. We discuss\nthe opinion met in the literature that the M3Y NN forces provide a poorer\ndescription of the capture cross-sections in heavy-ion collisions in comparison\nto the NN forces coming from the relativistic mean-field approach. Our\ncalculations show that the M3Y NN forces give an agreement with the data which\nis not perfect yet is not worse than the one resulting from the RMF NN forces.\n",
        "title": "Systematic application of the M3Y NN forces for describing the capture\n  process in heavy-ion collisions involving deformed target nuclei",
        "texts": [
            "FIG. 1. Coordinate system used in the double-folding model.",
            "FIG. 2. Comparison of barrier energies evaluated ignoring the deformations of the target nuclei versus the approximate barrier energy 𝐵𝑍. Panel (a): fractional difference 𝜉𝛿𝐷 𝑠 (see Eq. (23)) corresponding to three values of 𝐺𝐸𝛿 indicated in the panel. Panel (b): squares correspond to fractional difference 𝜉𝑓𝐷 𝑠 (see Eq. (24)); thin horizontal line is the average of 𝜉𝑓𝐷 𝑠 (𝐵𝑍); thick black curve is the analytical approximation 𝜉𝑎 (𝐵𝑍) (see Eq. (25)).",
            "FIG. 4. Fractional difference 𝜉𝛿𝑓 𝜃 (𝜃) (see Eq. (28)) versus accident angle 𝜃. For convenience, we use the ordering numbers of reactions from Table IV.",
            "FIG. 5. Fractional difference 𝜉𝛿𝐷 𝜃𝑠(𝜃) (see Eq. (29)) as a function of accident angle 𝜃.",
            "FIG. 6. Calculated and experimental cross-sections as the functions of collision energy for six reactions. The values of 𝐵𝛿𝑠 are displayed by vertical lines. For convenience, we use the ordering numbers of reactions from Table IV.",
            "FIG. 7. Ratios of calculated cross-sections 𝜎𝑡ℎ and experimental 𝜎𝑒𝑥𝑝 as the functions of 𝐸𝑐.𝑚./𝐵𝑍. Panels (a), (c)",
            "Table I. Parameter set for the effective M3Y Paris NN forces. The coefficients 𝐺𝐷𝑖, 𝐺𝐸𝑓𝑖 were obtained by fitting the G-matrix elements at three selected distances 𝑟𝑣𝑖.",
            "Table II. Projectile nuclei: parameters of the experimental charge density (3pF-formula, Eq. (19)) [38].",
            "Table III. Target nuclei: deformations [39,40] and parameters of the experimental charge density (3pF-formula, Eqs. (20), (21)) [38].",
            "Table IV. The ordering numbers of reactions, the corresponding reactions, and the barrier energies: the approximate ones 𝐵𝑍 (Eq. (18)); 𝐵𝛿𝑠 calculated using the 𝛿NN forces with 𝐺𝐸𝛿 = −1040 MeV fm3; 𝐵𝑓𝐷𝐷𝑠 evaluated using the 𝑓DDNN forces; the experimental ones 𝐵𝑓 𝑒𝑥𝑝 with the corresponding references. In the last column, the references for the experimental capture crosssections and the number of experimental points are presented."
        ],
        "imgs": [
            "$2305.00699v1-Figure1-1.png",
            "$2305.00699v1-Figure2-1.png",
            "$2305.00699v1-Figure4-1.png",
            "$2305.00699v1-Figure5-1.png",
            "$2305.00699v1-Figure6-1.png",
            "$2305.00699v1-Figure7-1.png",
            "$2305.00699v1-TableI-1.png",
            "$2305.00699v1-TableII-1.png",
            "$2305.00699v1-TableIII-1.png",
            "$2305.00699v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00700",
        "abstract": "  Motivated by a recent literature on the double-descent phenomenon in machine\nlearning, we consider highly over-parameterized models in causal inference,\nincluding synthetic control with many control units. In such models, there may\nbe so many free parameters that the model fits the training data perfectly. We\nfirst investigate high-dimensional linear regression for imputing wage data and\nestimating average treatment effects, where we find that models with many more\ncovariates than sample size can outperform simple ones. We then document the\nperformance of high-dimensional synthetic control estimators with many control\nunits. We find that adding control units can help improve imputation\nperformance even beyond the point where the pre-treatment fit is perfect. We\nprovide a unified theoretical perspective on the performance of these\nhigh-dimensional models. Specifically, we show that more complex models can be\ninterpreted as model-averaging estimators over simpler ones, which we link to\nan improvement in average performance. This perspective yields concrete\ninsights into the use of synthetic control when control units are many relative\nto the number of pre-treatment periods.\n",
        "title": "Double and Single Descent in Causal Inference with an Application to\n  High-Dimensional Synthetic Control",
        "texts": [
            "Figure 1: Average out-of-sample (blue) and in-sample (orange) RMSE on non-experimental CPS controls.",
            "Figure 2: Average RMSE for linear regression for a varying number of covariates.",
            "Figure 3: Average of the coefficient norm ∥β̂J∥ for varying size of the set J of covariates.",
            "Figure 4: Minimal-norm least-squares solutions for linear regression with J = {1, 2}, where n varies.",
            "Figure 5: Minimal-norm least-squares solutions for draws YA (black) and YB (orange) for linear regression with J = {1, 2}, where n varies",
            "Figure 6: Average out-of-time (blue) and training (orange) RMSE for synthetic control for a varying number of control units.",
            "Figure 7: Synthetic-control examples for T = 2, where the set J of included units varies.",
            "Figure 8: Illustration of permutation bound based on the examples from Figures 4 and 7.",
            "Figure 9: Average out-of-time (blue) and training (orange) RMSE for synthetic control for a varying number of control units as in Figure 6, but with ten pre-treatment periods and control units chosen randomly among all available donors.",
            "Table 1: CPS and NSW dataset variables"
        ],
        "imgs": [
            "$2305.00700v3-Figure1-1.png",
            "$2305.00700v3-Figure2-1.png",
            "$2305.00700v3-Figure3-1.png",
            "$2305.00700v3-Figure4-1.png",
            "$2305.00700v3-Figure5-1.png",
            "$2305.00700v3-Figure6-1.png",
            "$2305.00700v3-Figure7-1.png",
            "$2305.00700v3-Figure8-1.png",
            "$2305.00700v3-Figure9-1.png",
            "$2305.00700v3-Table1-1.png"
        ]
    },
    {
        "id": "2305.00705",
        "abstract": "  Model-based testing (MBT) provides an automated approach for finding\ndiscrepancies between software models and their implementation. If we want to\nincorporate MBT into the fast and iterative software development process that\nis Continuous Integration Continuous Deployment, then MBT must be able to test\nthe entire model in as little time as possible. However, current academic MBT\ntools either traverse models at random, which we show to be ineffective for\nthis purpose, or use precalculated optimal paths which can not be efficiently\ncalculated for large industrial models. We provide a new traversal strategy\nthat provides an improvement in error-detection rate comparable to using\nrecalculated paths. We show that the new strategy is able to be applied\nefficiently to large models. The benchmarks are performed on a mix of\nreal-world and pseudo-randomly generated models. We observe no significant\ndifference between these two types of models.\n",
        "title": "Efficient dynamic model based testing using greedy test case selection",
        "texts": [
            "Fig. 2. Number of transitions required to achieve given percentages of state coverage of the model at Philips by both the greedy and random strategies",
            "Fig. 3. Number of transitions required to achieve given percentages of state coverage of the sorting machine model by both the greedy and random strategies",
            "Fig. 4. Number of transitions required to achieve given percentages of state coverage of several generated statespaces",
            "Table 1. Average number of transitions required to different detect mutations of the Bounded Transmission Protocol though MBT using greedy test case selection, a priori generated path [6], and random test case selection"
        ],
        "imgs": [
            "$2305.00705v1-Figure2-1.png",
            "$2305.00705v1-Figure3-1.png",
            "$2305.00705v1-Figure4-1.png",
            "$2305.00705v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00706",
        "abstract": "  The rapid rise in cloud computing has resulted in an alarming increase in\ndata centers' carbon emissions, which now accounts for >3% of global greenhouse\ngas emissions, necessitating immediate steps to combat their mounting strain on\nthe global climate. An important focus of this effort is to improve resource\nutilization in order to save electricity usage. Our proposed Full Scaling\nAutomation (FSA) mechanism is an effective method of dynamically adapting\nresources to accommodate changing workloads in large-scale cloud computing\nclusters, enabling the clusters in data centers to maintain their desired CPU\nutilization target and thus improve energy efficiency. FSA harnesses the power\nof deep representation learning to accurately predict the future workload of\neach service and automatically stabilize the corresponding target CPU usage\nlevel, unlike the previous autoscaling methods, such as Autopilot or FIRM, that\nneed to adjust computing resources with statistical models and expert\nknowledge. Our approach achieves significant performance improvement compared\nto the existing work in real-world datasets. We also deployed FSA on\nlarge-scale cloud computing clusters in industrial data centers, and according\nto the certification of the China Environmental United Certification Center\n(CEC), a reduction of 947 tons of carbon dioxide, equivalent to a saving of\n1538,000 kWh of electricity, was achieved during the Double 11 shopping\nfestival of 2022, marking a critical step for our company's strategic goal\ntowards carbon neutrality by 2030.\n",
        "title": "Full Scaling Automation for Sustainable Development of Green Data\n  Centers",
        "texts": [
            "Figure 1: Model Architecture. Red dashed lines represent the workload forecast module, including Multi-scale Time Series Representation and Representation-enhanced Deep Autoregressive Model. Blue dashed lines highlight the scaling decision module via task-conditioned Bayesian neural regression. According to service tolerance for response time(rt), the optimal value between upper and lower bounds is obtained.",
            "Figure 10: The performance (lower is better) of different autoscaling approaches.",
            "Figure 11: The performance of Autoscaling deployed in the production environment. Blue vertical dotted line indicates the launch of FSA. Green frame highlights the comparison of the metrics under the same workload before and after enabling FSA.",
            "Figure 2: Multi-scale Time Series Representation",
            "Figure 4: Visualization of TS representation of two weeks (every 10min). Changes in daily and weekly periods are clearly indicated.",
            "Figure 5: The performance(lower is better) of different autoscaling approaches.",
            "Figure 6: The Comparison of Electric Energy Consumptions. The red line represents the electricity consumption of baseline, and blue line is the electricity cost of FSA. The green histogram is the carbon emission reduction using FSA over the past four years.",
            "Figure 7: Exemplar forecastings for workload TS. Blue lines are the ground truths and orange lines are the model predictions.",
            "Figure 8: Visualization of TS representation of different windows of TS (every 10 minutes).",
            "Figure 9: Visualization of CPU-utilization and workload estimation. Blue lines are the mean of estimation. Red scattered points are the ground truths. Purple area is the confidence interval.",
            "Table 1: The performance (lower is better) averaged over 5 runs. We conduct the ablation study on our model without repr.",
            "Table 2: The performance (lower is better) averaged over 5 runs."
        ],
        "imgs": [
            "$2305.00706v1-Figure1-1.png",
            "$2305.00706v1-Figure10-1.png",
            "$2305.00706v1-Figure11-1.png",
            "$2305.00706v1-Figure2-1.png",
            "$2305.00706v1-Figure4-1.png",
            "$2305.00706v1-Figure5-1.png",
            "$2305.00706v1-Figure6-1.png",
            "$2305.00706v1-Figure7-1.png",
            "$2305.00706v1-Figure8-1.png",
            "$2305.00706v1-Figure9-1.png",
            "$2305.00706v1-Table1-1.png",
            "$2305.00706v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00708",
        "abstract": "  Over the past 50 years, conventional network routing design has undergone\nsubstantial growth, evolving from small networks with static nodes to large\nsystems connecting billions of devices. This progress has been achieved through\nthe separation of concerns principle, which entails integrating network\nfunctionalities into a graph or random network design and employing specific\nnetwork protocols to facilitate diverse communication capabilities. This paper\naims to highlight the potential of designing routing techniques for quantum\nnetworks, which exhibit unique properties due to quantum mechanics. Quantum\nrouting design requires a substantial deviation from conventional network\ndesign protocols since it must account for the unique features of quantum\nentanglement and information. However, implementing these techniques poses\nsignificant challenges, such as decoherence and noise in quantum systems,\nrestricted communication ranges, and highly specialized hardware prerequisites.\nThe paper commences by examining essential research on quantum routing design\nmethods and proceeds to cover fundamental aspects of quantum routing,\nassociated quantum operations, and the steps necessary for building efficient\nand robust quantum networks. This paper summarizes the present state of quantum\nrouting techniques, including their principles, protocols, and challenges,\nhighlighting potential applications and future directions.\n",
        "title": "Routing Protocols for Quantum Networks: Overview and Challenges",
        "texts": [
            "Fig. 1: Entanglement generation, purification, and swapping in quantum networks.",
            "Fig. 2: The process of communication distribution in quantum networks.",
            "Fig. 3: Edge subdivision-based network design for quantum networks.",
            "Fig. 4: Classification of quantum routing."
        ],
        "imgs": [
            "$2305.00708v1-Figure1-1.png",
            "$2305.00708v1-Figure2-1.png",
            "$2305.00708v1-Figure3-1.png",
            "$2305.00708v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00709",
        "abstract": "  On-chip integration of two-dimensional (2D) materials offers great potential\nfor the realization of novel optoelectronic devices in different photonic\nplatforms. In particular, indium selenide (InSe) is a very promising 2D\nmaterial due to its ultra-high carrier mobility and outstanding\nphoto-responsivity. Here, we report a high-speed photodetector based on a\nmultilayer 90 nm thick InSe integrated on a silicon nitride (SiN) waveguide.\nThe device exhibits a low dark current of 10 nA at 1V bias, a remarkable\nphotoresponsivity of 0.38 AW-1, and high external quantum efficiency of 48.4%\nmeasured at 5 V bias. This performance is tested at near-infrared (NIR) 976 nm\nwavelength under ambient conditions. Furthermore, using numerical and\nexperimental investigations, the estimated absorption coefficient per unit\nlength is 0.11dB/um. To determine the dynamic response of the photodetector,\nits small and large signal frequency response are also evaluated. A 3-dB\nradiofrequency (RF) bandwidth of 85 MHz is measured with an open-eye diagram\nobserved at 1 Gbit/s data transmission. Given these outstanding optoelectronic\nmerits, active photonic devices based on integrated multilayer InSe can be\nrealized for a variety of applications including short-reach optical\ninterconnects, LiDAR imaging, and biosensing.\n",
        "title": "A High-Speed Waveguide Integrated InSe Photodetector on SiN Photonics\n  for NIR Applications",
        "texts": [
            "Figure 1. Hybrid integration of InSe into SiN photonic circuit (a) optical image of the SiN unloaded waveguide chip. (b) 3D cross-section and schematic representation of heterogeneous InSe/SiN photodetector. (c) A SEM image of the transferred InSe on SiN waveguide. (f) An AFM image scan, the dashed yellow line shows a thickness of ∼ 90 nm InSe and interaction length of ~ 30 µm.",
            "Figure 2. Material characterization and guided light interaction of 90 nm thick InSe layer with a length of 30 µm at 976 nm wavelength (a) SEM scan with EDS maps captured from the multilayer InSe. The scale bar is 50 μm. (b) XRD spectrum of the bulk β-InSe. (c) electric-field profiles (|E|2) of TE modes of unloaded SiN waveguide and 90 nm InSe on SiN at 976 nm (top panel). FDTD simulation of beam propagation (bottom panel) (d) measured optical propagation losses of InSe. Inset shows a schematic representation of the measurement setup.",
            "Figure 3. Static response of InSe photodetector (a) I-V characteristics of the waveguide integrated InSe photodetector under dark and different powers for 976 nm wavelength, respectively. Inset shows the dark current of the device. (b) The generated photocurrent for different coupled laser powers. (c-d) The measured photocurrent, responsivity, and EQE are at different powers.",
            "Figure 4. Dynamic performance characteristics of the InSe photodetector (a) Normalized frequency response at 10V. A total of 50 measurements (blue scattered points) and average (red line) data are plotted. A 3-dB cutoff frequency of 85 MHz is measured. (b-c) the temporal response recorded in the time domain for 100 MHz and 1GHz modulated optical signals, the curves are smoothed by using 200 points moving average.",
            "Figure 5. Measured eye diagram at data rate from 50 Mbit/s to 1 Gbit/s NRZ modulation at 10 V bias .",
            "Figure 6: A performance summary of the integrated photodetector based on 2D materials which are previously reported showing their operating spectral response, bandwidth, and responsivity along with the InSe photodetector presented in this work."
        ],
        "imgs": [
            "$2305.00709v1-Figure1-1.png",
            "$2305.00709v1-Figure2-1.png",
            "$2305.00709v1-Figure3-1.png",
            "$2305.00709v1-Figure4-1.png",
            "$2305.00709v1-Figure5-1.png",
            "$2305.00709v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00710",
        "abstract": "  The development of new manufacturing techniques such as 3D printing have\nenabled the creation of previously infeasible chemical reactor designs.\nSystematically optimizing the highly parameterized geometries involved in these\nnew classes of reactor is vital to ensure enhanced mixing characteristics and\nfeasible manufacturability. Here we present a framework to rapidly solve this\nnonlinear, computationally expensive, and derivative-free problem, enabling the\nfast prototype of novel reactor parameterizations. We take advantage of\nGaussian processes to adaptively learn a multi-fidelity model of reactor\nsimulations across a number of different continuous mesh fidelities. The search\nspace of reactor geometries is explored through an amalgam of different,\npotentially lower, fidelity simulations which are chosen for evaluation based\non weighted acquisition function, trading off information gain with cost of\nsimulation. Within our framework we derive a novel criteria for monitoring the\nprogress and dictating the termination of multi-fidelity Bayesian optimization,\nensuring a high fidelity solution is returned before experimental budget is\nexhausted. The class of reactor we investigate are helical-tube reactors under\npulsed-flow conditions, which have demonstrated outstanding mixing\ncharacteristics, have the potential to be highly parameterized, and are easily\nmanufactured using 3D printing. To validate our results, we 3D print and\nexperimentally validate the optimal reactor geometry, confirming its mixing\nperformance. In doing so we demonstrate our design framework to be extensible\nto a broad variety of expensive simulation-based optimization problems,\nsupporting the design of the next generation of highly parameterized chemical\nreactors.\n",
        "title": "Multi-Fidelity Data-Driven Design and Analysis of Reactor and Tube\n  Simulations",
        "texts": [
            "Figure 1: Left: A side-view of how coil radius, pitch, and the inversion parameter effects a given coil, with an additional horizontal inlet and outlet. Right: When parameterizing a coil with horizontal inlet and outlet, we include a smooth transition based on a quadratic interpolation of points.",
            "Figure 10: The number of equivalent tanks-in-series evaluated colored by the respective cost of simulation. The upper half of the figure shows these quantities against iteration and the lower half shows these quantities against wall-clock time, highlighting the importance of lower-cost simulations.",
            "Figure 11: The fidelities selected throughout optimization within Z . The upper plot demonstrates the average simulation cost at each fidelity. As we apply discrete fidelities which are continuously approximated, we present the lower plot which demonstrates the number of times each discrete fidelity is evaluated. Simulation cost is confirmed to be not only a function of fidelity, but x as well, as there is no clear distribution of simulation costs across Z .",
            "Figure 12: The maximum predicted time to complete a ‘standard’ iteration compared with the maximum predicted time to complete both a standard iteration as well as a greedy iteration, the actual simulation time, and the remaining time. As the blue line passes above the black line, a greedy iteration must be performed as there is not enough remaining budget to perform both a greedy and standard evaluation",
            "Figure 13: Optimal reactor geometry viewed from different perspectives. The optimal geometry contains an inversion.",
            "Figure 15: Experimental validation of optimal reactor configuration via additive manufacturing and operation under pulsed-flow operating conditions.",
            "Figure 16: The residence-time distribution predicted via CFD simulation of the optimal, high-fidelity solution returned from the framework, alongside 3 sets of experimental data obtained via the 3D printed reactor.",
            "Figure 17: The number of equivalent tanks-in-series evaluated coloured by the respective cost of simulation. Optimization is performed with hyper-parameters γ = 1/2 and β = 1/2. The upper half of the figure shows these quantities against iteration and the lower half shows these quantities against wall-clock time, highlighting the importance of lower-cost simulations.",
            "Figure 18: The fidelities selected throughout optimization withinZ . The upper plot demonstrates the average simulation cost at each fidelity. Optimization is performed with hyper-parameters γ = 1/2 and β = 1/2.",
            "Figure 19: The optimal solution resulting from optimization with hyper-parameters γ = 1/2 and β = 1/2, the solution visually is similar to the solution presented in the main part of this article. The number of equivalent tanks-in-series of this configuration and operating conditions is 34.5.",
            "Figure 2: A side-view of the meshing procedure of a coil based on axial fidelity. We first define a central path based on geometric parameters. Subsequently, circles (tube cross-sections) are defined along this path the number of which depends on the axial fidelity. Finally, the mesh density near the inlet and outlet walls is increased by raising the number of circles to track the tracer concentration with higher accuracy.",
            "Figure 20: The number of equivalent tanks-in-series evaluated coloured by the respective cost of simulation. Optimization is performed with hyper-parameters γ = 1/2 and β = 1. The upper half of the figure shows these quantities against iteration and the lower half shows these quantities against wall-clock time, highlighting the importance of lower-cost simulations.",
            "Figure 21: The fidelities selected throughout optimization withinZ . The upper plot demonstrates the average simulation cost at each fidelity. Optimization is performed with hyper-parameters γ = 1/2 and β = 1.",
            "Figure 22: The optimal solution resulting from optimization with hyper-parameters γ = 1/2 and β = 1, the solution differs in that it does not contain an inversion, however the coil radius and operating conditions are consistent with the other optimal solutions. The number of equivalent tanks-in-series of this configuration and operating conditions is 26.8.",
            "Figure 3: A cross-section of the mesh radially. First, a coarse finite element topology is created. Subsequently, the number of cells near the tube wall are increased in order to better capture the effects of fluid flow near the boundary layer. Finally the mesh is further subdivided based on the radial fidelity value.",
            "Figure 4: Experimental residence time distribution against the residence time distribution modeled using the ideal tank-in-series relation, given by Eq. 4, with a value of equivalent tanks in series derived from Eq. 5",
            "Figure 8: An instance of helical-tube reactor geometry as affected by axial and radial fidelity.",
            "Figure 9: Validation of five discrete mesh fidelities corresponding to different cell counts, across two sets of experimental data under different conditions."
        ],
        "imgs": [
            "$2305.00710v3-Figure1-1.png",
            "$2305.00710v3-Figure10-1.png",
            "$2305.00710v3-Figure11-1.png",
            "$2305.00710v3-Figure12-1.png",
            "$2305.00710v3-Figure13-1.png",
            "$2305.00710v3-Figure15-1.png",
            "$2305.00710v3-Figure16-1.png",
            "$2305.00710v3-Figure17-1.png",
            "$2305.00710v3-Figure18-1.png",
            "$2305.00710v3-Figure19-1.png",
            "$2305.00710v3-Figure2-1.png",
            "$2305.00710v3-Figure20-1.png",
            "$2305.00710v3-Figure21-1.png",
            "$2305.00710v3-Figure22-1.png",
            "$2305.00710v3-Figure3-1.png",
            "$2305.00710v3-Figure4-1.png",
            "$2305.00710v3-Figure8-1.png",
            "$2305.00710v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00711",
        "abstract": "  Hawking's quasi-local energy definition quantifies the energy enclosed by a\nspacelike 2-sphere in terms of the amount of lightbending on the sphere caused\nby the energy distribution inside the sphere. This paper establishes for the\nfirst time a direct connection between the formal mathematical definition of a\nquasi-local energy and observations, in the context of cosmological\nperturbation theory. This is achieved by studying the Hawking Energy of\nspherical sections of the past lightcone of a cosmic observer in a perturbed\nFriedmann-Lema\\^{i}tre spacetime. We express the Hawking Energy in terms of\ngauge-invariant perturbation variables and comment on the cosmic observables\nneeded to in principle measure it. We then calculate its angular power spectrum\nand interpret its contributions.\n",
        "title": "The Hawking Energy in a Perturbed Friedmann-Lema\\^{i}tre Universe",
        "texts": [
            "Figure 1: Geodesic Lightcone Coordinates adapted to past lightcones along the observer’s worldine γ(λ). The past lightcone at a point p on this worldline is then given by the hypersurface w=const., whereas τ=const. surfaces foliate the lightcone. k is a future-pointing null vector on the lightcone. The union of all k in all directions (θ̃1, θ̃2) on the celestial sphere at p is the set of light cone generators.",
            "Figure 2: Angular power spectrum CE ℓ at redshifts z = 0.5, 1, 1.5, 2, 3, 5 from top to bottom up to ℓ = 800. The black dotted curves correspond to the respective density contribution only, see (3.34). The red dashed curve for the highest redshift z = 5 corresponds to all terms except lensing. Hence, the difference in the amplitudes between the density contribution only and all terms is due to lensing cross correlations.",
            "Figure 3: Monopole (blue) and dipole (red) as function of redshift. The dotted red curve is the dipole without the peculiar velocity of the observer. Thus, the dominant part of the dipole amplitude is due to the observer’s peculiar velocity.",
            "Table 1: Cosmological parameters based on Planck data [15] used in the computation of the power spectra in this section."
        ],
        "imgs": [
            "$2305.00711v2-Figure1-1.png",
            "$2305.00711v2-Figure2-1.png",
            "$2305.00711v2-Figure3-1.png",
            "$2305.00711v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00713",
        "abstract": "  In the wake of measurements on $B_c^+ \\to J/\\psi K^+$, $B_c^+ \\to J/\\psi\n\\pi^+\\pi^-\\pi^+$, and $B_c^+ \\to J/\\psi K^+ K^-\\pi^+$ at Large Hadron Collider\nexperiments, we propose to study the decays $B_c^+ \\to J/\\psi M^+$\ncomprehensively, with $M$ being the light charged pseudoscalar ($P$), vector\n($V$), scalar ($S$), axial-vector ($A$), and tensor ($T$) mesons, within the\nimproved perturbative QCD (iPQCD) formalism at leading order in the Standard\nModel. The theoretical predictions for experimental observables such as\nbranching fractions, relative ratios, and longitudinal polarization fractions\nin the iPQCD formalism await near future examinations relying on the upgraded\nLarge Hadron Collider, even the forthcoming Circular Electron-Positron\nCollider. We emphasize that the investigations on the\nfactorizable-emission-suppressed or -forbidden decays like $B_c^+ \\to J/\\psi\nS^+$, $B_c^+ \\to J/\\psi A^+_{1^1\\!P_1}$, and $B_c^+ \\to J/\\psi T^+$, should go\ndefinitely beyond naive factorization to explore the rich dynamics, which\ncould, in turn, further help understand the QCD nature of $B_c$ meson, as well\nas that of related hadrons. The future confirmations on those predictions about\nthe relative ratios between the branching fractions of $B_c^+ \\to J/\\psi\nb_1(1235)^+ (a_0(980)^+, a_0(1450)^+, a_2(1320)^+)$ and $B_c^+ \\to J/\\psi\n\\pi^+$ could further examine the reliability of this iPQCD formalism. Because\nof containing only tree-level $\\bar b \\to \\bar c$ transitions, the {\\it CP}\nasymmetries in the $B_c^+ \\to J/\\psi M^+$ decays exhibit naturally zero.\n",
        "title": "$B_c$-meson decays into $J/\\psi$ plus a light meson in the improved\n  perturbative QCD formalism",
        "texts": [
            "FIG. 1. (Color online) Leading order Feynman diagrams for the decays B+ c → J/ψM+ in the iPQCD formalism.",
            "TABLE I. Relative ratios from the branching fractions for the decays B+ c → J/ψP+, B+ c → J/ψV +, and B+ c → J/ψa+1 in the literature at both aspects of theory and experiment."
        ],
        "imgs": [
            "$2305.00713v2-Figure1-1.png",
            "$2305.00713v2-TableI-1.png"
        ]
    },
    {
        "id": "2305.00718",
        "abstract": "  The human eye consists of two types of photoreceptors, rods and cones. Rods\nare responsible for monochrome vision, and cones for color vision. The number\nof rods is much higher than the cones, which means that most human vision\nprocessing is done in monochrome. An event camera reports the change in pixel\nintensity and is analogous to rods. Event and color cameras in computer vision\nare like rods and cones in human vision. Humans can notice objects moving in\nthe peripheral vision (far right and left), but we cannot classify them (think\nof someone passing by on your far left or far right, this can trigger your\nattention without knowing who they are). Thus, rods act as a region proposal\nnetwork (RPN) in human vision. Therefore, an event camera can act as a region\nproposal network in deep learning Two-stage object detectors in deep learning,\nsuch as Mask R-CNN, consist of a backbone for feature extraction and a RPN.\nCurrently, RPN uses the brute force method by trying out all the possible\nbounding boxes to detect an object. This requires much computation time to\ngenerate region proposals making two-stage detectors inconvenient for fast\napplications. This work replaces the RPN in Mask-RCNN of detectron2 with an\nevent camera for generating proposals for moving objects. Thus, saving time and\nbeing computationally less expensive. The proposed approach is faster than the\ntwo-stage detectors with comparable accuracy\n",
        "title": "Event Camera as Region Proposal Network",
        "texts": [
            "Fig. 1. Block diagram of the Mask RCNN based implementation of detectron2 (referred to as the base detectron2 in this work)[1].",
            "Fig. 2. Architecture of the proposed method. This is referred to as the modified detectron2 architecture in this work.",
            "Fig. 4. A frame from each recorded video",
            "TABLE I AVERAGE PRECISION(AP) VALUES FOR EXPERIMENTS CONDUCTED ON RECORDED VIDEOS. INTERSECTION OVER UNION (IOU) IS CONSIDERED TO BE LARGER THAN OR EQUAL TO 0.75. MEAN AVERAGE PRECISION(MAP) IS CALCULATED BY TAKING THE MEAN OF ALL THE AP. AR IS THE AVERAGE RECALL"
        ],
        "imgs": [
            "$2305.00718v1-Figure1-1.png",
            "$2305.00718v1-Figure2-1.png",
            "$2305.00718v1-Figure4-1.png",
            "$2305.00718v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00719",
        "abstract": "  In semiconductors, the identification of doping atomic elements allowing to\nencode a qubit within spin states is of intense interest for quantum\ntechnologies. In transition metal dichalcogenides semiconductors, the strong\nspin-orbit coupling produces locked spin-valley states with expected long\ncoherence time. Here we study the substitutional Bromine Br\\textsubscript{Te}\ndopant in 2H-MoTe$_2$. Electron spin resonance measurements show that this\ndopant carries a spin with long-lived nanoseconds coherence time. Using\nscanning tunneling spectroscopy, we find that the hydrogenic wavefunctions\nassociated with the dopant levels have characteristics spatial modulations that\nresult from their hybridization to the \\textbf{Q}-valleys of the conduction\nband. From a Fourier analysis of the conductance maps, we find that the\namplitude and phase of the Fourier components change with energy according to\nthe different irreducible representations of the impurity-site point-group\nsymmetry. These results demonstrate that a dopant can inherit the locked\nspin-valley properties of the semiconductor and so exhibit long spin-coherence\ntime.\n",
        "title": "Hydrogenic Spin-Valley states of the Bromine donor in 2H-MoTe$_2$",
        "texts": [
            "Fig. 1 Transport properties of Br-doped 2H-MoTe2 a, Longitudinal resistivity ρxx as a function of temperature. It is calculated from ρxx = Rxxl × t/L where t ≈ 30 µm is the thickness of the crystal, l ≈ 1 mm the width and L ≈ 1 mm the length. The room temperature resistivity is ρ ≈ 50 mΩ cm and decreases upon cooling down to the temperature of 225 K, indicating a saturation regime from room temperature down to 225 K where the mobility is limited by phonon-scattering. At lower temperature, an activated regime and a hopping regime are visualized on an Arrhenius plot as shown in main text. b, Carrier concentration n3D on semilog scale as a function of the temperature. From the transverse Hall resistance Rxy measured as a function of a perpendicular magnetic field B, one obtains the Hall coefficient ρH = Rxyt B and so the carrier concentration from n3D = 1 eρH . In the saturation regime, n3D = 2 × 1018 cm−3 as indicated by the horizontal dashed line. Inset: Carrier concentration as function of temperature on linear scale to highlight the temperature dependence from 150 K to 300 K. c, Mobility as function of temperature. The mobility is calculated from µ = 1/eρxxn3D. Using the relation for the resistivity and the carrier concentration and using l = L, the mobility µ = Rxy/Rxx does not depend on geometrical factors and so is obtained with high precision. The mobility is increasing from room temperature down to 225 K because of the reduction in phonon scattering as expected in the saturation regime [8]. It reaches a maximum of µ ≈ 570 cm2V−1s−1 as indicated by the horizontal dashed line. The peak in mobility just before the activated regime is commonly observed in doped semiconductors [8] because of the drop in carrier concentration at this temperature as visible on panel b. However, this peak and the mobility data at lower temperature are not meaningful. d Mobility in the hopping regime calculated from µ = 1/eρxxn3D where we assume that all carriers of density n3D = 2× 1018 cm−3 are contributing to the hopping transport, as done in Ref. [8]. e, Hopping length calculated following Ref. [8]. The temperature dependence of the resistivity is fitted by a Mott law ρ ∝ exp(ξc) with the correlation length ξc = (T0/T )1/3, valid at two dimensions, and gives T0 ≈ 27× 103 K. From the correlation length, one obtains the average hopping length r̄ = aξc/4 where a is the Bohr radius calculated in the main text. f, Correlation time τc calculated using the Einstein relation µ(T ) = eD/kBT between the mobility calculated in the hopping regime and the diffusion constant D = r̄2/τc.",
            "Fig. 10 Displaying the phase of a 2D FFT. The phase of the 2D-FFT is relevant only at wavevectors where the Fourier amplitude is large. In other words, the phase of a complex number of zero amplitude is undefined. a, Topographic image of the BrTe dopant. The white scale bar is 3 nm long. b, Map of the amplitude of the 2D-FFT applied to the topographic image. The dashed black circles indicate the position of major peaks in the 2D-FFT and are plot at the same position in the phase maps de. c, Map of the phase of the 2D-FFT. Because of the phase noise in areas where the amplitude is small, the visualization of the phase pattern is difficult. d, Adding dashed white circles around the area where a peak is observed in the amplitude map of the 2D-FFT already helps the visualization of the phase pattern. e, To improve even more the visualization, the phase data is only shown within the white dashed circles, otherwise, the phase is set to zero. The same procedure is employed for displaying the phase maps everywhere in the main manuscript and Supplementary. Note that the phase pattern observed here corresponds to the fully symmetry irrep A. For panels cde, the white scale bars are equal to the length of the reciprocal lattice vector ‖~a?‖.",
            "Fig. 11 Amplitude of 2D-FFT at different sample bias.. Maps of the amplitude of the 2D-FFT applied to the conductance maps shown in Fig. 9, at different sample bias. The black scale bars show on the last panel is equal to the length of the reciprocal lattice vector ‖~a?‖.",
            "Fig. 12 Phase of 2D-FFT at different sample bias.. Maps of the amplitude of the 2DFFT applied to the conductance maps shown in Fig. 9, at different sample bias. The black scale bars show on the last panel is equal to the length of the reciprocal lattice vector ‖~a?‖.",
            "Fig. 13 Amplitude and phase of the Fourier components qi. a, Plot of the amplitude of the Fourier components qi (continuous line) and q̄i (dashed line) as function of sample bias. Note the maxima at the sample bias of 0.07 V, -0.7 V and -0.9 V, corresponding to the CBS, IGS and VBS, respectively. b, Plot of the phase of the same Fourier components. Note that the phase remains constant in the energy ranges CBS, IGS and VBS, where the phase value is either a multiple of π or a multiple of π/3. Note the rapid phase shift, indicated by vertical red lines, at sample bias -0.015 V, -0.47 V and -0.8 V, separating the CBS from the IGS from the VBS, successively. They indicate change in the symmetry of the dopant states, as expected from the lifting of the valley degeneracy according to the irreps of the double point-group C3v as shown in Fig. 4a of the main text.",
            "Fig. 14 Side by side comparison of conductance maps of BrTe and calculated probability densities. abc, Conductance maps at sample bias of 0.07 V, -0.7 V and -0.9 V, corresponding to the CBS, IGS and VBS, respectively. The scale bar shown on panel c is 3 nm long. def, For each panel, the probability density of symmetry adapted eigenstates is calculated for the irrep indicated in the panel. Using the same valley wavevectors, we see that changing the phase factors in the linear combination of valley Bloch states is sufficient to explain the change of spatial maps at different energies. The thin dash lines indicate similar motifs on both the experimental conductance maps and the calculated probability density. As a guide to eye, a plus symbol indicates the center of all images.",
            "Fig. 15 DFT calculation of BrTe dopant in a MoTe2 monolayer. a, DOS as function of energy for a pristine (black) and BrTe dopant (red). For the dopant, the DFT calculations show that the last electron-filled state (Fermi energy) is located at the bottom of the conduction band, indicated by a red arrow. b, Map of the local DOS, integrated between EF+0.1 V and EF+0.3 V, showing a modulation of the DOS around the dopant. c, This modulation is a consequence of the hybridization of the p orbital of the dopant with the Bloch states at the K-point of the conduction band, see text. Both images are plot on the same scale. Te atoms are indicated as white dots, the Br atom is indicated as a red dot at the centers of the images.",
            "Fig. 16 Partial density of states for BrTe dopant in a MoTe2 monolayer. From the DFT calculations, we extract the PDOS as function of energy for the p-orbitals and dorbitals of the Br atom and the p- and d-orbitals of the 1st and 2nd neighbors Mo atoms surrounding the Br atom. We see that near zero energy, where is located the donor-state, a large contribution arise from the px+py orbitals of the Br atom but the largest contribution arise from the dz2 orbitals of the 1st and 2nd neighbors Mo atoms. This is consistent with expected E symmetry of the Bloch states at the K-point and confirm the hybridization of the dopant level with the Bloch states at the K-valleys known to have mostly dz2 character.",
            "Fig. 2 Point-defects: Scanning tunneling microscopy (STM) topographies and two-dimensional fast Fourier transforms (2D-FFTs). ab, STM topographies of MoTe (Isetpoint = 180 pA) and BrTe (Isetpoint = 400 pA), respectively, measured at sample bias -1 V and temperature of 77 K. The color bar quantifies the topographic height. A non linear color scale has been used to improve the visibility of Te atoms in the background. The white scale bar on each panel is 3 nm long. cd, Maps of the amplitude of the 2D-FFTs applied to the topographic images. The color bar quantifies the FFT amplitude. A non-linear color scale has been employed to improve the visibility of the FFT peaks of small amplitude. The black scale bar on each panel is equal to the length of the reciprocal lattice vector ‖~a?‖ = 20.44 nm−1. c,e, For MoTe, only the Bragg peaks (pink plus symbol) are observed. efg, For BrTe, peaks in the Fourier amplitude are observed at the intra-valley Fourier components mi = qj − qi (green star symbols) and peaks of strongest amplitude are observed at the inter-valley Fourier components qi = qj − q̄i (red and blue disc symbols) and hi = qi − q̄i (orange disc symbols). The arrows show how the Fourier components arise from the valleys wavevectors qj and q̄i.",
            "Fig. 3 BrTe : Scanning tunneling spectroscopy (STS), conductance maps and two-dimensional fast Fourier transforms (2D-FFTs). a, Scanning tunneling microscopy (STM) topography of BrTe. b, Differential conductance dI dV (V ) as function of sample bias. The red (black) curve is obtained by averaging the spectra within the circle located at the center (away) from the dopant, shown on panel a. The ranges corresponding to valence band states (VBS), in-gap states (IGS) and conduction band states (CBS) are indicated as green, red and blue zones, respectively. c, Differential conductance map as function of sample bias and distance along a path going through BrTe center, shown as a white dashed line in panel a. The color bar quantifies the conductance value. The origin of the distance scale starts at the most left end of the white dashed line. The VBS, IGS and CBS ranges are indicated at the bottom. def, Differential conductance maps at sample bias of 0.07, -0.7 et -0.9 V, corresponding to the CBS, IGS and VBS, respectively. The scale bar shown on panel f is 3 nm long. As a guide to eye, a plus symbol indicates the center of the image. ghi, Maps of the amplitude of 2D-FFTs applied to the conductance maps. Note that the wavevectors coordinates of the maxima are not changing with energy. jkl, Maps of the phase of the 2D-FFTs. Note that the phase pattern is changing with energy. The scale bars shown on panels il are equal to the length of the reciprocal lattice vector ‖~a?‖. m, Plot of the amplitude of the Fourier components mi (continuous line) and m̄i (dashed line) as function of sample bias. Note that the amplitude is large only in the colored zones corresponding to the VBS, IGS and CBS. n, Plot of the corresponding phase for the same components. Note that the phase remains constant in the energy ranges VBS, IGS and CBS, where the phase value is either a multiple of π or a multiple of π/3. Note the rapid phase shift, indicated by vertical red lines, at sample bias -0.015 V, -0.47 V and -0.8 V, separating the CBS from the IGS from the VBS, successively.",
            "Fig. 4 ESR signal as function of azimuthal angle. a, The black curves show the ESR signal as function of azimuthal angle. The red dashed curves show the fitting curves. The red arrows are separated by 3 ×A, the black arrows are separated by 2 ×A, enabling the determination of the hyperfine coupling constants for in-plane and out-of-plane magnetic field. b, The black curves show the ESR signal as function of azimuthal angle near 50 ◦ where the quadrupolar-induced weak resonances are observed in the simulation. We see clearly, at 50 ◦ and 40 ◦, that the two weak resonances are located symmetrically with respect to the major line. From their magnetic field separation, indicated by vertical red dashed lines, the quadrupolar coupling constant νq = −1800 MHz is determined.",
            "Fig. 5 ESR signal as function of temperature. The black curves show the ESR signal as function of temperature for a magnetic field applied in-plane. The red dashed curves show the fitting curves from which the linewidth and the spin coherence time is extracted as described in the main text.",
            "Fig. 6 Atomic position of the Br dopant. a, Topographic STM image of the BrTe dopant. To locate its position with respect to the Te lattice, a 2D FFT is performed followed by a selection of the Bragg peaks and reversed FFT, whose results is shown in panel b, where the Te atom lattice is observed. This last image is multiplied by 200 and added to the original topographic image to highlight the position of the dopant with respect to the Te lattice, shown panel c. The BrTe is clearly substituting a Te atom. A plus symbol on each image is plotted at the same position to help the visualization of the dopant position. The position of Te atoms is indicated as green on each image. The scale bar on panel a is 3 nm long.",
            "Fig. 7 Topographic profile of the two point-defects. The scale bars are 2 nm and 4 nm long for MoTe and BrTe, respectively. The continuous red curve is a plot of the envelope function ρ(r) = |ψ(r)|2 ∝ exp(−2r/aB) where ψ(r) ∝ exp(−r/aB) describes the decay of the n = 1 hydrogenic wavefunction.",
            "Fig. 9 Conductance maps at different sample bias. Differential conductance maps dI dV from the conduction band at sample bias = 0.2 V, to the valence band at sample bias = -1.1 V. The white scale bar on the last panel is 3 nm long. A plus symbol indicates the center of the images.",
            "Table 2 Parameters of the effective spin Hamiltonian."
        ],
        "imgs": [
            "$2305.00719v1-Figure1-1.png",
            "$2305.00719v1-Figure10-1.png",
            "$2305.00719v1-Figure11-1.png",
            "$2305.00719v1-Figure12-1.png",
            "$2305.00719v1-Figure13-1.png",
            "$2305.00719v1-Figure14-1.png",
            "$2305.00719v1-Figure15-1.png",
            "$2305.00719v1-Figure16-1.png",
            "$2305.00719v1-Figure2-1.png",
            "$2305.00719v1-Figure3-1.png",
            "$2305.00719v1-Figure4-1.png",
            "$2305.00719v1-Figure5-1.png",
            "$2305.00719v1-Figure6-1.png",
            "$2305.00719v1-Figure7-1.png",
            "$2305.00719v1-Figure9-1.png",
            "$2305.00719v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00720",
        "abstract": "  To solve 3SAT instances on quantum annealers they need to be transformed to\nan instance of Quadratic Unconstrained Binary Optimization (QUBO). When there\nare multiple transformations available, the question arises whether different\ntransformations lead to differences in the obtained solution quality. Thus, in\nthis paper we conduct an empirical benchmark study, in which we compare four\nstructurally different QUBO transformations for the 3SAT problem with regards\nto the solution quality on D-Wave's Advantage_system4.1. We show that the\nchoice of QUBO transformation can significantly impact the number of correct\nsolutions the quantum annealer returns. Furthermore, we show that the size of a\nQUBO instance (i.e., the dimension of the QUBO matrix) is not a sufficient\npredictor for solution quality, as larger QUBO instances may produce better\nresults than smaller QUBO instances for the same problem. We also empirically\nshow that the number of different quadratic values of a QUBO instance, combined\nwith their range, can significantly impact the solution quality.\n",
        "title": "Influence of Different 3SAT-to-QUBO Transformations on the Solution\n  Quality of Quantum Annealing: A Benchmark Study",
        "texts": [
            "Figure 1: Embedding sizes for experiment 1. Noticeably the",
            "Figure 2: Number of different quadratic values for the QU-",
            "Figure 3: Distribution of the size of the values ranges (biggest",
            "Table 1: Pattern QUBOs for the four different types of"
        ],
        "imgs": [
            "$2305.00720v1-Figure1-1.png",
            "$2305.00720v1-Figure2-1.png",
            "$2305.00720v1-Figure3-1.png",
            "$2305.00720v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00721",
        "abstract": "  Multiuser Massive MIMO is ongoing wireless technology with high prospects in\nthe distributed architecture with various system design and splitting options.\nAny of such solutions suffer from imperfect synchronization that can be reduced\nvia promising OTA (Over the Air) pilot exchanges. In this paper we introduce\nrequirements and algorithm for flexible non orthogonal pilot design for time\nsynchronization without changes to 3GPP protocol stack. Our solution decreases\nnumber of synchronization slots and solves problem of separating guard\nintervals.\n",
        "title": "Pilot Synthesis for Distributed Synchronization",
        "texts": [
            "Fig. 1. Overall representation of synchronization process.",
            "Fig. 2. Visualization of algorithm idea.",
            "Fig. 4. Representation of 1 of converged set of 4 pilots in TD/FD.",
            "Fig. 5. ACF/MCF of converged set of 4 pilots.",
            "Table 3 contains performance analysis results of pilot synthesis algorithm with PAPR reduction technique for various ratio between MainPeak-to-SidePeak and PAPR values. Such procedure works efficiently, but slightly decrease ACF/MCF properties of designed pilots.",
            "TABLE III. PAPR REDUCTION PERFORMANCE"
        ],
        "imgs": [
            "$2305.00721v1-Figure1-1.png",
            "$2305.00721v1-Figure2-1.png",
            "$2305.00721v1-Figure4-1.png",
            "$2305.00721v1-Figure5-1.png",
            "$2305.00721v1-Table3-1.png",
            "$2305.00721v1-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00723",
        "abstract": "  As supported by abundant experimental evidence, neural networks are\nstate-of-the-art for many approximation tasks in high-dimensional spaces.\nStill, there is a lack of a rigorous theoretical understanding of what they can\napproximate, at which cost, and at which accuracy. One network architecture of\npractical use, especially for approximation tasks involving images, is\n(residual) convolutional networks. However, due to the locality of the linear\noperators involved in these networks, their analysis is more complicated than\nthat of fully connected neural networks. This paper deals with approximation of\ntime sequences where each observation is a matrix. We show that with relatively\nsmall networks, we can represent exactly a class of numerical discretizations\nof PDEs based on the method of lines. We constructively derive these results by\nexploiting the connections between discrete convolution and finite difference\noperators. Our network architecture is inspired by those typically adopted in\nthe approximation of time sequences. We support our theoretical results with\nnumerical experiments simulating the linear advection, heat, and Fisher\nequations.\n",
        "title": "Predictions Based on Pixel Data: Insights from PDEs and Finite\n  Differences",
        "texts": [
            "Figure 1. Visual representation of the prediction provided by the neural network we consider for one specific test initial condition, and snapshots coming from the space-time discretisation of the reaction diffusion equation (40). The parameters of the network and of the PDE can be found respectively in subsection 4.3 and appendix A. From the left we have the initial condition, the true space discretisation of the solution at time 40δt, the network prediction, and the difference between the last two matrices.",
            "Figure 2. Plots of the two activation functions adopted in the architecture",
            "Figure 3. Test errors for the linear advection equation",
            "Figure 4. Test errors for the heat equation",
            "Figure 5. Test errors for the Fisher equation",
            "Table 2. Network architecture for the linear advection problem. In this experiment, we assume periodic boundary conditions, and hence all the convolutional layers have circular/periodic padding. Including the bias vectors, this network has 4952 parameters.",
            "Table 3. Network architecture for the heat equation. For this problem, we assume homogeneous Dirichlet boundary conditions, and hence the convolutional layers are defined with zero-padding.",
            "Table 4. Network architecture for the Fisher equation. In this experiment, we assume homogeneous Dirichlet boundary conditions, and hence all the convolutional layers have zero-padding. Including the bias vectors, this network has 5104 parameters."
        ],
        "imgs": [
            "$2305.00723v1-Figure1-1.png",
            "$2305.00723v1-Figure2-1.png",
            "$2305.00723v1-Figure3-1.png",
            "$2305.00723v1-Figure4-1.png",
            "$2305.00723v1-Figure5-1.png",
            "$2305.00723v1-Table2-1.png",
            "$2305.00723v1-Table3-1.png",
            "$2305.00723v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00724",
        "abstract": "  We present the analysis of the topological graph descriptor Local Degree\nProfile (LDP), which forms a widely used structural baseline for graph\nclassification. Our study focuses on model evaluation in the context of the\nrecently developed fair evaluation framework, which defines rigorous routines\nfor model selection and evaluation for graph classification, ensuring\nreproducibility and comparability of the results. Based on the obtained\ninsights, we propose a new baseline algorithm called Local Topological Profile\n(LTP), which extends LDP by using additional centrality measures and local\nvertex descriptors. The new approach provides the results outperforming or very\nclose to the latest GNNs for all datasets used. Specifically, state-of-the-art\nresults were obtained for 4 out of 9 benchmark datasets. We also consider\ncomputational aspects of LDP-based feature extraction and model construction to\npropose practical improvements affecting execution speed and scalability. This\nallows for handling modern, large datasets and extends the portfolio of\nbenchmarks used in graph representation learning. As the outcome of our work,\nwe obtained LTP as a simple to understand, fast and scalable, still robust\nbaseline, capable of outcompeting modern graph classification models such as\nGraph Isomorphism Network (GIN). We provide open-source implementation at\n\\href{https://github.com/j-adamczyk/LTP}{GitHub}.\n",
        "title": "Strengthening structural baselines for graph classification using Local\n  Topological Profile",
        "texts": [
            "Fig. 1. Training time using LDP features: SVM vs RF clasifier.",
            "Fig. 2. Experiment time using LDP and LTP approaches.",
            "Table 1. Statistics of datasets used, following [4].",
            "Table 2. Classification accuracy on testing sets using LDP features and three analyzed models. The best result for each dataset is marked in bold.",
            "Table 3. Number of wins and absolute average difference between the result for a given hyperparameter value and the best result for any hyperparameter value. Higher number of wins is better, lower absolute average difference is better. For each hyperparameter, the value with the lowest absolute average difference has been marked in bold.",
            "Table 4. Classification accuracy of LDP with additional descriptors and LTP. The best result for each dataset is marked in bold.",
            "Table 5. Comparison of accuracy with fair comparison results from [4]. Higher is better. Best result for each dataset has been marked in bold.",
            "Table 6. Comparison of average model ranks. The best result is marked in bold."
        ],
        "imgs": [
            "$2305.00724v1-Figure1-1.png",
            "$2305.00724v1-Figure2-1.png",
            "$2305.00724v1-Table1-1.png",
            "$2305.00724v1-Table2-1.png",
            "$2305.00724v1-Table3-1.png",
            "$2305.00724v1-Table4-1.png",
            "$2305.00724v1-Table5-1.png",
            "$2305.00724v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00726",
        "abstract": "  Glasner and Megrelishvili proved that every continuous action of a\ntopological group $G$ on a dendrite $X$ is tame. We produce two examples of an\naction on a dendrite which is not $\\mathrm{tame}_1$, answering a question they\nraised. We then show that actions on dendrites have $\\beta$-rank at most $2$\nand produce examples of tame metric dynamical systems of $\\beta$-rank $\\alpha$\nfor any $\\alpha<\\omega_1$, answering another question of Glasner and\nMegrelishvili.\n",
        "title": "Some examples of tame dynamical systems answering questions of Glasner\n  and Megrelishvili",
        "texts": [
            "Figure 2. (An approximation of) the stage X1 of the construction. Points that have order 4 or will become points of order 4 in X2 are coloured in red, while points that have order 3 in X1 or will become points of order 3 in X2 are coloured in green."
        ],
        "imgs": [
            "$2305.00726v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00729",
        "abstract": "  We present a comparative study on how and why contrastive learning (CL) and\nmasked image modeling (MIM) differ in their representations and in their\nperformance of downstream tasks. In particular, we demonstrate that\nself-supervised Vision Transformers (ViTs) have the following properties: (1)\nCL trains self-attentions to capture longer-range global patterns than MIM,\nsuch as the shape of an object, especially in the later layers of the ViT\narchitecture. This CL property helps ViTs linearly separate images in their\nrepresentation spaces. However, it also makes the self-attentions collapse into\nhomogeneity for all query tokens and heads. Such homogeneity of self-attention\nreduces the diversity of representations, worsening scalability and dense\nprediction performance. (2) CL utilizes the low-frequency signals of the\nrepresentations, but MIM utilizes high-frequencies. Since low- and\nhigh-frequency information respectively represent shapes and textures, CL is\nmore shape-oriented and MIM more texture-oriented. (3) CL plays a crucial role\nin the later layers, while MIM mainly focuses on the early layers. Upon these\nanalyses, we find that CL and MIM can complement each other and observe that\neven the simplest harmonization can help leverage the advantages of both\nmethods. The code is available at https://github.com/naver-ai/cl-vs-mim.\n",
        "title": "What Do Self-Supervised Vision Transformers Learn?",
        "texts": [
            "Figure 1: CL outperforms MIM in linear probing and small model regimes. In contrast, MIM excels in fine-tuning, large model regimes, and dense prediction. Red squares (■) denote CL, and blue triangles (▲) denote MIM. By default, we report the performance of ViT-B trained or pretrained on ImageNet-1K. We use the results from original papers and He et al. (2022) for object detection. Regarding the scaling experiment, we report the results that we reproduced based on official configurations except with 100 epochs, marking them as MoCo† and SimMIM†. Left: CL outperforms MIM in linear probing but underperforms in fine-tuning. Middle: CL outperforms MIM in small model regimes (ViT-Ti and ViT-S), and MIM shows superior scalability in large model regimes (ViT-L and ViT-H). Right: MIM outperforms CL in the dense prediction downstream tasks, such as object detection with Mask R-CNN (He et al., 2017) on COCO (Lin et al., 2014).",
            "Figure 10: The explicit decoder architecture of MAE helps ViTs effectively leverage the advantages of MIM. We analyze the encoder and decoder of a pre-trained model with a masking ratio of zero. The left side of each figure represents the encoder and the right side the decoder. Left: The mutual information of MAE is lower than that of SimMIM in the encoder but higher in the decoder. Right: The decoder of MAE captures low-frequencies, while the encoder captures high-frequencies. As a result, the decoder predicts blurred images. Moreover, the later layers (excluding the last layer) of the encoder do not reduce high-frequency information, while those of SimMIM do.",
            "Figure 11: Later layers of CL and early layers of MIM play a key role. We report linear probing accuracies by using the representations of the intermediate layers. CL outperforms MIM in later layers, and MIM outperforms CL in early layers.",
            "Figure 12: The simple linear combination of CL (MoCo) and MIM (SimMIM) objectives outperforms the vanilla CL and MIM. λ is the importance weight of CL, so λ = 0 means SimMIM and λ = 1 means MoCo. Left: “CL + MIM” outperforms CL and MIM in both linear probing and fine-tuning accuracy. Middle: Mutual information of “CL + MIM” decreases at the end of the model, suggesting that the self-attentions of later layers collapse into homogeneity and capture the same object shape information. Right: Fourier analysis shows that “CL + MIM” amplifies high frequencies at the beginning and reduces them at the end. It implies that “CL + MIM” exploits high-frequency information at the beginning and low-frequency information at the end.",
            "Figure 2: Self-attentions of CL (MoCo) capture global information, but they collapse into homogeneous attention maps for all query tokens and heads. Self-attentions of MIM (SimMIM) mainly focus on local areas and similar tokens. We visualize the attention maps for two different query tokens in the beginning through the end layers. We omit the results for self-attention heads, which show mostly consistent results. Left: Self-attentions of CL capture global patterns and the shape of an object. However, all attention maps capture the same shape information regardless of the query tokens. Right: Self-attentions of MIM capture local patterns and are correlated with queries.",
            "Figure 5: CL lacks representational diversity in the later layers. We measure cosine similarities of representations in the self-attentions between the heads (left), depths (middle), and spatial coordinates (right). All of the results show that the representational similarity of later self-attentions of CL is higher than that of MIM. Increasing heads or depths of CL is not effective in improving the diversity. Left: The similarity of representations from two heads in self-attention. Middle: The similarity between representations before and after self-attentions transform them. Right: The similarities of representations at two spatial coordinates. ViT-{S, L} is trained with 100 epochs.",
            "Figure 6: Self-attention layers of CL and MIM transform representations differently. We visualize 196 spatial representation tokens for an example validation image in a representation space. The blue (•) and red (•) data points denote the tokens before and after the self-attention transformation. Left: The self-attentions of CL (e.g., MoCo) translate all the tokens equally, so the distances between the tokens of an image do not increase. Middle: However, CL moves the “centers of representations (represented by ×)” away from each other. Therefore, the images are linearly separable. The circle (•) and triangle (4) data represent tokens from different images. Right: The self-attentions of MIM (e.g., SimMIM) transform representations differently according to query tokens, thus increasing the distances between tokens. See Figure 7 for quantitative analyses.",
            "Figure 7: CL barely changes or even decreases the distribution volume of tokens from a single image, implying that it hardly distinguishes between token. Instead, it significantly increases the distribution volume of images. To demonstrate these properties, we visualize singular value spectra, the singular values of the distribution of representations sorted by the magnitude. The higher a singular value, the larger the volume of a distribution. The right of this figure shows the 64th and 128th highest singular value for depth. Top: Singular value spectra of tokens from a single image. CL decreases the singular values of the tokens, but MIM increases. Bottom: Singular value spectra of images. CL significantly increases the volumes occupied by images, but MIM hardly does so.",
            "Figure 8: CL is biased toward shape, whereas MIM is biased toward texture. We report the predictive results of models for linear probing tasks. However, we observe consistent results in finetuned models (See Figure F.2). Left: Result of classification on Stylized ImageNet. It shows that CL is more shape-biased than MIM and even than the supervised pre-trained model. Vertical lines represent averaged results for the shape categories. We also report the results of supervised ViT with ImageNet1K class labels for comparison. Right: Accuracy drops on images with frequency-based random noises. MIM shows a more significant amount of accuracy drop than CL with high-frequency noises, demonstrating MIM’s texture-biased property. The frequency window size of the frequency-based noise is 0.1π.",
            "Figure 9: CL exploits low-frequency, but MIM exploits high-frequency. Moreover, a few last layers of CL reduce high-frequency by capturing global patterns. MIM also reduces it even though they capture local patterns, because the later layers behave like decoders. See also Figure 11.",
            "Figure C.1: MIM and CL methods each have consistent properties. To show this, we visualize selfattention behaviors in terms of attention distance and normalized mutual information (MI). SimCLR?, which was introduced in Chen et al. (2021), stands for MoCo with a momentum coefficient of 0. Left: The attention distance of CL methods (namely MoCo, SimCLR?, and DINO) is higher than that of MIM methods (namely SimMIM, BEiT, and MAE). This suggests that CL methods consistently capture global patterns. Right: The normalized mutual information of MIM is higher than that of CL; i.e., the self-attentions of MIM are more correlated with query tokens than CL.",
            "Figure C.2: ViTs exhibit consistent self-attention patterns, regardless of their size. To better understand these patterns, we visualize the self-attention behaviors of three ViTs—ViT-{Ti, S, B}—using two metrics: attention distance and normalized mutual information (MI). Left: All selfattentions of MoCo capture global patterns in the later layers. In contrast, the self-attentions of SimMIM capture local patterns. Right: Likewise, all self-attention maps of MoCo collapse into homogeneity in the later layers.",
            "Figure D.1: Locality inductive bias harms linear probing but improves fine-tuning. We report the linear probing and fine-tuning accuracy of MoCo with restricted self-attentions via attention masks."
        ],
        "imgs": [
            "$2305.00729v1-Figure1-1.png",
            "$2305.00729v1-Figure10-1.png",
            "$2305.00729v1-Figure11-1.png",
            "$2305.00729v1-Figure12-1.png",
            "$2305.00729v1-Figure2-1.png",
            "$2305.00729v1-Figure5-1.png",
            "$2305.00729v1-Figure6-1.png",
            "$2305.00729v1-Figure7-1.png",
            "$2305.00729v1-Figure8-1.png",
            "$2305.00729v1-Figure9-1.png",
            "$2305.00729v1-FigureC.1-1.png",
            "$2305.00729v1-FigureC.2-1.png",
            "$2305.00729v1-FigureD.1-1.png"
        ]
    },
    {
        "id": "2305.00732",
        "abstract": "  Attosecond chronoscopy represents a major breakthrough in the study of\nultrafast phenomena and has the potential to revolutionize our understanding of\nthe fundamental physics of matter. We theoretically investigate the\nspin-orientation-resolved attosecond chronoscopy for the first time by the\ncircular RABBIT technique for Kr atoms. Due to the spin-orbit interaction and\nthe sensitivity of ionization in circularly polarized fields to the sense of\nelectron rotation in the initial state, the spin-resolved ionization rates of\nphotoelectrons emitted from $^2P_{1/2}$ and $^2P_{3/2}$ channels can be\nexpressed via $m$-resolved ionization rates of initial state, where $m$ is the\norbital magnetic quantum number. We demonstrate that the yields difference\nbetween spin-up and spin-down photoelectrons from each channel are closely\nassociated with the different behaviors of corresponding Wigner time delay. We\nfind that the Wigner time delay between spin-up and spin-down photoelectrons in\nthe polarization plane can reach several tens of attoseconds in the co-rotating\ngeometry, but a few attoseconds in the counter-rotating geometry. Our approach\nopens up a new avenue for probing the spin-dependent behavior of Wigner time\ndelay, and lays the foundation for spin-orientation-resolved attosecond\nchronoscopy, which can be verified by the current experimental techniques.\n",
        "title": "Spin-orientation-resolved attosecond chronoscopy in strong field\n  ionization",
        "texts": [
            "FIG. 2. TDSE simulations of delay-integrated angle-resolved photoelectronenergy spectra for spin-up (a) and spin-down (b) electrons in the co-rotating geometries. The photoelectron emission angle in the co-polarization plane, φ = arctan(py/px), was integrated over its 2π range, and the XUV-IR delay was integrated over two IR optical-cycle periods. Photoelectron-energy spectra and the corresponding spin polarization [Eq. (10)] in the light-polarization plane, that is, θ = arccos(pz/ptotal) = 90◦ for the co-rotating (c) and counter-rotating (d) geometries. The vertical dashed lines in (c) indicate the potential energy difference ∆Ip = 0.66 eV between 2P1/2 state and 2P3/2 state of the core.",
            "FIG. 4. The same as Fig. 3 but in the counter-rotating geometry."
        ],
        "imgs": [
            "$2305.00732v2-Figure2-1.png",
            "$2305.00732v2-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00733",
        "abstract": "  We describe the simplest non-trivial modular category $\\mathfrak{E}$ with two\nsimple objects. Then we extract from this category the invariant for\nnon-oriented links in 3-sphere and two invariants for 3-manifolds: the\ncomplex-valued Turaev - Reshetikhin type invariant $tr_{\\varepsilon}$ and the\nreal-valued Turaev - Viro type invariant $tv_{\\varepsilon}$. These two\ninvariants for 3-manifolds are related by the equality\n$|tr_{\\varepsilon}|^2\\cdot (\\varepsilon + 2) = tv_{\\varepsilon}$, where\n$\\varepsilon$ is a root of the equation $\\varepsilon^2 = \\varepsilon + 1$.\nFinally, we show that $tv_{\\varepsilon}$ coincides with the well-known\n$\\varepsilon$ invariant for 3-manifolds.\n",
        "title": "Invariants for links and 3-manifolds from the modular category with two\n  simple objects",
        "texts": [
            "Figure 1. Diagrams of objects 1+A+ 1+A (on the left) and A+A+ 1+ 1 (on the right)",
            "Figure 13. Diagram of the left hand side of the lemma 7 statement",
            "Figure 14. Diagram of the right hand side of the lemma 7 statement",
            "Figure 16. Condition θA⊗A = (θA ⊗ θA) ◦ cA,A ◦ cA,A",
            "Figure 2. Example of a morphism from the object 1+A+A+ 1+A to the object A+ 1+ 1+A+ 1",
            "Figure 21. From left to right: positive crossing, negative crossing, left half-circle, right half-circle, positive loop, negative loop, trivial arc",
            "Figure 36. Knotted diagram of the 6j-symbol",
            "Figure 5. Tensor product of morphism diagrams (left), results of the tensor product of morphisms between simple objects (centre and right)",
            "Figure 7. Diagram of the left hand side of the statement of the lemma 1",
            "Figure 8. Diagram of the right hand side of the statement of the lemma 1",
            "Figure 9. Different colours for arrows with different values"
        ],
        "imgs": [
            "$2305.00733v3-Figure1-1.png",
            "$2305.00733v3-Figure13-1.png",
            "$2305.00733v3-Figure14-1.png",
            "$2305.00733v3-Figure16-1.png",
            "$2305.00733v3-Figure2-1.png",
            "$2305.00733v3-Figure21-1.png",
            "$2305.00733v3-Figure36-1.png",
            "$2305.00733v3-Figure5-1.png",
            "$2305.00733v3-Figure7-1.png",
            "$2305.00733v3-Figure8-1.png",
            "$2305.00733v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00736",
        "abstract": "  FU Orionis (FUor) and EX Lupi (EXor) type objects are two groups of peculiar\nand rare pre-main sequence low-mass stars that are undergoing powerful\naccretion outbursts during their early stellar evolution. Water masers are\nwidespread in star forming regions and are powerful probes of mass accretion\nand ejection, but little is known about the prevalence of them toward\nFUors/EXors. We perform the first systematic search for the 22.2 GHz water\nmaser line in FUors/EXors to determine its overall incidence to perform\nfollow-up high angular resolution observations. We used the Effelsberg 100-m\nradio telescope to observe the 22.2 GHz H2O maser toward a sample of 51\nobjects. We detect 5 water masers; 3 are associated with eruptive stars,\nresulting in a 6% detection rate for eruptive sources. These detections include\none EXor, V512 Per (also known as SVS 13 or SVS 13A), and two FUors, Z CMa and\nHH 354 IRS. This is the first reported detection of water maser emission\ntowards HH 354 IRS. We detect water maser emission in our pointing towards the\nFUor binary RNO 1B/1C, which most likely originates from the nearby deeply\nembedded source IRAS 00338+6312 (~4'', from RNO 1B/1C). Emission was also\ndetected from H$_2$O(B) (also known as SVS 13C), a Class 0 source ~30'', from\nthe EXor V512 Per. The peak flux density of H$_2$O(B) in our observations,\n498.7 Jy, is the highest observed to date. In addition to the two non-eruptive\nClass 0 sources (IRAS 00338+6312 and H$_2$O(B) /SVS 13C), we detect maser\nemission towards one Class 0/I (HH 354 IRS) and two Class I (V512 Per and Z\nCMa) eruptive stars. We demonstrate the presence of 22.2 GHz water maser\nemission in FUor/EXor systems, opening the way to radio interferometric\nobservations to study these eruptive stars on small scales. Comparing our data\nwith historical observations suggest that multiple water maser flares have\noccurred in both V512 Per and H$_2$O(B).\n",
        "title": "The Effelsberg survey of FU~Orionis and EX~Lupi objects II. -- H$_2$O\n  maser observations",
        "texts": [
            "Fig. 1: H2O maser spectrum of Z CMa observed on 2022 January 25. The dashed vertical line indicates the 3LSR of 13.8 km s−1 from the NH3 (1,1) transition (Szabó et al. 2023).",
            "Fig. 2: Spectrally smoothed line profile of H2O maser emission observed in HH 354 IRS on 2021 November 18 and 2022 January 25. The dashed vertical line indicates the average 3LSR of −1.47 km s−1 derived from the NH3 (1,1) and (2,2) transitions (Szabó et al. 2023).",
            "Fig. 3: H2O maser spectra toward V512 Per in November 2021: the two epochs are indicated at upper left. The dashed line indicates the average 3LSR of 8.39 km s−1 derived from the NH3 (1,1), (2,2) and (3,3) transitions (Szabó et al. 2023).",
            "Fig. 4: Pointed H2O maser spectra towards V512 Per and H2O(B) observed on 2022 February 5. The spectrum of V512 Per is multiplied by 20 to better match the spectrum of H2O(B).",
            "Fig. 5: Channel maps of H2O masers in H2O(B) (SVS 13C) and V512 Per (SVS 13A). The contours start at 0.5 Jy, and then increase by a factor of two. The plus signs represent the positions of the two H2O masers (orange and green) previously detected by Haschick et al. (1980) and YSOs (purple; e.g., Plunkett et al. 2013). Based on previous observations (Plunkett et al. 2013; Podio et al. 2021), the outflow directions are indicated by red and blue arrows. The beam size is shown in the lower right corner of the last panel. The colour bar represents the flux density in units of Jy.",
            "Fig. 6: H2O maser observed in IRAS 00338+6312 at four epochs in 2021 November, 2022 January and February. The dashed vertical line indicates the systemic 3LSR of −17.83 km s−1 derived from the NH3 (1,1), (2,2) and (3,3) transitions (Szabó et al. 2023).",
            "Fig. 7: Long-term variations in flux density of detected water masers. The colour-coded dots and grey triangles represent flux densities for maser detections, colour-coded by velocity (see colour-bar at right), and upper limits for non-detections, respectively. References for archival data are given in Sect. 4.1.",
            "Table 1: Basic information about the sources towards which water maser emission was detected at 22.2 GHz.",
            "Table 2: Properties of observed water maser features.",
            "Table A.1: H2O maser velocity components and NH3 LSR velocities from observations of W75N on 2021 November 18."
        ],
        "imgs": [
            "$2305.00736v1-Figure1-1.png",
            "$2305.00736v1-Figure2-1.png",
            "$2305.00736v1-Figure3-1.png",
            "$2305.00736v1-Figure4-1.png",
            "$2305.00736v1-Figure5-1.png",
            "$2305.00736v1-Figure6-1.png",
            "$2305.00736v1-Figure7-1.png",
            "$2305.00736v1-Table1-1.png",
            "$2305.00736v1-Table2-1.png",
            "$2305.00736v1-TableA.1-1.png"
        ]
    },
    {
        "id": "2305.00737",
        "abstract": "  In the paper we introduce the construction of invariants for 3-manifolds,\nbased on the same key concepts as the classical Dijkgraaf-Witten invariant. We\nintroduce the notion of a special $G$-system and describe how each system\ninduces the invariant not only for closed 3-manifolds, but also for manifolds\nwith boundary. Finally, we show how to construct a very simple one-dimensional\nspecial $G$-system using group cohomologies.\n",
        "title": "Symmetric Dijkgraaf-Witten type invariants for 3-manifolds",
        "texts": [
            "Figure 6. Coloured tetrahedrons T+ (on the left) and T− (on the right)"
        ],
        "imgs": [
            "$2305.00737v2-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00738",
        "abstract": "  Limited training data and severe class imbalance impose significant\nchallenges to developing clinically robust deep learning models. Federated\nlearning (FL) addresses the former by enabling different medical clients to\ncollaboratively train a deep model without sharing data. However, the class\nimbalance problem persists due to inter-client class distribution variations.\nTo overcome this, we propose federated classifier anchoring (FCA) by adding a\npersonalized classifier at each client to guide and debias the federated model\nthrough consistency learning. Additionally, FCA debiases the federated\nclassifier and each client's personalized classifier based on their respective\nclass distributions, thus mitigating divergence. With FCA, the federated\nfeature extractor effectively learns discriminative features suitably globally\nfor federation as well as locally for all participants. In clinical practice,\nthe federated model is expected to be both generalized, performing well across\nclients, and specialized, benefiting each individual client from collaboration.\nAccording to this, we propose a novel evaluation metric to assess models'\ngeneralization and specialization performance globally on an aggregated public\ntest set and locally at each client. Through comprehensive comparison and\nevaluation, FCA outperforms the state-of-the-art methods with large margins for\nfederated long-tailed skin lesion classification and intracranial hemorrhage\nclassification, making it a more feasible solution in clinical settings.\n",
        "title": "FCA: Taming Long-tailed Federated Medical Image Classification by\n  Classifier Anchoring",
        "texts": [
            "Figure 1: Variations of class distributions encountered under the federated setting. Variations occur between 1) different clients, where some clients have missing and rare classes, and 2) each individual client and the global federated server.",
            "Figure 2: Illustration of the proposed federated classifier anchoring (FCA). FCA introduces a personalized classifier at each client as an anchor for the federated model by 1) debiasing classifiers according to each client’s local class distribution and 2) guiding federated model updating through consistency regularization between classifiers.",
            "Table 1: Statistics of different clients from the Fed-ISIC2019 dataset [49], preprocessed and curated from ISIC2019 [15, 29, 30], including classes 0 (Melanoma), 1 (Melanocytic Nevus), 2 (Basal Cell Carcinoma), 3 (Actinic Keratosis), 4 (Benign Keratosis), 5 (Dermatofibroma), 6 (Vascular Lesion), and 7 (Squamous Cell Carcinoma).",
            "Table 2: Statistics of different clients for federated intracranial CT hemorrhage detection [2] under the 5-client setting with mild inter-client class variations, including classes 0 (Epidural), 1 (Intraparenchymal), 2 (Intraventricular), 3 (Subarachnoid), and 4 (Subdural).",
            "Table 3: Statistics of different clients for federated intracranial CT hemorrhage detection [2] under the 10-client setting with severely imbalanced inter-client class variations and missing classes, including classes 0 (Epidural), 1 (Intraparenchymal), 2 (Intraventricular), 3 (Subarachnoid), and 4 (Subdural).",
            "Table 4: Quantitative results of different learning frameworks for federated longtailed skin lesion classification under two evaluation settings, i.e., the specialized and generalized evaluation sets. Each learning framework is trained under five different seeds and both the average performance and standard deviation are reported. The best results are marked in bold.",
            "Table 5: Quantitative results of different learning frameworks for ICH classification under two splitting settings, i.e., Split 1 (the 5-client setting containing imbalanced but no missing classes) and Split 2 (the 10-client setting containing severely imbalanced with missing classes). We report the average bACC and bAUC on the generalized and specialized test sets. Each learning framework is trained under five different seeds and both the average performance and standard deviation are reported. The best results are marked in bold.",
            "Table 6: Ablation studies of FCA viewed from the lens of classifier-guided learning. The components are as follows: 1) # guide indicates the number of classifiers used to train the federated feature extractor, 2) learnable guide (Xor ×) indicates whether guides/classifiers are learnable of frozen, and 3) regularization (Xor ×) indicates whether an explicit loss regularization is deployed during training. K represents the total number of clients.",
            "Table 7: Ablation studies of FCA on λ1, the weight of the federated classifier’s training loss, λ2, the weight of each personalized classifier’s training loss. Xor × indicates the presence of consistency regularization (CR).",
            "Table 8: Ablation studies of FCA on the direction of consistency regularization (denoted as arrows). G and S are short for the evaluation on the generalization and specialization test sets respectively."
        ],
        "imgs": [
            "$2305.00738v1-Figure1-1.png",
            "$2305.00738v1-Figure2-1.png",
            "$2305.00738v1-Table1-1.png",
            "$2305.00738v1-Table2-1.png",
            "$2305.00738v1-Table3-1.png",
            "$2305.00738v1-Table4-1.png",
            "$2305.00738v1-Table5-1.png",
            "$2305.00738v1-Table6-1.png",
            "$2305.00738v1-Table7-1.png",
            "$2305.00738v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00739",
        "abstract": "  Human-AI decision making is becoming increasingly ubiquitous, and\nexplanations have been proposed to facilitate better Human-AI interactions.\nRecent research has investigated the positive impact of explanations on\ndecision subjects' fairness perceptions in algorithmic decision-making. Despite\nthese advances, most studies have captured the effect of explanations in\nisolation, considering explanations as ends in themselves, and reducing them to\ntechnical solutions provided through XAI methodologies. In this vision paper,\nwe argue that the effect of explanations on fairness perceptions should rather\nbe captured in relation to decision subjects' right to contest such decisions.\nSince contestable AI systems are open to human intervention throughout their\nlifecycle, contestability requires explanations that go beyond outcomes and\nalso capture the rationales that led to the development and deployment of the\nalgorithmic system in the first place. We refer to such explanations as\nprocess-centric explanations. In this work, we introduce the notion of\nprocess-centric explanations and describe some of the main challenges and\nresearch opportunities for generating and evaluating such explanations.\n",
        "title": "Generating Process-Centric Explanations to Enable Contestability in\n  Algorithmic Decision-Making: Challenges and Opportunities",
        "texts": [
            "Figure 1: Overview of the conceptual framework that locates process-centric explanations as necessary elements for contestability by design, which in turn affects decision subjects fairness perceptions. In pink, we highlight the concepts defined by Schoeffer et al. [42]. Grey refers to different stages of the ML pipeline, green refers to explanatory elements, orange refers to contestability elements, yellow refers to different stakeholders, and blue refers to discretionary choices and their rationales."
        ],
        "imgs": [
            "$2305.00739v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00741",
        "abstract": "  Neurons with internal memory have been proposed for biological and\nbio-inspired neural networks, adding interesting functionality. We propose and\nmodel a nanoscale optoelectronic neural node with charge-based time-limited\nmemory and signal evaluation. Connectivity is achieved by weighted light\nsignals emitted and received by the nodes. The device is based on\nwell-developed III-V nanowire technology, which has shown high photo-conversion\nefficiency, low energy consumption and sub-wavelength light concentration. We\ncreate a flexible computational model of the complete artificial neural node\ndevice using experimental values for wire performance. The model can simulate\ncombinations of nodes with different hardware derived properties and widely\nvariable light interconnects. Using this model, we simulate the hardware\nimplementation for two types of neural networks. First, we show that\nintentional variations in the memory decay time of the nodes can significantly\nimprove the performance of a reservoir network. Second, we simulate the\nnanowire node implementing an anatomically constrained functioning model of the\ncentral complex network of the insect brain and find that it functions well\neven including variations in the node performance as would be found in\nrealistic device fabrication. Our work demonstrates the feasibility of a\nconcrete, variable, nanophotonic neural node with a memory. The use of variable\nmemory time constants to open new opportunities for network performance is a\ngeneral hardware derived feature and should be applicable for a broad range of\nimplementations.\n",
        "title": "Artificial Nanophotonic Neuron with Internal Memory for Biologically\n  Inspired and Reservoir Network Computing",
        "texts": [
            "FIG 1: Basic functionality required of the neural node nanodevices for network computations. (a) Schematic illustration of a set of connected nodes communicating with a broadcasting scheme using optical signals that inhibit or excite the nodes. The internode coupling strengths are given by local light intensity and absorption efficiency at the receiver units. The signal interpretation in the node is done electrically after conversion of the light into an electrical current. (b) Schematic example of the desired (electrical) impulse response of a dynamic node upon (light) excitation and inhibition. An exciting pulse pushes the node into an active state. This state will gradually decay with memory timescale τMEM leading to a reduced output. An inhibiting pulse that arrives later will subtract from the remaining value of the active state which will lead to a faster termination of output activity (if the inhibiting pulse is strong enough). (c) Typical nonlinear activation function needed for signal processing in each node.",
            "FIG. 2: Optoelectronic node realized by NW design. a) Realization using specific NW geometry with specific compositions and sizes of the components and connections in the circuit. b) Equivalent circuit diagram for the NW device in a). Left leg holds the receiver parts and the floating gate memory, whereas the right leg holds the control unit and the transmitter. 𝑅mem does not have a direct correspondence in (a) but encapsulates all pathways of charge leakage from the memory.",
            "FIG. 3: Modelling of optoelectronic NW devices based on experimental data. (a) Dark current versus voltage for the pin-diode. Results for the NW model (lines) with different surface recombination velocities, are compared to experimental results (markers) from [33] where the doping in the p+-segment was varied as indicated in the legend. (b) Calculated time-resolved photo-current for the pin-diode. (c) Internal quantum efficiency of the NW LED. Dashed line indicates a two-parameter fit to a simple ABC-model, which was then used as input to the dynamic neuron model. (d) Calculated time-resolved photo-emission for the NW LED.",
            "FIG. 4: Modelled transistor and resulting activation function calibrated against experimental data. (a) Simulated source-drain voltage sweep for a set of different gate voltages for the designed NW field effect transistor. Minimum 𝑉ds during the applications is marked by a dashed line, which is also the voltage used to extract the source drain current 𝐼ds as a function of 𝑉gate. (b) Stationary activation function in terms of the source-drain current of the transistor, derived from the excitatory part of Fig. 2(b) using typical device parameters (see Appendix A). The dashed blue line indicates the resulting gate voltage as a function of exciting current. This drops off as the photodiode is eventually pushed above threshold.",
            "FIG. 5: Illustration of the reservoir network and the sine wave generation task it was trained to solve. (a) The network is fed a step-like signal in time through random input weights. (b) A reservoir of physical nodes with random weights generates rich internal dynamics because of random feedback connections from the output node. (c) Using teacher forcing the output weights are trained to provide a sine wave with frequency proportional to the input signal [36,37].",
            "FIG. 6: Training and prediction sequence. Example of a network trained for 2000 ns after which the target output signal was replaced by the network output signal constructed by the trained weights 𝑤out. (a) Comparison between two reservoirs with a single or distributed value of memory time constants 𝜏mem. The single-τ line has been displaced for clarity. (b) Input control signal and target output signal for the training and prediction sequences.",
            "FIG. 7: Prediction error statistics. (a) RMS errors in predicted frequencies for 24 runs with randomly generated networks and target signals. Mean error is shown as a dashed line and the shadowed area corresponds to an error less or equal than 5Δ𝑓 where Δ𝑓 = 0.08 GHz is set by the discrete frequencies from the Fourier spectral analysis of the time signal. (b) Histogram over the accuracy of the predictions in all time-windows used in the spectral analysis of the time signals of the 24 runs of (a). The shaded region corresponds to the same tolerated error as in (a).",
            "FIG. 8: Navigational network. (a) Schematic diagram of our implementation of the recurrent network of [8]. Inputs to the network are optical flow as a measure of speed and the perceived heading with respect to an internal compass. The nodes of the innermost layer for heading (TB1 cells) are interconnected recurrently with weights in a sinusoidal pattern. Orange indicates the memory layers (rectifier, CPU4 and pontine cells) and the blue the steering layer (CPU1 cells). (b) Example result for an outbound journey from the nest (N) to the yellow dot and back to N of a duration of 1500 ns.",
            "FIG. 9: Statistical studies of the robustness of the navigational network with respect to distortions and errors. Minimum distances to the nest are shown as function of outbound travel length. Parameters varied are weights connecting the layers (a), the threshold voltage of the transistors (b) and the variation in the memory time constant of the CPU4 layer (c)."
        ],
        "imgs": [
            "$2305.00741v1-Figure1-1.png",
            "$2305.00741v1-Figure2-1.png",
            "$2305.00741v1-Figure3-1.png",
            "$2305.00741v1-Figure4-1.png",
            "$2305.00741v1-Figure5-1.png",
            "$2305.00741v1-Figure6-1.png",
            "$2305.00741v1-Figure7-1.png",
            "$2305.00741v1-Figure8-1.png",
            "$2305.00741v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00742",
        "abstract": "  We extend the multi-reference covariant density functional theory (MR-CDFT)\nby including fluctuations in quadrupole deformations and average isovector\npairing gaps simultaneously for the nuclear matrix elements (NMEs) of\nneutrinoless double-beta $(0\\nu\\beta\\beta)$ decay in the candidate nuclei\n$^{76}$Ge, $^{82}$Se, $^{100}$Mo, $^{130}$Te, and $^{136}$Xe assuming the\nexchange of either light or heavy neutrinos. The results indicate a linear\ncorrelation between the predicted NMEs and the isovector pairing strengths, as\nwell as the excitation energies of $2^{+}_1$ and $4^{+}_1$ states. By adjusting\nthe pairing strengths based on the excitation energies of the $2^{+}_1$ states,\nwe calculate the NMEs for $0\\nu\\beta\\beta$ decay, which are reduced by\napproximately $12\\%$ to $62\\%$ compared to the results obtained in the previous\nstudies by Song et al. [Phys. Rev. C95, 024305 (2017)]. Additionally, upon\nintroducing the average isovector pairing gap as an additional generator\ncoordinate in the calculation, the NMEs increase by a factor ranging from\n$56\\%$ to $218\\%$.\n",
        "title": "Impact of isovector pairing fluctuation on neutrinoless double-beta\n  decay in multi-reference covariant density functional theory",
        "texts": [
            "FIG. 2. Correlation between excitation energies of 2+1 , 4+1 states and the NMEs M0ν ν/N in 130Te and 130Xe. The Pearson correlation coefficient r is provided. The dashed lines indicate the location of the corresponding data from Ref. [76].",
            "FIG. 3. Excitation energies of (a) 2+1 states and (b) 4+1 states in the candidate nuclei of 0νββ decay from the GCM calculation with and without multiplying the pairing strengths by the scaling factor χ, in comparison with corresponding data [76].",
            "FIG. 5. The energies of mean-field states (normalized to the global energy minimum) from the CDFT calculation with the adjusted pairing strengths for (a) 130Te and (b) 130Xe as a function of quadrupole deformation parameter β2 and average pairing gap ∆u3 of protons and neutrons. The red dots mark the location of ∆u3 in the states from the mean-field calculation with a constraint only on the quadrupole deformation parameter β2.",
            "FIG. 6. The energies of states (normalized to the global energy minimum) for 130Te (a) and 130Xe (c) with projection onto the particle numbers (N,Z) and angular momentum (J = 0) as a function of β2 and ∆u3. The distribution of the square of collective wave functions |g0 1| 2 for the ground states of 130Te (b) and 130Xe (d) in the β2-∆u3 plane. The red dots are the same as those in Fig. 5.",
            "FIG. 7. The normalized NME M̃0ν ν (qF ,qI) (30) of 0νββ decay from the calculation with the exchange of light Majorana neutrinos as a function of the parameters (β2,∆u3) of Te130 and Xe130 , where quadrupole deformation parameter β2 in each subfigure is fixed to different value changing from −0.30 to +0.30, while the pairing gap ∆u3 varies from 1.0 MeV to 2.0 MeV.",
            "FIG. 8. The NMEs of 0νββ decay for the five candidate nuclei from the MR-CDFT calculation with pairing strengths adjusted to the excitation energies of 2+1 states, labeled as GCM(PC-PK1)(χ). The results of calculations with and without the isovector pairing fluctuation are set as the upper and lower boundaries, respectively. The NMEs from the GCM(β2) calculations using χ = 1 [21] are indicated with red dots. The NMEs are compared to those from other nuclear model calculations, including the GCM with the D1S force [50], interacting Boson model (IBM2) [86, 87], ISM [88], the spherical [19] and deformed QRPA [24] based on the G matrix, the spherical [43] and deformed [15] QRPA based on Skryme EDFs, and the ab initio VS-IMSRG calculation with the long-range (L) [34] and additionally short-range (L+S) [85] transition operators.",
            "TABLE II. The employed values of the scaling factor χ (7) multiplied to the pairing strengths for the nuclei of interest.",
            "TABLE IV. Comparison of NMEs M0ν ν/N of 0νββ decay for the five candidate nuclei from GCM calculations with the relativistic EDF PC-PK1 and non-relativistic EDF D1S, ab initio VS-IMSRG calculation, deformed QRPA calculations with the Brueckner G matrix and Skyrme EDF SkM*, interacting Boson model (IBM2) and interacting shell model (ISM) calculations. In the two GCM results, upper and lower boundary values correspond to the results of calculations with and without isovector pairing fluctuation. In the VS-IMSRG results, upper and lower boundary values correspond to the results of calculations with and without the contact transition operator."
        ],
        "imgs": [
            "$2305.00742v3-Figure2-1.png",
            "$2305.00742v3-Figure3-1.png",
            "$2305.00742v3-Figure5-1.png",
            "$2305.00742v3-Figure6-1.png",
            "$2305.00742v3-Figure7-1.png",
            "$2305.00742v3-Figure8-1.png",
            "$2305.00742v3-TableII-1.png",
            "$2305.00742v3-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00744",
        "abstract": "  We study the nonreciprocal Cahn-Hilliard model with thermal noise as a\nprototypical example of a generic class of non-Hermitian stochastic field\ntheories, analyzed in two companion papers [Suchanek, Kroy, Loos,\nArXiv:2303.16701 (2023); Suchanek, Kroy, Loos, ArXiv:2305.05633 (2023)]. Due to\nthe nonreciprocal coupling between two field components, the model is\ninherently out of equilibrium and can be regarded as an active field theory.\nBeyond the conventional homogeneous and static-demixed phases, it exhibits a\ntraveling-wave phase, which can be entered via either an oscillatory\ninstability or a critical exceptional point. By means of a Fourier\ndecomposition of the entropy production rate, we quantify the associated\nscale-resolved time-reversal symmetry breaking, in all phases and across the\ntransitions, in the low-noise regime. Our perturbative calculation reveals its\ndependence on the strength of the nonreciprocal coupling. Surging entropy\nproduction near the static-dynamic transitions can be attributed to\nentropy-generating fluctuations in the longest wavelength mode and heralds the\nemerging traveling wave. Its translational dynamics can be mapped on the\ndissipative ballistic motion of an active (quasi)particle.\n",
        "title": "Entropy production in the nonreciprocal Cahn-Hilliard model",
        "texts": [
            "FIG. 1. (a) Phase diagram of the stationary solutions of Eq. (1) as established in Ref. [24] for κ = 0.01, γ = 0.015 and β = 0.05. The mixed phase is marked in yellow, the static-demixed phase in blue and the traveling-wave phase in red; (b-d) snapshots of the stationary solutions for ϵ = 2.5 × 10−5. Unlike to the static-demixed phase, the maxima and minima of the profiles of the fields ϕA (gray) and ϕB (black) in the traveling-wave phase have a characteristic mean phase shift ⟨∆θπ⟩ > 0, with ∆θπ ≡ θA − (θB − π), which is aligned with the direction of propagation. This coupling of the propagation direction to the relative phase shift (which determines the parity of the profile) entails the PT symmetry breaking in the nonreciprocal Cahn-Hilliard model.",
            "FIG. 2. Entropy production rate S and the first-mode contribution σ1 [defined in Eqs. (14, 15)] as a function of the “demixing” parameter α in the homogeneous phase in the vicinity of the phase boundaries (at αc, indicated by dashed vertical lines), respectively: (a) near the transition to the static-demixed phase [here, δ = 0.8δc, path c1 in Fig. 1(a)]; (b) near the traveling-wave phase (here, δ = 1.2δc, path c2 in Fig. 1). The analytical prediction of Eq. (19) is shown by solid red lines. Symbols depict simulation results, dashed lines serve as guides to the eye. Insets depict zooms into a smaller y−axis range. We observe very distinct behavior near the transitions. Toward the static-static transition [in (a)], the entropy production rate only mildly increases but stays regular. Toward the static-dynamic transition [in (b)], the first-mode contribution σ1, and hence also S, increase steeply, and formally diverges in the zero-noise limit, even after UV regularization. Other parameters are κ = 0.01, γ = 0.015, β = 0.05, ϵ = 10−10.",
            "FIG. 3. Scaling of the entropy production rate S and the first-mode contribution σ1 [defined in Eqs. (14, 15), shown here in panel (a)], S and σ1 θ [defined in Eqs. (B13, B8), and shown in panels (b,c)] with the noise intensity ϵ, for ϵ → 0 within the different phases: (a) Mixed phase (δ = 0.03, α = −0.02); (b) static-demixed phase (δ = 0.045, α = −0.07); (c) traveling-wave phase (δ = 0.06, α = −0.07). The analytical results for the low noise limits given in Eqs. (19), (30), (32) are shown by solid lines. The numerical results confirm the analytics, including that S ∼ ϵ0 in the static phases, and S ∼ ϵ−1 in the traveling-wave phase. Other parameters are κ = 0.01, γ = 0.015, β = 0.05.",
            "FIG. 5. Total entropy production S from Eq. (B13) and its first-mode’s contribution σ1 from Eq. (B12) within the traveling-wave phase in the vicinity of the phase boundaries: (a) toward the transition to the static-demixed phase [here, α = −0.07, path c5 in Fig. 2(a)], and in (b) toward the mixed phase [here, δ = 1.2δc, path c6 in Fig. 1(a)]. The analytical result for σ1 in Eq. (32) is shown by solid red lines, symbols depict corresponding simulation results. As one moves deeper into the traveling-wave phase, S generally increases, i.e., it increases with increasing amplitude of the travelingwave (A1,∗ A,B) 2 ∝ |α − αc| [24], as well as with an increase of the deterministic speed of the traveling waves v2 ∼ |δ − δc| [panel (a)].",
            "FIG. 6. Scaled variance of the phase fluctuations near the transition as a function of δ for α = −0.07, β = 0.05, γ = 0.015, κ = 0.01, ϵ = 10−10 from the numerical simulation of Eq. (1). The solid line shows the analytical result Eq. (C3) which holds within the one mode approximation. The inset shows the same results in a log-scale."
        ],
        "imgs": [
            "$2305.00744v3-Figure1-1.png",
            "$2305.00744v3-Figure2-1.png",
            "$2305.00744v3-Figure3-1.png",
            "$2305.00744v3-Figure5-1.png",
            "$2305.00744v3-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00749",
        "abstract": "  In this paper, we extend the Discrete Empirical Interpolation Method (DEIM)\nto the third-order tensor case based on the t-product and use it to select\nimportant/ significant lateral and horizontal slices/features. The proposed\nTubal DEIM (TDEIM) is investigated both theoretically and numerically. The\nexperimental results show that the TDEIM can provide more accurate\napproximations than the existing methods. An application of the proposed method\nto the supervised classification task is also presented.\n",
        "title": "Robust Low-Tubal-rank tensor recovery Using Discrete Empirical\n  Interpolation Method with Optimized Slice/Feature Selection",
        "texts": [
            "Figure 1: (Left) The selected horizontal slice indices (Right) The selected lateral slice indices for p = 5. Top singular tensors of tubal rank R = 15 were used for Example 1.",
            "Figure 10: Errors of different sampling algorithms, (Left) Foreman video (Right) Suzie video. Top singular tensors of tubal rank R = 40 were used for Example 3.",
            "Figure 11: (Upper) The accuracy yielded by the lightweight classification model of digits (1, 7) using a low tubal rank approximation of the weight tensor by the proposed TDEIM approach for different numbers of sampled lateral and horizontal slices. (Bottom) The classification accuracy of the lightweight model using a low tubal rank approximation of the weight tensor (with the tubal rank R = 15) using the proposed TDEIM method for different combinations of digits for Example 4.",
            "Figure 3: Errors of different sampling algorithms, (Left) p = 5 (Right) p = 3. Top singular tensors of tubal rank R = 15 were used for Example 1.",
            "Figure 4: The error constants η̃p and η̃q for the data tensor (25) with p = 3 for Example 1.",
            "Figure 7: Errors of different sampling algorithms, (Left) lena (Right) peppers. Top singular tensors of tubal rank R = 20 were used for Example 2.",
            "Figure 8: (Left) The selected horizontal slice indices. (Right) The selected lateral slice indices for the Foreman video. Top singular tensors of tubal rank R = 40 were used for Example 3.",
            "Figure 9: (Left) The selected horizontal slice indices (Right) The selected lateral slice indices for the Suzie video. Top singular tensors of tubal rank R = 40 were used for Example 3.",
            "Table 1: Comparing the approximation errors obtained via the TDEIM (Algorithm 5) and the baselines for a low tubal approximation of tubal rank R = 10 using optimization based tensors tensors for Example 1.",
            "Table 2: Comparing the running time (seconds) of the HTDEIM (Algorithm 6) and the TDEIM (Algorithm 5) for the data tensor (25) for Example 1.",
            "Table 3: Comparing the errors of the HTDEIM (Algorithm 6) and the TDEIM (Algorithm 5) for Example 1."
        ],
        "imgs": [
            "$2305.00749v2-Figure1-1.png",
            "$2305.00749v2-Figure10-1.png",
            "$2305.00749v2-Figure11-1.png",
            "$2305.00749v2-Figure3-1.png",
            "$2305.00749v2-Figure4-1.png",
            "$2305.00749v2-Figure7-1.png",
            "$2305.00749v2-Figure8-1.png",
            "$2305.00749v2-Figure9-1.png",
            "$2305.00749v2-Table1-1.png",
            "$2305.00749v2-Table2-1.png",
            "$2305.00749v2-Table3-1.png"
        ]
    },
    {
        "id": "2305.00750",
        "abstract": "  The paper investigates the features of emissions and fuel consumption (EFC)\nin a car-following (CF) platoon based on two experimental datasets. Four\nclassical EFC models are employed and a universal concave growth pattern of the\nEFC along a platoon has been demonstrated. A general framework of coupling EFC\nand CF models is tested by calibrating and simulating three classical CF\nmodels. This work first demonstrates that, at vehicle-pair level, all models\nperform well on EFC prediction. The intelligent driver model outperforms the\nother CF models on calibration accuracy, but this is not true on EFC\nprediction. Second, at platoon level, the predicted EFC is nearly constant\nalong the platoon which qualitatively differs from the experimental\nobservation. The investigation highlights that accurate estimations at vehicle\nlevel may be insufficient for analysis at platoon level due to the significant\nrole of oscillation growth and evolution in EFC estimation.\n",
        "title": "Experimental features of emissions and fuel consumption in a\n  car-following platoon",
        "texts": [
            "Figure 1: A general coupling framework of EFC calculation and prediction.",
            "Figure 10: The cumulative frequency distribution of the calibration errors (RMSPE) of the spacing under different CF models in experiment II.",
            "Figure 11: The simulated velocity and EFC of the 10th car in experiment I under 𝑣𝑣leading=40 km/h calculated by the MEF model with calibrated IDM, FVDM, and Gipps in the local test. The results of the other three EFC models are highly similar, hence not shown.",
            "Figure 12: The simulated velocity and EFC of the 10th car in experiment II calculated by the MEF model with calibrated IDM, FVDM, and Gipps in the local test. The results of the other two CF models and three EFC models are highly similar, hence not shown.",
            "Figure 13: Evolution of the spatiotemporal pattern of velocity and EFC in experiment I in platoon test when 𝑣𝑣leading=40km/h. EFC is calculated by the MEF model (the results of the other three EFC models are highly similar, hence not shown). From left to right, these panels represent velocity (km/h), NOx (mg), CO2 (g), and Fuel (ml), respectively. In the simulation, the trajectory of the leading car is given. For the following cars, only the initial velocity and the initial location are given.",
            "Figure 14: The simulated velocity and EFC of the 10th car in experiment I under 𝑣𝑣leading=40 km/h calculated by the MEF model with calibrated IDM, FVDM, and Gipps in the platoon test. The results of the other three EFC models are highly similar, hence not shown.",
            "Figure 15: The EFC predictions along the platoons in the platoon test calculated by the MEF model (the results of the other three EFC models are highly similar, hence not shown). From left to right, these panels represent NOx (g/km), CO2 (kg/km), and Fuel (L/km), respectively.",
            "Figure 2: Evolution of the spatiotemporal pattern of velocity and EFC in the experiment. EFC is calculated by the MEF model. From left to right, these panels represent velocity (km/h), NOx (mg), CO2 (g), and Fuel (ml), respectively.",
            "Figure 4: The experimental EFC of each car in the platoon with different vleading calculated by the VT-micro model and MEF model.",
            "Figure 5: Evolution of the experimental (left) and simulated (right) spatiotemporal pattern of velocity and EFC of experiment II in platoon test. EFC is calculated by the MEF model with the calibrated IDM. From top to bottom, these panels represent velocity (km/h), NOx (mg), CO2 (g), and Fuel (ml), respectively. In the simulation, only the initial velocity and the initial location of the vehicles are given.",
            "Figure 6: The EFC predictions along the platoons of experiment II in the platoon test. From left to right, these panels represent NOx (g/km), CO2 (kg/km), and Fuel (L/km), respectively. The orange lines represent the experimental EFC of experiment II.",
            "Figure 7: The distribution of calibrated parameters of (a)IDM, (b)FVDM, and (c)Gipps model in experiment I. The calibration ranges are the upper and lower bounds of the vertical coordinate of the boxplot.",
            "Figure 8: The distribution of calibrated parameters of (a)IDM, (b)FVDM, and (c)Gipps model in experiment II. The calibration ranges are the upper and lower bounds of the vertical coordinate of the boxplot.",
            "Figure 9: The cumulative frequency distribution of the calibration errors (RMSPE) of the spacing under different CF models and vleading in experiment I.",
            "Table 1: The EFC prediction error (RMSPE) in local and platoon tests in Experiment I.",
            "Table 2: The EFC prediction error (RMSPE) in local and platoon tests in Experiment II."
        ],
        "imgs": [
            "$2305.00750v1-Figure1-1.png",
            "$2305.00750v1-Figure10-1.png",
            "$2305.00750v1-Figure11-1.png",
            "$2305.00750v1-Figure12-1.png",
            "$2305.00750v1-Figure13-1.png",
            "$2305.00750v1-Figure14-1.png",
            "$2305.00750v1-Figure15-1.png",
            "$2305.00750v1-Figure2-1.png",
            "$2305.00750v1-Figure4-1.png",
            "$2305.00750v1-Figure5-1.png",
            "$2305.00750v1-Figure6-1.png",
            "$2305.00750v1-Figure7-1.png",
            "$2305.00750v1-Figure8-1.png",
            "$2305.00750v1-Figure9-1.png",
            "$2305.00750v1-Table1-1.png",
            "$2305.00750v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00753",
        "abstract": "  In the present work, some MoS2 and WS2 nanosheets were prepared and\ncharacterized. Depending on the preparation procedures, trigonal prismatic (2H)\nor octahedral (1T) coordination of the metal atoms were obtained, exhibiting\nmetallic (1T) or semiconducting (2H) character. Both MoS2 and WS2 nanosheets\nwere found exhibiting large nonlinear optical (NLO) response, strongly\ndependent on their metallic (1T) or semiconducting (2H) character. So, the\nsemiconducting character 2H-MoS2 and 2H-WS2 exhibit positive nonlinear\nabsorption and strong self-focusing, while their metallic character\ncounterparts exhibit strong negative nonlinear absorption and important\nself-defocusing. In addition, the semiconducting MoS2 and WS2 were found\nexhibiting important and very broadband optical limiting action extended from\n450 to 1750 nm. So, by selecting the crystalline phase of the nanosheets, i.e.,\ntheir semiconduction/metallic character, their NLO response can be greatly\nmodulated. The results of the present work demonstrate unambiguously that the\ncontrol of the crystalline phase of MoS2 and WS2 provides an efficient strategy\nfor 2D nanostructures with custom made NLO properties for specific\noptoelectronic and photonic applications.\n",
        "title": "Crystalline Phase Effects on the Nonlinear Optical Response of MoS2 and\n  WS2 Nanosheets",
        "texts": [
            "Figure 2. Raman spectra (average of 120 measurements) for (a) 2H-MoS2 (blue) and 1TMoS2 (red) upon 633 nm excitation, and (b) 2H-WS2 (blue) and 1T-WS2 (red) upon 514 nm excitation, obtained at ambient conditions.",
            "Figure 3. High-resolution scanning TEM HAADF images of 2H-MoS2 and 2H-WS2 (a and b) and 1T-MoS2 and 1T-WS2 (c and d).",
            "Figure 5. OA Z-scans of 1T-MoS2, 2H-MoS2 dispersions, under different laser excitation intensities at (a, c) 532 and (b, d) 1064 nm. All dispersions had a concentration of 0.1 mg/mL.",
            "Figure 6. OA Z-scans of 1T-WS2 and 2H-WS2 dispersions, under different laser excitation intensities at (a, c) 532 and (b, d) 1064 nm. All dispersions had a concentration of 0.1 mg/mL.",
            "Figure 7. “Divided” Z-scans of 2H-MoS2, 1T-MoS2, 2H-WS2, 2H/1T-WS2 and 1T-WS2 dispersions, under (a) 532 and (b) 1064 nm, all having a concentration of 0.1 mg/mL.",
            "Figure 8. Variation of the optical limiting onset values, OLon, of 2H-MoS2 and 2H-WS2, versus the laser irradiation wavelength.",
            "Table 1. Determined NLO parameters of 2H-MoS2, 1T-MoS2, 2H-WS2 and 1T-WS2 (all values referring to a concentration of 1 mg/mL).",
            "Table 2. OLon values of 2H-MoS2 and 2H-WS2 under different irradiation wavelength."
        ],
        "imgs": [
            "$2305.00753v1-Figure2-1.png",
            "$2305.00753v1-Figure3-1.png",
            "$2305.00753v1-Figure5-1.png",
            "$2305.00753v1-Figure6-1.png",
            "$2305.00753v1-Figure7-1.png",
            "$2305.00753v1-Figure8-1.png",
            "$2305.00753v1-Table1-1.png",
            "$2305.00753v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00756",
        "abstract": "  Observations across the electromagnetic spectrum of radiative processes\ninvolving interstellar dust -- emission, extinction, and scattering -- are used\nto constrain the parameters of dust models and more directly to aid in\nforeground removal of dust for extragalactic and cosmology observations. The\nmore complementary observations, the better. Here, we quantify the relationship\nbetween scattered light and thermal emission from dust in a diffuse (cirrus)\nintermediate latitude cloud, Spider, using data from the Dragonfly Telephoto\nArray and the Herschel Space Observatory. A challenge for optical observations\nof faint cirrus is accurate removal of a contaminating spatially varying sky\nbackground. We present a technique to analyse two images of the same cirrus\nfield concurrently, correlating pixel values to capture the relationship and\nsimultaneously fitting the sky background as a complex non-correlating additive\ncomponent. For the Spider, we measure a $g-r$ color of 0.644$\\pm 0.024$ and a\nvisible wavelength to 250 $\\mu$m intensity ratio of $10^{-3} \\times (0.855\n\\pm0.025)$ and $10^{-3} \\times (1.55\\pm0.08)$ for $g$ and $r$-band\nrespectively. We show how to use any dust model that matches the thermal dust\nemission to predict an upper limit to the amount of scattered light. The actual\nbrightness of the cirrus will be fainter than this limit because of anisotropic\nscattering by the dust combined with anisotropy of the incident interstellar\nradiation field (ISRF). Using models of dust and the ISRF in the literature we\nillustrate that the predicted brightness is indeed lower, though not as faint\nas the observations indicate.\n",
        "title": "Joint Modelling of Dust Scattering and Thermal Emission: The Spider\n  Complex",
        "texts": [
            "Figure 1. Reduced and stacked g-band (upper) and r-band (lower) images of Spider taken with the Dragonfly Telephoto Array in 2017.",
            "Figure 2. Herschel 250 μm image of the Spider. The largest (thin, yellow outline) box shows the footprint of the Dragonfly g- and r-band combined images from 2014. The most elongated (bold, blue solid outline) box shows the footprint of the Dragonfly r-band combined image from 2017. The smallest (dashed, green outline) box shows the footprint of the Dragonfly g-band combined image from 2017.",
            "Figure 3. 2D histogram of intensities of scattered light (2017 g band, 36″) and thermal emission (250 μm) after star and galaxy masking and subtraction of the sky. The linear fit using Equation (3) excluded data at high surface brightness in a central rectangular region in Spider containing the brightest cirrus, which corresponds to the plume of black points (low pixel count n) that clearly departs from a linear relationship in this figure.",
            "Figure 4. The relationship between thermal dust emission and scattered light (see text for details). Data: shape of the thermal emission SED in Spider as measured by Herschel (magenta) and Planck/IRAS (cyan), normalized to 6 MJy sr−1 at 250 μm; scattered light (Dragonfly) relative to 250 μm thermal emission (red and green dots). Curves: modified blackbody fit to the data (black); ISRF (blue) cut off at the neutral hydrogen ionization limit (dashed); ISRF times dust model absorption cross section, scaled such that energy absorbed equals energy thermally emitted by dust (black); dust model prediction of the emitted intensity, very close to the MBB (black); ISRF times corresponding scattering cross section in the dust model assuming no anisotropy (red)—the observations are lower than this by about a factor of 0.3 (the level of the dashed–dotted curve).",
            "Figure 5. Phase functions for the illustrative LamC plus aSil dust model, showing significant reductions relative to isotropic at backscattering angles. Red and green curves are for the corresponding passbands and dashed curves are the Henyey–Greenstein approximations for the same asymmetry parameter.",
            "Figure 6. Zoom to highlight the near-infrared to near/far-ultraviolet portion of Figure 4. To provide the context of the frequency dependence of the ISRF (blue), that curve has been multiplied by 0.1. New additions are overplots of our coarse sampling of measurements of correlation spectra of scattered DGL relative to 100 μm: BOSS spectrum (Chellew et al. 2022) in lime green; CIBER spectrum (Arai et al. 2015), renormalized to match the BOSS spectrum at 1 μm (orange); FOS spectrum (Kawara et al. 2017) with the same renormalization (cyan); likewise, two Galaxy Evolution Explorer (GALEX) passbands (joined by a dashed magenta line) from Murthy et al. (2010). See text for details and discussion. The upper x-axis ranges from 2.5 μm on the left to 0.0857 μm on the right.",
            "Table 1 Summary of Dragonfly Observations: Number of 10 Minutes Exposures Stacked and FWHM",
            "Table 2 Field-averaged g to r Intensity Ratio and Color",
            "Table 3 Ratio of Scattered Light to Thermal Emission at 250 μm"
        ],
        "imgs": [
            "$2305.00756v1-Figure1-1.png",
            "$2305.00756v1-Figure2-1.png",
            "$2305.00756v1-Figure3-1.png",
            "$2305.00756v1-Figure4-1.png",
            "$2305.00756v1-Figure5-1.png",
            "$2305.00756v1-Figure6-1.png",
            "$2305.00756v1-Table1-1.png",
            "$2305.00756v1-Table2-1.png",
            "$2305.00756v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00758",
        "abstract": "  For $d\\in\\mathbb{N}$, a compact sphere packing of Euclidean space\n$\\mathbb{R}^{d}$ is a set of spheres in $\\mathbb{R}^{d}$ with disjoint\ninteriors so that the contact hypergraph of the packing is the vertex scheme of\na homogeneous simplicial $d$-complex that covers all of $\\mathbb{R}^{d}$.\n  We are motivated by the question: For $d,n\\in\\mathbb{N}$ with $d,n\\geq2$, how\nmany configurations of numbers $0<r_{0}<r_{1}<\\ldots<r_{n-1}=1$ can occur as\nthe radii of spheres in a compact sphere packing of $\\mathbb{R}^{d}$ wherein\nthere occur exactly $n$ sizes of sphere?\n  We introduce what we call `heteroperturbative sets' of labeled triangulations\nof unit spheres and we discuss the existence of non-trivial examples of\nheteroperturbative sets. For a fixed heteroperturbative set, we discuss how a\ncompact sphere packing may be associated to the heteroperturbative set or not.\n  We proceed to show, for $d,n\\in\\mathbb{N}$ with $d,n\\geq2$ and for a fixed\nheteroperturbative set, that the collection of all configurations of $n$\ndistinct positive numbers that can occur as the radii of spheres in a compact\npacking is finite, when taken over all compact sphere packings of\n$\\mathbb{R}^{d}$ which have exactly $n$ sizes of sphere and which are\nassociated to the fixed heteroperturbative set.\n",
        "title": "On compact packings of Euclidean space with spheres of finitely many\n  sizes",
        "texts": [
            "Figure 2.2. The set T3 is not heteroperturbative. Triangulate the unit sphere of R3 with an equatorial strip of bisected darts as indicated on the left of the figure. By rotating the vertices and edges on the equator around the polar axis we obtain a combinatorially equivalent triangulation, as on the right. On the right, with respect to the geodesic metric on the sphere, some edges have increased in length when compared to the corresponding edges on the left, but no edge on the right has decreased in length when compared to the corresponding edge on the left.",
            "Figure 2.3. The vertex scheme of a spherical triangulation of the unit sphere in R 3 need not be isomorphic to face lattice of the polytope obtained as the convex hull of all vertices of the trangulation. Consider an octahedral triangulation of the unit sphere of R 3 with the vertex at the north pole moved slightly down on one of the meridians so as to not be lie on the vertical line through the origin. We split this meridian into two rather “skinny” triangles as in the figure on the left. However, two vertices can then “see” each other over the chord connecting the south pole with the slightly moved north pole. It is then seen that the face lattice of the polytope formed as the convex hull of the vertices of the triangulation is not isomorphic to the vertex scheme of the triangulation."
        ],
        "imgs": [
            "$2305.00758v1-Figure2.2-1.png",
            "$2305.00758v1-Figure2.3-1.png"
        ]
    },
    {
        "id": "2305.00759",
        "abstract": "  We show how multiplexing influences propagating fronts in multilayer networks\nof coupled bistable oscillators. Using numerical simulation, we investigate\nboth deterministic and noise-sustained propagation. In particular, we\ndemonstrate that the multiplexing allows to reduce the intra-layer dynamics to\na common regime where the front propagation speed in all the interacting layers\nattains the same fixed value. In the presence of noise the dynamics is more\ncomplicated and is characterized by the ability of the system to adjust to the\ncommon propagation speed for varying the multiplexing strength. In addition, we\nfind that the noise-induced stabilization of wavefront propagation in\nmultilayer networks allows to obtain less pronounced deviations of the\nwavefront compared to the stabilization achieved in the isolated layer.\nFinally, we demonstrate that the reduction of the wavefront deviations can be\nenhanced by increasing the number of interacting layers.\n",
        "title": "Multiplexing-based control of wavefront propagation: the interplay of\n  inter-layer coupling, asymmetry and noise",
        "texts": [
            "FIG. 1. Stochastic control of front propagation (coarsening) in a single-layer network (Eq. (1) in the presence of parametric noise in each oscillator: bx = 0.9+ √ 2Dni(t)). (a) Schematic representation of a one-layer network (layer x); (b)-(d) Spatio-temporal dynamics for increasing noise intensity, D. System parameters: a = 1, σx = 1.",
            "FIG. 2. Multiplexing-based control of front propagation (coarsening) in a two-layer multiplex network Eqs. (2) in the absence of noise. (a) Schematic representation of the network (layers x and y); (b) Dependence of the front propagation speed on the multiplexing strength in layer x (solid curves) and y (dashed curves) for intra-layer coupling σx,y = 1 (red curves) and σx,y = 2 (blue curves); (c)-(e) Spatio-temporal dynamics of layer x (upper panels) and y (lower panes) for fixed intra-layer coupling (σx = σy = 2) and increasing multiplexing strength: σ = 10−3 (panels (c)), σ = 8×10−3 (panels (d)), σ = 5×10−2 (panels (e)). Other parameters: ax = 1.0, bx = 0.9, ay = 1.0, by = 1.0.",
            "FIG. 3. Multiplexing-based control of front propagation (coarsening) in a two-layer multiplex network (Eqs. (2) in the presence of noise: (a) Dependence of the mean front propagation speed on the multiplexing strength in layer x (solid curves) and y (dashed curves) for intra-layer coupling σx,y = 1; (b)-(e) Spatio-temporal dynamics of layer x (upper panels) and y (lower panes) for fixed intra-layer coupling (σx = σy = 1) and increasing multiplexing strength: σ = 10−3 (panels (b)), σ = 10−2 (panels (c)), σ = 1.3 (panels (d)), σ = 5.0 (panels (e)). Other parameters: ax = 1.0, bx = 0.9, ay = 1.0, by = 0.9, D = 0.14.",
            "FIG. 4. Multiplexing-based control of front propagation (coarsening) in a three-layer multiplex network Eqs. (3) in the presence of noise: (a) Schematic representation of a three-layer network; (b)-(e) Spatio-temporal dynamics of layers x, y, z for fixed intra-layer coupling (σx = σy = σz = 1) and increasing multiplexing strength: σ = 10−3 (panels (b)), σ = 10−1 (panels (c)), σ = 0.5 (panels (d)), σ = 7.0 (panels (e)). Other parameters: ax = ay = az = 1.0, bx = by = bz = 0.9, D = 0.14."
        ],
        "imgs": [
            "$2305.00759v1-Figure1-1.png",
            "$2305.00759v1-Figure2-1.png",
            "$2305.00759v1-Figure3-1.png",
            "$2305.00759v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00760",
        "abstract": "  Developers interrupting their participation in a project might slowly forget\ncritical information about the code, such as its intended purpose, structure,\nthe impact of external dependencies, and the approach used for implementation.\nForgetting the implementation details can have detrimental effects on software\nmaintenance, comprehension, knowledge sharing, and developer productivity,\nresulting in bugs, and other issues that can negatively influence the software\ndevelopment process. Therefore, it is crucial to ensure that developers have a\nclear understanding of the codebase and can work efficiently and effectively\neven after long interruptions. This registered report proposes an empirical\nstudy aimed at investigating the impact of the developer's activity breaks\nduration and different code quality properties. In particular, we aim at\nunderstanding if the amount of activity in a project impact the code quality,\nand if developers with different activity profiles show different impacts on\ncode quality. The results might be useful to understand if it is beneficial to\npromote the practice of developing multiple projects in parallel, or if it is\nmore beneficial to reduce the number of projects each developer contributes.\n",
        "title": "Breaks and Code Quality: Investigating the Impact of Forgetting on\n  Software Development. A Registered Report",
        "texts": [
            "Fig. 1. Illustration of the forgetting curve [4], extended with examples that exemplify its application to software development.",
            "Fig. 2. Empirical Study Design Process",
            "Fig. 3. Activity break influence measurement",
            "TABLE I ANTI-PATTERNS AND CODE SMELLS COLLECTED IN THIS WORK",
            "TABLE III REDABILITY METRICS COLLECTED IN THIS WORK"
        ],
        "imgs": [
            "$2305.00760v3-Figure1-1.png",
            "$2305.00760v3-Figure2-1.png",
            "$2305.00760v3-Figure3-1.png",
            "$2305.00760v3-TableI-1.png",
            "$2305.00760v3-TableIII-1.png"
        ]
    },
    {
        "id": "2305.00761",
        "abstract": "  We investigate the effect of buffer gases on the coherent population trapping\nresonance induced by a $\\sigma$-polarized optical field in $^{87}$Rb atoms. Our\nexperimental results show that inert gases, which depolarize the excited state\nof the alkali-metal atoms, provide higher contrast than nitrogen that\neffectively quenches their fluorescence. We also demonstrate that elimination\nof the spontaneous radiation does not significantly decrease the width at\nmoderate temperatures of an atomic medium. Therefore, a mixture of inert gases\ncan be preferable over a mixture with nitrogen for atomic clocks.\n",
        "title": "Effect of depolarizing and quenching collisions on contrast of the\n  coherent population trapping resonance",
        "texts": [
            "FIG. 1. Energy level structure and electric-dipole transitions to sublevels of hyperfine component Fe = 2 induced by an optical field with σ+ polarization. Columns show distribution of populations over 5S1/2 and 5P1/2 states. They were calculated in a model without (a) and with (b) accounting for the depolarization; see Appendix for details. The heights of the columns for the excited state are increased by about five orders of magnitude.",
            "FIG. 2. The layout of experimental setup.",
            "FIG. 3. Metrological (central) and magneto-sensitive CPT resonances obtained in atomic cells filled with nitrogen and argon at a pressure of 90 Torr. The dashed lines serve as a guide for the eye and show the difference in the amplitudes of the resonances.",
            "FIG. 4. Dependencies of the CPT resonance contrast on the laser intensity for different temperatures and pressures of nitrogen, argon, and neon.",
            "FIG. 5. Dependencies of the maximal (in terms of intensity) quality factor Qmax of the CPT resonance on the cell temperature for different pressures of nitrogen, argon, and neon. The legend is the same as in Fig. 4.",
            "FIG. 6. Dependencies of the CPT resonance width on the optical field intensity for different temperatures in neon (a) and nitrogen (b) and on the temperature for atomic cells with nitrogen, argon and neon (c). Pressure of all buffer gases is 90 Torr. The dashed line in (c) is the spin-exchange broadening for 87Rb calculated via Eq. (1)."
        ],
        "imgs": [
            "$2305.00761v1-Figure1-1.png",
            "$2305.00761v1-Figure2-1.png",
            "$2305.00761v1-Figure3-1.png",
            "$2305.00761v1-Figure4-1.png",
            "$2305.00761v1-Figure5-1.png",
            "$2305.00761v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00762",
        "abstract": "  This paper extends the gradient-based reconstruction approach of Chamarthi\n\\cite{chamarthi2023gradient} to genuine high-order accuracy for inviscid test\ncases involving smooth flows. A seventh-order accurate scheme is derived using\nthe same stencil as of the explicit fourth-order scheme proposed in Ref.\n\\cite{chamarthi2023gradient}, which also has low dissipation properties. The\nproposed method is seventh-order accurate under the assumption that the\nvariables at the \\textit{cell centres are point values}. A problem-independent\ndiscontinuity detector is used to obtain high-order accuracy. Accordingly,\nprimitive or conservative variable reconstruction is performed around regions\nof discontinuities, whereas smooth solution regions apply flux reconstruction.\nThe proposed approach can still share the derivatives between the inviscid and\nviscous fluxes, which is the main idea behind the gradient-based\nreconstruction. Several standard benchmark test cases are presented. The\nproposed method is more efficient than the seventh-order weighted compact\nnonlinear scheme (WCNS) for the test cases considered in this paper.\n",
        "title": "Efficient high-order Gradient-based Reconstruction for compressible\n  flows",
        "texts": [
            "Figure 1: Schematic representation of the computational grid in two dimensions with cell centre points (blue) and relevant fluxes for the cell of interest.",
            "Figure 13: Density contours obtained by using the different schemes for the Example 3.10 for Re = 1000 on a grid size of 1280 × 640 at t=1.0 are shown in Figs. 13(a), 13(b) and 13(c). Fig. 13(d) shows the reference solution.",
            "Figure 15: Dispersion and Dissipation properties of the unlimited schemes.",
            "Figure 17: Mathematica Workbook showing order of accuracy of the seventh order scheme.",
            "Figure 2: Numerical solution for Sod shock tube problem using N = 200 grid points at t = 0.2, for Sod test case of Example 3.2, where solid line: exact solution; blue squares: WCNS7M; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 3: Numerical solution for Lax problem using N = 200 grid points at t = 0.14, for Lax test case of Example 3.2, where solid line: exact solution; blue squares: WCNS7M; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 4: Numerical solution for Le Blanc problem with the initial conditions given by Equation (53), Example (3.3). Solid line: exact solution; blue squares: WCNS7M; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 5: Numerical solution for Sedov problem with the initial conditions given by Equation (54), Example 3.3. Solid line: exact solution; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 6: Numerical solution for blast wave problem using N = 600 grid points at t = 0.038, Example 3.4. Solid line: exact solution; blue squares: WCNS7M; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 7: Numerical solution for Shu-Osher problem using N = 200 grid points at t = 1.8, Example 3.5. Solid line: exact solution; blue squares: WCNS7M; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 8: Numerical solution for Titarev-Toro problem using N = 1000 grid points at t = 5. Solid line: exact solution; blue squares: WCNS7M; red stars: MEG7-cons and green circles: MEG7-prim.",
            "Figure 9: Numerical results of Richtmeyer - Meshkov instability described in Example 3.6 for the considered schemes. The figures are drawn with 24 contours.",
            "Table 1: Order of accuracy for various schemes, Example 3.1. L2 density error norms and convergence rate are shown."
        ],
        "imgs": [
            "$2305.00762v1-Figure1-1.png",
            "$2305.00762v1-Figure13-1.png",
            "$2305.00762v1-Figure15-1.png",
            "$2305.00762v1-Figure17-1.png",
            "$2305.00762v1-Figure2-1.png",
            "$2305.00762v1-Figure3-1.png",
            "$2305.00762v1-Figure4-1.png",
            "$2305.00762v1-Figure5-1.png",
            "$2305.00762v1-Figure6-1.png",
            "$2305.00762v1-Figure7-1.png",
            "$2305.00762v1-Figure8-1.png",
            "$2305.00762v1-Figure9-1.png",
            "$2305.00762v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00763",
        "abstract": "  Intel's software guard extensions (SGX) provide hardware enclaves to\nguarantee confidentiality and integrity for sensitive code and data. However,\nsystems leveraging such security mechanisms must often pay high performance\noverheads. A major source of this overhead is SGX enclave transitions which\ninduce expensive cross-enclave context switches. The Intel SGX SDK mitigates\nthis with a switchless call mechanism for transitionless cross-enclave calls\nusing worker threads. Intel's SGX switchless call implementation improves\nperformance but provides limited flexibility: developers need to statically fix\nthe system configuration at build time, which is error-prone and\nmisconfigurations lead to performance degradations and waste of CPU resources.\nZC-SWITCHLESS is a configless and efficient technique to drive the execution of\nSGX switchless calls. Its dynamic approach optimises the total switchless\nworker threads at runtime to minimise CPU waste. The experimental evaluation\nshows that ZC-SWITCHLESS obviates the performance penalty of misconfigured\nswitchless systems while minimising CPU waste.\n",
        "title": "SGX Switchless Calls Made Configless",
        "texts": [
            "Fig. 1: Intel SGX switchless ocall architecture.",
            "Fig. 13: Throughput for ocalls of the write system call to /dev/null (100,000 operations, average over 10 executions) for aligned and unaligned buffers.",
            "Fig. 3: Runtime for 100, 000 ocalls with 8 in-enclave threads for different durations of g function.",
            "Fig. 4: ZC-SWITCHLESS general overview.",
            "Fig. 7: Throughput for ocalls of the write system call to /dev/null (100,000 operations, average over 10 executions) for aligned and unaligned buffers."
        ],
        "imgs": [
            "$2305.00763v2-Figure1-1.png",
            "$2305.00763v2-Figure13-1.png",
            "$2305.00763v2-Figure3-1.png",
            "$2305.00763v2-Figure4-1.png",
            "$2305.00763v2-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00764",
        "abstract": "  Electrochemical reactions for hydrogen and hydrogen peroxide production are\nessential for energy conversion to diminish energy crisis, but still lack\nefficient electrocatalysts. Development of non\\-noble metal bifunctional\nelectrocatalysts for hydrogen evolution and 2e oxygen reduction reaction to\nease reaction kinetics is a challenging task. Integration of single components\nby employing easy strategies provides a key\\-step towards the realization of\nhighly active electrocatalysts. In this vein, MoSe2 owns catalytic active sites\nand high specific surface area but suffers from insufficient conductivity and\nhigh catalytic performance that noble\\-metals provide. Herein, MoSe2 was used\nas a platform for the incorporation of manganese metallated porphyrin. The\ndeveloped hybrid, namely MoSe2\\-MnP, by the initial metal\\-ligand coordination\nand the subsequent grafting with MnP was fully characterized and\nelectrochemically assessed. The bifunctional electrocatalyst lowered the\noverpotential toward hydrogen evolution, improved reaction kinetics and charge\ntransfer processes and was extremely stable after 10000 ongoing cycles.\nSimultaneously, rotating ring disk electrode analysis showed that oxygen\nreduction proceeds through the 2e pathway for the selective production of\nhydrogen peroxide with a high yield of 97 percent. The new facile modification\nroute can be applied in diverse transition metal dichalcogenides and will help\nthe development of new advanced functional materials.\n",
        "title": "Molybdenum diselenide-manganese porphyrin bifunctional electrocatalyst\n  for hydrogen evolution reaction and selective hydrogen peroxide production",
        "texts": [
            "Figure 1. (a) ATR-IR spectra, (b) Raman spectra (514 nm), and (c) TGA graphs for MoSe2MnP, (red), MoSe2 (black), f-MoSe2 (blue) and MnP (pink).",
            "Figure 2. (a and b) Low- and medium-magnification high-angle annular dark-field (HAADF)STEM images recorded on a MoSe2-MnP flake, respectively. (c) High-magnification HAADFSTEM image of the red highlighted area in Figure 2b. (d) EDS spectrum acquired in the green highlighted area of Figure 2c. Signals coming from C, N, Mo, Se and Mn can be observed in this spectrum. Impurities due to Ca, Fe, Co and Cu from the sample holder, objective lens of the",
            "Figure 4. (a) LSVs for HER before (solid lines) and after 10,000 cycles (dashed lines), (b) Tafel slopes, and (c) Nyquist plots, for MoSe2-MnP (red), MoSe2 (black), f-MoSe2 (blue), MnP (pink) and Pt/C (grey). The LSVs obtained at 1,600 rpm rotation speed and 5 mV/s scan rate in aqueous 0.1 Μ KOH.",
            "Figure 5. (a) ORR polarization curves at 1,600 rpm for MoSe2-MnP (red), MoSe2 (black), fMoSe2 (blue) and MnP (pink), (b) ORR polarization curves at different rotation rates (400-3,600 rpm) for MoSe2-MnP, and (c) ring response for MoSe2-MnP. All measurements were conducted in O2 saturated aqueous 0.1 M KOH electrolyte and the corresponding LSV polarization curves were recorded at a scan rate of 5 mV/s.",
            "Table 1. Electrocatalytic HER parameters for MoSe2-MnP in comparison with MoSe2, f-MoSe2, MnP and Pt/C."
        ],
        "imgs": [
            "$2305.00764v1-Figure1-1.png",
            "$2305.00764v1-Figure2-1.png",
            "$2305.00764v1-Figure4-1.png",
            "$2305.00764v1-Figure5-1.png",
            "$2305.00764v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00766",
        "abstract": "  The popularity of the Java programming language has led to its wide adoption\nin cloud computing infrastructures. However, Java applications running in\nuntrusted clouds are vulnerable to various forms of privileged attacks. The\nemergence of trusted execution environments (TEEs) such as Intel SGX mitigates\nthis problem. TEEs protect code and data in secure enclaves inaccessible to\nuntrusted software, including the kernel and hypervisors. To efficiently use\nTEEs, developers must manually partition their applications into trusted and\nuntrusted parts, in order to reduce the size of the trusted computing base\n(TCB) and minimise the risks of security vulnerabilities. However, partitioning\napplications poses two important challenges: (i) ensuring efficient object\ncommunication between the partitioned components, and (ii) ensuring the\nconsistency of garbage collection between the parts, especially with\nmemory-managed languages such as Java. We present Montsalvat, a tool which\nprovides a practical and intuitive annotation-based partitioning approach for\nJava applications destined for secure enclaves. Montsalvat provides an RMI-like\nmechanism to ensure inter-object communication, as well as consistent garbage\ncollection across the partitioned components. We implement Montsalvat with\nGraalVM native-image, a tool for compiling Java applications ahead-of-time into\nstandalone native executables that do not require a JVM at runtime. Our\nextensive evaluation with micro- and macro-benchmarks shows our partitioning\napproach to boost performance in real-world applications\n",
        "title": "Montsalvat: Intel SGX Shielding for GraalVM Native Images",
        "texts": [
            "Figure 1: Overview ofMontsalvat’s workflow. Anno-",
            "Figure 12: Performance of unpartitioned SPECjvm",
            "Figure 2: For the trusted image, the relay meth-",
            "Figure 3: Performance of proxy object creation vs.",
            "Figure 4: Performance of remote method invoca-",
            "Figure 5: Garbage collection performance.",
            "Figure 6: Enclave performance is better when fewer",
            "Figure 7: Read and write times for partitioned PalDB.",
            "Figure 8: Typical GraphChi program workflow.",
            "Figure 9: Execution time for partitioned PageRank.",
            "Table 1: Ratio between unpartitioned SPECjvm2008 native images in enclaves (SGX-NI in Figure 12) against their on-JVM counterparts in SCONE (SCONE+JVM)."
        ],
        "imgs": [
            "$2305.00766v1-Figure1-1.png",
            "$2305.00766v1-Figure12-1.png",
            "$2305.00766v1-Figure2-1.png",
            "$2305.00766v1-Figure3-1.png",
            "$2305.00766v1-Figure4-1.png",
            "$2305.00766v1-Figure5-1.png",
            "$2305.00766v1-Figure6-1.png",
            "$2305.00766v1-Figure7-1.png",
            "$2305.00766v1-Figure8-1.png",
            "$2305.00766v1-Figure9-1.png",
            "$2305.00766v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00767",
        "abstract": "  In recent years, raw video denoising has garnered increased attention due to\nthe consistency with the imaging process and well-studied noise modeling in the\nraw domain. However, two problems still hinder the denoising performance.\nFirstly, there is no large dataset with realistic motions for supervised raw\nvideo denoising, as capturing noisy and clean frames for real dynamic scenes is\ndifficult. To address this, we propose recapturing existing high-resolution\nvideos displayed on a 4K screen with high-low ISO settings to construct\nnoisy-clean paired frames. In this way, we construct a video denoising dataset\n(named as ReCRVD) with 120 groups of noisy-clean videos, whose ISO values\nranging from 1600 to 25600. Secondly, while non-local temporal-spatial\nattention is beneficial for denoising, it often leads to heavy computation\ncosts. We propose an efficient raw video denoising transformer network\n(RViDeformer) that explores both short and long-distance correlations.\nSpecifically, we propose multi-branch spatial and temporal attention modules,\nwhich explore the patch correlations from local window, local low-resolution\nwindow, global downsampled window, and neighbor-involved window, and then they\nare fused together. We employ reparameterization to reduce computation costs.\nOur network is trained in both supervised and unsupervised manners, achieving\nthe best performance compared with state-of-the-art methods. Additionally, the\nmodel trained with our proposed dataset (ReCRVD) outperforms the model trained\nwith previous benchmark dataset (CRVD) when evaluated on the real-world outdoor\nnoisy videos. Our code and dataset will be released after the acceptance of\nthis work.\n",
        "title": "RViDeformer: Efficient Raw Video Denoising Transformer with a Larger\n  Benchmark Dataset",
        "texts": [
            "Fig. 1. Illustration of our capturing system (top row), the captured noisyclean pairs (middle row), and the close-up of three regions (bottom row).",
            "Fig. 3. From top to bottom, each row lists the original clean frame, noisy frame, clean frame after intensity correction, the residual brightness channel before and after intensity correction. Left: processing with Gcor < 1; Right: processing with Gcor > 1 (proposed).",
            "Fig. 4. Differences between blue channels of noisy and clean raw frames before and after spatial alignment. Zoom in for better observation.",
            "TABLE 1 Detailed configurations of different versions of our RViDeformer. The MACs are calculated based on the Bayer raw input with a resolution of 1920×1080.",
            "TABLE 2 Quantitative comparisons of PSNR and SSIM for supervised raw video denoising on the ReCRVD test set. The GMACs for one frame are calculated based on the Bayer raw input with a resolution of 1920×1080.",
            "TABLE 3 Quantitative comparisons of PSNR and SSIM for supervised raw video denoising on the CRVD test set. The GMACs for one frame are calculated based on the Bayer raw input with a resolution of 1920×1080. The results of VBM4D are quoted from [12]. The results of EDVR and FastDVDnet are quoted from [27]. The results of FastDVDnet-S are quoted from [66].",
            "TABLE 4 Quantitative comparisons of PSNR and SSIM for unsupervised raw video denoising on ReCRVD test set. The GMACs for one frame are calculated based on the Bayer raw input with a resolution of 1920×1080.",
            "TABLE 5 Quantitative comparisons of PSNR and SSIM for unsupervised raw video denoising on the CRVD test set. The GMACs for one frame are calculated based on the Bayer raw input with a resolution of 1920×1080.",
            "TABLE 6 Ablation study for the MTSB, MSSB block and the multi-branch self-attention in RViDeformer-M by evaluating on ReCRVD test set.",
            "TABLE 7 Quantitative comparisons of no-reference metrics for supervised raw video denoising on CRVD outdoor test set."
        ],
        "imgs": [
            "$2305.00767v1-Figure1-1.png",
            "$2305.00767v1-Figure3-1.png",
            "$2305.00767v1-Figure4-1.png",
            "$2305.00767v1-Table1-1.png",
            "$2305.00767v1-Table2-1.png",
            "$2305.00767v1-Table3-1.png",
            "$2305.00767v1-Table4-1.png",
            "$2305.00767v1-Table5-1.png",
            "$2305.00767v1-Table6-1.png",
            "$2305.00767v1-Table7-1.png"
        ]
    },
    {
        "id": "2305.00768",
        "abstract": "  In social psychology, Social Value Orientation (SVO) describes an\nindividual's propensity to allocate resources between themself and others. In\nreinforcement learning, SVO has been instantiated as an intrinsic motivation\nthat remaps an agent's rewards based on particular target distributions of\ngroup reward. Prior studies show that groups of agents endowed with\nheterogeneous SVO learn diverse policies in settings that resemble the\nincentive structure of Prisoner's dilemma. Our work extends this body of\nresults and demonstrates that (1) heterogeneous SVO leads to meaningfully\ndiverse policies across a range of incentive structures in sequential social\ndilemmas, as measured by task-specific diversity metrics; and (2) learning a\nbest response to such policy diversity leads to better zero-shot generalization\nin some situations. We show that these best-response agents learn policies that\nare conditioned on their co-players, which we posit is the reason for improved\nzero-shot generalization results.\n",
        "title": "Heterogeneous Social Value Orientation Leads to Meaningful Diversity in\n  Sequential Social Dilemmas",
        "texts": [
            "Figure 1: Overview of the methodology. Blue shapes show agents that are actively being trained, whereas gray ones denote frozen agents (bots). Circles represent the agents trained with diverse SVO, triangles denote a best response agent, and squares denote a held-out set of co-players. Evaluation is zero-shot, meaning the best response agent is frozen (gray triangle) and is evaluated against the held-out bots.",
            "Figure 2: Payoff matrices for Stag hunt, Chicken and Prisoner’s dilemma. The values shown correspond to the payoff of the row player. The payoff of the column player is the transpose of the shown matrix (i.e. the games are symmetric games). Cooperation corresponds to the first row and column. Defection corresponds to the send row and column.",
            "Figure 3: “In the matrix” repeated games. This is a 2-player game where agents can gather 2 types of resources (green corresponding to cooperation, red corresponding to defection).When agents interact (using an interaction beam) they get rewards according to their inventory counts and a game specific payoff matrix. The payoff matrix can be Stag hunt, Chicken or Prisoner’s dilemma type payoff matrix",
            "Figure 5: “In the matrix” repeated games. Diversity of policies of selfish-baseline bots and SVO bots. Each subfigure shows average inventory counts during evaluation for 4 agents, trained with 50% self-play and 50% population play. The bottom row corresponds to SVO bots with \\𝑖 ∈ {−15°, 0°, 60°, 75°} and the top row corresponds to selfishbaseline bots. Green and red represents cooperative and defective resource counts respectively. Error bars show the standard deviation of results over 3 random seeds.",
            "Figure 6: Externality mushrooms. Diversity of policies of selfish-baseline bots and SVO bots. Each plot shows average fraction of mushrooms consumed by 5 agents during evaluation, trained with 50% self-play and 50% population play in Externality mushrooms dense game. The bottom row corresponds to SVO agents with \\𝑖 ∈ {−15°, 0°, 60°, 75°, 90°} and the top row corresponds to selfish-baseline agents. Error bars show the standard deviation of results over 3 random seeds.",
            "Figure 7: Comparing how well best-response agents learn conditional policies in Stag hunt in the matrix.",
            "Figure 8: Comparing how well best-response agents learn conditional policies in Chicken in the matrix.",
            "Figure 9: Comparing how well best-response agents learn conditional policies in Prisoner’s dilemma in the matrix.",
            "Table 1: Zero-shot generalization performance of best response agents, selfish-baseline agent, random agent and exploiter. The score is calculated by first re scaling the rewards received by each agent such that in each scenario the agent with highest(lowest) reward gets score 1(0) and then averaging over all scenarios for each environment."
        ],
        "imgs": [
            "$2305.00768v1-Figure1-1.png",
            "$2305.00768v1-Figure2-1.png",
            "$2305.00768v1-Figure3-1.png",
            "$2305.00768v1-Figure5-1.png",
            "$2305.00768v1-Figure6-1.png",
            "$2305.00768v1-Figure7-1.png",
            "$2305.00768v1-Figure8-1.png",
            "$2305.00768v1-Figure9-1.png",
            "$2305.00768v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00770",
        "abstract": "  Turbulence is a non-local phenomenon and has multiple-scales. Non-locality\ncan be addressed either implicitly or explicitly. Implicitly, by subsequent\nresolution of all spatio-temporal scales. However, if directly solved for the\ntemporal or spatially averaged fields, a closure problem arises on account of\nmissing information between two points. To solve the closure problem in\nReynolds-averaged Navier-Stokes equations (RANS), an eddy-viscosity hypotheses\nhas been a popular modelling choice, where it follows either a linear or\nnon-linear stress-strain relationship. Here, a non-constant diffusivity is\nintroduced. Such a non-constant diffusivity is also characteristic of\nnon-Fickian diffusion equation addressing anomalous diffusion process. An\nalternative approach, is a fractional derivative based diffusion equations.\nThus, in the paper, we formulate a fractional stress-strain relationship using\nvariable-order Caputo fractional derivative. This provides new opportunities\nfor future modelling effort. We pedagogically study of our model construction,\nstarting from one-sided model and followed by two-sided model. Non-locality at\na point is the amalgamation of all the effects, thus we find the two-sided\nmodel is physically consistent. Further, our construction can also addresses\nviscous effects, which is a local process. Thus, our fractional model addresses\nthe amalgamation of local and non-local process. We also show its validity at\ninfinite Reynolds number limit. This study is further extended to tempered\nfractional calculus, where tempering ensures finite jump lengths, this is an\nimportant remark for unbounded flows. Two tempered definitions are introduced\nwith a smooth and sharp cutoff, by the exponential term and Heaviside function,\nrespectively and we also define the horizon of non-local interactions. We\nfurther study the equivalence between the two definitions.\n",
        "title": "Fractional and tempered fractional models for Reynolds-averaged\n  Navier-Stokes equations",
        "texts": [
            "Figure 1. A schematic representation for the inverse modeling, here the spatial location (y+) is the input of the feed forward neural network, while the fractional order (α) is the output, which is used to computed the loss function which comprises of f-RANS model using velocity from DNS databases",
            "Figure 10. Fractional order of truncated f-RANS model for Channel and Couette for a constant truncating parameter δ+. Recall that δ+ is a composite function for wall bounded flows, leading to a non-differentiable α curve.",
            "Figure 11. Equivalence between tempered and truncated f-RANS model for Channel and Couette. In this experiment δ+ is found such that the truncated f-RANS model has the same fractional order as tempered f-RANS model given λ. Within the legend (δ+l , λ) and (δ+r , λ), the δ+l and δ+r are for the left- and right-sided truncated fractional derivative, respectively for given λ of tempered f-RANS. We observe, that δ+ is a spatial varying function. Also, the left- and right-sided derivatives have different values of δ+.",
            "Figure 2. Fractional order of one-sided f-RANS model for channel, couette and pipe flow. Here the x-axis of the plot: channel and couette: y+/Reτ , pipe: (1− r)+/R+. It is observed as the Reynolds / Karman number increases the fractional order lowers corresponding to higher turbulence intensity. The channel and pipe show an artifact due to symmetry, where a fractional order if unity is not a physical solution at the center-line, merely a numerical solution of our constructed model",
            "Figure 3. Fractional order of one-sided f-RANS model for channel, couette and pipe flow. Here the x-axis of the plot: channel and couette: y+, pipe: (1 − r)+. Remarkably, the fractional order for couette flow shows universality. The channel and pipe shows an artifact due to symmetry, exposing the limitation of the one-sided model. For all three cases, the the fractional order is universal/overlaps in the viscous sub-layer and to some extent the buffer layer.",
            "Figure 4. Fractional order of two-sided f-RANS model for channel, couette and pipe flow. Here the x-axis of the plot: channel and couette: y+/Reτ , pipe: (1− r)+/R+. It is observed as the Reynolds / Karman number increases the fractional order lowers corresponding to higher turbulence intensity. The artifact due symmetry of one-sided model is no longer present in this case, as the non-locality is considered in a physical manner.",
            "Figure 5. Comparison of total shear stress obtained using one- and two-sided f-RANS model with DNS databases for couette, channel and pipe flow. Here the x-axis of the plot: channel and couette: y+/Reτ , pipe: (1− r)+/R+. The error in either model is less than 1%",
            "Figure 6. Fractional order of two-sided f-RANS model for channel, couette and pipe flow, plotted for one-half of the domain (y+/Reτ ≤ 1 or (1− r)+/R+ ≤ 1). Here the x-axis of the plot: channel and couette: y+, pipe: (1− r)+. A universal region and wake region is observed in all three cases. The universal region spans across the viscous sub-layer, buffer and logarithmic region of the mean velocity.",
            "Figure 7. Fractional order for two-sided model shown for the universal part of the curve obtained by subtracting the wake contribution. Fractional order plotted for one-half of the domain (y+/Reτ ≤ 1 or (1−r)+/R+ ≤ 1) Here the x-axis of the plot: channel and couette: y+, pipe: (1− r)+.",
            "Figure 8. Power law fitting for channel, couette and pipe shown in red-dashed line for minimum fractional order shown as black dots for two-sided model.",
            "Figure 9. Fractional order of tempered f-RANS model for Channel and Couette for the given tempering parameter λ.",
            "Table 1. Analogy between velocity and fractional order (of two-sided model) for different regions of the flow for all three cases. Here c, p and κ are arbitrary constants depending upon the individual case.",
            "Table 2. Comparing the fractional order obtained at center-line using the computational experiments with asymptotic analysis for all three flows."
        ],
        "imgs": [
            "$2305.00770v2-Figure1-1.png",
            "$2305.00770v2-Figure10-1.png",
            "$2305.00770v2-Figure11-1.png",
            "$2305.00770v2-Figure2-1.png",
            "$2305.00770v2-Figure3-1.png",
            "$2305.00770v2-Figure4-1.png",
            "$2305.00770v2-Figure5-1.png",
            "$2305.00770v2-Figure6-1.png",
            "$2305.00770v2-Figure7-1.png",
            "$2305.00770v2-Figure8-1.png",
            "$2305.00770v2-Figure9-1.png",
            "$2305.00770v2-Table1-1.png",
            "$2305.00770v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00772",
        "abstract": "  The solution to the elastodynamic equation in the exterior of a polyhedral\ndomain or a screen exhibits singular behavior from the corners and edges. The\ndetailed expansion of the singularities implies quasi-optimal estimates for\npiecewise polynomial approximations of the Dirichlet trace of the solution and\nthe traction. The results are applied to hp and graded versions of the time\ndomain boundary element method for the weakly singular and the hypersingular\nintegral equations. Numerical examples confirm the theoretical results for the\nDirichlet and Neumann problems for screens and for polygonal domains in 2d.\nThey exhibit the expected quasi-optimal convergence rates and the singular\nbehavior of the solutions.\n",
        "title": "Higher-order time domain boundary elements for elastodynamics -- graded\n  meshes and hp versions",
        "texts": [
            "Figure 1: β̃-graded meshes for the square and the circular screen with β̃ = 2 (a) and β̃-graded meshes for 1D obstacles with β̃ = 3 (b).",
            "Figure 10: Expected exponent with dependence on ωint and its complementary (k = 5/3) and tested polygonal meshes (a and b); plot of the vertical component of Φ on the base of Γ1 (c).",
            "Figure 11: Asymptotic behavior towards the vertices",
            "Figure 12: Squared error of the energy norm with h version on Γ1, β̃-graded mesh",
            "Figure 13: Asymptotic behavior towards the vertices in Γ2 for different boundary conditions (a) and plot of the vertical component of Φ on the base of Γ2 for the indicated boundary condition (b).",
            "Figure 14: Squared error of the energy norm with h version on Γ1, β̃-graded mesh, g̃2(x, t) = H[t]f(t)x4",
            "Figure 15: Time history of Ψ1 and Ψ2 calculated at the middle point of Γ for the couples of velocities cS = 1, cP = 2 and cS = 1, cP = 3 (a). Vertical component Ψ2 calculated at the final time instant T = 7.5 and the related elastostatic solution Ψ2,∞(x, t) = k2 √ 1/4− x2 (k2 = −4/3 for cP = 2 and k1 = −9/8 for cP = 3) (b).",
            "Figure 17: Squared error of the energy norm calculated up to time instant T = 2",
            "Figure 2: Geometry and graded mesh on the wedge.",
            "Figure 3: Geometry and graded mesh on a circular cone: viewed from the side (a) and from above (b).",
            "Figure 4: Affine map between meshes on (a) square and (b) cone. The parallelograms in (b) correspond to rectangles in (a), and two adjacent triangles in (b) are mapped to the diagonal squares Rii in (a).",
            "Figure 6: Squared error of the energy norm for various discretization methods.",
            "Figure 7: Asymptotic behaviour towards the left end of Γ",
            "Figure 8: Behaviour of the horizontal component Φ1 on Γ and w.r.t the distance towards the right endpoint at T = 1. Both plots are obtained imposing on Γ an algebraically 3-graded mesh of 80 segments.",
            "Figure 9: Squared error of the energy norm for various discretization methods",
            "Table 2: Energy norm squared of the approximate solution for T = 1 (h version with algebraically graded mesh)"
        ],
        "imgs": [
            "$2305.00772v1-Figure1-1.png",
            "$2305.00772v1-Figure10-1.png",
            "$2305.00772v1-Figure11-1.png",
            "$2305.00772v1-Figure12-1.png",
            "$2305.00772v1-Figure13-1.png",
            "$2305.00772v1-Figure14-1.png",
            "$2305.00772v1-Figure15-1.png",
            "$2305.00772v1-Figure17-1.png",
            "$2305.00772v1-Figure2-1.png",
            "$2305.00772v1-Figure3-1.png",
            "$2305.00772v1-Figure4-1.png",
            "$2305.00772v1-Figure6-1.png",
            "$2305.00772v1-Figure7-1.png",
            "$2305.00772v1-Figure8-1.png",
            "$2305.00772v1-Figure9-1.png",
            "$2305.00772v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00774",
        "abstract": "  This paper investigates using satellite data to improve adaptive sampling\nmissions, particularly for front tracking scenarios such as with algal blooms.\nOur proposed solution to find and track algal bloom fronts uses an Autonomous\nUnderwater Vehicle (AUV) equipped with a sensor that measures the concentration\nof chlorophyll a and satellite data. The proposed method learns the kernel\nparameters for a Gaussian process model using satellite images of chlorophyll a\nfrom the previous days. Then, using the data collected by the AUV, it models\nchlorophyll a concentration online. We take the gradient of this model to\nobtain the direction of the algal bloom front and feed it to our control\nalgorithm. The performance of this method is evaluated through realistic\nsimulations for an algal bloom front in the Baltic sea, using the models of the\nAUV and the chlorophyll a sensor. We compare the performance of different\nestimation methods, from GP to curve interpolation using least squares.\nSensitivity analysis is performed to evaluate the impact of sensor noise on the\nmethods performance. We implement our method on an AUV and run experiments in\nthe Stockholm archipelago in the summer of 2022.\n",
        "title": "Adaptive Sampling of Algal Blooms Using Autonomous Underwater Vehicle\n  and Satellite Imagery: Experimental Validation in the Baltic Sea",
        "texts": [
            "Fig. 1: System overview with the SAM AUV, the GPS, the Sentinel satellite, and the CMEMS data.",
            "Fig. 12: The feedback control architecture on SAM with cascaded heading and depth PIDs for flight control (top), trim stabilization with pitch and buoyancy control (middle), and coupled velocity and roll control with the counter-rotating propellers (bottom).",
            "Fig. 15: Overview of the full mission having the trajectory of the AUV (red) tracking the front (black) in the chlorophyll a field (blue-yellow). The white star indicates the initial position, and the white square the final position.",
            "Fig. 16: Trajectory of the AUV (red) tracking the front (black line), with arrows representing the true and estimated gradient.",
            "Fig. 21: Influence of sensor noise in the tracking error, for two different estimation algorithms: GP and LSQ.",
            "Fig. 22: Influence of sensor noise in the gradient estimation error, for two different estimation algorithms: GP and LSQ.",
            "Fig. 24: Two experimental surveys and a simulated scenario under experimental conditions with AUV trajectory (red) tracking the front (black line) in the chlorophyll a map (blue-yellow).",
            "Fig. 25: Trajectory of the AUV (red) tracking the front (black line), with arrows representing the true and estimated gradient.",
            "Fig. 26: Trajectory of the AUV (red) tracking the front (black line), with arrows representing the true and estimated gradient.",
            "Fig. 27: Concentration of chlorophyll a: measurements from the AUV, and reference value.",
            "Fig. 28: Gradient of chlorophyll a: AUV estimated gradient, and true gradient.",
            "Fig. 8: The SAM AUV developed by SMaRC.",
            "TABLE I: Kernel hyperparameters obtained through maximum likelihood estimation, using the low-resolution and high-resolution datasets.",
            "TABLE II: Control algorithm parameters."
        ],
        "imgs": [
            "$2305.00774v1-Figure1-1.png",
            "$2305.00774v1-Figure12-1.png",
            "$2305.00774v1-Figure15-1.png",
            "$2305.00774v1-Figure16-1.png",
            "$2305.00774v1-Figure21-1.png",
            "$2305.00774v1-Figure22-1.png",
            "$2305.00774v1-Figure24-1.png",
            "$2305.00774v1-Figure25-1.png",
            "$2305.00774v1-Figure26-1.png",
            "$2305.00774v1-Figure27-1.png",
            "$2305.00774v1-Figure28-1.png",
            "$2305.00774v1-Figure8-1.png",
            "$2305.00774v1-TableI-1.png",
            "$2305.00774v1-TableII-1.png"
        ]
    },
    {
        "id": "2305.00777",
        "abstract": "  We study the canonical signaling game, endowing the sender with commitment\npower: before learning the state, sender designs a strategy, which maps the\nstate into a probability distribution over actions. We provide a geometric\ncharacterization of the sender's attainable payoffs, described by the\ntopological join of the graphs of the interim payoff functions associated with\ndifferent sender actions. We then incorporate payoff irrelevant messages into\nthe game, characterizing the attainable payoffs when sender commits to (i) both\nmessages and actions, and (ii) only messages. By studying the tradeoffs between\nthese model variations, we highlight the power of commitment to actions. We\napply our results to the design of adjudication procedures and rating systems.\n",
        "title": "Signaling With Commitment",
        "texts": [
            "Figure 1: Motivating Example. Note that for µ ≥ θa, purple and blue coincide.",
            "Figure 2: Motivating Example (Continued).",
            "Figure 3: Motivating Example (Continued). Note that for µ ≥ θa, purple and blue coincide.",
            "Figure 4: Risk-averse sender/inefficient signaling",
            "Figure 5: Risk-averse sender/efficient signaling",
            "Figure 6: Risk-loving sender/inefficient signaling"
        ],
        "imgs": [
            "$2305.00777v1-Figure1-1.png",
            "$2305.00777v1-Figure2-1.png",
            "$2305.00777v1-Figure3-1.png",
            "$2305.00777v1-Figure4-1.png",
            "$2305.00777v1-Figure5-1.png",
            "$2305.00777v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00781",
        "abstract": "  It has been known that the catalytic effect makes the life-time of a\nmetastable state shorter. We discuss this phenomenon in a decay process of a\nmetastable vacuum in the brane-limit of type IIB string theory. Due to the\nnon-linear effect of DBI action, the bubble created by the decay makes an\nenergetically favorable bound state with an impurity that plays the role of\ncatalyst, which is quite specific to this model and different from other\ncatalysts such as a back hole. Furthermore, we found that this low-energy\neffective theory around almost unstable regions reduces to a simple quantum\nmechanical system, and the vacuum life-time can be calculated using known\nresults, even beyond the WKB approximation. Finally, we compare the life-time\nof the vacuum with the Trans-Planckian Censorship Conjecture (TCC) and find\nthat as long as the string scale is at least one order magnitude smaller than\nthe Planck scale, there is a nonzero window to satisfy the TCC condition.\n",
        "title": "Life-time of Metastable Vacuum in String Theory and Trans-Planckian\n  Censorship Conjecture",
        "texts": [
            "Figure 1: The schematic diagram for annihilation of D5-branes and anti-D5-branes.",
            "Figure 12: The result of the WKB approximation and the VPE for AB = 1.5. The former is estimated to have a slightly shorter lifetime near the critical value, which is consistent with an argument beyond the dilute gas approximation. Although neither calculation is reliable in the orange region, based on physical assumptions, we expect a monotonically decreasing function connecting the two.",
            "Figure 14: The Contours γ, Cu and Cl on the complex λ-plane.The dashed lines represent the branch cut of λ−s. The brobs on the real axis correspond to the eigenvalues of the differential operator TA,B.",
            "Figure 3: Bounce solutions for b̃D3 = 0.1(blue), 0.5(green) and 1(black).",
            "Figure 6: The magnetic field dependence of the normalization constant.",
            "Figure 7: Magnetic field dependence of g(b̃D3). We connected the points calculated for the arbitrary magnetic field strength smoothly.",
            "Figure 8: The life-times for AB = 1.5(left), 1.1(right). τ̃ represents the dimensionless τ divided by TDW/∆V . In the small b̃D3 region, we should note that the WKB approximation goes wrong, and its life-time shows strange behavior against naive expectations. Considering this, we should exclude the region b̃D3 ≤ 0.3 from our discussion."
        ],
        "imgs": [
            "$2305.00781v1-Figure1-1.png",
            "$2305.00781v1-Figure12-1.png",
            "$2305.00781v1-Figure14-1.png",
            "$2305.00781v1-Figure3-1.png",
            "$2305.00781v1-Figure6-1.png",
            "$2305.00781v1-Figure7-1.png",
            "$2305.00781v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00782",
        "abstract": "  We investigate statistics and scaling laws of avalanches in two-dimensional\nfrictional particles by numerical simulations. We find that the critical\nexponent for avalanche size distributions is governed by microscopic friction\nbetween the particles in contact, where the exponent is larger and closer to\nmean-field predictions if the friction coefficient is finite. We reveal that\nmicroscopic ``slips\" between frictional particles induce numerous small\navalanches which increase the slope, as well as the power-law exponent, of\navalanche size distributions. We also analyze statistics and scaling laws of\nthe avalanche duration and maximum stress drop rates, and examine power spectra\nof stress drop rates. Our numerical results suggest that the microscopic\nfriction is a key ingredient of mean-field descriptions and plays a crucial\nrole in avalanches observed in real materials.\n",
        "title": "The role of microscopic friction in statistics and scaling laws of\n  avalanches",
        "texts": [
            "FIG. 2. Double logarithmic plots of (a) avalanche size distributions P (S), (b) distributions of the avalanche duration P (T ), and (c) power spectra of stress drop rates F (ω), where we use N = 8192 and increase the friction coefficient µ as indicated by the arrows and listed in the legends. The dashed (solid) line in (a) indicates the power-law decay P (S) ∼ S−τ (Eq. (7)) with the exponent τ ≃ 0.98 (1.33). The solid line in (b) represents P (T ) ∼ T−κ (Eq. (8)) with κ = 1.30. Both the dashed and solid lines in (c) have the slope −2 (Eq. (9)). Note that the data for µ > 0 are arbitrarily shifted downward from the original positions to prevent overlap.",
            "FIG. 3. (a) and (b): Scatter plots of (a) the avalanche duration T and (b) maximum stress drop rate M as functions of the avalanche size S. The data (each dot) are taken from 106 stress drop events in a steady state, where we use N = 8192 and µ = 0.2. The symbols (circles) are the averages of (a) T and (b) M in each bin of S. The solid lines in (a) and (b) represent the scaling laws, Eqs. (10) and (11), respectively. The lower bound of avalanche duration is the strain increment, i.e. T ≥ δγ = 10−7, and the maximum stress drop rates for small avalanches are bounded by the linear relation, M ∝ S (dashed line in (b)). (c) and (d): Double logarithmic plots of (c) T/S1/2 and (d) M/S1/2 as functions of S, where we use N = 8192 and increase the friction coefficient µ as indicated by the arrows and listed in the legends. Note that the data for µ > 0 are arbitrarily shifted downward from the original positions to prevent overlap.",
            "FIG. 4. (a) The mean avalanche size 〈S〉 (squares) and cutoff size Sc (circles), and (b) the mean avalanche interval 〈∆γ〉 (squares) as functions of the number of frictionless particles N . The lines indicate the power laws, 〈S〉 ∼ Nα, Sc ∼ Ndf /d, and 〈∆γ〉 ∼ N−χ, where we estimate the exponents as α ≃ 0.31, χ ≃ 0.62, and df/d ≃ 0.29 (i.e. df ≃ 0.58).",
            "FIG. 7. Double logarithmic plots of (a) the mean avalanche size 〈S〉, (b) mean avalanche interval 〈∆γ〉, (c) mean avalanche duration 〈T 〉, and (d) mean maximum stress drop rate 〈M〉 as functions of the friction coefficient µ. The symbols represent the system size N as listed in the legend of (a). The horizontal dashed lines indicate the values in the frictionless system, µ = 0, while the shaded regions indicate the frictionless limit, µ < µc ∼ 10−5."
        ],
        "imgs": [
            "$2305.00782v1-Figure2-1.png",
            "$2305.00782v1-Figure3-1.png",
            "$2305.00782v1-Figure4-1.png",
            "$2305.00782v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00783",
        "abstract": "  Traditional recommender systems estimate user preference on items purely\nbased on historical interaction records, thus failing to capture fine-grained\nyet dynamic user interests and letting users receive recommendation only\npassively. Recent conversational recommender systems (CRSs) tackle those\nlimitations by enabling recommender systems to interact with the user to obtain\nher/his current preference through a sequence of clarifying questions. Despite\nthe progress achieved in CRSs, existing solutions are far from satisfaction in\nthe following two aspects: 1) current CRSs usually require each user to answer\na quantity of clarifying questions before reaching the final recommendation,\nwhich harms the user experience; 2) there is a semantic gap between the learned\nrepresentations of explicitly mentioned attributes and items. To address these\ndrawbacks, we introduce the knowledge graph (KG) as the auxiliary information\nfor comprehending and reasoning a user's preference, and propose a new CRS\nframework, namely Knowledge Enhanced Conversational Reasoning (KECR) system. As\na user can reflect her/his preference via both attribute- and item-level\nexpressions, KECR closes the semantic gap between two levels by embedding the\nstructured knowledge in the KG. Meanwhile, KECR utilizes the connectivity\nwithin the KG to conduct explicit reasoning of the user demand, making the\nmodel less dependent on the user's feedback to clarifying questions. KECR can\nfind a prominent reasoning chain to make the recommendation explainable and\nmore rationale, as well as smoothen the conversation process, leading to better\nuser experience and conversational recommendation accuracy. Extensive\nexperiments on two real-world datasets demonstrate our approach's superiority\nover state-of-the-art baselines in both automatic evaluations and human\njudgments.\n",
        "title": "Explicit Knowledge Graph Reasoning for Conversational Recommendation",
        "texts": [
            "Fig. 1. An illustration of connection information inside the KG in the movie domain. The solid lines between entities represent their relations, while the underlined entitymarked in red represents what the usermentioned during the conversation.",
            "Fig. 2. The overall workflow of KECR. KECR is composed by three key components: Static Context Information Modelling, Dynamic Reasoning Flow Modelling and Conditional Response Generation.",
            "Fig. 3. A sample conversation between our KECR (wizard) and a real user (seeker). The words in red font denotes the dialogue action and the selected entities during the reasoning.",
            "Table 1. An example of a conversation for movie recommendation. Mentioned items and attributes are marked in blue and red, respectively.",
            "Table 2. Statistics of REDIAL and GoRecDial.",
            "Table 3. Recommendation performance comparison of all methods on two datasets, where the best performance is boldfaced. Improvements over all baselines are statistically significant with 𝑝 < 0.01.",
            "Table 4. Response generation performance comparison of all methods on two datasets by Distinct-n, where the best performance is boldfaced. We additionally underline the second-best performance on Distinct-n.",
            "Table 5. Performance comparison of all ablation methods on two datasets by Recall@10, BLEU and Distinct-3, where the best performance is boldfaced.",
            "Table 6. Human evaluation of all methods on sampled conversation on fluency, coherence, informativenss and syntax, where the best performance is boldfaced."
        ],
        "imgs": [
            "$2305.00783v1-Figure1-1.png",
            "$2305.00783v1-Figure2-1.png",
            "$2305.00783v1-Figure3-1.png",
            "$2305.00783v1-Table1-1.png",
            "$2305.00783v1-Table2-1.png",
            "$2305.00783v1-Table3-1.png",
            "$2305.00783v1-Table4-1.png",
            "$2305.00783v1-Table5-1.png",
            "$2305.00783v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00787",
        "abstract": "  Generating talking person portraits with arbitrary speech audio is a crucial\nproblem in the field of digital human and metaverse. A modern talking face\ngeneration method is expected to achieve the goals of generalized audio-lip\nsynchronization, good video quality, and high system efficiency. Recently,\nneural radiance field (NeRF) has become a popular rendering technique in this\nfield since it could achieve high-fidelity and 3D-consistent talking face\ngeneration with a few-minute-long training video. However, there still exist\nseveral challenges for NeRF-based methods: 1) as for the lip synchronization,\nit is hard to generate a long facial motion sequence of high temporal\nconsistency and audio-lip accuracy; 2) as for the video quality, due to the\nlimited data used to train the renderer, it is vulnerable to out-of-domain\ninput condition and produce bad rendering results occasionally; 3) as for the\nsystem efficiency, the slow training and inference speed of the vanilla NeRF\nseverely obstruct its usage in real-world applications. In this paper, we\npropose GeneFace++ to handle these challenges by 1) utilizing the pitch contour\nas an auxiliary feature and introducing a temporal loss in the facial motion\nprediction process; 2) proposing a landmark locally linear embedding method to\nregulate the outliers in the predicted motion sequence to avoid robustness\nissues; 3) designing a computationally efficient NeRF-based motion-to-video\nrenderer to achieves fast training and real-time inference. With these\nsettings, GeneFace++ becomes the first NeRF-based method that achieves stable\nand real-time talking face generation with generalized audio-lip\nsynchronization. Extensive experiments show that our method outperforms\nstate-of-the-art baselines in terms of subjective and objective evaluation.\nVideo samples are available at https://genefaceplusplus.github.io .\n",
        "title": "GeneFace++: Generalized and Stable Real-Time Audio-Driven 3D Talking\n  Face Generation",
        "texts": [
            "Figure 1: The inference process of GeneFace++. In subfigure (a), we show the overall threestage pipeline. In subfigure (b), \"DA Postnet\" denotes the Domain Adaptative Postnet proposed in GeneFace. In subfigure (c), \"KNN\" denotes finding the K-nearest neighbors of the input landmark, and \"Landmark LLE Proj.\" denotes Landmark Locally Linear Embedding Projection method proposed in Section 4.2. In subfigure (d), as for the indexing operation, we perform bi-linear interpolation to query the continuous coordinates in the discrete (spatial/hyper) grids.",
            "Figure 2: The training process of the Pitch-Aware Audio-to-Motion module. Learnable models are marked with red dotted rectangles and parameter-frozen models are colored in gray. In subfigure (a), Enc. and Dec. denote Encoder and Decoder in VAE, respectively. Disc. means Discriminator. In subfigure (b), the thunder-like symbol represents the \"stop gradient\" operator. In subfigure(c), \"LogDiscretize\" denotes the operation that quantizes the log-scale continuous pitch value into discrete tokens.",
            "Figure 3: The comparison of generated key frame results. We show the speaking word and time step in the demo video. We mark the un-sync and bad rendering quality results with the red and brown arrows, respectively. Please zoom in for better visualization.",
            "Figure 6: The comparison of generated key frame results. We show the speaking word and time step in the demo video. Please zoom in for better visualization.",
            "Table 1: Quantitative evaluation with different methods. Best results are in bold.",
            "Table 2: User study with different methods. The error bars are 95% confidence interval.",
            "Table 3: Ablation study results on pitch-aware audio-to-motion module. Temporal error is the L2 error on the velocity of the landmark sequence.",
            "Table 4: Ablation study results on landmark LLE method. α is the hyper-parameter defined in Equation 10. BadCase% denotes the percentage of bad cases in the generated frames.",
            "Table 5: Ablation study results on number of hyper coordinate dimensions of landmark."
        ],
        "imgs": [
            "$2305.00787v1-Figure1-1.png",
            "$2305.00787v1-Figure2-1.png",
            "$2305.00787v1-Figure3-1.png",
            "$2305.00787v1-Figure6-1.png",
            "$2305.00787v1-Table1-1.png",
            "$2305.00787v1-Table2-1.png",
            "$2305.00787v1-Table3-1.png",
            "$2305.00787v1-Table4-1.png",
            "$2305.00787v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00788",
        "abstract": "  Spiking neurons and neural networks constitute a fundamental building block\nfor brain-inspired computing, which is posed to benefit significantly from\nphotonic hardware implementations. In this work, we experimentally investigate\nan interconnected system based on an ultrafast spiking VCSEL-neuron and a\nsilicon photonics (SiPh) integrated micro-ring resonator (MRR) weight bank, and\ndemonstrate two different functional arrangements of these devices. First, we\nshow that MRR weightbanks can be used in conjuction with the spiking\nVCSEL-neurons to perform amplitude weighting of sub-ns optical spiking signals.\nSecond, we show that a continuous firing VCSEL-neuron can be directly modulated\nusing a locking signal propagated through a single weighting micro-ring, and we\nutilize this functionality to perform optical spike firing rate-coding via\nthermal tuning of the micro-ring resonator. Given the significant track record\nof both integrated weight banks and photonic VCSEL-neurons, we believe these\nresults demonstrate the viability of combining these two classes of devices for\nuse in functional neuromorphic photonic systems.\n",
        "title": "Interfacing spiking VCSEL-neurons with silicon photonics weight banks\n  towards integrated neuromorphic photonic systems",
        "texts": [
            "Figure 1: Experimental setups for a) spike weighting in the micro-ring, and b) direct VCSEL-modulation via signal coming through a micro-ring. TL - tuneable laser; ISO - isolator; VOA - variable optical attenuator; PC(1,2,3) - polarization controllers; MZM - Mach-Zehnder modulators; PM - power meter; CIRC - circulator; VCSEL - vertical cavity surface emitting laser; EDFA - erbium-doped fiber amplifier; BPF - bandpass filter; RT OSC - real-time oscilloscope; OSA - optical spectrum analyzer; GC - grating coupler; PD - photodetector. Ratios indicdated are for the power couplers/splitters.",
            "Figure 2: micro-ring characterization: THRU port readout (top) and DROP port readout (bottom), with power at fixed wavelength (dashed line) and maxima (minima) position as function of VMR.",
            "Figure 3: Sequences of deterministically triggered excitable spikes in the VCSEL-neuron after passing through the weighting micro-ring for three different values of VMR. Traces were recorded on both outputs of the micro-ring: the THRU port (left column, in red) and the DROP port (right column, in green).",
            "Figure 4: Demonstration of spike amplitude weighting at both THRU (top row) and DROP (bottom row) ports of the micro-ring resonator output. In each case, the spike trace shown corresponds to a mean spike envelope calculated from all the recorded repetitions for a given value of VMR.",
            "Figure 5: Mean amplitudes of all spikes (ns = 7 per measurement, nm = 15 repetitions) as a function of micro-ring heater bias VMR with Lorenzian fit (solid line) using the least squares method. The two plots show (a) THRU; (b) DROP port readouts.",
            "Figure 6: Demonstration of rate coding in spiking VCSEL-neuron injection locked to a signal coming from the MRR. (a) Injection signal power as a function of VMR. (b) Spike firing rate in the VCSEL-neuron as a function of VMR. (c) Mean spike amplitudes within the spike train. (d-f) Examples of continuous spiking traces produced by the VCSEL-neuron locked to the signal from the MRR. As the voltage applied to the micro-ring is gradually increased from (a) 1.5 V through (b) 1.95 V to (c) 2.25 V, the spike firing rate monotonically increases."
        ],
        "imgs": [
            "$2305.00788v1-Figure1-1.png",
            "$2305.00788v1-Figure2-1.png",
            "$2305.00788v1-Figure3-1.png",
            "$2305.00788v1-Figure4-1.png",
            "$2305.00788v1-Figure5-1.png",
            "$2305.00788v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00790",
        "abstract": "  Over the last decade, Web traffic has significantly shifted towards HTTPS due\nto an increased awareness for privacy. However, DNS traffic is still largely\nunencrypted, which allows user profiles to be derived from plaintext DNS\nqueries. While DNS over TLS (DoT) and DNS over HTTPS (DoH) address this problem\nby leveraging transport encryption for DNS, both protocols are constrained by\nthe underlying transport (TCP) and encryption (TLS) protocols, requiring\nmultiple round-trips to establish a secure connection. In contrast, QUIC\ncombines the transport and cryptographic handshake into a single round-trip,\nwhich allows the recently standardized DNS over QUIC (DoQ) to provide DNS\nprivacy with minimal latency. In the first study of its kind, we perform\ndistributed DoQ measurements across multiple vantage points to evaluate the\nimpact of DoQ on Web performance. We find that DoQ excels over DoH, leading to\nsignificant improvements with up to 10% faster loads for simple webpages. With\nincreasing complexity of webpages, DoQ even catches up to DNS over UDP (DoUDP)\nas the cost of encryption amortizes: With DoQ being only ~2% slower than DoUDP,\nencrypted DNS becomes much more appealing for the Web.\n",
        "title": "DNS Privacy with Speed? Evaluating DNS over QUIC and its Impact on Web\n  Performance",
        "texts": [
            "Figure 1: Geographical distribution of the 313 verified DoX resolvers (red dots) and vantage points (blue dots).",
            "Figure 2: Median Handshake time (a, left) and Resolve time (b, right) inms per protocol over all vantage points (top row) andper vantage point (bottomrows). Ordered by thenumber of verified DoX resolvers per continent.",
            "Figure 3: CDFs of the relative differences in FCP and PLT between DNS protocols with DoUDP as baseline.",
            "Figure 4: CDFs of the relative differences in PLT betweenDoQ (horizontal baseline), DoUDP (purple line), and DoH (green line), grouped by vantage point and webpage. A lighter background color depicts a higher percentage of DoQ page loads being faster than DoH. Sorted from left to right by the average number of DNS queries required for loading each webpage (in brackets) and from top to bottom by the number of verified DoX resolvers per continent.",
            "Table 1: Median single query sizes in bytes, as well as sample sizes of single query response time and Web performance measurements."
        ],
        "imgs": [
            "$2305.00790v2-Figure1-1.png",
            "$2305.00790v2-Figure2-1.png",
            "$2305.00790v2-Figure3-1.png",
            "$2305.00790v2-Figure4-1.png",
            "$2305.00790v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00795",
        "abstract": "  Document layout analysis is a known problem to the documents research\ncommunity and has been vastly explored yielding a multitude of solutions\nranging from text mining, and recognition to graph-based representation, visual\nfeature extraction, etc. However, most of the existing works have ignored the\ncrucial fact regarding the scarcity of labeled data. With growing internet\nconnectivity to personal life, an enormous amount of documents had been\navailable in the public domain and thus making data annotation a tedious task.\nWe address this challenge using self-supervision and unlike, the few existing\nself-supervised document segmentation approaches which use text mining and\ntextual labels, we use a complete vision-based approach in pre-training without\nany ground-truth label or its derivative. Instead, we generate pseudo-layouts\nfrom the document images to pre-train an image encoder to learn the document\nobject representation and localization in a self-supervised framework before\nfine-tuning it with an object detection model. We show that our pipeline sets a\nnew benchmark in this context and performs at par with the existing methods and\nthe supervised counterparts, if not outperforms. The code is made publicly\navailable at: https://github.com/MaitySubhajit/SelfDocSeg\n",
        "title": "SelfDocSeg: A Self-Supervised vision-based Approach towards Document\n  Segmentation",
        "texts": [
            "Fig. 1: Scope and Motivation. A basic methodological distinction between SelfDocSeg and existing approaches. While earlier works utilize information from visual, layout, and textual modalities for large-scale pre-training, we deal with visual cues only for boosting representation learning.",
            "Fig. 2: Layout Mask Generation Pipeline. The figure illustrates a stepwise approach with different strategies adapted for generating the final layout mask for a given document image.",
            "Fig. 3: Model Overview. A simple architectural design of SelfDocSeg pretraining modeled after the BYOL [28] framework along with a layout prediction module.",
            "Fig. 4: Qualitative analysis of the SelfDocSeg framework on the DocLayNet datasets (Left: Predicted layout Right: Ground-truth)",
            "Table 1: Quantitative analysis of the performance of the document object detection task along with the guidances used during supervision. V, L, and T stand for visual, layout, and textual cues respectively.",
            "Table 2: Semi-supervised scenario. We evaluate the performance of Mask RCNN fine-tuning with varying % of labeled data used in DocLayNet.",
            "Table 3: Ablation Study. Contribution of individual learning objectives during SelfDocSeg pre-training on DocLayNet."
        ],
        "imgs": [
            "$2305.00795v2-Figure1-1.png",
            "$2305.00795v2-Figure2-1.png",
            "$2305.00795v2-Figure3-1.png",
            "$2305.00795v2-Figure4-1.png",
            "$2305.00795v2-Table1-1.png",
            "$2305.00795v2-Table2-1.png",
            "$2305.00795v2-Table3-1.png"
        ]
    },
    {
        "id": "2305.00798",
        "abstract": "  Machine learning models have achieved remarkable success in various\nreal-world applications such as data science, computer vision, and natural\nlanguage processing. However, model training in machine learning requires\nlarge-scale data sets and multiple iterations before it can work properly.\nParallelization of training algorithms is a common strategy to speed up the\nprocess of training. However, many studies on model training and inference\nfocus only on aspects of performance. Power consumption is also an important\nmetric for any type of computation, especially high-performance applications.\nMachine learning algorithms that can be used on low-power platforms such as\nsensors and mobile devices have been researched, but less power optimization is\ndone for algorithms designed for high-performance computing.\n  In this paper, we present a C++ implementation of logistic regression and the\ngenetic algorithm, and a Python implementation of neural networks with\nstochastic gradient descent (SGD) algorithm on classification tasks. We will\nshow the impact that the complexity of the model and the size of the training\ndata have on the parallel efficiency of the algorithm in terms of both power\nand performance. We also tested these implementations using shard-memory\nparallelism, distributed memory parallelism, and GPU acceleration to speed up\nmachine learning model training.\n",
        "title": "Performance and Energy Consumption of Parallel Machine Learning\n  Algorithms",
        "texts": [
            "Fig. 1. A visualization of an ANN (a) and a CNN (b) from [7]. ReLu is shorthand for rectified linear unit. 2) Convolutional Neural Networks: While ANNs are very useful, their computational complexity increases exponentially with larger inputs such as images. As ANN models grow in size, they also risk overfitting to the training data. Convolutional neural networks (CNNs) were proposed as the solution to these problems [8]. CNNs are designed to process images effectively because convolutional kernels could summarize the adjacent information and different layers could be regarded as multi-scale feature extractors.",
            "Fig. 2. Figures from [22] show (a) how selected solutions are combined for future generations; (b) mutations in children solutions. ’Chromosomes’ refer to individual model parameters.",
            "Fig. 3. High level architecture of the pca genetic algorithm. Specific model classes used in the experiments are included in the diagram",
            "Fig. 5. Ratio of energy costs of MPI and OpenMP vs. serial baseline, with asynchronous and synchronous training on gisette datasets",
            "Fig. 6. Fitness values for 3 different models over 1000 generations. The 2 layer ANN reaches about 0.75 accuracy, while the other models reach about 0.6.",
            "Fig. 7. Parallel efficiencies for the 3 different models. Each simulation was run for 100 generations with 10,000 images, and the recorded time per generation is the average of all generations.",
            "Fig. 8. Parallel efficiencies for the 3 different models. As the number of images increase, the parallel efficiency also rises.",
            "TABLE III FINAL LOSS RESULTS AFTER 250 EPOCHS FOR SYNCHRONOUS TRAINING",
            "TABLE IV FINAL LOSS RESULTS AFTER 250 EPOCHS FOR ASYNCHRONOUS TRAINING"
        ],
        "imgs": [
            "$2305.00798v1-Figure1-1.png",
            "$2305.00798v1-Figure2-1.png",
            "$2305.00798v1-Figure3-1.png",
            "$2305.00798v1-Figure5-1.png",
            "$2305.00798v1-Figure6-1.png",
            "$2305.00798v1-Figure7-1.png",
            "$2305.00798v1-Figure8-1.png",
            "$2305.00798v1-TableIII-1.png",
            "$2305.00798v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00803",
        "abstract": "  Current measurements of planet population as a function of stellar mass show\nthree seemingly contradictory signatures: close-in super-Earths are more\nprevalent around M dwarfs than FGK dwarfs; inner super-Earths are correlated\nwith outer giants; and outer giants are less common around M dwarfs than FGK\ndwarfs. Here, we build a simple framework that combines the theory of pebble\naccretion with the measurements of dust masses in protoplanetary disks to\nreconcile all three observations. First, we show that cooler stars are more\nefficient at converting pebbles into planetary cores at short orbital periods.\nSecond, when disks are massive enough to nucleate a heavy core at 5 AU, more\nthan enough dust can drift in to assemble inner planets, establishing the\ncorrelation between inner planets and outer giants. Finally, while stars of\nvarying masses are similarly capable of converting pebbles into cores at long\norbital periods, hotter stars are much more likely to harbor more massive dust\ndisks so that the giant planet occurrence rate rises around hotter stars. Our\nresults are valid over a wide range of parameter space for a disk accretion\nrate that follows $\\dot{M}_\\star \\sim 10^{-8}\\,M_\\odot\\,{\\rm\nyr}^{-1}(M_\\star/M_\\odot)^2$. We predict a decline in mini-Neptune population\n(but not necessarily terrestrial planets) around stars lighter than $\\sim\n0.3-0.5 M_\\odot$. Cold giants ($\\gtrsim$5 AU), if they exist, should remain\ncorrelated with inner planets even around lower mass stars.\n",
        "title": "Small Planets Around Cool Dwarfs: Enhanced Formation Efficiency of\n  Super-Earths around M dwarfs",
        "texts": [
            "Figure 1. Stokes parameters St that delineate different accretion regimes for a 0.5M⊙ host star and Ṁ1⊙ = 10−8 M⊙ yr−1. Different columns show αt = 10−4, 10−3, and 10−2 from left to right while different rows show protoplanet masses Mp = 0.01,0.10, and 1.00M⊕ from top to bottom. The colored curves draw Stf and they are each labelled with corresponding fragmentation velocity vf . The minimum St required for a transition from headwind to shear-dominated accretion is drawn in black dashed line while the 3D and 2D accretion regimes are represented by different shades of grey. The transition to 2D regime is calculated assuming the accretion is already shear-dominated. This assumption fails only for our lowest protocore mass Mp = 0.01M⊕ and lowest αt = 10−4 at wide separations (P ≳ 104 days). In black dot-dashed lines, we delineate the minimum St for the radial motion of the particles to be dominated by the aerodynamic drag and drift rather than coupling to the viscous gas motion, set by St > 3αt/2|γ|. The broken power-law feature in all St-period relations reflect the switch from accretion-dominated (inner orbit) to irradiation-dominated (outer orbit) disk heating.",
            "Figure 2. Mass-weighted formation efficiency ϵ̄ vs. orbital period evaluated for M⋆ = 0.5M⊙, Mp = 1.0M⊕, αt = 10−3, and Ṁ1⊙ = 10−8 M⊙ yr−1. Different colors correspond to varying fragmentation velocity vf . The massweighted formation efficiency follows the overall behavior of ϵ evaluated at Stf (lighter color) with an order unity reduction, i.e. dϵ̄/dP ∼ dϵ(St = Stf)/dP . Deviations from this approximation occur for i) vf = 10m/s at ∼20–200 days because accretion transitions from 3D to 2D regime over a spectrum of St at different orbital periods and for ii) vf = 1m/s at ∼300 days because Stf crosses 2αt/π there such that the grain size distribution is set by only the turbulent regime within ∼300 days and by both turbulent and settling regimes beyond it. The kink at ∼200 days arises from a change in γ from viscous to irradiation-dominated disk heating.",
            "Figure 3. Required dust mass to reach pebble isolation mass Miso (dashed lines) at each orbital period for a variety of αt (different columns), vf (different colors) and M⋆ (different rows). The accretion rate is fixed at Ṁ1⊙ = 10−8M⊙ yr−1. In general, more mass is required at higher αt, lower vf , and higher M⋆, reflecting lower accretion efficiencies. In the inner disk that is viscously-heated, Mdust→iso usually drops with orbital period whereas in the outer disk that is irradiation-heated, Mdust→iso tends to increase with orbital period. Exceptions are discussed in more detail in the main text.",
            "Figure 4. Left: the cumulative distribution function (CDF) of disk masses from Manara et al. (2022) augmented by factors of ∼3 to have the maximum disk mass match that of Class I disks measured in Tobin et al. (2020), color-coded with respect to stellar mass bins. The vertical dashed lines represent Mdust→iso in the inner orbits (taken as the larger mass between 30 and 100 days) evaluated for αt = 10−3, Ṁ1⊙ = 10−8 M⊙ yr−1, and vf =3 m/s, at the midpoint stellar mass for each given bin. Middle: the fraction of disks with enough mass to create an isolation mass in the inner orbits (taken as the larger mass between 30 and 100 days) for αt = 10−4. The vertical gray rectangle shows the range of measured fraction of FGK stars with Kepler planets from Zhu & Wu (2018) and Yang et al. (2020). Right: same as the middle panel but for αt = 10−3. All models but one produce fpl matching the measured value for FGK stars. In general, the fraction of disks that can create inner cores rises as the stellar mass decreases from ∼1M⊙ to ∼ 0.3− 0.5M⊙ if the cores form in viscously heated regions in the 3D regime (e.g., Ṁ1,⊙ = 10−8 M⊙ yr−1). For Ṁ1,⊙ = 10−9 M⊙ yr−1, planetary cores form in irradiated regions of the disk at P = 100 days for αt = 10−3 and 2D accretion becomes important for αt = 10−4; ϵ has a shallower dependence on M⋆ in these conditions.",
            "Figure 5. Top: the ratio of required dust mass to create the inner cores to the required dust mass to create an outer isolation mass at 5 AU as a function of stellar mass. Middle: the fraction of disks with enough mass to create an isolation mass at 5 AU fpl,outer vs. stellar mass. Bottom: the ratio of growth timescale of inner cores to the drain-out timescale of the dust mass that was drifted in before the creation of an 5 AU isolation mass. In diamonds, we plot the occurrence rate of giants (100–6000M⊕) between 1-5 AU computed by Fulton et al. (2021) with the errorbar delimiting 15.9–84.1% confidence intervals, reproduced from their Figure 7 (see footnote 3). In general, disks around higher mass stars are more likely to nucleate an outer planet and when they do, more than enough mass can drift in to the inner disk to create shortperiod planetary cores for M⋆ ≤ M⊙ (exception shown in light color), the latter of which can assemble before all the solids drain out to the inner edge of the disk.",
            "Figure A.1. Fraction of disks that can create isolation masses when the disk mass distribution of Manara et al. (2022) are scaled to Tobin et al. (2020) in M⋆-dependent manner (see text for more detail). The left and the middle columns illustrate fpl,inner, equivalent to the right two panels of Figure 4 while the right column shows fpl,outer, equivalent to the middle panel of Figure 5.The top and bottom rows correspond to a M⋆-bin dependent scaling of the Manara et al. (2022) disk masses assuming Mdust ∝ M0.125"
        ],
        "imgs": [
            "$2305.00803v2-Figure1-1.png",
            "$2305.00803v2-Figure2-1.png",
            "$2305.00803v2-Figure3-1.png",
            "$2305.00803v2-Figure4-1.png",
            "$2305.00803v2-Figure5-1.png",
            "$2305.00803v2-FigureA.1-1.png"
        ]
    },
    {
        "id": "2305.00804",
        "abstract": "  As inverter-based generation becomes more common in distribution networks, it\nis important to create models for use in optimization-based problems that\naccurately represent their non-linear behavior when saturated. This work\npresents models for grid-following and grid-forming inverters, and demonstrates\ntheir use in optimization-based fault studies. The developed models are shown\nto provide results in line with experimental tests from literature; however,\ngrid-forming inverter models fail to provide feasible solutions for certain\nfault types even when currents, voltages, and powers from the models seem\nreasonable. This work lays down the foundation for the development of relaxed\nmodels for both grid-following and grid-forming inverter models for use in\noptimization problems.\n",
        "title": "Developing Optimization-Based Inverter Models for Short Circuit Studies",
        "texts": [
            "Fig. 3. One-line diagram of the 4-bus case study system.",
            "Fig. 7. Feasibility of the Grid-Following Inverter Under Faults.",
            "Fig. 8. Simple Grid-Forming – Fault Currents [A] For Line-Line Fault.",
            "Fig. 9. Simple Grid-Forming – Fault Currents [A] For 3-Phase Fault."
        ],
        "imgs": [
            "$2305.00804v1-Figure3-1.png",
            "$2305.00804v1-Figure7-1.png",
            "$2305.00804v1-Figure8-1.png",
            "$2305.00804v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00805",
        "abstract": "  Deep forest is a non-differentiable deep model which has achieved impressive\nempirical success across a wide variety of applications, especially on\ncategorical/symbolic or mixed modeling tasks. Many of the application fields\nprefer explainable models, such as random forests with feature contributions\nthat can provide local explanation for each prediction, and Mean Decrease\nImpurity (MDI) that can provide global feature importance. However, deep\nforest, as a cascade of random forests, possesses interpretability only at the\nfirst layer. From the second layer on, many of the tree splits occur on the new\nfeatures generated by the previous layer, which makes existing explanatory\ntools for random forests inapplicable. To disclose the impact of the original\nfeatures in the deep layers, we design a calculation method with an estimation\nstep followed by a calibration step for each layer, and propose our feature\ncontribution and MDI feature importance calculation tools for deep forest.\nExperimental results on both simulated data and real world data verify the\neffectiveness of our methods.\n",
        "title": "Interpreting Deep Forest through Feature Contribution and MDI Feature\n  Importance",
        "texts": [
            "Figure 2: The new features play an important role in deep forests but are hard to interpret.",
            "Figure 3: Feature contributions for the regression problem. As shown in (b) and the prediction figures in (c) (d), the predictive performance improves from the first layer to the last layer. The feature contributions show that the model captures more details in both input features.",
            "Figure 4: Feature contributions for the 3-class classification problem. As shown in (b) and the prediction figures in (c) (d), the predictive performance improves from the first layer to the last layer. The learned feature contributions are coarse and ambiguous in (c), while clear and precise in (d). The colored areas in the contribution plots indicate an increase in the probabilities of data in these areas belonging to the corresponding class in the areas, and the gray areas indicate a decrease in probability.",
            "Figure 5: With the growing of layers in deep forest, the estimated MDI catches the underlying importance of features more accurately.",
            "Figure 6: Overall MDI and local MDI for the 3-class problem.",
            "Figure 7: Running time comparison of our MDI method to that of MDA for deep forest. Each experiment is repeated 20 times and the average running time is reported.",
            "Table 1: Key symbols and notations.",
            "Table 2: Example of feature contributions of two sample points for the 3-class classification problem. Only values related to the two relevant dimensions are presented. The values associated with the predicted class are shown in bold.",
            "Table 3: Average AUC scores of 20 runs for relevant feature identification. The best result of each data set is shown in bold.",
            "Table 4: Comparison of different calibration methods based on average AUC scores for relevant feature identification. The best result of each data set is shown in bold.",
            "Table 5: Example of feature contribution of deep forest in the bike sharing task. Positive and negative contributions are based on the training label mean."
        ],
        "imgs": [
            "$2305.00805v1-Figure2-1.png",
            "$2305.00805v1-Figure3-1.png",
            "$2305.00805v1-Figure4-1.png",
            "$2305.00805v1-Figure5-1.png",
            "$2305.00805v1-Figure6-1.png",
            "$2305.00805v1-Figure7-1.png",
            "$2305.00805v1-Table1-1.png",
            "$2305.00805v1-Table2-1.png",
            "$2305.00805v1-Table3-1.png",
            "$2305.00805v1-Table4-1.png",
            "$2305.00805v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00806",
        "abstract": "  Electric vehicle (EV) supply equipment location and allocation (EVSELCA)\nproblems for freight vehicles are becoming more important because of the\ntrending electrification shift. Some previous works address EV charger location\nand vehicle routing problems simultaneously by generating vehicle routes from\nscratch. Although such routes can be efficient, introducing new routes may\nviolate practical constraints, such as drive schedules, and satisfying\nelectrification requirements can require dramatically altering existing routes.\nTo address the challenges in the prevailing adoption scheme, we approach the\nproblem from a fixed-route perspective. We develop a mixed-integer linear\nprogram, a clustering approach, and a metaheuristic solution method using a\ngenetic algorithm (GA) to solve the EVSELCA problem. The clustering approach\nsimplifies the problem by grouping customers into clusters, while the GA\ngenerates solutions that are shown to be nearly optimal for small problem\ncases. A case study examines how charger costs, energy costs, the value of time\n(VOT), and battery capacity impact the cost of the EVSELCA. Charger equipment\ncosts were found to be the most significant component in the objective\nfunction, leading to a substantial reduction in cost when decreased. VOT costs\nexhibited a significant decrease with rising energy costs. An increase in VOT\nresulted in a notable rise in the number of fast chargers. Longer EV ranges\ndecrease total costs up to a certain point, beyond which the decrease in total\ncosts is negligible.\n",
        "title": "Electric Vehicle Supply Equipment Location and Capacity Allocation for\n  Fixed-Route Networks",
        "texts": [
            "Figure 1: Illustrative EVSELCA problem instance in the Chicago metropolitan area. The main figure shows traffic analysis zones and depots used for e-commerce delivery in the area as well as candidate charging facility locations. The inset depicts the study region including links of routes and a depot of those routes. Links in the inset are color-coded, and each color indicates a specific route.",
            "Figure 2: Time-to-best-solution statistics for the three solution approaches.",
            "Figure 3: Impact of percent decrease in charger costs.",
            "Figure 4: Impact of percent change in energy costs.",
            "Figure 5: Impact of percent increase in VOT costs.",
            "Figure 6: Impact of battery capacity (in miles range).",
            "Table 1: Summary of the existing relevant literature",
            "Table 3: Parameters used in the MILP.",
            "Table 7: Summary of computational performance of the three solution approaches."
        ],
        "imgs": [
            "$2305.00806v2-Figure1-1.png",
            "$2305.00806v2-Figure2-1.png",
            "$2305.00806v2-Figure3-1.png",
            "$2305.00806v2-Figure4-1.png",
            "$2305.00806v2-Figure5-1.png",
            "$2305.00806v2-Figure6-1.png",
            "$2305.00806v2-Table1-1.png",
            "$2305.00806v2-Table3-1.png",
            "$2305.00806v2-Table7-1.png"
        ]
    },
    {
        "id": "2305.00807",
        "abstract": "  Data-enabled predictive control (DeePC) is a recently established form of\nModel Predictive Control (MPC), based on behavioral systems theory. While\neliminating the need to explicitly identify a model, it requires an additional\nregularization with a corresponding weight to function well with noisy data.\nThe tuning of this weight is non-trivial and has a significant impact on\nperformance. In this paper, we compare three reformulations of DeePC that\neither eliminate the regularization, or simplify the tuning to a trivial point.\nA building simulation study shows a comparable performance for all three\nreformulations of DeePC. However, a conventional MPC with a black-box model\nslightly outperforms them, while solving much faster, and yielding smoother\noptimal trajectories. Two of the DeePC variants also show sensitivity to an\nunobserved biased input noise, which is not present in the conventional MPC.\n",
        "title": "A comparison of methods to eliminate regularization weight tuning from\n  data-enabled predictive control",
        "texts": [
            "Fig. 1. Inputs and outputs for the system identification, respectively construction of the Hankel matrices",
            "TABLE I SOLVERS FOR ALL CONTROLLERS",
            "TABLE II KEY PERFORMANCE INDICATORS WITH INTERNAL GAINS",
            "TABLE III KEY PERFORMANCE INDICATORS WITHOUT INTERNAL GAINS",
            "TABLE IV GENERAL PROPERTIES OF THE COMPARED METHODS"
        ],
        "imgs": [
            "$2305.00807v1-Figure1-1.png",
            "$2305.00807v1-TableI-1.png",
            "$2305.00807v1-TableII-1.png",
            "$2305.00807v1-TableIII-1.png",
            "$2305.00807v1-TableIV-1.png"
        ]
    },
    {
        "id": "2305.00808",
        "abstract": "  Three independent searches for new physics using data collected at BABAR are\npresented. Firstly, two searches for dark matter and baryogenesis:\n$B^{0}\\rightarrow \\Lambda + \\psi_{D}$ and $B^{+} \\rightarrow p + \\psi_{D}$ are\ndetailed, where $\\psi_{D}$ is a new dark fermion. Neither signal is observed\nand new upper limits on the branching fractions, at the 90 $\\%$ confidence\nlevel (C.L), are placed at $\\mathcal{O}(10^{-5} - 10^{-6})$ across the mass\nrange $1.0< m_{\\psi_{D}}<4.3$ GeV/c$^{2}$. Secondly, new limits on the\ncoupling, $g_{aW}$, of an axion-like particle ($a$) to the $W$ boson, at the 90\n$\\%$ C.L, are presented at $\\mathcal{O}(10^{-5})$ GeV$^{-1}$ for $a$ masses in\nthe mass range 0.175 $<m_{a}<$ 4.78 GeV/c$^{2}$. Thirdly, a model-independent\nsearch for heavy neutral leptons (HNL) found new upper limits at the 95 $\\%$\nC.L on the extended Pontecorvo-Maki-Nakagawa-Sakata (PMNS) matrix element,\n$|U_{\\tau 4}|^{2}$, which depend on the HNL mass hypothesis and vary from $2.31\n\\times 10^{-2}$ to $5.04 \\times 10^{-6}$, across the mass range $100 < m_{4} <\n1300$ MeV/c$^{2}$, with more stringent limits on higher HNL masses.\n",
        "title": "Recent Results from BABAR: Dark Matter, Axion-like Particles and Heavy\n  Neutral Leptons, a contribution to the 2023 Electroweak session of the 57th\n  Rencontres de Moriond",
        "texts": [
            "Figure 2 – Derived 90 % C.L upper limits on the branching fraction (left) B0 → ψD + Λ (right) B+ → ψD + p for BABAR data set corresponding to 398 fb−1. The theory expectation values for the effective operators were received from Elor et al. following communication with the authors.",
            "Figure 4 – Upper limits at 95% C.L on |Uτ4|2. The magenta line represents the result when uncertainties are included this is expected to be a very conservative upper limit. BABAR data corresponds to 424 fb−1."
        ],
        "imgs": [
            "$2305.00808v1-Figure2-1.png",
            "$2305.00808v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00809",
        "abstract": "  In exoplanetary systems, the interaction between the central star and the\nplanet can trigger Auroral Radio Emission (ARE), due to the Electron Cyclotron\nMaser mechanism. The high brightness temperature of this emission makes it\nvisible at large distances, opening new opportunities to study exoplanets and\nto search for favourable conditions for the development of extra-terrestrial\nlife, as magnetic fields act as a shield that protects life against external\nparticles and influences the evolution of the planetary atmospheres. In the\nlast few years, we started an observational campaign to observe a sample of\nnearby M-type stars known to host exoplanets with the aim to detect ARE. We\nobserved YZ Ceti with the upgraded Giant Metrewave Radio Telescope (uGMRT) in\nband 4 (550-900 MHz) nine times over a period of five months. We detected radio\nemission four times, two of which with high degree of circular polarization.\nWith statistical considerations we exclude the possibility of flares due to\nstellar magnetic activity. Instead, when folding the detections to the orbital\nphase of the closest planet YZ Cet b, they are at positions where we would\nexpect ARE due to star-planet interaction (SPI) in sub-Alfvenic regime. With a\ndegree of confidence higher than 4.37 sigma, YZ Cet is the first extrasolar\nsystems with confirmed SPI at radio wavelengths. Modelling the ARE, we estimate\na magnetic field for the star of about 2.4 kG and we find that the planet must\nhave a magnetosphere. The lower limit for the polar magnetic field of the\nplanet is 0.4 G.\n",
        "title": "Star-Planet Interaction at radio wavelengths in YZ Ceti: Inferring\n  planetary magnetic field",
        "texts": [
            "Figure 1. Radio light curve at band 4 towards the system YZ Cet as a function of the orbital phase of planet b. Detectable flux density is visible at two ranges of phases (blue areas). Upper limits are shown by open downward triangles.",
            "Figure 2. Schematic view of the detected radio emission as a function of the position of planet b in the orbit. YZ Cet is in the center, the direction of the Earth is on the right. Detection is marked by red-orange filled circles, whose size is proportional to the flux density. Non-detections are marked by red empty circles.",
            "Figure 5. Schematic view of the magnetic connection between star and planet. The stellar dipole is assumed to be perpendicular to the orbital plane. The axes of the ECME cones are tangent to the dipole line (angle ψ to the dipole axis). The aperture of the cone is θ with thickness ∆θ, centered in O.",
            "Figure 6. Schematic view of the emission pattern of the ARE. Directions are projected in a unitary spherical surface. The ECME pattern is a hollow cone, represented by the blue ring on the sphere. The emission originates in the dipolar field line connecting the planet and the star in the point O and it rotates following the planet. The radiation is direct toward the Earth when the line of sight (point E) intercepts the cone (blue circular corona) between points A-B and C-D. This occurs when the projection E′ of E in the plane of the orbit intercepts the projection of the blue ring (the orange ellipse) between points A′-B′ and C′-D′.",
            "Table 1. Log of the uGMRT Observations"
        ],
        "imgs": [
            "$2305.00809v1-Figure1-1.png",
            "$2305.00809v1-Figure2-1.png",
            "$2305.00809v1-Figure5-1.png",
            "$2305.00809v1-Figure6-1.png",
            "$2305.00809v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00811",
        "abstract": "  We show 2 matrices that have identical eigenvalues but different\neigenfunctions. This shows that in obtaining two body nuclear matrix elements\nempirically, it is not sufficient to consider only energy levels. Other\nquantities like transitions must also be included.\n",
        "title": "Comparisons of Matrices with Different Elements but Identical\n  Eigenvalues",
        "texts": [
            "Table 1: The numerical result of M1.",
            "Table 2: The numerical result of M2.",
            "Table 3: Relative signs for the cases same v and alternating sign v.",
            "Table 4: Ratio of lifetimes.",
            "Table 5: Transition amplitudes from n = 0."
        ],
        "imgs": [
            "$2305.00811v2-Table1-1.png",
            "$2305.00811v2-Table2-1.png",
            "$2305.00811v2-Table3-1.png",
            "$2305.00811v2-Table4-1.png",
            "$2305.00811v2-Table5-1.png"
        ]
    },
    {
        "id": "2305.00812",
        "abstract": "  A permanent magnet can be levitated simply by placing it in the vicinity of\nanother permanent magnet that rotates in the order of 200 Hz. This surprising\neffect can be easily reproduced in the lab with off-the-shelf components. Here\nwe investigate this novel type of magnetic levitation experimentally and\nclarify the underlying physics. Using a 19 mm diameter spherical NdFeB magnet\nas rotor magnet, we capture the detailed motion of levitating, spherical NdFeB\nmagnets, denoted floater magnets. We find that as levitation occurs, the\nfloater magnet frequency-locks with the rotor magnet, and, noticeably, that the\nmagnetization of the floater is oriented close to the axis of rotation and\ntowards the like pole of the rotor magnet. This is in contrast to what might be\nexpected by the laws of magnetostatics as the floater is observed to align its\nmagnetization essentially perpendicular to the magnetic field of the rotor.\nMoreover, we find that the size of the floater has a clear influence on the\nlevitation: the smaller the floater, the higher the rotor speed necessary to\nachieve levitation, and the further away the levitation point shifts. We verify\nthat magnetostatic interactions between the rotating magnets are responsible\nfor creating the equilibrium position of the floater. Hence, this type of\nmagnetic levitation does not rely on gravity as a balancing force to achieve an\nequilibrium position. Based on theoretical arguments and a numerical model, we\nshow that a constant, vertical field and eddy-current enhanced damping is\nsufficient to produce levitation from rest. This enables a gyroscopically\nstabilised counter-intuitive steady-state moment orientation, and the resulting\nmagnetostatically stable, mid-air equilibrium point. The numerical model\ndisplay the same trends with respect to rotation speed and the floater magnet\nsize as seen in the experiments.\n",
        "title": "Magnetic levitation by rotation",
        "texts": [
            "Fig. 1. The experimental setup, including a closeup of the rotor and floater magnet. The closeup is an image taken with the high-speed camera and where the floater magnet has been painted to indicate its magnetic poles. The floater magnet can clearly be seen to be levitating.",
            "Fig. 2. The phase angle, ϕ , between the floater and the rotor magnets. The phase angle is the angle between the projection onto the xy-plane of the respective magnetization vectors of the two magnets, mr and m f . The levitation distance is the center-to-center distance between the rotor and the floater magnets.",
            "Fig. 3. a) Levitation time as function of rotor speed and b) initial levitation distance as function or rotor speed. For both figures the color of the dots denote the mode occurring during levitation. The multicolored dots mean that the mode changes from the left colored mode to the right colored mode, e.g. for the red/blue case the mode changes from an Up-down mode exclusively to a Side mode exclusively. The levitation distance is defined as the distance from the center of the rotor spherical magnet to the center of the floater spherical magnet.",
            "Fig. 4. The fall rate of the floater magnet as function of motor speed for the semi-stable region. The errorbars are the standard deviation of three experiments for each rotor speed.",
            "Fig. 5. a) Minimum rotation speed to achieve levitation as function of floater magnet spheres diameter (blue points, bottom x-axis) and remanence (red points, top x-axis). b) The initial levitation distance as function of floater magnet spheres diameter (blue points, bottom x-axis) and remanence (red points, top x-axis) at a rotor speed of 150 Hz for the remanence variation and 300 Hz for the floater magnet diameter variation. The error bars on b) given are the standard deviation of the position as determined from the tracker software.",
            "Fig. 6. Simulation results at various rotor frequencies with the floater position fixed. The rotor is displaced by δr = 1 mm relative to the rotation axis, yielding a slight vertical B-field, the effective damping is η = 1 Pa · s, both magnetisations are 1.18 T and the diameters are 12.7 mm and 19 mm for floater and rotor respectively. a-c) Steady-state behaviour in the 3 different dynamical phases for d = 20 mm. a-b) phase lag, ϕ , and floater polar angle, θf, vs. time over 25 ms. c) Transverse components of the normalised floater moment over 150 ms. d) The dynamical phase of every simulation at various rotor frequencies, fr, and rotor/floater distances d. Orange crosses mark stable force equilibria. e-f) θf and vertical force Fz for all simulations in the blue phase between 270 and 360 Hz. The stable equilibria are the points where spline-fits of the force curves in fig. f) cross from positive (attractive) to negative (repulsive) as d decreases."
        ],
        "imgs": [
            "$2305.00812v2-Figure1-1.png",
            "$2305.00812v2-Figure2-1.png",
            "$2305.00812v2-Figure3-1.png",
            "$2305.00812v2-Figure4-1.png",
            "$2305.00812v2-Figure5-1.png",
            "$2305.00812v2-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00813",
        "abstract": "  Humans interact with the environment using a combination of perception -\ntransforming sensory inputs from their environment into symbols, and cognition\n- mapping symbols to knowledge about the environment for supporting\nabstraction, reasoning by analogy, and long-term planning. Human\nperception-inspired machine perception, in the context of AI, refers to\nlarge-scale pattern recognition from raw data using neural networks trained\nusing self-supervised learning objectives such as next-word prediction or\nobject recognition. On the other hand, machine cognition encompasses more\ncomplex computations, such as using knowledge of the environment to guide\nreasoning, analogy, and long-term planning. Humans can also control and explain\ntheir cognitive functions. This seems to require the retention of symbolic\nmappings from perception outputs to knowledge about their environment. For\nexample, humans can follow and explain the guidelines and safety constraints\ndriving their decision-making in safety-critical applications such as\nhealthcare, criminal justice, and autonomous driving. This article introduces\nthe rapidly emerging paradigm of Neurosymbolic AI combines neural networks and\nknowledge-guided symbolic approaches to create more capable and flexible AI\nsystems. These systems have immense potential to advance both algorithm-level\n(e.g., abstraction, analogy, reasoning) and application-level (e.g.,\nexplainable and safety-constrained decision-making) capabilities of AI systems.\n",
        "title": "Neurosymbolic AI -- Why, What, and How",
        "texts": [
            "Fig. 1. The two primary types of neurosymbolic techniques—lowering and lifting—can be further divided into four sub-categories. Across the low (L), medium (M), and high (H) scales, these methods can be used to provide a variety of functions at both algorithmic and application levels.",
            "Fig. 2. The figure illustrates two methods for compressing knowledge graphs to integrate them with neural processing pipelines. One approach involves embedding knowledge graph paths into vector spaces, enabling integration with the neural network’s hidden representations. The other method involves encoding knowledge graphs as masks to modify the neural network’s inductive biases. An example of an inductive bias is the correlation information stored in the self-attention matrices of a transformer neural network [8], [9].",
            "Fig. 3. Illustrates a federated pipeline method using the Langchain library. The method employs a language model trained on chain-of-thought reasoning to segment the input query into tasks. The language model then utilizes task-specific symbolic solvers to derive solutions. Specifically, the language model recognizes that search and scientific computing (mathematics) symbolic solvers are necessary for the given query. The resulting solutions are subsequently combined and transformed into natural language for presentation to the user.",
            "Fig. 4. depicts a pipeline that is fully differentiable from end to end. It consists of a composition of functions corresponding to various pipeline components. This pipeline enables the development of application-tailored AI systems that can be easily trained end-to-end. To accomplish this, trainable map functions are applied to raw data, converting it to concepts in the domain model. The example given in the figure relates to mental health diagnosis and conversational assistance. The map functions link fragments of raw data to decision variables in the diagnosis model, which are then used to apply constraints to the patient’s response generated by the text generation model. Results from an existing implementation demonstrates that expert satisfaction levels reached 70% using such a pipeline, compared to 47% with LLMs in federated pipelines, such as OpenAI’s text-Davinci-003 [10]."
        ],
        "imgs": [
            "$2305.00813v1-Figure1-1.png",
            "$2305.00813v1-Figure2-1.png",
            "$2305.00813v1-Figure3-1.png",
            "$2305.00813v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00814",
        "abstract": "  Understanding spin dynamics on femto- and picosecond timescales offers new\nopportunities for faster and more efficient spintronic devices. Here, we\nexperimentally investigate the coherent spin dynamics after ultrashort laser\nexcitation by time-resolved magneto optical Kerr effect (TR-MOKE) in thin\nNi80Fe20 films. We provide a detailed study of the magnetic field and pump\nfluence dependence of the coherent precessional dynamics. We show that the\ncoherent precession lifetime increases with the applied external magnetic field\nwhich cannot be understood by viscous Gilbert damping of the coherent magnons.\nInstead, it can be explained by nonlinear magnon interactions and by the change\nin the fraction of incoherent magnons. This interpretation is in agreement with\nthe observed trends of the coherent magnon amplitude and lifetime as a function\nof the exciting laser fluence. Our results provide a new insight into the\nmagnetization relaxation processes in ferromagnetic thin films, which is of\ngreat importance for further spintronic applications.\n",
        "title": "Coherent and incoherent magnons induced by strong ultrafast\n  demagnetization in thin permalloy films",
        "texts": [
            "FIG. 1. (a) Schematic diagram of the measurement geometry. (b) Typical experimental TR-MOKE data showing different temporal regimes of the magnetization dynamics for 5 nm Py sample measured at µ0H = 113 mT and F = 4.6 mJ cm−2.",
            "FIG. 2. Ultrafast demagnetization traces at different pump fluences for 5 nm Py sample in (a) polar (b) longitudinal MOKE geometry. (c) Demagnetization times (τM) vs. pump fluence (d) Fast remagnetization times (τE) vs. pump fluence and (e) quenching vs. pump fluence measured in both polar and longitudinal geometry. Solid circles and open circles represent the data corresponding to polar and longitudinal MOKE respectively.",
            "FIG. 3. (a) Ultrafast demagnetization traces for 5 nm Py sample measured at different values of magnetic field and for fixed F = 4.6 mJ cm−2. (b) upper panel: Demagnetization times (τM) vs. magnetic field and lower panel: Fast remagnetization times (τE) vs. magnetic field.",
            "FIG. 4. Magnetic field dependent dynamics: (a) Backgroundsubtracted time-resolved Kerr rotation data for 5 nm Py sample measured at two different magnetic fields and at F = 4.6 mJ cm−2. Solid lines are fitting lines. (b) Magnetic field dependence of precession frequency. Solid line represent the Kittel fit to the data points. (c) Magnetic field dependence of quenching (green) and of precessional amplitude (red). (d) Magnetic field dependence of the precessional relaxation time (τd) measured after ultrafast demagnetization in TR-MOKE (red), using microwave spectroscopy (blue) and analytical calculation (black).",
            "FIG. 5. Pump fluence dependent dynamics: (a) Backgroundsubtracted time-resolved Kerr rotation data for 5 nm Py sample measured at µ0H = 113 mT and different pump fluences. Solid lines are fitting lines. (b) Pump fluence dependence of precessional frequencies at µ0H = 113 mT. (c) Pump fluence dependence of quenching (olive) and precessional amplitude (brown). Pump fluence dependent quenching plotted here (olive) is the same as plotted by solid circles in Fig. 2(e). (d) Pump fluence dependence of precessional relaxation time (τd) measured after ultrafast demagnetization in TR-MOKE."
        ],
        "imgs": [
            "$2305.00814v2-Figure1-1.png",
            "$2305.00814v2-Figure2-1.png",
            "$2305.00814v2-Figure3-1.png",
            "$2305.00814v2-Figure4-1.png",
            "$2305.00814v2-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00815",
        "abstract": "  We study pressure acoustic propagation in asymmetric spoof-fluid-spoof\nacoustic waveguides and its potential application in acoustic gas sensors.\nFirst, a stable and efficient analytical method is established for fast\ncalculation of the dispersion curves based on spectral expansion and\nenforcement of continuity between segments at suitable collocation points. The\nanalysis is validated by a commercial finite element software. The geometric\ndesign of the waveguide is then optimized for the emergence of a nearly-flat\ndispersion curve associated with vertical geometric asymmetry. The waveguide is\nfabricated using 3D printing technology and the measurement results corroborate\nthe numerical simulations. Based on the nearly-flat dispersion curve supported\nby this waveguide, a CO$_2$ sensor is proposed allowing to relate the phase\ndifference measured between two points in the waveguide to the composition of\nthe gas in the waveguide. The proposed sensor is experimentally validated in a\ncontrolled environment and the measurement results match the computational\npredictions well. The sensor is robust with respect to noise and\nsignal-recording duration due to fast phase measurements and shows high\nsensitivity to gas concentration due to reliance on the second, nearly-flat,\ndispersion curve. In addition, the sensor is label-free and low-cost, while\nexhibiting rapid response, low-maintenance requirements and potential for\nmeasurements in a wide range of CO$_2$ concentrations without saturation\nissues.\n",
        "title": "An Asymmetric Spoof-Fluid-Spoof Acoustic Waveguide and its Application\n  as a CO$_2$ Sensor",
        "texts": [
            "Figure 1: A 2D sketch of the asymmetric spoof-fluid-spoof waveguide.",
            "Figure 10: Comparison of the calculated and measured relative phase change versus the concentration of CO2.",
            "Figure 2: Dispersion diagram of the first five modes for a1 = a3 = g = 10.3 mm, d = 34.3 mm, h1=18.2 mm, h3 =20.6 mm, obtained using the spectral-collocation and the finite-element methods.",
            "Figure 5: (a) Fabricated segment of the ASFS waveguide, (b) Measurement setup.",
            "Figure 6: Comparison of calculated and measured dispersion curves for the ASFS waveguide.",
            "Figure 8: (a) Cross section view of the numerically analyzed sensor, (b) Isometric view of the fabricated sensor",
            "Figure 9: Experimental setup: a PMMA box (with an inlet for gas and an outlet) containing the fabricated sensor, with two microphones inserted in the sockets, an earphone speaker attached by duct tape at the longer"
        ],
        "imgs": [
            "$2305.00815v2-Figure1-1.png",
            "$2305.00815v2-Figure10-1.png",
            "$2305.00815v2-Figure2-1.png",
            "$2305.00815v2-Figure5-1.png",
            "$2305.00815v2-Figure6-1.png",
            "$2305.00815v2-Figure8-1.png",
            "$2305.00815v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00816",
        "abstract": "  Renormalisation group approaches are tailor made for resolving the\nscale-dependence of quantum and statistical systems, and hence their phase\nstructure and critical physics. Usually this advantage comes at the price of\nhaving to truncate the full theory at hand, which asks for optimal expansion\nschemes. In the present work we use a functional renormalisation group (fRG)\napproach for the effective action which includes general scale-dependent\nreparametrisations of the theory [1]. This approach is used in an O(N)-theory\nto set up adaptive RG-flows that correspond to an optimal systematic expansion\nof the theory about the ground state or rather its full covariance or\npropagator. These parametrisations are induced by flowing fields that encode\nthe differential reparametrisation steps. The approach is put to work for an\ninvestigation of the thermal phase transition in the O(4)-theory in view of\napplications to QCD. The respective results are compared with those obtained in\nstandard fRG computations.\n",
        "title": "Flowing fields and optimal RG-flows",
        "texts": [
            "FIG. 1: Field and RG-time dependence of the anomalous dimension in the broken phase, Figure 1a, and in the symmetric phase, Figure 1b, in four dimensions at finite temperature. The critical temperature is Tc ≈ 0.260 and the initial conditions are given in Section V B. All units are given in terms of the UV-cutoff Λ = 1, and the dashed black line indicates the equations of motion in the limit of massless Goldstone bosons. The solution of the differential equation (34) for ηφ depends on a boundary condition that is in general k-dependent. The kink at about k ≈ 0.2 in Figure 1a originates in a strong k-dependence of the boundary condition when entering the broken phase, see Appendix C. The figure does not show negative values of ηφ(ρ), which appear in the unphysical part of the potential in the broken phase. For a detailed discussion see Appendix B 1.",
            "FIG. 10: RG-time dependence of the anomalous dimension in d = 2 + 1 at T = 0.05. The (purple) solution is regular and of type ηφ,1 (see Appendix B 1 b), the others are of type ηφ,2 (see Appendix B 1 a) and diverge as ρ → 0. The dashed lines indicate the solution to the equations of motion ρ0, which corresponds to the magnification point in solutions of type ηφ,2.",
            "FIG. 2: Comparison of the RG-scale dependence of the (1PI) effective potential derivative u = ∂ρV (a) and the flowing field φk (b). Results are shown in the broken phase in d = 3 at T = 0.05 for the initial conditions specified in Section V A. We compare results of the approximation with field-dependent Zφ(ρ) to LPA′ (dashed lines) and indicate the field dependence in terms of ρϕ = ρΛ. All units are given in terms of the UV-cutoff Λ = 1.",
            "FIG. 3: Anomalous dimension in d = 1 + 2 deep in the broken phase (T = 0.05). With the onset of strong, convexity restoring dynamics at k ≈ 0.85, it diverges as ρ→ 0. The divergence is situated in the unphysical (flat) part of the potential ρ < ρ0, where the latter is the solution to the equations of motion ((16)), and does not affect the results in the physical regime ρ > ρ0. The numerical treatment of this divergence is discussed in Appendix B 2. The dashed black line indicates ρ0 in the limit of massless Goldstone bosons. All units are given in terms of the UV-cutoff Λ = 1.",
            "FIG. 4: RG-scale dependence of the anomalous dimension ηφ(ρ0) on the equations of motion (16), in the vicinity of the critical temperature 0.260 < Tc < 0.261. The current result is compatible with a scaling solution ηφ,c ≈ 0.042.",
            "FIG. 5: Temperature dependence of the dynamical fields as a function of the UV-field at k = 0.01. All units are given in terms of the UV-cutoff Λ = 1.",
            "FIG. 6: Transformation of the field basis and potential in d = 1 + 3 at different temperatures. We show results in terms of the coordinates at the initial cut-off scale Λ. The solution to the equation of motion (16) is indicated by the dashed lines. The critical temperature is given by Tc ≈ 0.26. Hence the (purple) line is located in the broken phase. All units are given in terms of the UV-cutoff Λ = 1.",
            "FIG. 7: Potential and wave function renormalisation at k = 0.01 for different boundary conditions of the anomalous dimension: The hybrid scheme in (red), see Appendix C and and additionally the UV-boundary conditions (43) in (blue). The solution for the potential deviates genuinely in the un-physical domain to the left of the minimum. As k → 0 the negative part of the potential will flatten out and we expect agreement within numerical errors for the physical part of the potential, whereas the Zφ genuinely differ for ϕ > ϕEoM: By definition the (red) solution is > 1 and (blue) < 1. All units are given in terms of the UV-cutoff Λ = 1.",
            "FIG. 8: Anomalous dimension (multiplied by ρ) in d = 1 + 2 deep in the broken phase (T = 0.05). We can infer from ρηφ|ρ=0 6= 0 that the anomalous dimension ηφ diverges as ρ → 0, necessitating the numerical correction Appendix B 2. Since the numerical simulation uses the cut-off solution, the reconstruction of the anomalous dimension at small ρ displays some numerical artefacts.",
            "FIG. 9: Different solutions to the RG-adapted flow (34) in the d = 1 + 2 calculation at k = 0.001. All units are given in terms of the UV-cutoff Λ = 1. We depict the regular solution ηφ,1 (green), specified in Appendix B 1 b, as well as the LPA′-like solution ηφ,2 (red), which is used in the computation, from Appendix B 1 a. The solution to the equations of motion ρ0 is indicated for reference, as well as the respective focus points of the other ηφ . Irregularities in ηφ,1 at small ρ are caused by the numerical cut-off Appendix B 2. The other solutions are for illustrative purposes, the dashed solutions are unusable for our application: (grey) zoom into a numerically unstable coordinate range (ηφ < 0) or produce non-monotonous fields φk (ηφ|ρ→0 =∞), (blue) can be numerically implemented but has all of the drawbacks of ηφ,1 and ηφ,2 and none of the benefits."
        ],
        "imgs": [
            "$2305.00816v1-Figure1-1.png",
            "$2305.00816v1-Figure10-1.png",
            "$2305.00816v1-Figure2-1.png",
            "$2305.00816v1-Figure3-1.png",
            "$2305.00816v1-Figure4-1.png",
            "$2305.00816v1-Figure5-1.png",
            "$2305.00816v1-Figure6-1.png",
            "$2305.00816v1-Figure7-1.png",
            "$2305.00816v1-Figure8-1.png",
            "$2305.00816v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00818",
        "abstract": "  Mobility-as-a-Service (MaaS) systems are two-sided markets, with two mutually\nexclusive sets of agents, i.e., travelers/users and operators, forming a\nmobility ecosystem in which multiple operators compete or cooperate to serve\ncustomers under a governing platform provider. This study proposes a MaaS\nplatform equilibrium model based on many-to-many assignment games incorporating\nboth fixed-route transit services and mobility-on-demand (MOD) services. The\nmatching problem is formulated as a convex multicommodity flow network design\nproblem under congestion that captures the cost of accessing MOD services. The\nlocal stability conditions reflect a generalization of Wardrop's principles\nthat include operators' decisions. Due to the presence of congestion, the\nproblem may result in non-stable designs, and a subsidy mechanism from the\nplatform is proposed to guarantee local stability. A new exact solution\nalgorithm to the matching problem is proposed based on a branch and bound\nframework with a Frank-Wolfe algorithm integrated with Lagrangian relaxation\nand subgradient optimization, which guarantees the optimality of the matching\nproblem but not stability. A heuristic which integrates stability conditions\nand subsidy design is proposed, which reaches either an optimal MaaS platform\nequilibrium solution with global stability, or a feasible locally stable\nsolution that may require subsidy. For the heuristic, a worst-case bound and\ncondition for obtaining an exact solution are both identified. An expanded\nSioux Falls network test with 82 nodes and 748 links derives generalizable\ninsights about the model for coopetitive interdependencies between operators\nsharing the platform, handling congestion effects in MOD services, effects of\nlocal stability on investment impacts, and illustrating inequities that may\narise under heterogeneous populations.\n",
        "title": "On-demand Mobility-as-a-Service platform assignment games with\n  guaranteed stable outcomes",
        "texts": [
            "Figure 1. Network structure illustration.",
            "Figure 2. Example of instability.",
            "Figure 3. Flow chart of the exact solution algorithm for 𝐿1, with added 𝐿2 and 𝐿3 components for bounded heuristic for 𝐿1𝑆.",
            "Figure 6. Network construction of the Sioux Falls case.",
            "Figure 7. Base case assignment and fares.",
            "Figure 8. Reducing MOD Operating cost Case (Operator 5 operating cost reduced by 50%): (a) link flows, (b) single outcome fares, and (c) subsidies.",
            "Figure 9. Solution to 𝐿1 with subsidy found for the reducing fixed-route operating cost Case (Operator 4 operating cost reduced by 60%).",
            "Table 2. Seller- and Buyer-optimal operator revenue for the scenarios (percentage changes relative to base case)"
        ],
        "imgs": [
            "$2305.00818v1-Figure1-1.png",
            "$2305.00818v1-Figure2-1.png",
            "$2305.00818v1-Figure3-1.png",
            "$2305.00818v1-Figure6-1.png",
            "$2305.00818v1-Figure7-1.png",
            "$2305.00818v1-Figure8-1.png",
            "$2305.00818v1-Figure9-1.png",
            "$2305.00818v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00820",
        "abstract": "  Entangled coherent states play pivotal roles in various fields such as\nquantum computation, quantum communication, and quantum sensing. We\nexperimentally demonstrate the generation of entangled coherent states with the\ntwo-dimensional motion of a trapped ion system. Using Raman transitions with\nappropriate detunings, we simultaneously drive the red and blue sidebands of\nthe two transverse axes of a single trapped ion and observe multi-periodic\nentanglement and disentanglement of its spin and two-dimensional motion. Then,\nby measuring the spin state, we herald entangled coherent states of the\ntransverse motions of the trapped ion and observe the corresponding modulation\nin the parity of the phonon distribution of one of the harmonic oscillators.\nLastly, we trap two ions in a linear chain and realize Molmer-Sorensen gate\nusing two-dimensional motion.\n",
        "title": "Experimental Realization of Entangled Coherent States in Two-dimensional\n  Harmonic Oscillators of a Trapped Ion",
        "texts": [
            "FIG. 1. Experimental setup. (a) Schematic diagram of trap electrodes, ion, and pulsed laser beams for Raman transition. ∆~k indicates the direction of momentum transfer, which is the difference of the two pulsed laser beams, RV and RH . Upper right is the cross-section of the trap in the transverse plane. The angles between ∆~k and the Y and X principal axes are 24˝ and 66˝, respectively. The ion chain is formed along the Z axis. (b) Representative spectra showing the blue sidebands for the transverse modes of a single ion and (c) of a linear chain of two ions where Xcm and Ycm are in-phase modes and Xtilt and Ytilt are out-of-phase modes.",
            "FIG. 2. Entanglement of spin and the two motional modes. In (a-d) time evolution of the spin state for various detuning ratios is observed. Partial disentanglement of spin and motion takes place when wave packets return to the origin in only one dimension. Complete disentanglement is observed when wave packets return to the origin in both dimensions. Error bars indicate quantum projection noise. Solid curves are fits to 3. R is the ratio of detunings to the radial modes, defined as R “ δX{δY . Values of R estimated from fitting are (a) ´0.261 ˘ 0.001, (b) ´0.653 ˘ 0.003, (c) ´1.547 ˘ 0.016, and (d) ´3.892˘0.071. Times at which each motional mode is disentangled from the spin are indicated by vertical lines. Solid red lines correspond to the Y mode and dashed blue lines to the X mode. (e) A representative phase space diagram for the motional modes. In each phase space, the wave function evolves into a coherent superposition of two wave packets, corresponding to the φS basis spin eigenstates. The trajectories are determined by Rabi frequency and detuning from each mode.",
            "FIG. 3. Generation of entangled cat state and measurement of phonon state distribution. (a) Experimental sequence used to generate entangled coherent state and observe the modulation of its parity. (b) A representative plot for phonon distribution of the Y mode with R “ ´2{3 when the X mode is disentangled and (c) entangled. Orange bars are the theoretically expected phonon population for a cat state and blue bars are population extracted by fitting the blue sideband Rabi oscillation, which is presented in the insets. Solid curves in the insets are fits to the blue sideband Rabi oscillation model. (d), (e) Evolution of parity and mean phonon numbers as a functions of tSDF for R “ ´2 and R “ ´2{3, respectively. In (d), the maximum magnitude of the displacement in the Y phase space is |β| “ ?nY » 2 and for the X phase space, |α| “ ?nX » 0.7. In (e), |β| » 1.5 and |α| » 1.0 at maximum. Black line is a fit to phonon number parity of the entangled coherent state. Solid red line is the mean phonon number in the Y mode derived from the Rabi frequency and temperatures of each mode obtained from the phonon number parity fitting. Dahsed blue line is the mean phonon number of the X mode calculated the same way. All the error bars in this figure represent standard errors of fitted parameters.",
            "FIG. 4. Characterization of Mølmer–Sørensen gate with two-dimensional motion. (a) Normalized contributions of each mode for the geometric phase needed for the generation of the Bell state, 1{?2p|Óy ` |Òyq. d2 is the detuning from the Xcm mode. At the detuning indicated by a vertical dashed line, the detuning ratio is R “ ´1{3 and the X and Y mode contribute almost equally. (b) Time evolution of the spin states of a two-qubit system under two-dimensional Mølmer–Sørensen interaction when R “ ´1{3. The optimal gate time tg “ 182 µs. Error bars represent quantum projection noise. (c) Qubit state population oscillation as a function of the phase of the π{2-pulse. Qubit state parity(not shown in the plot), Πpφq “ PÒÒpφq ` PÓÓpφq ´ pPÓÒpφq ` PÒÓpφqq, oscillates with an amplitude of Πa “ 0.852˘ 0.007. Error bars are the standard deviation calculated from five iterations of the same experiment. The average population of the even states at tg, PÒÒ `PÓÓ, is 0.942˘ 0.009 as shown in the inset. The parity oscillation and even state population yield a gate fidelity of 0.897˘ 0.006."
        ],
        "imgs": [
            "$2305.00820v1-Figure1-1.png",
            "$2305.00820v1-Figure2-1.png",
            "$2305.00820v1-Figure3-1.png",
            "$2305.00820v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00821",
        "abstract": "  The ChatGPT Python API plays a crucial role in promoting Learner-Centered\nInstruction (LCI) and aligns with the principles of Tinker Learning, allowing\nstudents to discover their learning strategies. LCI emphasizes the importance\nof active, hands-on learning experiences and encourages students to take\nresponsibility for their learning journey. By integrating the ChatGPT Python\nAPI into the educational process, students can explore various resources,\ngenerate new ideas, and create content in a more personalized manner. This\ninnovative approach enables students to engage with the learning material\ndeeper, fostering a sense of ownership and motivation. As they work through the\nCreative Learning Spiral, students develop essential skills such as critical\nthinking, problem-solving, and creativity. The ChatGPT Python API is a valuable\ntool for students to explore different solutions, evaluate alternatives, and\nmake informed decisions, all while encouraging self-directed learning. In\nTinker Learning environments, the integration of ChatGPT Python API empowers\nstudents to experiment and iterate, allowing them to find the most effective\nlearning strategies that cater to their individual needs and preferences. This\npersonalized approach helps students to become more confident in their\nabilities, leading to tremendous academic success and long-term skill\ndevelopment. By leveraging the capabilities of the ChatGPT Python API,\neducational institutions can create a more engaging, supportive, and dynamic\nlearning environment. This approach aligns with the principles of\nLearner-Centered Instruction and Tinker Learning, promoting a culture of\ncuriosity, exploration, and creativity among students while preparing them for\nthe challenges of the fast-paced, ever-changing world.\n",
        "title": "Empowering Learner-Centered Instruction: Integrating ChatGPT Python API\n  and Tinker Learning for Enhanced Creativity and Problem-Solving Skills",
        "texts": [
            "Fig. 2. The example of Methods for Analyzing Highly Cited Blockchain in Education Related Papers from 2019- 2023 Using ChatGPT and LDA.",
            "Fig. 4. The performance of all participants in all assignments.",
            "Table 1. Course Evaluation. There are forty-one students participated in the classroom feedback."
        ],
        "imgs": [
            "$2305.00821v1-Figure2-1.png",
            "$2305.00821v1-Figure4-1.png",
            "$2305.00821v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00826",
        "abstract": "  Kagome-lattice materials possess attractive properties for quantum computing\napplications, but their synthesis remains challenging. Herein, we show surface\nkagome electronic states (SKESs) on a Sn-terminated triangular Co3Sn2S2\nsurface, which are imprinted by vertical p-d electronic hybridization between\nthe surface Sn (subsurface S) atoms and the buried Co kagome lattice network in\nthe Co3Sn layer under the surface. Owing to the subsequent lateral\nhybridization of the Sn and S atoms in a corner-sharing manner, the kagome\nsymmetry and topological electronic properties of the Co3Sn layer is proximate\nto the Sn surface. The SKESs and both hybridizations were verified via qPlus\nnon-contact atomic force microscopy (nc-AFM) and density functional theory\ncalculations. The construction of SKESs with tunable properties can be achieved\nby the atomic substitution of surface Sn (subsurface S) with other group III-V\nelements (Se or Te), which was demonstrated theoretically. This work exhibits\nthe powerful capacity of nc-AFM in characterizing localized topological states\nand reveals the strategy for synthesis of large-area transition-metal-based\nkagome lattice materials using conventional surface deposition techniques.\n",
        "title": "Discovery and construction of surface kagome electronic states induced\n  by p-d electronic hybridization",
        "texts": [
            "Fig. 1 | Schematic of vertically hybridized electronic states in charge-transfer kagome metal Co3Sn2S2. Schematic of the energy bands near Fermi level in (a) charge-transfer insulator and (b) charge-transfer metal, showing the difference in their p-d orbital overlap on the cleaved surfaces. (c) Schematic of surface kagome electronic state (SKES, the left part) and incomplete surface kagome electronic state (i-SKES, the right part) formation through vertical p-d hybridization in a charge-transfer kagome metal.",
            "Fig. 2 | Surface kagome electronic structure of the Sn surface in Co3Sn2S2. (a) Side view of the atomic model of the vertically stacked Sn-S-Co3Sn-S-Sn layers in Co3Sn2S2. (c) STM image of the S surface of Co3Sn2S2. (b) Schematic of the nc-AFM measurements using a qPlus sensor with a CO-functionalized tip in the frequency modulation mode. (d) Chemical-bond-resolved nc-AFM image of the S surface taken in the blue square in (c). (e) Zoomed-in image from (d) to show the incomplete kagome lattice. Three distinct regions within a unit cell with bright, blurry, and dark contrast, which are marked by black solid line triangles, red solid line triangles, and blue dashed line hexagon, are labeled as αI, βI, and γI regions. The atomic structure of S surface with the underlying Co3Sn plane is superimposed. (f) STM image of the Sn surface of Co3Sn2S2. (g) Chemical-bond-resolved nc-AFM image of the Sn surface taken in the area marked by a blue square in (f). (h) Zoomed-in image from (g), showing the kagome lattice. Three distinct regions within a unit cell with bright, blurry, and dark contrast, which are marked by black solid line triangles, red solid line triangles, and blue dashed line hexagon, are labeled as αII, βII, and γII regions. The atomic structure superimposed is the Sn surface with the underlying S and Co3Sn plane. Scanning parameters: (c) and (f), Vs = -400 mV, It = 100 pA; (d) and (e), amplitude = 100 pm, scanning height = 180 pm lower from a tunneling junction of Vs = -4 mV, It = 10 pA; (g) and",
            "Fig. 3 | Identification of the Sn surface by short-range force spectra. (a) Experimental vertical short-range force spectra measured at the center of the αI (black), βI (red), and γI (blue) regions. (b) and (c) DFT optimized surface structure and vertical short-range force spectra on the S surface. (d) Experimental vertical short-range force spectra measured at the center of the αII (black), βII (red), and γII (blue) regions. (e) and (f) DFT optimized surface structure and vertical short-range force spectra on the Sn surface. Spectra displayed in (a) were obtained with an amplitude of 25 pm and 50 pm for that shown in (d). Both experimental vertical short-range force curves were deconvoluted from associated frequency-shift curves using the Sader-Jarvis method35.",
            "Fig. 4 | Vertical p-d hybridizations at the Sn and S surfaces in Co3Sn2S2. (a) PLDOS of the Sn surface. Two black dashed lines at -0.38 and 0.50 eV indicate the boundaries of a group of isolated p-d hybridized states. (b) PLDOS of the top three atomic layers of the Sn surface, from -0.38 to 0.50 eV. Blue and red dashed lines denote the vertically p-d hybridized states between the surface",
            "Fig. 5 | Theoretical strategy for artificially constructing a family of surface kagome electronic states. (a) Schematic of the vertical p-d hybridization between the Co3 trimer and the surface atoms. Blue and yellow triangles indicate the hybridized triangular-shaped electronic state on the two sublattices of the kagome symmetry, respectively. (b) Schematic of the surface planes located on top of sublattice a (blue, SLa plane) and sublattice b (yellow, SLb plane) of the kagome plane (red). (c-e) Plots of |ψ|2 isosurface contours of hybridized states. (c) Contour of a p-d hybridized SKES for SLa = Sn and SLb = Se. Deposition of Ge and Pb on the S surface also generate the same type of SKESs. (d) Contour of a p-d hybridized asymmetric SKES for SLa = Sb and SLb = S, where the S and Sb sites show substantially different intensities. Deposition of Bi on the S surface also generate the same type of SKESs. (e) Contour for SLa = Al and SLb = S, where"
        ],
        "imgs": [
            "$2305.00826v1-Figure1-1.png",
            "$2305.00826v1-Figure2-1.png",
            "$2305.00826v1-Figure3-1.png",
            "$2305.00826v1-Figure4-1.png",
            "$2305.00826v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00829",
        "abstract": "  The spin-orbit angle, or obliquity, is a powerful observational marker that\nallows us to access the dynamical history of exoplanetary systems. Here, we\nhave examined the distribution of spin-orbit angles for close-in exoplanets and\nput it in a statistical context of tidal interactions between planets and their\nstars. We confirm the observed trends between the obliquity and physical\nquantities directly connected to tides, namely the stellar effective\ntemperature, the planet-to-star mass ratio, and the scaled orbital distance. We\nfurther devised a tidal efficiency factor combining critical parameters that\ncontrol the strength of tidal effects and used it to corroborate the strong\nlink between the spin-orbit angle distribution and tidal interactions. In\nparticular, we developed a readily usable formula to estimate the probability\nthat a system is misaligned, which will prove useful in global population\nstudies. By building a robust statistical framework, we reconstructed the\ndistribution of the three-dimensional spin-orbit angles, allowing for a sample\nof nearly 200 true obliquities to be analyzed for the first time. This\nrealistic distribution maintains the sky-projected trends, and additionally\nhints toward a striking pileup of truly aligned systems. The comparison between\nthe full population and a pristine subsample unaffected by tidal interactions\nsuggests that perpendicular architectures are resilient toward tidal\nrealignment, providing evidence that orbital misalignments are sculpted by\ndisruptive dynamical processes that preferentially lead to polar orbits. On the\nother hand, star-planet interactions seem to efficiently realign or quench the\nformation of any tilted configuration other than for polar orbits, and in\nparticular for antialigned orbits.\n",
        "title": "DREAM II. The spin-orbit angle distribution of close-in exoplanets under\n  the lens of tides",
        "texts": [
            "Fig. 1. Distribution of close-in exoplanets as a function of their radius and orbital period, featuring the Neptune desert and savanna. White diamonds indicate exoplanets with measured spin–orbit angles. Blue stars highlight planets in the survey described in DREAM I.",
            "Fig. 10. Distribution of Pearson (blue) and Spearman (orange) r correlation coefficients between misalignment fractions (blue bars on top of Fig. 7) and log-tidal efficiencies (Eq. (4)). Misalignment fractions are randomly sampled from their PDFs to generate this distribution (Sect. 4.3).",
            "Fig. 2. Distribution of spin–orbit angles as a function of the stellar effective temperature. Circles represent projected obliquities λ and diamonds true obliquities ψ. Exoplanets from the survey described in DREAM I are highlighted as blue symbols. The blue bars on top of the plots count the percentage of misaligned systems (λ or ψ ą 30˝) within each Teff bin. The top panel encompasses all systems with a known spin–orbit angle, whereas the bottom panels are subsets with only hot Jupiters (left) and sub-Saturns (right). The gray histogram on the right of the top plot counts the number of measurements within each spin–orbit angle bin. The color map represents a smoothed number-density of planets to guide the eye. The Kraft break (Teff “ 6250 K) is shown as a magenta vertical line.",
            "Fig. 3. Distribution of spin–orbit angles as a function of the planet-to-star mass ratio, subdivided into systems with a cold (Teff ă 6250 K, left) or hot (Teff ą 6250 K, right) host star. Same color, symbol, and histogram schemes as in Fig. 2.",
            "Fig. 4. Distribution of spin–orbit angles as a function of the semi-major axis-to-stellar radius ratio, subdivided into systems with a cold (Teff ă 6250 K, left) or hot (Teff ą 6250 K, right) host star. Same color, symbol, and histogram schemes as in Fig. 2.",
            "Fig. 5. Distribution of spin–orbit angles as a function of the tidal efficiency factor τ. Same color, symbol, and histogram schemes as in Fig. 2. All systems with a zero tidal efficiency factor have been set to the minimal value of the sample. The gray histogram on the left of the plot covers only the first (lowest) tidal efficiency bin.",
            "Fig. 6. Histogram of 3D spin–orbit angles for the full (top) and pristine (bottom) samples. The ψ distributions for individual systems are estimated using the procedure outlined in Sect. 4.1 and the histograms are built following the approach of Sect. 4.2.",
            "Fig. 7. Same as Fig. 5, but with 3D obliquities for all systems. ψ is estimated for systems that only have a sky-projected measurement using the procedure outlined in Sect. 4.1. We note the different vertical range for the blue bar plot on the top of the figure as compared to Fig. 5. The bar plot is built according to the procedure described in Sect. 4.3. The orange dashed line on the bar plot is the best linear fit between the misalignment fraction and the tidal efficiency, with the orange shaded area around it shown as its 1σ envelope. The bar plot, along with its linear fit, is also separately shown in Fig. 8 for clarity.",
            "Fig. 8. Misalignment fraction as a function of the tidal efficiency factor for all systems in our sample. Top: misalignment fraction bar plot, reported from the top of Fig. 7. The best linear fit relation (Eq. (12)) can be used as an estimator for the probability that a system lies in a misaligned configuration. Bottom: residuals between the medians of the misalignment fractions and the linear fit.",
            "Fig. 9. Estimates of ψ as a function of λ under the isotropic stellar inclination assumption, for three different values of the orbital inclination. Distributions for ψ are computed as described in the main text, assuming Gaussian distributions for λ and ip with respective standard deviations of 5˝ and 1˝. Plotted values are the medians of the ψ distributions, with error bars set to their 68% HDIs."
        ],
        "imgs": [
            "$2305.00829v1-Figure1-1.png",
            "$2305.00829v1-Figure10-1.png",
            "$2305.00829v1-Figure2-1.png",
            "$2305.00829v1-Figure3-1.png",
            "$2305.00829v1-Figure4-1.png",
            "$2305.00829v1-Figure5-1.png",
            "$2305.00829v1-Figure6-1.png",
            "$2305.00829v1-Figure7-1.png",
            "$2305.00829v1-Figure8-1.png",
            "$2305.00829v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00833",
        "abstract": "  Large language models have been shown to struggle with multi-step reasoning,\nand do not retain previous reasoning steps for future use. We propose a simple\nmethod for solving both of these problems by allowing the model to take\nSelf-Notes. Unlike recent chain-of-thought or scratchpad approaches, the model\ncan deviate from the input context at any time to explicitly think and write\ndown its thoughts. This allows the model to perform reasoning on the fly as it\nreads the context and even integrate previous reasoning steps, thus enhancing\nits memory with useful information and enabling multi-step reasoning.\nExperiments across a wide variety of tasks demonstrate that our method can\noutperform chain-of-thought and scratchpad methods by taking Self-Notes that\ninterleave the input text.\n",
        "title": "Learning to Reason and Memorize with Self-Notes",
        "texts": [
            "Figure 1: (top) Baseline vanilla LM directly generates the answer (A) given the context (C) and the question (Q). (middle) Scratchpad allows the model to generate intermediate reasoning tokens before answering the question but after it has seen the context. (bottom) Our Self-Notes method allows the model to deviate from the input context at any time to reason and take notes.",
            "Figure 2: Performance of the proposed Self-Notes method with varying amounts of Self-Notes supervision.",
            "Figure 5: Ablation comparing the impact of (a) extra compute due to additional tokens, and (b) position of the additional tokens.",
            "Table 2: Test Accuracy (in %) for the reasoning and state-tracking tasks. “*” indicates out-of-distribution harder test settings.",
            "Table 3: Toy-Story setting without ground-truth notes.",
            "Table 5: Ablation comparing the performance of Self-Notes with (i) ground truth self-notes at test time, and (ii) abstaining from generation of self-notes during inference.",
            "Table 6: Results with Dummy Tokens. For the chess tasks, we report the results for the OOD setting (over 80 moves).",
            "Table 8: Test sample from the Algorithmic task. In this example, the question (Q∗) is “print d” and the answer (A∗) is “d = 3 ;”. The vanilla model fails at tracking the variable(s) and incorrectly predicts “d = 2 ;”. The scratchpad runs past the GPT-2 context length, since the context window also includes the input text, and thus cannot generate a valid scratchpad end token, so it can’t make a prediction. The Self-Notes method correctly tracks the state of each variable as it sees statements, and successfully predicts “d = 3 ;”."
        ],
        "imgs": [
            "$2305.00833v1-Figure1-1.png",
            "$2305.00833v1-Figure2-1.png",
            "$2305.00833v1-Figure5-1.png",
            "$2305.00833v1-Table2-1.png",
            "$2305.00833v1-Table3-1.png",
            "$2305.00833v1-Table5-1.png",
            "$2305.00833v1-Table6-1.png",
            "$2305.00833v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00835",
        "abstract": "  We address the Bose polaron problem of a mobile impurity interacting strongly\nwith a host Bose-Einstein condensate (BEC) through a Feshbach resonance. On the\nrepulsive side at strong couplings, theoretical approaches predict two distinct\npolaron branches corresponding to attractive and repulsive polarons, but it\nremains unclear how the two are related. This is partly due to the challenges\nresulting from a competition of strongly attractive (destabilizing)\nimpurity-boson interactions with weakly repulsive (stabilizing) boson-boson\ninteractions, whose interplay is difficult to describe with contemporary\ntheoretical methods. Here we develop a powerful variational framework that\ncombines Gaussian correlations among impurity-boson scattering states,\nincluding up to an infinite number of bosonic excitations, with exact\nnon-Gaussian correlations among bosons occupying an impurity-boson bound state.\nThis variational scheme enables a full treatment of strong nonlinearities\narising in the Feshbach molecule on the repulsive side of the resonance. Within\nthis framework, we demonstrate that the interplay of impurity-induced\ninstability and stabilization by repulsive boson-boson interactions results in\na discrete set of metastable many-body bound states at intermediate energies\nbetween the attractive and repulsive polaron branches. These states exhibit\nstrong quantum statistical characteristics in the form of non-Gaussian quantum\ncorrelations, requiring non-perturbative beyond mean-field treatments for their\ncharacterization. Furthermore, these many-body bound states have sizable\nmolecular spectral weights, accessible via molecular spectroscopy techniques.\nThis work provides a unified theory of attractive and repulsive Bose polarons\non the repulsive side of the Feshbach resonance.\n",
        "title": "A unified theory of strong coupling Bose polarons: From repulsive\n  polarons to non-Gaussian many-body bound states",
        "texts": [
            "FIG. 1. Schematic illustration of the Bose polaron spectrum across an impurity-boson Feshbach resonance for repulsively interacting bosons. In the presence of inter-boson interactions, the attractive polaron persists to the repulsive side as a well-defined resonance, while other metastable many-body bound states appear in addition to the repulsive polaron. These many-body bound states emerge due to the competition of multiple impurity-boson binding and inter-boson repulsion. The structure of the main component of each manybody bound state is shown schematically.",
            "FIG. 2. (a) Energy of polaron states, including attractive and repulsive polaron, and metastable states ms1 to ms6 (see text), across an impurity-boson Feshbach resonance. On the attractive side (a < 0), an impurity resonance exists corresponding to the attractive polaron branch (green dashed line), which extends to the repulsive side and remains the well-defined stable saddle point across the resonance. On the repulsive side, the repulsive polaron branch emerges as the unstable saddle point solution with a bound state, as well as two many-body bound states ms1 and ms2 (red and blue solid lines). The red dotted line indicates the bare dimer energy. Beyond a critical scattering length (denoted by a vertical black dotted line), further metastable many-body bound states ms3 to ms6 emerge in the spectrum (grey shaded solid lines). Note that the normalized energy is rescaled to show all bound states compactly. The grey-shaded region (2) on the repulsive side is bounded by 1/kna ≃ 1.2 where µ/εB ≃ 9 × 10−3, providing a conservative bound for the validity of our theory. (b) The energy landscape over the phase space of the bound Bogoliubov mode, around the saddle points corresponding to different regions in (a). The real and imaginary parts of the coherent state variable αB serve as coordinates for the phase space of the bound Bogoliubov mode. In (1), the attractive polaron (green shaded point) is a stable saddle point, with all the fluctuation modes having positive energy. Within region (2), a dynamical instability occurs as a precursor to the formation of the repulsive polaron, signified by a single unstable phase mode with a corresponding stable amplitude mode. In (3), the repulsive polaron (purple shaded dot) is a saddle point solution with a single unstable Bogoliubov mode. The energy and particle number of many-body bound states in (a) are depicted qualitatively on the energy surfaces. The radius of each circle denotes the mean bound state occupation number, while its position on the surface denotes the energy of the state. Repulsive inter-boson interaction increases the energy of the many-body bound state with a higher particle number. By increasing 1/kna, further many-body bound-states enter the atom-dimer continuum (grey shaded solid lines). Increasing the binding energy increases the number of bound bosons in the lowest many-body bound state. The vertical black dashed lines mark the level crossings between many-body bound states.",
            "FIG. 4. Energy in units of the dimer binding energy (a) and mean bound state occupation number (b) of the many-body bound states (red, blue and grey solid lines for ms1, ms2 and ms3 respectively), attractive polaron (green dashed line), and repulsive polaron (purple solid line). Initially, the ms2 state has higher mean bound state occupation number and energy than thems1 state, indicating the dominant effect of the interboson interaction on the energy of the states. Beyond the first level crossing, the mean occupation number of the ms1 state increases above the ms2 state due to the gain in energy from binding more bosons. The ms3 state enters the dimerboson continuum at the critical scattering length indicated by vertical dotted line in panel (b) and maintains an almost constantNB ≃ 3. For increasing 1/kna, the mean bound state occupation number of ms1 and ms2 states approach integer values. At the level crossing between ms1 and ms3, the states strongly mix, resulting in sharp spikes in ⟨NB⟩ in panel (b).",
            "FIG. 5. Energy of the many-body bound states including the effect of condensate distortion obtained by fully solving Eqs. 19 (dotted lines), compared to the energies obtained by setting αx = 0. Including condensate distortion effects results in marginal changes in the energy (denoted by ∆Emsi , i = 1, 2, 3 ), and wave function of many-body bound states.",
            "FIG. 6. (a) Illustration of the energy landscape and the metastable states at 1/kna = 2.74. As in Fig. 2 (b) panels (3) and (4), the radius, respectively, the vertical order of each circle on the energy surface reflect the mean bound state occupation number, respectively, the energy of the corresponding metastable state. Panels (b) and (c) show the quantitative calculations of the Q representation of the repulsive and attractive polaron, respectively. Panels (d) to (f) depict the Q representation of ms1 to ms3 states.",
            "FIG. 7. g (2) B of the many-body bound states. Clear deviations from the results of a Gaussian state indicates the nonGaussian nature of bosons spatial correlations occupying the bound state.",
            "FIG. 8. (a) Quasiparticle residue of different many-body bound states, compared to the attractive and repulsive polaron. At strong couplings, the quasiparticle residue of attractive polaron and all the many-body bound states are substantially smaller than the repulsive polaron for strong couplings. (b) Molecular quasiparticle residue of the states in (a). The states ms1 and ms2 have substantial molecular weight with non-monotonic behavior as a function of 1/kna, in contrast to the prediction for the attractive polaron. The sharp spikes in Zmol of ms1 and ms3 occurs at the corresponding level crossing.",
            "FIG. 9. Energy of polaron states across an impurity-boson Feshbach resonance, as in Fig. 2, on a linear scale (see Appendix D). The large separation of the bound state energy from the BEC energy scale is evident."
        ],
        "imgs": [
            "$2305.00835v3-Figure1-1.png",
            "$2305.00835v3-Figure2-1.png",
            "$2305.00835v3-Figure4-1.png",
            "$2305.00835v3-Figure5-1.png",
            "$2305.00835v3-Figure6-1.png",
            "$2305.00835v3-Figure7-1.png",
            "$2305.00835v3-Figure8-1.png",
            "$2305.00835v3-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00837",
        "abstract": "  Accurate segmentation of skin lesions in dermatoscopic images is crucial for\nthe early diagnosis of skin cancer and improving the survival rate of patients.\nHowever, it is still a challenging task due to the irregularity of lesion\nareas, the fuzziness of boundaries, and other complex interference factors. In\nthis paper, a novel LCAUnet is proposed to improve the ability of complementary\nrepresentation with fusion of edge and body features, which are often paid\nlittle attentions in traditional methods. First, two separate branches are set\nfor edge and body segmentation with CNNs and Transformer based architecture\nrespectively. Then, LCAF module is utilized to fuse feature maps of edge and\nbody of the same level by local cross-attention operation in encoder stage.\nFurthermore, PGMF module is embedded for feature integration with prior guided\nmulti-scale adaption. Comprehensive experiments on public available dataset\nISIC 2017, ISIC 2018, and PH2 demonstrate that LCAUnet outperforms most\nstate-of-the-art methods. The ablation studies also verify the effectiveness of\nthe proposed fusion techniques.\n",
        "title": "LCAUnet: A skin lesion segmentation network with enhanced edge and body\n  fusion",
        "texts": [
            "Figure 1: Examples of challenging in skin lesion segmentation: (a) irregular shape; (b) blurry boundary with low contrast; (c) small size; (d) hairs’ interference; (e) diagnostic marks’ interference; (f) circular field of view.",
            "Figure 10: Visualization of ablative analysis for key modules in LCAUnet.(a) Input images. (b) GroundTruth. (c)Baseline. (d)Baseline+PGMF. (e) Baseline+EE(EdgeEncoder). (f) Baseline+EE+LCAF. (g) Baseline+EE+ LCAF+PGMF(Ours).The red outline and blue outline respectively indicate the ground truth and segmentation results.",
            "Figure 11: Visual comparison of different attention maps extracted by edge encoder and body encoder. (a) Input images. (b) Ground truth. (c) Attention map of the last stage in edge encoder. (d) Attention map of the last stage in body encoder.(5)Attention map of final layer of our model.",
            "Figure 2: The proposed LCAUnet framework comprises a dual-encoder that incorporates both edge and body encoders to simultaneously extract edge and body features. Additionally, the framework includes an efficient fusion module, LCAF, which facilitates the fusion of edge and body features, and an AMSFF module that is embedded in the decoder to fully integrate adjacent scale features.",
            "Figure 3: Description of generating PDC from vanilla convolution.",
            "Figure 4: Two adjacent Swin Transformer blocks.",
            "Figure 5: Structure diagram of LCAF.",
            "Figure 6: Structure diagram of PGMF.",
            "Figure 7: Visual comparison with different state-of-the-art methods on the ISIC 2017 dataset. (a) Input images. (b) Ground truth. (c) U-Net. (d) AttU-Net. (e) FAT-Net. (f) TransUnet. (g) Ours. The red outline and blue outline respectively indicate the ground truth and segmentation results.",
            "Figure 8: Visual comparison with different state-of-the-art methods on the ISIC 2018 dataset. (a) Input images. (b) Ground truth. (c) U-Net. (d) AttU-Net. (e) FAT-Net. (f) TransUnet. (g) Ours. The red outline and blue outline respectively indicate the ground truth and segmentation results.",
            "Figure 9: Visual comparison with different state-of-the-art methods on the PH2 dataset. (a) Input images. (b) Ground truth. (c) U-Net. (d) AttU-Net. (e) FAT-Net. (f) TransUnet. (g) Ours. The red outline and blue outline respectively indicate the ground truth and segmentation results.",
            "Table 1: Results of LCAUnet on ISIC2017 dataset compared with the latest methods.",
            "Table 2: Results of LCAUnet on ISIC2018 dataset compared with the latest methods.",
            "Table 3: Results of LCAUnet on PH2 dataset compared with the latest methods.",
            "Table 4: The ablation experiment results of LCAUnet on the ISIC 2017, ISIC 2018 and PH2 datasets."
        ],
        "imgs": [
            "$2305.00837v1-Figure1-1.png",
            "$2305.00837v1-Figure10-1.png",
            "$2305.00837v1-Figure11-1.png",
            "$2305.00837v1-Figure2-1.png",
            "$2305.00837v1-Figure3-1.png",
            "$2305.00837v1-Figure4-1.png",
            "$2305.00837v1-Figure5-1.png",
            "$2305.00837v1-Figure6-1.png",
            "$2305.00837v1-Figure7-1.png",
            "$2305.00837v1-Figure8-1.png",
            "$2305.00837v1-Figure9-1.png",
            "$2305.00837v1-Table1-1.png",
            "$2305.00837v1-Table2-1.png",
            "$2305.00837v1-Table3-1.png",
            "$2305.00837v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00842",
        "abstract": "  We develop an axial model for single steadily propagating positive streamers\nin air. It uses observable parameters to estimate quantities that are difficult\nto measure. More specifically, for given velocity, radius, length and applied\nbackground field, our model approximates the ionization density, the maximal\nelectric field, the channel electric field, and the width of the charge layer.\nThese parameters determine the primary excitations of molecules and the\ninternal currents. Our approach is to first analytically approximate electron\ndynamics and electric fields in different regions of a uniformly-translating\nstreamer head, then we match the solutions on the boundaries of the different\nregions to model the streamer as a whole, and we use conservation laws to\ndetermine unknown quantities. We find good agreement with numerical simulations\nfor a range of streamer lengths and background electric fields, even if they do\nnot propagate in a steady manner. Therefore quantities that are difficult to\naccess experimentally can be estimated from more easily measurable quantities\nand our approximations. The theoretical approximations also form a stepping\nstone towards efficient axial multi-streamer models.\n",
        "title": "Estimating the properties of single positive air streamers from\n  measurable parameters",
        "texts": [
            "Figure 3: Current density, electric field and particle densities on axis for streamers in three background electric fields. All streamers are shown when the head has reached ζtip = 15 mm. The origin of the coordinate system, z = 0, is at the centre of the hemisphere fitted through the maximum of the charge number density. The corresponding v and R are shown in figure 5.",
            "Figure 4: The charge layer within the co-moving coordinate system (r, z) at Ebg = 4.5 kV/cm. The solid blue line represents the maximum of nq (for each z) from numerical simulation and the shaded area is the corresponding charge layer parameterized using ℓ. Also shown are: the tangent circle with radius R, ℓ̃ and the positions zch, ztip and znq,max .",
            "Figure 5: The velocity and radius as a function of the head position extracted from simulations at different background electric fields.",
            "Figure 6: The dimensionless parameter ℓ/R as a function of the head position extracted from simulations at different background electric fields. This parameter characterizes the validity of the planar front approximation. The fluctuations observed are due to the small size of ℓ̃ which is only a few times the smallest grid size.",
            "Figure 7: The configuration used for computing the photo-ionization source term. The charge layer is approximated by a hemisphere S with radius R centered around z = 0. The color indicates that in reality the front is not radiating with uniform intensity but fades at the edges (even though we do not account for this here). Also shown is the path of a photon produced at r′ and absorbed at zez. Photoionization then creates electron avalanches that develop the local electric field. We use the avalanches on the z-axis for our approximations.",
            "Figure 8: Our approximation (orange) for the electron density compared to numerical results (blue) of a steady streamer simulation. The applied background field is 4.5 kV/cm. The approximated parameters used to make this comparison are evaluated in figure (9)",
            "Figure 9: Comparison of simulations (blue, green) and our approximations (orange) for streamers with varying head positions in different background fields Ebg. Ebg, L, R and v were taken from the simulations and used to calculate the plotted approximations from (63). The plotted quantities are the maximum electric field Emax, the (average) channel electric fields Ech, the degree of ionization ni,ch and the charge layer width ℓ̃. The four background electric fields Ebg are plotted as · · for 4.5 kV/cm (steady), for 10 kV/cm, for 14 kV/cm, and · · · for 24 kV/cm).",
            "Table 1: The ionization density ni,ch (×1019 m−3) for streamers in different background fields. All streamers are taken at ζtip = 15 mm. We compare the old approximation (equation (22)) and our approximation (equation (26)) with our simulated results."
        ],
        "imgs": [
            "$2305.00842v2-Figure3-1.png",
            "$2305.00842v2-Figure4-1.png",
            "$2305.00842v2-Figure5-1.png",
            "$2305.00842v2-Figure6-1.png",
            "$2305.00842v2-Figure7-1.png",
            "$2305.00842v2-Figure8-1.png",
            "$2305.00842v2-Figure9-1.png",
            "$2305.00842v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00844",
        "abstract": "  Objective: To assess the performance of the OpenAI GPT API in accurately and\nefficiently identifying relevant titles and abstracts from real-world clinical\nreview datasets and compare its performance against ground truth labelling by\ntwo independent human reviewers.\n  Methods: We introduce a novel workflow using the OpenAI GPT API for screening\ntitles and abstracts in clinical reviews. A Python script was created to make\ncalls to the GPT API with the screening criteria in natural language and a\ncorpus of title and abstract datasets that have been filtered by a minimum of\ntwo human reviewers. We compared the performance of our model against\nhuman-reviewed papers across six review papers, screening over 24,000 titles\nand abstracts.\n  Results: Our results show an accuracy of 0.91, a sensitivity of excluded\npapers of 0.91, and a sensitivity of included papers of 0.76. On a randomly\nselected subset of papers, the GPT API demonstrated the ability to provide\nreasoning for its decisions and corrected its initial decision upon being asked\nto explain its reasoning for a subset of incorrect classifications.\n  Conclusion: The GPT API has the potential to streamline the clinical review\nprocess, save valuable time and effort for researchers, and contribute to the\noverall quality of clinical reviews. By prioritizing the workflow and acting as\nan aid rather than a replacement for researchers and reviewers, the GPT API can\nenhance efficiency and lead to more accurate and reliable conclusions in\nmedical research.\n",
        "title": "Automated Paper Screening for Clinical Reviews Using Large Language\n  Models",
        "texts": [
            "Figure 1: Overview of the Python script to automate screening with the GPT API.",
            "Figure 2: Confusion matrices for the included and excluded papers for all datasets (A-F) and the overall performance (G).",
            "Table 1: Included studies and their characteristics. The first five datasets are systematic reviews with meta-analyses. The last study is a scoping review.",
            "Table 2: Data formatting for the Python script automating screening with the GPT API. All non-English characters were removed prior to analysis.",
            "Table 3: Performance of GPT in screening titles and abstracts against a human reviewer ground truth. Kappa (Human) is the agreement between two independent human reviewers. Kappa (Screen) is the agreement between GPT and the final papers included/excluded in each dataset."
        ],
        "imgs": [
            "$2305.00844v1-Figure1-1.png",
            "$2305.00844v1-Figure2-1.png",
            "$2305.00844v1-Table1-1.png",
            "$2305.00844v1-Table2-1.png",
            "$2305.00844v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00846",
        "abstract": "  Motivated by applications in Bayesian analysis we introduce a\nmultidimensional beta distribution in an ordered simplex. We study properties\nof this distribution and connect them with the generalized incomplete beta\nfunction. This function is crucial in applications of multidimensional beta\ndistribution, thus we present two efficient numerical algorithms for computing\nthe generalized incomplete beta function, one based on Taylor series expansion\nand another based on Chebyshev polynomials.\n",
        "title": "On ordered beta distribution and the generalized incomplete beta\n  function",
        "texts": [
            "Figure 1: The errors of the approximation ET(N) (solid line) and EC(N) (line with circles) versus N on the x-axis."
        ],
        "imgs": [
            "$2305.00846v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00847",
        "abstract": "  Gamma-ray bursts (GRBs) 201015A and 201216C are valuable cases with detection\nof very high energy (VHE) gamma-ray afterglows. By analysing their prompt\nemission data, we find that GRB 201216C is an extremely energetic long GRB with\na hard gamma-ray spectrum, while GRB 201015A is a relative sub-energetic, soft\nspectrum GRB. Attributing their radio-optical-X-ray afterglows to the\nsynchrotron radiation of the relativistic electrons accelerated in their jets,\nwe fit their afterglow lightcurves with the standard external shock model and\ninfer their VHE afterglows from the synchrotron self-Compton scattering process\nof the electrons. It is found that the jet of GRB 201015A is mid-relativistic\n($\\Gamma_0=44$) surrounded by a very dense medium ($n=1202$ cm$^{-3}$) and the\njet of GRB 201216C is ultra-relativistic ($\\Gamma_0=331$) surrounded by a\nmoderate dense medium ($n=5$ cm$^{-3}$). The inferred peak luminosity of the\nVHE gamma-ray afterglows of GRB 201216C is approximately $10^{-9}$ erg\ncm$^{-2}$ s$^{-1}$ at $57-600$ seconds after the GRB trigger, making it can be\ndetectable with the MAGIC telescopes at a high confidence level, even the GRB\nis at a redshift of 1.1. Comparing their intrinsic VHE gamma-ray lightcurves\nand spectral energy distributions with GRBs~180720B, 190114C, and 190829A, we\nshow that their intrinsic peak luminosity of VHE gamma-ray afterglows at\n$10^{4}$ seconds post the GRB trigger is variable from $10^{45}$ to $5\\times\n10^{48}$ erg s$^{-1}$, and their kinetic energy, initial Lorentz factor, and\nmedium density are diverse among bursts.\n",
        "title": "Very-High-Energy Gamma-Ray Afterglows of GRB 201015A and GRB 201216C",
        "texts": [
            "Figure 2. Prompt gamma-ray lightcurves of GRB 201216C. The solid red step lines mark the analysis results with the Bayesian block algorithm. The dash orange horizontal lines represents SNR = 10.",
            "Figure 3. Prompt gamma-ray spectra of GRB 201216C observed with Swift/BAT (15−150 keV), Fermi/GBM-NaI (8−900 keV), and Fermi/GBM-BGO (200 − 40000 keV). The purple solid line is our joint fit result with the Band function following the procedure described in Wang et al. (2022).",
            "Figure 4. The X-ray, optical, and radio afterglows of GRB 201015A (left panel) and GRB 201216C (right panel) together with the fits by the external FS model. In the left-hand panel, the points of the purple down arrows indicate the limits of the radio afterglows. In the right-hand panel, the points of dark yellow represents the SN 2011kl associated with GRB 111209A in the r’ band at z = 1.1. The dash line dark yellow represents the 24.2 mag limit of GROND telescope in an exposure time of 8 minutes.",
            "Figure 5. Posterior distribution contours of the model parameters derived from the fit for GRB 201015A. The vertical dashed lines mark the 1σ confidence level regions centering at their median probabilities.",
            "Figure 7. Theoretically predicted afterglow SEDs of GRB 201015A at 40 − 600 seconds (left panel) and GRB 201216C at 57 − 600 seconds (right panel), in which emission is attributed to the synchrotron and SSC emissions of leptons. The shaded areas mark the uncertainties based on the errors of posterior distribution of parameters. The red line represents the sensitivity of MAGIC for a given observation epoch, which is derived from the integral sensitivity for point-like sources with a Crab Nebula-like spectrum in 50 hours of observations (Aleksić et al. 2016). The red and green down arrows represent the LAT and HAWC limits, respectively. The SED of GRB 201216C at 5500 seconds is also shown (purple line) to exam whether the model prediction violates the limit observed with Fermi/LAT.",
            "Figure 8. GRBs with VHE gamma-ray afterglow detection in the logLrγ,p,iso − logLγ,p,iso plane in comparison with a sample of GRBs (black dots) including low-luminosity and high-luminosity GRBs from (Liang et al. 2015; Huang et al. 2020), where the logLrγ,p,iso is calculated with the relation Lγ,p,iso–Γ0–Ep,z (Liang et al. 2015). The solid and dashed lines are the best fit and its dispersion in the 3σ confidence level for the relation between logLrγ,p,iso and logLγ,p,iso."
        ],
        "imgs": [
            "$2305.00847v1-Figure2-1.png",
            "$2305.00847v1-Figure3-1.png",
            "$2305.00847v1-Figure4-1.png",
            "$2305.00847v1-Figure5-1.png",
            "$2305.00847v1-Figure7-1.png",
            "$2305.00847v1-Figure8-1.png"
        ]
    },
    {
        "id": "2305.00849",
        "abstract": "  The covariance matrix adaptation evolution strategy (CMA-ES) is an efficient\ncontinuous black-box optimization method. The CMA-ES possesses many attractive\nfeatures, including invariance properties and a well-tuned default\nhyperparameter setting. Moreover, several components to specialize the CMA-ES\nhave been proposed, such as noise handling and constraint handling. To utilize\nthese advantages in mixed-integer optimization problems, the CMA-ES with margin\nhas been proposed. The CMA-ES with margin prevents the premature convergence of\ndiscrete variables by the margin correction, in which the distribution\nparameters are modified to leave the generation probability for changing the\ndiscrete variable. The margin correction has been applied to\n($\\mu/\\mu_\\mathrm{w}$,$\\lambda$)-CMA-ES, while this paper introduces the margin\ncorrection into (1+1)-CMA-ES, an elitist version of CMA-ES. The (1+1)-CMA-ES is\noften advantageous for unimodal functions and can be computationally less\nexpensive. To tackle the performance deterioration on mixed-integer\noptimization, we use the discretized elitist solution as the mean of the\nsampling distribution and modify the margin correction not to move the elitist\nsolution. The numerical simulation using benchmark functions on mixed-integer,\ninteger, and binary domains shows that (1+1)-CMA-ES with margin outperforms the\nCMA-ES with margin and is better than or comparable with several specialized\nmethods to a particular search domain.\n",
        "title": "(1+1)-CMA-ES with Margin for Discrete and Mixed-Integer Problems",
        "texts": [
            "Figure 1: Comparison of the (1+1)-CMA-ES with margin with and without discretization of the mean vector.",
            "Figure 2: The medians and interquartile ranges of the number of evaluations on the mixed-integer optimization problems. The success rates are also shown if they are not one.",
            "Figure 3: The medians and interquartile ranges of the number of evaluations over 50 independent trials on the integer optimization problems. We note that all trials were successful.",
            "Figure 4: The medians and interquartile ranges of the number of evaluations over 50 independent trials on the binary optimization problems. We note that all trials were successful.",
            "Figure 5: The success rate of the CMA-ES with margin and the (1+1)-CMA-ES with margin not applied post-process on the discrete optimization problems. The success rates were computed over 50 independent trials.",
            "Table 1: Recommended hyperparameter setting of the (1+1)- CMA-ES with margin."
        ],
        "imgs": [
            "$2305.00849v1-Figure1-1.png",
            "$2305.00849v1-Figure2-1.png",
            "$2305.00849v1-Figure3-1.png",
            "$2305.00849v1-Figure4-1.png",
            "$2305.00849v1-Figure5-1.png",
            "$2305.00849v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00851",
        "abstract": "  Many works show that node-level predictions of Graph Neural Networks (GNNs)\nare unrobust to small, often termed adversarial, changes to the graph\nstructure. However, because manual inspection of a graph is difficult, it is\nunclear if the studied perturbations always preserve a core assumption of\nadversarial examples: that of unchanged semantic content. To address this\nproblem, we introduce a more principled notion of an adversarial graph, which\nis aware of semantic content change. Using Contextual Stochastic Block Models\n(CSBMs) and real-world graphs, our results uncover: $i)$ for a majority of\nnodes the prevalent perturbation models include a large fraction of perturbed\ngraphs violating the unchanged semantics assumption; $ii)$ surprisingly, all\nassessed GNNs show over-robustness - that is robustness beyond the point of\nsemantic change. We find this to be a complementary phenomenon to adversarial\nexamples and show that including the label-structure of the training graph into\nthe inference process of GNNs significantly reduces over-robustness, while\nhaving a positive effect on test accuracy and adversarial robustness.\nTheoretically, leveraging our new semantics-aware notion of robustness, we\nprove that there is no robustness-accuracy tradeoff for inductively classifying\na newly added node.\n",
        "title": "Revisiting Robustness in Graph Machine Learning",
        "texts": [
            "Figure 1: Average degree-dependent nodeclassification robustness. Semantic boundary indicates when the semantics (i.e., the most likely class) of a node of a given degree changes on average. Data from CSBM graphs2. All GNNs show robustness beyond the point of semantic change.",
            "Figure 10: The measured over-robustness with a perturbation model employing a test for degree preservation compared to the measured over-robustness for a perturbation model not employing a test for degree preservation. Concretely, Nettack with and without power-law degree distribution test for varying local budgets is employed. Degree preservation has close to no effects on the measured over-robustness. Plots with standard error.",
            "Figure 11: Over-Robustness Rover measured using `2-weak on CBA graphs with a budget of the degree of the target node. Plot with standard error.",
            "Figure 13: Test accuracy of models on test nodes on the CSBMs.",
            "Figure 14: Over-robustness Rover, i.e. the fraction of robustness beyond semantic change for different perturbation sets B∆(·). (Attack: `2-weak; Plots with Standard Error). A significant part of the measured robustness for every perturbation set can be attributed to over-robustness. The larger ∆, the larger the share of over-robustness.",
            "Figure 16: Conventional (Degree-Corrected) Robustness R(f) measured using Nettack.",
            "Figure 17: The harmonic mean of Radv and 1 − Rover, with Radv measured using Nettack and Rover using `2-weak.",
            "Figure 19: Conventional (Degree-Corrected) Robustness Rf measured using DICE.",
            "Figure 2: a) Decision boundary of classifier f follows a base classifier g except for the dotted line. b) Finite perturbation sets B(·) intersect only from one side with the dashed area. Over- and adversarial robustness are needed to characterize robustness.",
            "Figure 20: The harmonic mean of Radv and 1−Rover, with Radv measured using DICE and Rover using `2-weak.",
            "Figure 21: Semantic Aware Robustness Radv measured using SGA.",
            "Figure 22: Conventional (Degree-Corrected) Robustness Rf measured using SGA.",
            "Figure 23: The harmonic mean of Radv and 1−Rover, with Radv measured using SGA and Rover using `2-weak.",
            "Figure 26: The harmonic mean of Radv and 1 − Rover, with Radv measured using `2-strong and Rover using `2-weak.",
            "Figure 29: The harmonic mean of Radv and 1 − Rover, with Radv measured using `2-strong and Rover using GR-BCD.",
            "Figure 3: Fraction of Robustness beyond Semantic Change (Attack: `2-weak; Plot with Standard Error). (a) A large part of the measured robustness against Bdeg(·) can be attributed to over-robustness. (b) Applying `2-weak without budget restriction until it changes a classifiers prediction. Note that over-robustness can be significantly reduced by label propagation and for (b) that some over-robust models, especially for high K, show high adversarial robustness (Appendix J.6).",
            "Figure 32: Mean robustness per node degree. Error bars indicate the standard error of the mean over five model initializations.",
            "Figure 33: Mean robustness per node degree. Error bars indicate the standard error of the mean over eight data splits.",
            "Figure 34: Distribution of maximal (per-class) node robustness by node degree. Results are aggregated over different data splits. The box captures the lower quartile (Q1) and upper quartile (Q3) of the data. The whiskers are placed at Q1− 1.5 · IQR and Q3 + 1.5 · IQR, where IQR = Q3− Q1 is the interquartile range.",
            "Figure 35: Mean robustness per node degree. Error bars indicate the standard error of the mean over eight data splits.",
            "Figure 36: Distribution of maximal (per-class) node robustness by node degree. Results are aggregated over eight data splits. The box captures the lower quartile (Q1) and upper quartile (Q3) of the data. The whiskers are placed at Q1− 1.5 · IQR and Q3 + 1.5 · IQR, where IQR = Q3− Q1 is the interquartile range.",
            "Figure 5: Conceptual differences between over- and adversarial robustness. a) The decision boundary of classifier f follows the one of a base classifier g except for the dotted line. b) Finite perturbation budgets induce bounded perturbation sets B(·) intersecting only from one side with the dashed area. c) The red class is not seen because it lies in a low data likelihood region. d) Zoomed: A node whose perturbation set includes a region of adversarial and over-robust examples.",
            "Figure 6: (a) Degree distribution of a CSBM graph as parametrized in Section 5 (n = 1000). (b) Degree distribution of a CBA parametrized as described in Appendix H.",
            "Figure 7: Validation accuracies of the best performing hyperparameters of the different models on CSBMs. Note that GNNs for low K (high-structure relevance) underperform pure LP.",
            "Figure 8: Degree distribution by dataset.",
            "Figure 9: The measured over-robustness with a perturbation model employing a test for degree preservation compared to the measured over-robustness for a perturbation model not employing a test for degree preservation. Concretely, Nettack with and without power-law degree distribution test for varying local budgets is employed. Degree preservation has close to no effects on the measured over-robustness. Plots with standard error.",
            "Table 10: Percentage (%) of nodes for which we find perturbed graphs in B∆(·) violating semantic content preservation, i.e. with changed ground truth labels. Calculated by randomly connecting ∆ different-class nodes (`2-strong) to every target node. Note that for K=4.0 and K=5.0 structure is not necessary for good generalization (Table 1). Standard deviations are insignificant and hence, omitted.",
            "Table 16: Test accuracy mean and standard deviation over different data splits.",
            "Table 17: Model test accuracy and standard deviation over different data splits",
            "Table 18: Percentage of training, validation and test nodes per dataset for the semi-supervised setting.",
            "Table 2: Percentage (%) of test nodes for which perturbed graphs in B∆(·) violate semantic content preservation. Calculated by connecting ∆ different class nodes (`2-weak) to every target node. For K≥4.0 structure is not necessary for good generalization (Table 1). Results using other attacks are similar (see Appendix J.3). Standard deviations are insignificant and hence, omitted.",
            "Table 6: Average test accuracies of the models on the sampled test nodes on the CSBMs. Standard deviations rarely exceeds 1% and never 2% and hence, is omitted for brevity.",
            "Table 8: Percentage (%) of nodes for which we find perturbed graphs in B∆(·) violating semantic content preservation, i.e. with changed ground truth labels. Calculated by randomly connecting ∆ different-class nodes (DICE) to every target node. Note that for K=4.0 and K=5.0 structure is not necessary for good generalization (Table 1). Standard deviations are insignificant and hence, omitted.",
            "Table 9: Percentage (%) of nodes for which we find perturbed graphs in B∆(·) violating semantic content preservation, i.e. with changed ground truth labels. Calculated by randomly connecting ∆ different-class nodes (SGA) to every target node. Note that for K=4.0 and K=5.0 structure is not necessary for good generalization (Table 1). Standard deviations are insignificant and hence, omitted."
        ],
        "imgs": [
            "$2305.00851v2-Figure1-1.png",
            "$2305.00851v2-Figure10-1.png",
            "$2305.00851v2-Figure11-1.png",
            "$2305.00851v2-Figure13-1.png",
            "$2305.00851v2-Figure14-1.png",
            "$2305.00851v2-Figure16-1.png",
            "$2305.00851v2-Figure17-1.png",
            "$2305.00851v2-Figure19-1.png",
            "$2305.00851v2-Figure2-1.png",
            "$2305.00851v2-Figure20-1.png",
            "$2305.00851v2-Figure21-1.png",
            "$2305.00851v2-Figure22-1.png",
            "$2305.00851v2-Figure23-1.png",
            "$2305.00851v2-Figure26-1.png",
            "$2305.00851v2-Figure29-1.png",
            "$2305.00851v2-Figure3-1.png",
            "$2305.00851v2-Figure32-1.png",
            "$2305.00851v2-Figure33-1.png",
            "$2305.00851v2-Figure34-1.png",
            "$2305.00851v2-Figure35-1.png",
            "$2305.00851v2-Figure36-1.png",
            "$2305.00851v2-Figure5-1.png",
            "$2305.00851v2-Figure6-1.png",
            "$2305.00851v2-Figure7-1.png",
            "$2305.00851v2-Figure8-1.png",
            "$2305.00851v2-Figure9-1.png",
            "$2305.00851v2-Table10-1.png",
            "$2305.00851v2-Table16-1.png",
            "$2305.00851v2-Table17-1.png",
            "$2305.00851v2-Table18-1.png",
            "$2305.00851v2-Table2-1.png",
            "$2305.00851v2-Table6-1.png",
            "$2305.00851v2-Table8-1.png",
            "$2305.00851v2-Table9-1.png"
        ]
    },
    {
        "id": "2305.00855",
        "abstract": "  Environmentally-powered computer systems operate on renewable energy\nharvested from their environment, such as solar or wind, and stored in\nbatteries. While harvesting environmental energy has long been necessary for\nsmall-scale embedded systems without access to external power sources, it is\nalso increasingly important in designing sustainable larger-scale systems for\nedge applications. For sustained operations, such systems must consider not\nonly the electrical energy but also the thermal energy available in the\nenvironment in their design and operation. Unfortunately, prior work generally\nignores the impact of thermal effects, and instead implicitly assumes ideal\ntemperatures. To address the problem, we develop a thermodynamic model that\ncaptures the interplay of electrical and thermal energy in\nenvironmentally-powered computer systems. The model captures the effect of\nenvironmental conditions, the system's physical properties, and workload\nscheduling on performance. In evaluating our model, we distill the thermal\neffects that impact these systems using a small-scale prototype and a\nprogrammable incubator. We then leverage our model to show how considering\nthese thermal effects in designing and operating environmentally-powered\ncomputer systems of varying scales can improve their energy-efficiency,\nperformance, and availability.\n",
        "title": "Jointly Managing Electrical and Thermal Energy in Solar- and\n  Battery-powered Computer Systems",
        "texts": [
            "Figure 1: Environmentally-powered computer systems consist of processors powered by solar and batteries and include a cooling element (a). Common applications include small- to medium-scale embedded systems. e.g., for precision agriculture (b) and medium- to large-scale edge data centers (c). In both cases, systems may be exposed to highly variable temperatures.",
            "Figure 10: Temperature profiles of a single location in northeast United States across different seasons.",
            "Figure 13: Performance during summer for high (winteroptimal), medium (spring-optimal), and low (summeroptimal) insulation designs over various operating points.",
            "Figure 14: Performance comparison against Farmbeats. A thermal-aware operation outperforms Farmbeats thermalagnostic design during the summer and winter months. Both have the same performance during spring season.",
            "Figure 15: Performance comparison against a modified MultiExit Federated Edge Learning (ME-FEEL) approach [23]. A thermal-aware operation outperforms ME-FEEL by exiting in a higher stage leading to a higher training accuracy.",
            "Figure 2: A system’s usable battery capacity varies with both temperature (a) and discharge current (b).",
            "Figure 3: Energy-efficiency as a function of temperature (a), discharge current (b), and available battery capacity when charging at various temperature (c). For (a) and (b), the black points are experimental data and the red curves represent our model.",
            "Figure 4: Fan power as a function of insulation. Black points are experimental data and the red curve represents ourmodel.",
            "Figure 5: A simple and general thermodynamic model of an environmentally-powered computer system.",
            "Figure 6: The change in the enclosure’s temperature 𝑇𝑒𝑛𝑐 over time is a function of the (a) ambient temperature 𝑇𝑎𝑚𝑏 , (b) the enclosure’s thermal conductivity 𝑘 , and (c) the processor’s power usage 𝑃 .",
            "Figure 7: Small-scale prototype inside the incubator. the product to be cooled, and must be determined either experimentally using anemometers and manometers to measure the air speed and pressure, respectively, or using different computer-aided design (CAD) software to design and calculate airflow characteristics. Either method will yield system pressure requirements that increase with the air flow. The pressure exerted by the fan reduces as its air flow increases, and delivers the highest air flow when the back pressure is lowest. The intersection of the two curves is the operating point of the fan for the given system. We assume our model uses a fan that has the required airflow at its operating point. The power consumption of a variable speed fan has a cubic relationship with the change in the airflow. That is, if the airflow of the fan doubles, its power consumption increase by 8×. This relationship is shown in the equation below.",
            "Figure 8: An overview of thermodynamic model use cases. Figure 6 also validates our model: the curves represent our model, while datapoints represent the mean temperature change across five experiments, where error bars represent the max and min.",
            "Figure 9: Work done using i) naive and ii) thermal-aware scheduling that exploits the electrical/thermal feedback loop. priority. It is possible that no configuration meets the desired level of performance for the provided specifications.",
            "Table 1:Model notations, definitions, and units. shown below, where𝑚𝑒𝑛𝑐 =𝑚𝑎𝑖𝑟 +𝑚𝑏𝑎𝑡 +𝑚𝑝𝑟𝑜𝑐 or the total mass within the enclosure. Here, we assume the enclosure includes only processing elements, batteries, and ambient air."
        ],
        "imgs": [
            "$2305.00855v1-Figure1-1.png",
            "$2305.00855v1-Figure10-1.png",
            "$2305.00855v1-Figure13-1.png",
            "$2305.00855v1-Figure14-1.png",
            "$2305.00855v1-Figure15-1.png",
            "$2305.00855v1-Figure2-1.png",
            "$2305.00855v1-Figure3-1.png",
            "$2305.00855v1-Figure4-1.png",
            "$2305.00855v1-Figure5-1.png",
            "$2305.00855v1-Figure6-1.png",
            "$2305.00855v1-Figure7-1.png",
            "$2305.00855v1-Figure8-1.png",
            "$2305.00855v1-Figure9-1.png",
            "$2305.00855v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00857",
        "abstract": "  User interaction data is an important source of supervision in counterfactual\nlearning to rank (CLTR). Such data suffers from presentation bias. Much work in\nunbiased learning to rank (ULTR) focuses on position bias, i.e., items at\nhigher ranks are more likely to be examined and clicked. Inter-item\ndependencies also influence examination probabilities, with outlier items in a\nranking as an important example. Outliers are defined as items that observably\ndeviate from the rest and therefore stand out in the ranking. In this paper, we\nidentify and introduce the bias brought about by outlier items: users tend to\nclick more on outlier items and their close neighbors. To this end, we first\nconduct a controlled experiment to study the effect of outliers on user clicks.\nNext, to examine whether the findings from our controlled experiment generalize\nto naturalistic situations, we explore real-world click logs from an e-commerce\nplatform. We show that, in both scenarios, users tend to click significantly\nmore on outlier items than on non-outlier items in the same rankings. We show\nthat this tendency holds for all positions, i.e., for any specific position, an\nitem receives more interactions when presented as an outlier as opposed to a\nnon-outlier item. We conclude from our analysis that the effect of outliers on\nclicks is a type of bias that should be addressed in ULTR. We therefore propose\nan outlier-aware click model that accounts for both outlier and position bias,\ncalled outlier-aware position-based model ( OPBM). We estimate click\npropensities based on OPBM ; through extensive experiments performed on both\nreal-world e-commerce data and semi-synthetic data, we verify the effectiveness\nof our outlier-aware click model. Our results show the superiority of OPBM\nagainst baselines in terms of ranking performance and true relevance\nestimation.\n",
        "title": "On the Impact of Outlier Bias on User Clicks",
        "texts": [
            "Figure 1: Revisit count (a) and mouse hovering time (b) for the two conditions of one of our user study examples. The position of the target item is marked by an asterisk. The plots show that the user engagement with the target item is higher when presented as an outlier (condition I)",
            "Figure 2: Comparison of CTR for outlier and non-outlier items per rank. CTR is consistently higher for outlier items.",
            "Figure 3: CTR per rank for abnormal rankings grouped by the outliers’ position. The position of the outlier is marked with an asterisk. The values are smoothed using a SavitzkyGolay filter. Best viewed in color.",
            "Figure 5: Comparison of different estimators in term of NDCG@10 ((a) MSLR and (b) Yahoo!) and CE ((c) MSLR and (d) Yahoo!) under varying levels of outlier bias. Results are averaged over 8 runs; shaded area indicates the standard deviation.",
            "Figure 6: Comparison of OPBM and OPBM 𝑙𝑎𝑧𝑦 on varying sizes of queries with multiple outliers.",
            "Table 1: CTR of the target item’s position in both examples of our user study. The target item recieves more clicks when shown as an outlier (condition I).",
            "Table 2: Description of the observable features used to represent the items.",
            "Table 3: Users’ interactions with the outlier and non-outlier items, averaged over all abnormal rankings. We used Student’s t-test with 𝑝 < 0.001 for statistical significance test.",
            "Table 4: Comparison of OPBM and PBM on the Yahoo! and MSLR datasets, in terms of NDCG@10 andCE. A superscript ∗ indicates a significant difference compared to the secondbest performing method with 𝑝 < 0.001.",
            "Table 5: Comparison of OPBM, OPBM𝑙𝑎𝑧𝑦 and OPM on the Yahoo! and MSLR datasets, with outlier bias severity of 𝛼 = 0.75, and in terms of NDCG@10 and CE. A superscript ∗ indicates a significant difference with PBM with 𝑝 < 0.001."
        ],
        "imgs": [
            "$2305.00857v1-Figure1-1.png",
            "$2305.00857v1-Figure2-1.png",
            "$2305.00857v1-Figure3-1.png",
            "$2305.00857v1-Figure5-1.png",
            "$2305.00857v1-Figure6-1.png",
            "$2305.00857v1-Table1-1.png",
            "$2305.00857v1-Table2-1.png",
            "$2305.00857v1-Table3-1.png",
            "$2305.00857v1-Table4-1.png",
            "$2305.00857v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00865",
        "abstract": "  We perform a detailed study of linear perturbations of the JMaRT family of\nnon-BPS smooth horizonless solutions of type IIB supergravity beyond the\nnear-decoupling limit. In addition to the unstable quasi normal modes (QNMs)\nresponsible for the ergo- region instability, already studied in the\nliterature, we find a new class of `charged' unstable modes with positive\nimaginary part, that can be interpreted in terms of the emission of charged\n(scalar) quanta with non zero KK momentum. We use both matched asymptotic\nexpansions and numerical integration methods. Moreover, we exploit the recently\ndiscovered correspondence between JMaRT perturbation theory, governed by a\nReduced Confluent Heun Equation, and the quantum Seiberg-Witten (SW) curve of\n$\\mathcal{N} = 2$ SYM theory with gauge group SU(2) and $N_f = (0,2)$ flavours.\n",
        "title": "Charge instability of JMaRT geometries",
        "texts": [
            "Figure 2: Plot of the parameters λ = √ a2/a1 and σ = √∏ i tanh δi for different values of m and n. Points connected by lines have the same value of m, ranging from m = 3 (lowest line) to m = 15 (highest line), with n increasing from n = 1 left-most to n = m− 1 right-most."
        ],
        "imgs": [
            "$2305.00865v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00866",
        "abstract": "  Segment Anything Model (SAM) has attracted significant attention recently,\ndue to its impressive performance on various downstream tasks in a zero-short\nmanner. Computer vision (CV) area might follow the natural language processing\n(NLP) area to embark on a path from task-specific vision models toward\nfoundation models. However, deep vision models are widely recognized as\nvulnerable to adversarial examples, which fool the model to make wrong\npredictions with imperceptible perturbation. Such vulnerability to adversarial\nattacks causes serious concerns when applying deep models to security-sensitive\napplications. Therefore, it is critical to know whether the vision foundation\nmodel SAM can also be fooled by adversarial attacks. To the best of our\nknowledge, our work is the first of its kind to conduct a comprehensive\ninvestigation on how to attack SAM with adversarial examples. With the basic\nattack goal set to mask removal, we investigate the adversarial robustness of\nSAM in the full white-box setting and transfer-based black-box settings. Beyond\nthe basic goal of mask removal, we further investigate and find that it is\npossible to generate any desired mask by the adversarial attack.\n",
        "title": "Attack-SAM: Towards Attacking Segment Anything Model With Adversarial\n  Examples",
        "texts": [
            "Figure 1: Attack SAM to remove the masks. Figure (a) refers to the clean image with the location of point prompt marked in green star. Figure (b) and (c) are adversarial images generated by FGSM and PGD attacks, respectively. The white area in Figure (d) (e) (f) refer to masks predicted by SAM based on the given prompt and images in Figure (a) (b) (c), respectively. The results in Figure (e) (f) show that SAM is vulnerable to adversarial attacks considering the reduce white area compared to Figure (d).",
            "Figure 10: Towards generating any desired masks (setting 2) . The Maskclean and Maskadv in (c) (d) are generated on xclean and xadv in (a) (b) , respectively. With adversarial attack, the mask from same image but different point prompt in (d) could be generated.",
            "Figure 11: Towards generating any desired masks (setting 3) . The masks in (d) (e) (f) are generated on images in (a) (b) (c) , respectively. With (b) as a reference image and (e) as a reference mask, the xadv in (c) could predict a Maskadv in (f) that is similar to Maskreference in (e) .",
            "Figure 2: Preliminary study for corss-prompt transfer. (a) The adversarial image xpgd is Figure 1(c) is adopted for mask prediction with prompt (prompttarget) marked as a green star. Figure (b) and (c) are predicted masks based on (prompttarget, xclean) and (prompttarget, xpgd) , respectively. Note that prompttarget in (a) is different from the prompt (promptsource) when generating xpgd in Figure 1.",
            "Figure 4: Masks predicted on multiple (x, prompttarget) pairs in cross-prompt transfer task, with different numbers of promptsource (K) when generating adversarial images. With each colored region referring to a mask, the valid masks Maskadv reduce significantly as K increases.",
            "Figure 5: Masks predicted on multiple (x, prompt) pairs in cross-task transfer task. The xadv is generated by a pretrained ViT model for label classification task, and then used for mask generation with SAM on multiple prompts. Compared to Maskclean in (c) , several masks are removed in Maskadv in (d) but there are still masks remain.",
            "Figure 6: Results of mask enlargement attack. The Maskclean and Maskadv in (c) (d) are generated on xclean and xadv in (a) (b), respectively. Results show that the mask predicted by SAM could be enlarged by the adversarial attack.",
            "Figure 7: Results of mask shift attack. The Maskclean and Maskadv in (d) (e) (f) are generated on xclean and xadv in (a) (b) (c) , respectively. With adversarial attack, the original mask in (d) could be shifted by either duplicating in (e) or just translating in (f) to a new position.",
            "Figure 8: Results of mask flipping attack. The Maskclean and Maskadv in (d) (e) (f) are generated on xclean and xadv in (a) (b) (c) , respectively. With adversarial attack, the original mask in (d) could be flipped by either duplicating in (e) or just flipped in (f) .",
            "Figure 9: Towards generating any desired masks (setting 1). The Maskclean and Maskadv in (d) (e) (f) are generated on xclean and xadv in (a) (b) (c), respectively. With adversarial attack, manually designed mask in (e) (f) could be generated at a random position.",
            "Table 1: Results of mIoU in removing mask attack on SAM. Both FGSM and PGD-10 attack achieve much lower mIoU than the setting of no attack, while PGD-10 with ClipMSE achieves the lowest mIoU, outperforming other settings."
        ],
        "imgs": [
            "$2305.00866v2-Figure1-1.png",
            "$2305.00866v2-Figure10-1.png",
            "$2305.00866v2-Figure11-1.png",
            "$2305.00866v2-Figure2-1.png",
            "$2305.00866v2-Figure4-1.png",
            "$2305.00866v2-Figure5-1.png",
            "$2305.00866v2-Figure6-1.png",
            "$2305.00866v2-Figure7-1.png",
            "$2305.00866v2-Figure8-1.png",
            "$2305.00866v2-Figure9-1.png",
            "$2305.00866v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00867",
        "abstract": "  The decreasing cost and improved sensor and monitoring system technology\n(e.g. fiber optics and strain gauges) have led to more measurements in close\nproximity to each other. When using such spatially dense measurement data in\nBayesian system identification strategies, the correlation in the model\nprediction error can become significant. The widely adopted assumption of\nuncorrelated Gaussian error may lead to inaccurate parameter estimation and\noverconfident predictions, which may lead to sub-optimal decisions. This paper\naddresses the challenges of performing Bayesian system identification for\nstructures when large datasets are used, considering both spatial and temporal\ndependencies in the model uncertainty. We present an approach to efficiently\nevaluate the log-likelihood function, and we utilize nested sampling to compute\nthe evidence for Bayesian model selection. The approach is first demonstrated\non a synthetic case and then applied to a (measured) real-world steel bridge.\nThe results show that the assumption of dependence in the model prediction\nuncertainties is decisively supported by the data. The proposed developments\nenable the use of large datasets and accounting for the dependency when\nperforming Bayesian system identification, even when a relatively large number\nof uncertain parameters is inferred.\n",
        "title": "Bayesian system identification for structures considering spatial and\n  temporal correlation",
        "texts": [
            "Figure 1: Illustration of the impact of correlation in the model prediction error for the case of a simply supported beam with two sensors.",
            "Figure 10: Comparison of posterior mean and 90% HD CIs for models with multiplicative uncertainty structure.",
            "Figure 11:Comparison of posteriormean and 90%HDCIs formodelswith additive uncertainty structure.",
            "Figure 12: Comparison of posterior mean and 90% highest density credible intervals for models with multiplicative uncertainty structure.",
            "Figure 13: Comparison of posterior mean and 90% highest density credible intervals for models with additive uncertainty structure.",
            "Figure 14: Comparison of median and 90% credible intervals of the posterior predictive stress distribution per model and sensor at the location of peak stress for a truck on the right lane. The red dashed line denotes the measurements.",
            "Figure 15: Peak stress response at selected sensors as a function of log10 (𝐾r) (left) and log10 (𝐾v) (right).",
            "Figure 2: Overview of the Bayesian inference approach used in this work.",
            "Figure 3: Illustration of space and time coordinate system. Influence lines along the time axis 𝑡 are obtained for each sensor position 𝑥.",
            "Figure 5: Illustration of theĲsselbridge FEmodel (left), lateral load function (right), and parametrization of the FE model (bottom).",
            "Figure 6: Approximate location of sensors on the right girder. The prefix \"H\" is used to denote the sensors on the main structure of the Ĳsselbridge.",
            "Figure 7: Stress influence lines obtained from the measurement campaign. The blue and red lines correspond to the measured response for different truck positions in the transverse direction of the bridge.",
            "Figure 8: Rectilinear grid of sensor and measurement positions considered in the synthetic case study for 𝑁𝑥 = 𝑁𝑡 = {1, 5, 10}.",
            "Figure 9: Relative error between MAP estimates of probabilistic model parameters and ground truth as a function of grid size.",
            "Table 1: Interpretation of the Bayes factor from Jeffreys (2003).",
            "Table 10: Overview of models used in the case with real-world measurements using multiple sensors. See Table 3 for the meaning of the abbreviations and the details of the correlation function.",
            "Table 12: Controlled loading test parameters.",
            "Table 13: Properties of truck used in controlled load tests.",
            "Table 2: Names, labels and positions of strain gauges placed on the Ĳsselbridge main girder. The positions are measured from pillar F (see Figure 4).",
            "Table 3: List of correlation functions and corresponding parameters.",
            "Table 4: Description and uniform prior distribution bounds of physical model parameters.",
            "Table 5: Description and uniform prior distribution bounds of probabilistic model parameters.",
            "Table 6: Overview of models used in the case with synthetic measurements. See Table 3 for the meaning of the abbreviations and the details of the correlation function.",
            "Table 7: Log-evidence per model as a function of the number of measurements in space and time for different ground truth models, averaged over 20 randomly generated datasets. Underscores denote the ground truth model used to generate the data and bold type denotes the highest evidence.",
            "Table 8: Overview ofmodels used in the case with real-worldmeasurements. See Table 3 for themeaning of the abbreviations and the details of the correlation function.",
            "Table 9: NFE required for convergence rounded to the nearest thousandth, log-evidence, posterior probability and Bayes factors per model."
        ],
        "imgs": [
            "$2305.00867v1-Figure1-1.png",
            "$2305.00867v1-Figure10-1.png",
            "$2305.00867v1-Figure11-1.png",
            "$2305.00867v1-Figure12-1.png",
            "$2305.00867v1-Figure13-1.png",
            "$2305.00867v1-Figure14-1.png",
            "$2305.00867v1-Figure15-1.png",
            "$2305.00867v1-Figure2-1.png",
            "$2305.00867v1-Figure3-1.png",
            "$2305.00867v1-Figure5-1.png",
            "$2305.00867v1-Figure6-1.png",
            "$2305.00867v1-Figure7-1.png",
            "$2305.00867v1-Figure8-1.png",
            "$2305.00867v1-Figure9-1.png",
            "$2305.00867v1-Table1-1.png",
            "$2305.00867v1-Table10-1.png",
            "$2305.00867v1-Table12-1.png",
            "$2305.00867v1-Table13-1.png",
            "$2305.00867v1-Table2-1.png",
            "$2305.00867v1-Table3-1.png",
            "$2305.00867v1-Table4-1.png",
            "$2305.00867v1-Table5-1.png",
            "$2305.00867v1-Table6-1.png",
            "$2305.00867v1-Table7-1.png",
            "$2305.00867v1-Table8-1.png",
            "$2305.00867v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00869",
        "abstract": "  Functions of the ratio of the densities $p/q$ are widely used in machine\nlearning to quantify the discrepancy between the two distributions $p$ and $q$.\nFor high-dimensional distributions, binary classification-based density ratio\nestimators have shown great promise. However, when densities are well\nseparated, estimating the density ratio with a binary classifier is\nchallenging. In this work, we show that the state-of-the-art density ratio\nestimators perform poorly on well-separated cases and demonstrate that this is\ndue to distribution shifts between training and evaluation time. We present an\nalternative method that leverages multi-class classification for density ratio\nestimation and does not suffer from distribution shift issues. The method uses\na set of auxiliary densities $\\{m_k\\}_{k=1}^K$ and trains a multi-class\nlogistic regression to classify the samples from $p, q$, and $\\{m_k\\}_{k=1}^K$\ninto $K+2$ classes. We show that if these auxiliary densities are constructed\nsuch that they overlap with $p$ and $q$, then a multi-class logistic regression\nallows for estimating $\\log p/q$ on the domain of any of the $K+2$\ndistributions and resolves the distribution shift problems of the current\nstate-of-the-art methods. We compare our method to state-of-the-art density\nratio estimators on both synthetic and real datasets and demonstrate its\nsuperior performance on the tasks of density ratio estimation, mutual\ninformation estimation, and representation learning. Code:\nhttps://www.blackswhan.com/mdre/\n",
        "title": "Estimating the Density Ratio between Distributions with High Discrepancy\n  using Multinomial Logistic Regression",
        "texts": [
            "Figure 1: BDRE vs proposed MDRE on estimation of log density ratio where p = N (−1, 0.1) and q = N (1, 0.2). For MDRE, the auxillary distribution m is Cauchy C(0, 1). Plots (a) and (c) show the class probabilities P (Y |x) learned for BDRE and MDRE respectively overlayed on the plots of p, q and m. Plots (b) and (d) show the estimated log density-ratio by BDRE and MDRE respectively. Using auxiliary distribution m allows MDRE to better estimate the log density-ratio.",
            "Figure 10: Diagnostic plot for a high dimensional experiment.",
            "Figure 11: Diagnostic plot for a high dimensional experiment with randomized means.",
            "Figure 12: SpatialMultiOmniglot representation learning results with same encoder for f and g.",
            "Figure 13: dM/dQ on mixtures of distributions with finite support",
            "Figure 2: TRE for p = N (−1, 0.1) and q = N (1, 0.2) from Figure 1. In all scatter plots, x-axis denotes the sampling distribution and y-axis denotes the log-density-ratio. The density plot in the first row shows p, q and the 3 waymarks; the density plot in the second row shows p and q only. The scatter plots in the first row show individual density ratio estimators evaluated on samples from their corresponding training data (denominator density), demonstrating accurate estimation on the training set. The scatter plots in the second show individual density ratio estimators evaluated on samples from p and q. The estimation accuracy has degraded notably due to the train-eval distribution shift. The last row shows the performance of the overall density ratio estimator on samples from p,m1,m2,m3, q. We see that the overall ratio estimate is significantly affected by the deterioration of the individual ratio estimates, illustrating the sensitivity of TRE to distribution shift problems in case of well-separated distributions.",
            "Figure 3: MDRE with m = Cauchy(0, 1). The first density plots shows the target densities as well as the auxiliary distribution (in green, hard to see due to heavy tail and the range of axes). The three scatter plots show the estimated (red) and true (blue) density ratio p/q evaluated on samples from p,m, and q. MDRE accurately estimates the ratio across the input domain. Contrast with Figure 2.",
            "Figure 4: MDRE using TRE’s auxiliary distributions. Each scatter plot shows the overall log-density ratio estimates on samples from the distribution on the x-axis (MDRE in red and true ratio in blue). MDRE is capable of accurately estimating ratios on all samples. Contrast with the bottom row of Figure 2.",
            "Figure 5: Log density-ratio estimates corresponding to the numbers reported in Table 1. Note that the ground truth and MDRE curves are overlapping, while all the other estimators are significantly worse.",
            "Figure 6: Bayesian analysis of MDRE for p = N (−1.0, 0.1), q = N (1.0, 0.2).",
            "Figure 7: SpatialMultiOmniglot representation learning results. Plot (a) shows the MI estimated by the three methods, MDRE is able to estimate the ground truth MI very accurately. Plot (b) shows the resulting classification accuracy and plot (c) the impact of varying the number of auxiliary distributions on MI estimation with MDRE.",
            "Figure 8: 1D density ratio estimation analysis. Figure 8a evaluates the log density ratios on uniform samples inside the domain of the respective training distribution. Figure 8b evaluates the log density ratios on uniform samples from an expanded domain of the training distribution. The shading represents 1 standard deviation of the estimates.",
            "Figure 9: Uncertainty quantification for MDRE estimator. We plot the 3x standard deviation around the mean in light blue. In plots (c) and (d) the bars show the means of p and q.",
            "Table 1: 1D density ratio estimation task for p and q with large first-order and higher-order differences. In all cases, MDRE outperforms all the baselines.",
            "Table 2: High-dimensional mutual information estimation task. MDRE is able to accurately estimate the MI often by a very large margins.",
            "Table 4: MDRE on 1D density ratio estimation for three settings of sample sizes. MDRE estimates the density ratio well for all the three settings.",
            "Table 5: Experiment configurations for Table 1 of main text and Table 4 of Appendix C",
            "Table 6: Configuration of MDRE for the high dimensional experiments. LM stands for Linear Mixing"
        ],
        "imgs": [
            "$2305.00869v1-Figure1-1.png",
            "$2305.00869v1-Figure10-1.png",
            "$2305.00869v1-Figure11-1.png",
            "$2305.00869v1-Figure12-1.png",
            "$2305.00869v1-Figure13-1.png",
            "$2305.00869v1-Figure2-1.png",
            "$2305.00869v1-Figure3-1.png",
            "$2305.00869v1-Figure4-1.png",
            "$2305.00869v1-Figure5-1.png",
            "$2305.00869v1-Figure6-1.png",
            "$2305.00869v1-Figure7-1.png",
            "$2305.00869v1-Figure8-1.png",
            "$2305.00869v1-Figure9-1.png",
            "$2305.00869v1-Table1-1.png",
            "$2305.00869v1-Table2-1.png",
            "$2305.00869v1-Table4-1.png",
            "$2305.00869v1-Table5-1.png",
            "$2305.00869v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00871",
        "abstract": "  Stream processing systems (SPSs) have been designed to process data streams\nin real-time, allowing organizations to analyze and act upon data on-the-fly,\nas it is generated. However, handling sensitive or personal data in these\nmultilayered SPSs that distribute resources across sensor, fog, and cloud\nlayers raises privacy concerns, as the data may be subject to unauthorized\naccess and attacks that can violate user privacy, hence facing regulations such\nas the GDPR across the SPS layers. To address these issues, different\nprivacy-preserving mechanisms (PPMs) are proposed to protect user privacy in\nSPSs. Yet, selecting and applying such PPMs in SPSs is challenging, since they\nmust operate in real-time while tolerating little overhead. The multilayered\nnature of SPSs complicates privacy protection because each layer may confront\ndifferent privacy threats, which must be addressed by specific PPMs. To\novercome these challenges, we present Prinseps, our comprehensive privacy\nvision for SPSs. Towards this vision, we (1) identify critical privacy threats\non different layers of the multilayered SPS, (2) evaluate the effectiveness of\nexisting PPMs in addressing such threats, and (3) integrate privacy\nconsiderations into the decision-making processes of SPSs.\n",
        "title": "No One Size (PPM) Fits All: Towards Privacy in Stream Processing Systems",
        "texts": [
            "Figure 1: Typical workflow of an SPS based on our running example of a human activity recognition (HAR) application enabled by wearable sensors.",
            "Figure 2: Multilayered SPS architecture used in Prinseps, consisting of nodes",
            "Figure 3: Overview of Prinseps privacy-preserving architecture for SPSs.",
            "Table 2: Gender inference accuracy on five body locations for four HAR events before and after applying ObscureNet.",
            "Table 3: Event inference accuracy on five body locations for four HAR events before and after applying ObscureNet."
        ],
        "imgs": [
            "$2305.00871v2-Figure1-1.png",
            "$2305.00871v2-Figure2-1.png",
            "$2305.00871v2-Figure3-1.png",
            "$2305.00871v2-Table2-1.png",
            "$2305.00871v2-Table3-1.png"
        ]
    },
    {
        "id": "2305.00873",
        "abstract": "  To defend the inference attacks and mitigate the sensitive information\nleakages in Federated Learning (FL), client-level Differentially Private FL\n(DPFL) is the de-facto standard for privacy protection by clipping local\nupdates and adding random noise. However, existing DPFL methods tend to make a\nsharp loss landscape and have poor weight perturbation robustness, resulting in\nsevere performance degradation. To alleviate these issues, we propose a novel\nDPFL algorithm named DP-FedSAM, which leverages gradient perturbation to\nmitigate the negative impact of DP. Specifically, DP-FedSAM integrates\nSharpness Aware Minimization (SAM) optimizer to generate local flatness models\nwith improved stability and weight perturbation robustness, which results in\nthe small norm of local updates and robustness to DP noise, thereby improving\nthe performance. To further reduce the magnitude of random noise while\nachieving better performance, we propose DP-FedSAM-$top_k$ by adopting the\nlocal update sparsification technique. From the theoretical perspective, we\npresent the convergence analysis to investigate how our algorithms mitigate the\nperformance degradation induced by DP. Meanwhile, we give rigorous privacy\nguarantees with R\\'enyi DP, the sensitivity analysis of local updates, and\ngeneralization analysis. At last, we empirically confirm that our algorithms\nachieve state-of-the-art (SOTA) performance compared with existing SOTA\nbaselines in DPFL.\n",
        "title": "Towards the Flatter Landscape and Better Generalization in Federated\n  Learning under Client-level Differential Privacy",
        "texts": [
            "Fig. 1. Loss landscapes (a) and surface contours (b) comparison between DP-FedAvg (left) and FedAvg (right).",
            "Fig. 2. The averaged testing accuracy on EMNIST, CIFAR-10 and CIFAR-100 under symmetric noise for all compared methods.",
            "Fig. 3. Comparison of Loss landscapes (a) and surface contours (b). Compared with DP-FedAvg in the left of Figure 1 (a) with the same setting, DPFedSAM has a flatter landscape with both better generalization (flat minima, see the left of Figure 3 (a)) and higher weight perturbation robustness (see the left of Figure 3 (b)). Meanwhile, DP-FedSAM-topk also features similar advantages compared with DP-FedSAM in the right of Figure 3 (a) and (b).",
            "Fig. 4. Norm distribution and average norm of local updates.",
            "Fig. 5. Impact of hyper-parameters: perturbation radius ρ, local iteration steps K, total clients size M .",
            "TABLE 1 Averaged training accuracy (%) and testing accuracy (%) on two data in both IID and Non-IID settings for all compared methods.",
            "TABLE 2 Performance comparison under different privacy budgets ε on CIFAR-10 and CIFAR-100.",
            "TABLE 3 Performance comparison under different sparsity ratio p.",
            "TABLE 4 The averaged training accuracy and testing accuracy."
        ],
        "imgs": [
            "$2305.00873v1-Figure1-1.png",
            "$2305.00873v1-Figure2-1.png",
            "$2305.00873v1-Figure3-1.png",
            "$2305.00873v1-Figure4-1.png",
            "$2305.00873v1-Figure5-1.png",
            "$2305.00873v1-Table1-1.png",
            "$2305.00873v1-Table2-1.png",
            "$2305.00873v1-Table3-1.png",
            "$2305.00873v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00877",
        "abstract": "  Gravitational waves can generate electromagnetic effects inside a strong\nelectric or magnetic field within the Standard Model and general relativity.\nHere we propose using a quarterly split cavity and LC(inductor and\ncapacitor)-resonance circuit to detect a high-frequency gravitational wave from\n0.1 MHz to GHz. We perform a full 3D simulation of the cavity's signal for\nsensitivity estimate. Our sensitivity depends on the coherence time scale of\nthe high-frequency gravitational wave sources and the volume size of the split\ncavity. We discuss the resonant measurement schemes for narrow-band\ngravitational wave sources and also a non-resonance scheme for broadband\nsignals. For a meter-sized split cavity under a 14 Tesla magnetic field, the LC\nresonance enhanced sensitivity to the gravitational wave strain is expected to\nreach $h\\sim 10^{-20}$ around $10$ MHz.\n",
        "title": "Novel high-frequency gravitational waves detection with split cavity",
        "texts": [
            "FIG. 1: We plot the jeff with only cross/plus mode at z=0 in x-y plane in Eq.2. The arrows denote the direction of jµ and the different color scales represent the magnitude.",
            "FIG. 2: Split cavity: the top, bottom, and quarterly split periphery of the cylinder cavity are separated by insulation to form induction signal currents through the connection wiring. The slit angle is 3◦ in this case. The connecting wires and amplification LC circuit are also shown.",
            "FIG. 3: EM response simulation of the incoming gravitational waves h = 10−10 in the z-direction with a quarterly split cylinder R = 1cm and L = 5cm. The unit is V/m.",
            "FIG. 4: Projected sensitivity to the stress of a GW signal, with coherent factor Q=106 and 103, corresponding to narrowband searches. For comparison, existing experimental limits from ABRACADABRA[54, 55], SHAFT[56], and the projected sensitivity from DM-Radio[57, 58] are also shown in plot.",
            "FIG. 5: SNR=3 sensitivity for transient events, like PBH merger, and BH superradiance collapse. We use a bandwidth of ∆f = f for sensitivity estimate.",
            "TABLE I: Selected values of the cavity’s effective capacitance C and the accumulated charge q from EM simulations. The GW is assumed to propagate along the cavity axis with an amplitude h0 = 10−10 . The left and right columns show two experimental scales: a multi-center-sized cavity with f211 = 1.5× 1010 Hz, and a meter-sized cavity with f211 = 2.1× 108 Hz. Notice here our working frequencies are away from the closed cavity’s resonance frequencies."
        ],
        "imgs": [
            "$2305.00877v1-Figure1-1.png",
            "$2305.00877v1-Figure2-1.png",
            "$2305.00877v1-Figure3-1.png",
            "$2305.00877v1-Figure4-1.png",
            "$2305.00877v1-Figure5-1.png",
            "$2305.00877v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00879",
        "abstract": "  The baryon-meson scattering amplitude is computed within the $1/N_c$\nexpansion of QCD, where $N_c$ is the number of color charges. The most general\nexpression is obtained by accounting for explicitly the effects of the\ndecuplet-octet baryon mass difference and perturbative flavor $SU(3)$ symmetry\nbreaking. Although the resultant expression is general enough that it can be\napplied to any incoming and outgoing baryons and mesons, provided that the\nGell-Mann--Nishijima scheme is respected, results for $N\\pi$ scattering\nprocesses are explicitly dealt with. With these, some isospin relations are\nverified to be valid at the physical value $N_c=3$. The expressions obtained\nhere represent a first effort toward understanding scattering processes in the\ncontext of the $1/N_c$ expansion.\n",
        "title": "Baryon-meson scattering amplitude in the $1/N_c$ expansion",
        "texts": [
            "FIG. 1: Feynman diagrams for the tree-level scattering process (1"
        ],
        "imgs": [
            "$2305.00879v2-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00885",
        "abstract": "  Software Development (SD) is remarkably dynamic and is critically dependent\non the knowledge acquired by the project's software developers as the project\nprogresses. Software developers need to understand large amounts of information\nrelated to the tasks at hand. This information (context) is often not explicit,\nas it can be lost in large documentation repositories, a team member's brain,\nor beyond their cognitive memory capacity. These contexts include tool\nfeatures, integration strategies, data structures, code syntax, approaches to\ntasks, project definitions, and even implicit or tacit contexts, which add\nsignificant complexity to the SD process. Current software development\npractices still lack sufficient techniques using the existing SD execution\ninformation and context to provide developers with relevant process guidance,\naugmenting their capacity to do their job using available applicable\ninformation. This paper presents ongoing and future research on an approach to\nsupport conversational agent-based knowledge-augmented software development.\nDevelopers benefit by receiving recommendations about task-related information\nand workflows they need to execute. This work advances human-computer\ninteraction patterns in workflow engines, from graphical user interfaces to\nconversational patterns in software engineering.\n",
        "title": "Supporting Contextual Conversational Agent-Based Software Development",
        "texts": [
            "Fig. 1. Extended Context Model."
        ],
        "imgs": [
            "$2305.00885v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00887",
        "abstract": "  Probability theory is applied for the effect of severe disturbances on the\nreturn rate on capital within multiannual stands growing crops. Two management\nregimes are discussed, rotations of even-aged plants on the one hand, and\nuneven-aged semi-stationary state on the other. The effect of any disturbance\nappears two-fold, contributing to both earnings and capitalization. Results are\nillustrated using data from a recently published study, regarding spruce (Picea\nabies) forests in Austria. The economic results differ from those of the paper\nwhere the data is presented, here indicating continuous-cover forestry is\nfinancially inferior to rotation forestry. Any severe disturbance may induce a\nregime shift from continuous-cover to even-aged forestry. If such a regime\nshift is not accepted, the disturbance losses reduce profits but do not affect\ncapitalization, making continuous-cover forestry financially more sensitive to\ndisturbances. Revenue from carbon rent favors the management regime with higher\ncarbon stock. The methods introduced in this paper can be applied to any\ndataset, regardless of location and tree species.\n",
        "title": "Disturbance Effects on Financial Timberland Returns in Austria",
        "texts": [
            "Figure 1. The effect of disturbances on the expected value of capital return rate for the two regimes.",
            "Figure 2. The effect of disturbances on capitalization, capital return rate, gross profit rate, and survival probability in even-aged rotation forestry.",
            "Figure 3. The effect of disturbances on the change in appearance density of newly regenerated stands and stands mature for harvesting.",
            "Figure 4. The effect of disturbances on the expected value of capital return rate for the two regimes, when the greater carbon stock of the CCF is compensated by a carbon rent of 100 Eur/(ha*a)."
        ],
        "imgs": [
            "$2305.00887v1-Figure1-1.png",
            "$2305.00887v1-Figure2-1.png",
            "$2305.00887v1-Figure3-1.png",
            "$2305.00887v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00889",
        "abstract": "  We consider a safe optimization problem with bandit feedback in which an\nagent sequentially chooses actions and observes responses from the environment,\nwith the goal of maximizing an arbitrary function of the response while\nrespecting stage-wise constraints. We propose an algorithm for this problem,\nand study how the geometric properties of the constraint set impact the regret\nof the algorithm. In order to do so, we introduce the notion of the sharpness\nof a particular constraint set, which characterizes the difficulty of\nperforming learning within the constraint set in an uncertain setting. This\nconcept of sharpness allows us to identify the class of constraint sets for\nwhich the proposed algorithm is guaranteed to enjoy sublinear regret.\nSimulation results for this algorithm support the sublinear regret bound and\nprovide empirical evidence that the sharpness of the constraint set impacts the\nperformance of the algorithm.\n",
        "title": "The Impact of the Geometric Properties of the Constraint Set in Safe\n  Optimization with Bandit Feedback",
        "texts": [
            "Figure 1: The 2-norm sharpness of three different sets in R2.",
            "Figure 2: Examples of sets in R2 which are polytope-sharp and hence can be bounded linearly with respect to shrinkage via Proposition 10 (a), and sets that are not polytope-sharp (b).",
            "Figure 3: The cumulative sum of the instantaneous regret in the explorationexploitation phase of the algorithm with polytopic constraint sets that have different K constants (as defined in Proposition 7)."
        ],
        "imgs": [
            "$2305.00889v1-Figure1-1.png",
            "$2305.00889v1-Figure2-1.png",
            "$2305.00889v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00891",
        "abstract": "  Bohmian mechanics has garnered significant attention as an interpretation of\nquantum theory since the paradigmatic experiments by Kocsis et. al. [Science\n332, 6034 (2011)] and Mahler et. al. [Sci. Adv. 2, 2 (2016)], which inferred\nthe average trajectories of photons in the nonrelativistic regime. These\nexperiments were largely motivated by Wiseman's formulation of Bohmian\nmechanics, which grounded these trajectories in weak measurements. Recently,\nWiseman's framework was extended to the relativistic regime by expressing the\nvelocity field of single photons in terms of weak values of the photon energy\nand momentum. Here, we propose an operational, weak value-based definition for\nthe Bohmian \"local mass\" of relativistic single particles. For relativistic\nwavefunctions satisfying the scalar Klein-Gordon equation, this mass coincides\nwith the effective mass defined by de Broglie in his relativistic pilot-wave\ntheory, a quantity closely connected with the quantum potential that is\nresponsible for Bohmian trajectory self-bending and the anomalous photoelectric\neffect. We demonstrate the relationship between the photon trajectories and the\nmass in an interferometric setup.\n",
        "title": "How the result of a measurement of a photon's mass can turn out to be\n  100",
        "texts": [
            "FIG. 1. (a) Plot of the photon trajectories overlaid on the effective mass density, m̄2 eff . We have used the settings k0/σ = 10 and α = 0.83. (b) A zoomed-in view of (a), where we have distinguished regions of positive m̄2 eff with negative m̄2 eff using a different color scheme.",
            "FIG. 2. (a) Plot of the photon trajectories in a boosted reference frame with coordinates (t′, x′), overlaid on the effective mass density also plotted in these coordinates. We have used the same settings as Fig. 1 with ϑ = 0.4. (b) A zoomed-in view of (a), where the alternate colour scheme denotes regions where both m̄2 eff < 0 and ρ(t, x) < 0, such that trajectories travel backwards-in-time."
        ],
        "imgs": [
            "$2305.00891v1-Figure1-1.png",
            "$2305.00891v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00892",
        "abstract": "  We propose a novel low-rank tensor method for respiratory motion-resolved\nmulti-echo image reconstruction. The key idea is to construct a 3-way image\ntensor (space $\\times$ echo $\\times$ motion state) from the conventional\ngridding reconstruction of highly undersampled multi-echo k-space raw data, and\nexploit low-rank tensor structure to separate it from undersampling artifacts.\nHealthy volunteers and patients with iron overload were recruited and imaged on\na 3T clinical MRI system for this study. Results show that our proposed method\nSuccessfully reduced severe undersampling artifacts in respiratory motion-state\nresolved complex source images, as well as subsequent R2* and quantitative\nsusceptibility mapping (QSM). Compared to conventional respiratory\nmotion-resolved compressed sensing (CS) image reconstruction, the proposed\nmethod had a reconstruction time at least three times faster, accounting for\nsignal evolution along the echo dimension in the multi-echo data.\n",
        "title": "A Novel Low-Rank Tensor Method for Undersampling Artifact Removal in\n  Respiratory Motion-Resolved Multi-Echo 3D Cones MRI",
        "texts": [
            "Fig. 1. The process of constructing the input data tensor (A-D) and the proposed TV-regularized CPD (CPD-TV) method (E) for removing undersampling artifact for respiratory motion-resolved multi-echo reconstruction.",
            "Fig. 2. Magnitude images at TE3 and TE5 for the end-expiratory motion state of a representative healthy subject (HV #1) and difference images between hard gating (A) and the target methods (B-E). (B) CPD with the rank of 30, (C) CPD with the rank of 13, (D) CPD with the rank of 10, and (E) CPD-TV with the rank of 13.",
            "Fig. 3. Magnitude images at TE2 and TE3 for the end-expiratory motion state of a patient (Pt #2) with iron overload. Hard gating (A), motion-averaged (B), CPD with the rank of 13 (C), motion-resolved (D), and CPD-TV with the rank of 13 (E) reconstructions are shown in coronal and axial views. Reconstruction times of (D) and (E) using an Nvidia Tesla V100 GPU were 4.3 hours and 1.1 hours, respectively.",
            "Fig. 4. R2*/QSM reconstructions of a patient (Pt #2) with iron overload. (A) BH Cartesian, (B) Hard gating, (C) motion-averaged, (D) CPD with the rank of 13, (E) conventional motion-resolved, (F) CPD-TV with the rank of 13. Note that the reconstructions (B-F) are from FB Cones k-space and the coronal view of (A) was interpolated along the SI direction to match the resolution of FB Cones for better visualization.",
            "Fig. 5. Mean and standard deviation of ROI-based R2*/QSM measurements from representative healthy volunteers (HV) and patients (Pt). (A) BH Cartesian, (B) Hard gating, (C) motion-averaged, (D) CPD with the rank of 13, (E) conventional motionresolved, (F) CPD-TV with the rank of 13. Note that the reconstructions (B-F) are from FB Cones."
        ],
        "imgs": [
            "$2305.00892v1-Figure1-1.png",
            "$2305.00892v1-Figure2-1.png",
            "$2305.00892v1-Figure3-1.png",
            "$2305.00892v1-Figure4-1.png",
            "$2305.00892v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00894",
        "abstract": "  We operated a p-type point contact high purity germanium (PPCGe) detector\n(CDEX-1B, 1.008 kg) in the China Jinping Underground Laboratory (CJPL) for\n500.3 days to search for neutrinoless double beta ($0\\nu\\beta\\beta$) decay of\n$^{76}$Ge. A total of 504.3 kg$\\cdot$day effective exposure data was\naccumulated. The anti-coincidence and the multi/single-site event (MSE/SSE)\ndiscrimination methods were used to suppress the background in the energy\nregion of interest (ROI, 1989$-$2089 keV for this work) with a factor of 23. A\nbackground level of 0.33 counts/(keV$\\cdot$kg$\\cdot$yr) was realized. The lower\nlimit on the half life of $^{76}$Ge $0\\nu\\beta\\beta$ decay was constrained as\n$T_{1/2}^{0\\nu}\\ > \\ {1.0}\\times 10^{23}\\ \\rm yr\\ (90\\% \\ C.L.)$, corresponding\nto the upper limits on the effective Majorana neutrino mass: $\\langle\nm_{\\beta\\beta}\\rangle < $3.2$-$7.5$\\ \\mathrm{eV}$.\n",
        "title": "Searching for $^{76}$Ge neutrinoless double beta decay with the CDEX-1B\n  experiment",
        "texts": [
            "FIG. 12. CDEX-1B result of the effective Majorana neutrino mass. The green band indicates the parameter space allowed by the inverted ordering, and the magenta band represents the normal ordering [37]. Further, the brown and blue bands denote the result from CDEX-1B (this work) and CDEX-1A experiments [7], respectively. The purple and yellow bands represent the final result of the GERDA and Majorana Demonstrator experiments, respectively [2, 3, 7], which two experiments hold leading positions in the 76Ge-based 0νββ experiments currently. The projected sensitivity of CDEX-300ν is also imposed.",
            "FIG. 4. Two-dimensional distribution diagram of A/E vs. the energy of the 228Th calibration data. The upper and lower red dashed lines correspond to the µ(E) + 4σ(E) and µ(E) − 4σ(E) threshold, respectively. The SSEs exhibited a band distribution that decreased gradually with the energies. The major component of the double escape peak (DEP; 1592.50 keV) of 2614.51 keV γ-rays (208Tl) is regarded as SSE so that the events are primarily between the two dashed lines. The main component of the single escape peak (SEP; 2103.51 keV) is deemed as MSE, and thus the events are mainly outside the two dashed lines. The selection of fitting energy intervals (9 gray shadow bands in the figure) is basically equidistant, avoiding the omnipotent peaks, single escape peaks, and double escape peaks of different γ-rays, because the main component of the backgrounds in the region of interest (ROI) is attributed to Compton events.",
            "FIG. 9. (Top) Calibration and normalized simulated spectra of 228Th. Shadow bands include four distinct types of energy regions: double escape peak (DEP, 1592.5 keV), full energy peak (FEP, 1620.5 keV), Compton continuum (CC, 1860.0 keV), and single escape peak (SEP, 2103.5 keV). Calibration and simulated A/E distributions were compared in these energy regions. (Bottom) Simulated A/E distributions (after normalization, the center value of SSE distribution is 1) of 228Th are consistent with the corresponding calibration data. The systematic error of the simulation was obtained by comparing the cut efficiencies of the simulated data and calibration data. This error was regarded as a systematic error of the A/E cut survival efficiency of 0νββ events.",
            "TABLE I. Comparison of A/E cut efficiency for DEP events between calibration and pulse shape simulation.",
            "TABLE II. Comparison of the experimental parameters and results [7, 8]"
        ],
        "imgs": [
            "$2305.00894v2-Figure12-1.png",
            "$2305.00894v2-Figure4-1.png",
            "$2305.00894v2-Figure9-1.png",
            "$2305.00894v2-TableI-1.png",
            "$2305.00894v2-TableII-1.png"
        ]
    },
    {
        "id": "2305.00895",
        "abstract": "  Time-dependent drives play a crucial role in quantum computing efforts with\ncircuit quantum electrodynamics. They enable single-qubit control, entangling\nlogical operations, as well as qubit readout. However, their presence can lead\nto deleterious effects such as large ac-Stark shifts and unwanted qubit\ntransitions ultimately reflected into reduced control or readout fidelities.\nQubit cloaking was introduced in Lled\\'o, Dassonneville, et al. [C. Lled\\'o, R.\nDassonneville, A. Moulinas et al., Nat. Commun. \\textbf{14}, 6313 (2023)] to\ntemporarily decouple the qubit from the coherent photon population of a driven\ncavity, allowing for the application of arbitrary displacements to the cavity\nfield while avoiding the deleterious effects on the qubit. For qubit readout,\ncloaking permits to prearm the cavity with an, in principle, arbitrarily large\nnumber of photons, in anticipation to the qubit-state-dependent evolution of\nthe cavity field, allowing for improved readout strategies. Here we take a\ncloser look at two of them. First, arm-and-release readout, introduced together\nwith qubit cloaking, where after arming the cavity the cloaking mechanism is\nreleased and the cavity field evolves under the application of a constant drive\namplitude. Second, an arm-and-longitudinal readout scheme, where the cavity\ndrive amplitude is slowly modulated after the release. We show that the two\nschemes complement each other, offering an improvement over the standard\ndispersive readout for any values of the dispersive interaction and cavity\ndecay rate, as well as any target measurement integration time. Our results\nprovide a recommendation for improving qubit readout without changes to the\nstandard circuit QED architecture.\n",
        "title": "Qubit readouts enabled by qubit cloaking",
        "texts": [
            "FIG. 1. Path in phase-space of the cavity amplitude when the qubit is in ground (blue) or excited (red) state for the three different schemes: dispersive (dashed line), armand-release (A&R, dashed-dotted), and arm-and-longitudinal (A&L, full line). The coloured dots indicate different times in the evolution, κt = 0, 1, 2, 4, 10, 20. The parameters are: |χ|/κ = 1, and ε1/2π = 19.85MHz and 18.49MHz as well as αarm/ √ nmax ≈ 0.8 and 1/ √ 2 for A&R and A&L, respectively.",
            "FIG. 2. (a) Signal-to-noise ratio (SNR) as a function of measurement integration time for dispersive (dashed) and A&R (solid) readouts, for the corresponding pairs of trajectories shown in Fig. 1. (c,d) Normalized SNR vs |χ|/κ for dispersive (b) and A&R (c) readout. The different curves corresponds to different measurement integration times in units of 1/κ.",
            "FIG. 3. Top row: Path in phase-space of the cavity amplitude αg(t) for the three different schemes: standard dispersive (black dashed line), arm-and-release (A&R, full lines), and arm-and-longitudinal (A&L, red dashed line). The different colours for A&R trajectories indicate different initial amplitudes αarm, while the coloured dots indicate different times in the evolution, κt = 0, 1, 2, 4, 10, 20. All trajectories, in all three panels, visit the same maximum mean photon number nmax = 2.44. Bottom row: Assignment error as function of measurement integration time for the corresponding trajectories depicted in the top row’s panels. The parameters are from left to right: |χ|/κ = 1/3, 1, 3, and, for A&L, αarm/ √ nmax = √ 9/ √ 10, 1/ √ 2, 1/ √ 10. For dispersive, ε1/2π = 15.77MHz, 19.85MHz, 34.38MHz. For A&R, αarm ∈ (0, √ nmax] and ε1 is obtained, after fixing αarm, from the constraint of having less than the maximum mean photon number.",
            "FIG. 4. (a) SNR relative gain between A&R and dispersive, Eq. (20), as a function of |χ|/κ and measurement integration time. (b) Optimal value of the (normalized) amplitude α̃arm associated to the best SNR in panel (a). (c) SNR relative gain between arm-and-longitudinal and dispersive, Eq. (21), as a function of |χ|/κ and measurement integration time. (d) Ratio between the relative gains of A&L and A&R, Eq. (22). The black stars correspond to the parameters of the experiment in Ref. [5] and the red dot to those of Ref. [1] (in which A&R was used), see text. In (a,c,d) the gray contours indicate the separation between the regions with different optimal readout strategy. In all panels, for a given |χ|/κ all other parameters are fixed by the choice of nmax.",
            "FIG. 5. Numerically obtained paths of the cavity pointer states in phase space using a transmon multilevel Hamiltonian, no RWA, and no dispersive approximation for A&L (full lines) and standard dispersive (dashed lines). In (a) [(b)] we use κ/2π = 1MHz (10.1MHz), and for A&L readout we choose ntar = 2 (1), which is in between zero photons and the maximum number attained n̄max = 4 (2). This results in |χntar |/κ = 3.286 in (a) and 0.326 in (b). For the standard dispersive case, we use ω1/2π = 7.665GHz (7.666GHz) and ε1/2π = 4.876MHz (15MHz) for (a) [(b)]. All other system parameters read EJ/2π = 16.93GHz, EC/2π = 200.4MHz, g/2π = 159.1MHz, and ωr/2π = 7.655GHz."
        ],
        "imgs": [
            "$2305.00895v2-Figure1-1.png",
            "$2305.00895v2-Figure2-1.png",
            "$2305.00895v2-Figure3-1.png",
            "$2305.00895v2-Figure4-1.png",
            "$2305.00895v2-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00899",
        "abstract": "  The dip coating of suspensions made of monodisperse non-Brownian spherical\nparticles dispersed in a Newtonian fluid leads to different coating regimes\ndepending on the ratio of the particle diameter to the thickness of the film\nentrained on the substrate. In particular, dilute particles dispersed in the\nliquid are entrained only above a threshold value of film thickness. In the\ncase of anisotropic particles, in particular fibers, the smallest\ncharacteristic dimension will control the entrainment of the particle.\nFurthermore, it is possible to control the orientation of the anisotropic\nparticles depending on the substrate geometry. To test the hypotheses, we\nperformed dip-coating experiments with dilute suspensions of non-Brownian\nfibers with different length-to-diameter aspect ratios. We characterize the\nnumber of fibers entrained on the surface of the substrate as a function of the\nwithdrawal velocity, allowing us to estimate a threshold capillary number below\nwhich all the particles remain in the liquid bath. Besides, we measure the\nangular distribution of the entrained fibers for two different substrate\ngeometries: flat plates and cylindrical rods. We then measure the film\nthickness for more concentrated fiber suspensions. The entrainment of the\nfibers on a flat plate and a cylindrical rod is primarily controlled by the\nsmaller characteristic length of the fibers: their diameter. At first order,\nthe entrainment threshold scales similarly to that of spherical particles. The\nlength of the fibers only appears to have a minor influence on the entrainment\nthreshold. No preferential alignment is observed for non-Brownian fibers on a\nflat plate, except for very thin films, whereas the fibers tend to align\nthemselves along the axis of a cylindrical rod for a large enough ratio of the\nfiber length to the radius of the cylindrical rod.\n",
        "title": "Deposition and alignment of fiber suspensions by dip coating",
        "texts": [
            "Figure 1: Examples of coating films resulting from the dip coating of a flat plate withdrawn from a suspension of non-Brownian fibers when increasing the withdrawal velocity U for fibers of diameter d = 50µm, and length L = 200µm. The scale bar is 1mm. The withdrawal velocity U , and thus the thickness h of the coating film, increases from left to right. The arrow in the first picture of the figure indicates the direction along which the substrate has been withdrawn.",
            "Figure 10: Coating film thickness h on a flat substrate as a function of the effective capillary number Caφ for various volume fraction φ (blue diamonds: φ = 0%; purple squares: φ = 2.5%; orange circles: φ = 5%; grey diamonds: φ = 7.5%). The dashed line represents the LLD law [Eq. (1)]. The relative viscosity ηr of the suspension is fitted to collapse the experimental data to the LLD law. Bottom inset: Thickness of the coating film h as a function of the withdrawal velocity U . Top inset: Evolution of the relative viscosity ηr of fiber suspensions when varying the volume fraction φ. The solid line represents the Maron-Pierce model [Eq. (6)] with φc = 33%. The fibers used here have a diameter d = 50µm and a length L = 200µm.",
            "Figure 2: (a) Schematic of the experimental setup. The zoom view shows the notations used to characterize the orientation of the fibers: θ is the absolute value of the angle between the long axis of the fiber and the withdrawal direction. (b) Pictures of some fibers used in the experiments: (i) d = 50µm and L = 0.2mm, (ii) d = 280µm and L = 3mm, (iii) d = 280µm and L = 5mm. Scale bars are 1mm.",
            "Figure 3: Pictures of the deposition process for the three coating regimes obtained at different withdrawal velocities U for fibers of diameter d = 280µm and length L = 3mm. (a) At very low velocity, here U = 0.1mm/s, only the liquid is entrained on the substrate and the fibers remain trapped in the suspension bath. (b) For intermediate velocities, here U = 1mm/s, clusters of fibers start to be entrained on the substrate. (c) At larger withdrawal velocity, here U = 9mm/s, individual fibers are able to be entrained in the coating film. Scale bars are 2mm.",
            "Figure 4: Threshold capillary number Ca∗ for the entrainment of fibers on a flat substrate as a function of the Bond number Bo = [d/(2 `c)] 2. The solid line corresponds to Eq. (2) with β = 0.30 ± 0.07, and the grey shaded region is the uncertainty. Inset: Threshold withdrawal velocity U∗ for a planar substrate as a function of the fiber diameter d.",
            "Figure 5: Rescaled threshold capillary number of entrainment of isolated fibers on cylindrical rods as a function of the ratio d/(2R). The diameter of the fibers in the suspension is d = 50µm. The solid line corresponds to Eq. (5) where α ' 1.1 ± 0.1. The grey-shaded region corresponds to the uncertainty on α. Inset: Threshold withdrawal velocity U∗ for fiber entrainment on cylindrical rods as a function of d/(2R).",
            "Figure 6: Illustration of the entrainment of a fiber on a glass plate showing the value of the angular orientation of the deposited fiber, θ. Add: The red arrow shows the fiber depositing on the surface of the substrate. Scale bar is 2mm.",
            "Figure 7: Probability density function (PDF) of the orientation of fibers deposited on a flat substrate for different withdrawal velocities and thus thickness h of the coating film. The fibers have a diameter d = 50µm and different lengths: (a) L = 200µm, (b) L = 400µm, and (c) L = 1000µm.",
            "Figure 8: Probability density function (PDF) of the orientation of fibers deposited on cylindrical substrates. The radius of the cylindrical rods, the length of the deposited fibers, and the aspect ratios are (a) R = 275µm, L = 1000µm, L/R = 3.6 (b) R = 275µm, L = 400µm, L/R = 1.5 , and (c)R = 600µm, L = 400µm, L/R = 0.7 .",
            "Figure 9: Mean absolute value of the angular orientation of the deposited fibers 〈θ〉 as a function of L/R for a withdrawal velocity U = 3mm. The fibers have a diameter d = 50µm. L/R = 0 corresponds to flat substrates. Insets: Pictures of the deposited fibers. The dashed arrows point to the corresponding data points. Scale bars are 2mm.",
            "Table 1: Properties of the fibers used in this study: diameter d, length L, and aspect ratio a = L/d."
        ],
        "imgs": [
            "$2305.00899v1-Figure1-1.png",
            "$2305.00899v1-Figure10-1.png",
            "$2305.00899v1-Figure2-1.png",
            "$2305.00899v1-Figure3-1.png",
            "$2305.00899v1-Figure4-1.png",
            "$2305.00899v1-Figure5-1.png",
            "$2305.00899v1-Figure6-1.png",
            "$2305.00899v1-Figure7-1.png",
            "$2305.00899v1-Figure8-1.png",
            "$2305.00899v1-Figure9-1.png",
            "$2305.00899v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00900",
        "abstract": "  Exceptional points (EP) in non-Hermitian systems have been widely\ninvestigated due to their enhanced sensitivity in comparison to standard\nsystems. In this letter, we report the observation of higher-order\npseudo-Hermitian degeneracies in an electronic platform comprised of three\ninductively coupled gain-loss-loss LC resonators. Theoretical analysis\ndemonstrates that the proposed system can realize third-order EP with\nasymmetric coupling between adjacent inductors and an arbitrary scaling factor\nbetween two loss resonators. When capacitive perturbation is introduced on the\nmiddle resonator, the perturbed eigenfrequencies follow a cube-root dependence\non the perturbation parameter; in this case, the sensitivity is significantly\ngreater than conventional wireless readout methods. Our work enriches the\nexplorations of higher-order EP on electronic platforms and provides a new\ndegree of design freedom for the non-Hermitian-EP-enhanced wireless sensing\nsystem.\n",
        "title": "Observation of higher-order exceptional points in pseudo-Hermitian\n  radio-frequency circuits",
        "texts": [
            "FIG. 1. (a) Illustration and circuit schematic of the pseudo-Hermitian electronic trimer, which is composed of three planarly inductively coupled RLC resonators. (b) Real and (c) imaginary parts of eigenfrequency evolution as a function of κ12 at different scaling factors α when g = 0.1, κ13 = 0 and κ23 = (1+α)−3/2κ12.",
            "FIG. 3. Experimentally measured reflection spectra (solid curve) of (a) conventional system when κ = 0.1 and (b) pseudo-Hermitian system around EP3 when κ12 = 0.0816,κ23 = 0.0289 in comparison with the theoretical result (dashed curve) as the capacitive perturbation ε varies from −0.01 to 0.01. The gain parameter is g = 0.1.",
            "FIG. 4. Comparison between theoretical (curves) and experimental (markers) results of conventional and EP3 sensing schemes. The inset shows the experimental setup of the proposed pseudo-Hermitian sensing system."
        ],
        "imgs": [
            "$2305.00900v1-Figure1-1.png",
            "$2305.00900v1-Figure3-1.png",
            "$2305.00900v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00901",
        "abstract": "  A novel nonparametric clustering algorithm is proposed using the interpoint\ndistances between the members of the data to reveal the inherent clustering\nstructure existing in the given set of data, where we apply the classical\nnonparametric univariate kernel density estimation method to the interpoint\ndistances to estimate the density around a data member. Our clustering\nalgorithm is simple in its formation and easy to apply resulting in\nwell-defined clusters. The algorithm starts with objective selection of the\ninitial cluster representative and always converges independently of this\nchoice. The method finds the number of clusters itself and can be used\nirrespective of the nature of underlying data by using an appropriate\ninterpoint distance measure. The cluster analysis can be carried out in any\ndimensional space with viability to high-dimensional use. The distributions of\nthe data or their interpoint distances are not required to be known due to the\ndesign of our procedure, except the assumption that the interpoint distances\npossess a density function. Data study shows its effectiveness and superiority\nover the widely used clustering algorithms.\n",
        "title": "A new interpoint distance-based clustering algorithm using kernel\n  density estimation",
        "texts": [
            "Figure 1: Figures are drawn to illustrate our algorithm step-wise for h = 0.1. (a) Simulated bivariate data, (b) First cluster, within h-neighborhood, around the observation marked with ∗, (c) Second cluster around ∗, and (d) Third cluster around ∗ (without including the last unclustered member of data).",
            "Figure 2: Visual impact of cluster analysis is shown, which is obtained through our proposed clustering algorithm, with h = 0.20 and n′ = 3, for the simulated bivariate data set (S1), with measurements on mixed scales (namely, binary and continuous), where the first variable (placed along xaxis) is binary taking values 0 or 1, and the second one (drawn along y-axis) is independent Cauchy variable. (a) Plot of sampled data from 2 overlapping groups G1 and G2, and (b) graph of 2 resulted clusters C1 and C2.",
            "Figure 4: Existing four classes in the Ruspini data set (S2), identified by our clustering algorithm, as clusters C1–C4, for h = 0.10 and n′ = 4, 5, with 100% accuracy.",
            "Figure 5: 2D plot of multivariate normal data (S3) with respect to the first principal component (PC1, with 91.1% variation) versus the second principal component (PC2, with 3.4% variation), where cluster 1 (black), cluster 2 (red) and cluster 3 (green) of respective sizes (20, 15, 10), as resulted by our algorithm (h = 0.15, n′ = 3) with 100% accuracy, are plotted with the digits printed as indices of the sampled observations.",
            "Figure 6: Simulated data set (S4) with four groups G1 − G4, each with random sample of size 100, independently drawn from a square, rectangle, half-circle and circle shaped distributions, respectively, in a bivariate space where each variable is contaminated with Gaussian noise possessing mean 0 and standard deviation 0.05.",
            "Figure 7: (a) 2D scatter plot of the clustered spatial data (D1) for 60 places as determined by our algorithm with (h = 0.15, n′ = 3), and (b) 2D scatter plot of the clustered spatial data (D1) for 60 places as reached by both our algorithm with (h = 0.15, n′ = 1) and the ClusterKDE algorithm with (α1 = α2 = 5, h1 = h2).",
            "Table 1: Clustering results obtained through K−means and K−medoids algorithms at different values of the number of clusters (K), as a priori specified, for data set (S1)",
            "Table 2: Clustering results obtained through our algorithm for Ruspini data set (S2)",
            "Table 3: Clustering results obtained through our algorithm for multivariate normal data set (S3)",
            "Table 4: Run time of our algorithm on the data described under (S3)",
            "Table 5: Clustering results obtained through our algorithm for bivariate spatial data set (D1)",
            "Table 6: Clustering results obtained through K−means and K−medoids algorithms at different values of the number of clusters (K), as a priori specified, for bivariate spatial data set (D1)"
        ],
        "imgs": [
            "$2305.00901v1-Figure1-1.png",
            "$2305.00901v1-Figure2-1.png",
            "$2305.00901v1-Figure4-1.png",
            "$2305.00901v1-Figure5-1.png",
            "$2305.00901v1-Figure6-1.png",
            "$2305.00901v1-Figure7-1.png",
            "$2305.00901v1-Table1-1.png",
            "$2305.00901v1-Table2-1.png",
            "$2305.00901v1-Table3-1.png",
            "$2305.00901v1-Table4-1.png",
            "$2305.00901v1-Table5-1.png",
            "$2305.00901v1-Table6-1.png"
        ]
    },
    {
        "id": "2305.00904",
        "abstract": "  We use a simple effective model, obtained through the application of\nhigh-frequency homogenisation, to tackle the fundamental question of how the\nchoice of gradient function affects the performance of a graded metamaterial.\nThis approach provides a unified framework for comparing gradient functions\nefficiently and in a way that allows us to draw conclusions that apply to a\nrange of different wave regimes. We consider the specific problem of\nsingle-frequency localisation, for which the appropriate effective model is a\none-dimensional Schrodinger equation. Our analytic results both corroborate\nthose of existing studies (which use either expensive full-field wave\nsimulations or black-box numerical optimisation algorithms) and extend them to\nother metamaterial regimes. Based on our analysis, we are able to propose a\ndesign strategy for optimising monotonically graded metamaterials and offer an\nexplanation for the lack of a universal optimal gradient function.\n",
        "title": "On the problem of comparing graded metamaterials",
        "texts": [
            "Figure 1: Slowly varying the separation distances between scatterers causes the local band gap to shift up or down. The top example is a monotonically graded metamaterial, where the separation distances gradually decrease causing the band gap to shift upwards. This configuration exhibits a rainbow effect. The lower example is a symmetrically graded metamaterial, where the separation distances increase before decreasing again. This configuration will lead to wave localisation at the centre of the array. These results are for arrays of cylinders with Neumann boundary conditions, modelled using multipole expansions. The cylinders have radius 0.25 and the horizontal axes in the plots show the separation distance between the cylinders’ centres.",
            "Figure 2: The localised defect mode for a one-dimensional two-phase periodic material that is perturbed by the symmetric gradient g(X) = 1 − sech2X. In this case, ϵ = 0.05 and the homogenised envelope function, obtained by solving (2.1), accurately predicts the decay of the amplitude.",
            "Figure 3: High-frequency homogenisation can be used to derive the effective equation that is the basis of this work from a range of different graded wave scattering problems. For example, the two-dimensional analysis presented in Section 2.2 has been shown to apply both to a metasurface with comb-like teeth, as depicted in (a) and (c), and to a diffraction grating composed of elliptical cylinders, as depicted in (b) and (d). We show examples of both monotonic and symmetric, with the gradient function indicated with a dashed line in each case.",
            "Figure 4: For a simple example of a one-dimensional two-phase material, the dispersion relation and the homogenised coefficients can be computed explicitly. Here, we show the Bloch spectral bands for the material (2.22) in the specific case when the material contrast parameter r = 2. Then, we show the high-frequency homogenisation coefficient T , given by (2.24), as a function of r, for Ω0 being at the lower edge of the second and third band gaps, respectively.",
            "Figure 5: Symmetric gradient functions give symmetric eigenmodes whose localisation can be quantified using the full width at half maximum (FWHM). In the upper displays, we plot the first eigenmode of (2.1) for seven different symmetric gradient functions (and two different values of T/α). On each mode, the length corresponding to the FWHM is shown. Below this, the localisation (given by the reciprocal of the FWHM) is plotted as a function of T/α for each symmetric gradient function (the inset plot shows the same data on a log–log plot). Finally, the lower display shows the gradient with the most localised first eigenmode at each T/α (with multiple symbols shown in the event of a tie).",
            "Figure 6: Monotonic gradient functions give eigenmodes that transition from bring a propagating mode to a decaying mode. Their localisation can be quantified using the full width at half maximum (FWHM) of the last peak. In the upper displays, we plot the first eigenmode of (2.1) for seven different monotonic gradient functions (and two different values of T/α). On each mode, the length corresponding to the FWHM is shown. Below this, the localisation (given by the reciprocal of the FWHM) of the first mode is plotted for different values of T/α for each gradient function. Finally, the lower display shows the gradient with the most localised first eigenmode at each T/α (with multiple symbols shown in the event of a tie).",
            "Figure 7: A comparison of the localisation loc(g)0.2,1 and the slope of the gradient function g′(X0), evaluated. Both axes use logarithmic scales. In this figure, we use T = 0.2, α = 1 but note that the behaviour is the same for other parameter values. The dashed line is a straight line that has been fitted (in a least-squares sense) to the data points for the five convex gradient functions."
        ],
        "imgs": [
            "$2305.00904v2-Figure1-1.png",
            "$2305.00904v2-Figure2-1.png",
            "$2305.00904v2-Figure3-1.png",
            "$2305.00904v2-Figure4-1.png",
            "$2305.00904v2-Figure5-1.png",
            "$2305.00904v2-Figure6-1.png",
            "$2305.00904v2-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00906",
        "abstract": "  Symmetries and tunability are of fundamental importance in wave scattering\ncontrol, but symmetries are often obvious upon visual inspection which\nconstitutes a significant vulnerability of metamaterial wave devices to\nreverse-engineering risks. Here, we theoretically and experimentally show that\nit is sufficient to have a symmetry in the reduced basis of the \"primary\nmeta-atoms\" that are directly connected to the outside world; meanwhile, a\nsuitable topology of non-local interactions between them, mediated by the\ninternal \"secondary\" meta-atoms, can hide the symmetry from sight in the\ncanonical basis. We experimentally demonstrate covert symmetry-based scattering\ncontrol in a cable-network metamaterial featuring a hidden parity (P) symmetry\nin combination with hidden-P-symmetry-preserving and hidden-P-symmetry-breaking\ntuning mechanisms. First, we achieve physical-layer security in wired\ncommunications, using the domain-wise hidden P-symmetry as shared secret\nbetween the sender and the legitimate receiver. Then, within the approximation\nof negligible absorption, we report the first tuning of a complex scattering\nmetamaterial without mirror symmetry to feature exceptional points (EPs) of\nPT-symmetric reflectionless states, as well as quasi-bound states in the\ncontinuum. Finally, we show that these results can be reproduced in\nmetamaterials involving non-reciprocal interactions between meta-atoms,\nincluding the first observation of reflectionless EPs in a non-reciprocal\nsystem.\n",
        "title": "Covert Scattering Control in Metamaterials with Non-Locally Encoded\n  Hidden Symmetry",
        "texts": [
            "FIG. 1. General Principle of Reduced-Basis Representations and Hidden P Symmetry. (a) Conceptual sketch of a generic example scattering problem involving three asymptotic scattering channels and 12 meta-atoms. The ith meta-atom has a self-interaction αi and a reciprocal interaction hi,j with its direct neighbors. The ith asymptotic scattering channel is coupled to the jth meta-atom with a complex-valued weight wi,j (only non-zero weights are shown). Primary meta-atoms have direct contact with one or more asymptotic scattering channel(s) and are highlighted in red. Lines in this figure symbolically represent direct coupling. In the case of a cable-network metamaterial, direct coupling is implemented via cables that look “line-like” and the asymptotic scattering channels are monomodal waveguides. In general, however, the coupling mechanisms can be more complex. For instance, if a shaped wavefront illuminates a nanophotonic structure, the free-space asymptotic scattering channel couples with different complex-valued weights to multiple internal scattering entities depending on how the wavefront pattern overlaps with them. (b) Equivalent representation of the metamaterial from (a) in the reduced basis of primary meta-atoms. Here, the ith primary meta-atom has a self-interaction α̃i and has an interaction h̃i,j with the jth primary meta-atom. (c,d) Example of a metamaterial with a hidden P symmetry that is absent in the canonical basis (c) but evident in the reduced basis of primary meta-atoms (d).",
            "FIG. 2. Physical-Layer Secure Communication Built Off Hidden P Symmetry. (a) Wireline network with hidden P symmetry of its primary (red) meta-atoms. (b) Addition of hidden-Psymmetry-preserving tuning mechanism (Bob’s phase shifter φi) and hidden-P-symmetry-breaking tuning mechanism (Alice’s switch bi) to the network from (a). In addition, Eve non-invasively wire-",
            "FIG. 3. Reflectionless Exceptional Points without Mirror Symmetry. (a) Experimentally measured perturbation-frequency map of |S11|. The setup is that from Fig. 2(c) except that a manual rather than a computer-programmable phase shifter is used because of its lower attenuation, and there is no non-invasive third port. (b) For three selected perturbation strengths and the frequency interval highlighted by red bars in (a), the location of poles (+, blue) and zeros (x, red)",
            "FIG. 4. Equi-Reflectionality and Reflectionless Exceptional Points in Metamaterials with Non-Reciprocal Components. (a,b) Topology of equi-reflectional reciprocal (a) and nonreciprocal cable-network metamaterials involving circulators. (c) Photographic image of the experimental implementation of the metamaterial from (a). (d) Scattering measurements of the two metamaterials from (a,b). The overlayed scattering coefficients visualize equi-reflectionality and (non-)reciprocity. (e) Experimental observation of reflectionless EPs in the reciprocal and non-reciprocal metamaterials involving circulators. (f) Analytical scattering calculations (zero absorption) for the two metamaterials involving circulator-like devices. Multiple reflectionless EPs are seen in each case."
        ],
        "imgs": [
            "$2305.00906v1-Figure1-1.png",
            "$2305.00906v1-Figure2-1.png",
            "$2305.00906v1-Figure3-1.png",
            "$2305.00906v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00907",
        "abstract": "  Efficient fiber-to-chip couplers for multi-port access to photonic integrated\ncircuits are paramount for a broad class of applications, ranging, e.g., from\ntelecommunication to photonic computing and quantum technologies. While\ngrating-based approaches are convenient for out-of-plane access and often\ndesirable from a packaging point of view, on low-index photonic platforms, such\nas silicon nitride or thin-film lithium niobate, the limited grating strength\nhas thus far hindered the achievement of coupling efficiencies comparable to\nthe ones attainable in silicon photonics. Here we present a flexible strategy\nfor the realization of highly efficient grating couplers on low-index photonic\nplatforms. To simultaneously reach a high scattering efficiency and a\nnear-unitary modal overlap with optical fibers, we make use of self-imaging\ngratings designed with a negative diffraction angle. To ensure high\ndirectionality of the diffracted light, we take advantage of a metal\nback-reflector patterned underneath the grating structure by cryogenic deep\nreactive ion etching of the silicon handle. Using silicon nitride as a testbed\nmaterial, we experimentally demonstrate coupling efficiency up to -0.55 dB in\nthe telecom C-band with near unity chip-scale device yield.\n",
        "title": "Scalable and efficient grating couplers on low-index photonic platforms\n  enabled by cryogenic deep silicon etching",
        "texts": [
            "Figure 1. (a) Schematic illustration of the grating coupler along its longitudinal direction. The grating coupler features a grating period Λ and a linear apodization on the filling factor FF=d/Λ, such that the light propagating through the structure (yellow arrow) is partly radiated upward with a Gaussian-like shape and focused at a given distance from the circuitry plane. An optical fiber with the MFD of its fundamental mode is also drawn in correspondence of the beam waist of the radiated beam. Highlighted with red labels are also the several portions of the device: the waveguide (WG), the grating and the taper connecting these two elements. (b) Top view of the self-imaging apodized grating coupler. The taper features an opening angle of 70° and a length Lt equal to the distance between the first grating tooth and the longitudinal coordinate of the beam waist. At the intersection with the taper, the waveguide is characterized by a properly engineered width w that allows to match the desired MFD also in the transverse direction, in correspondence of the focal point of the diffracted beam. (c) 2D FDTD simulation of a grating coupler in the outcoupling scheme at λ=1550 nm. The colormap in the figure (a.u.) is the computed optical power |E|2 of the diffracted beam. The radiated beam features a diffraction angle equal to -12° and a focusing effect at a height of ≃175 µm from the circuit plane. (d) Simulated mode field profile in correspondence of the beam waist (blue curve). The red trace is a Gaussian function with MFD=10.4 µm (MFD of SMF-28 fibers at λ=1550 nm). (e) Poynting flux spectra computed in the 1500- 1600 nm wavelength range for upward-(blue) and downward-diffracted (orange) light, for light transmitted at the end of the grating structure (red), and for the back-reflected light (green). The optical power is normalized to the one at the input of the grating.",
            "Figure 2. (a) Photograph of a 20x20 mm2 die, where a dense matrix of membrane windows is fabricated via back-side etching of the silicon handle. The fabricated membranes contain only a few micrometers of material and are therefore transparent. (b) Optical microscope image of a completed sample, showing several grating couplers patterned atop the metal mirrors.",
            "Figure 3. (a) Coupling efficiency of the best device fabricated on chip, plotted on a logarithmic scale. The transmission is optimized with a 1565 nm alignment wavelength. The laser is swept at a fixed fiber position. The inset shows the same curve, with a close-up around the maximum. The red curve is a Gaussian function used to fit the experimental data. A maximum coupling efficiency of -0.55 dB has been extracted. (b) For the same device, the coupling efficiency spectrum is reported for five different alignment wavelengths in the range of 1535-1595 nm. A peak coupling efficiency larger than 80% is determined for all cases. (c) For the same device, the peak coupling efficiency of the grating coupler is reported as a function of the alignment wavelength. The alignment wavelength is varied in steps of 5 nm in the range of 1500-1600 nm. (d) Peak coupling efficiencies measured for ten identical devices patterned on the same photonic die. An average coupling efficiency equal to (83 ± 3)% is determined. Device n.3 is the one used for the measurements of Fig. 3a-c."
        ],
        "imgs": [
            "$2305.00907v1-Figure1-1.png",
            "$2305.00907v1-Figure2-1.png",
            "$2305.00907v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00908",
        "abstract": "  This study examines the effect of COVID-19 pandemic and associated lockdowns\non access to crucial diagnostic procedures for breast cancer patients,\nincluding screenings and treatments. To quantify the impact of the lockdowns on\npatient outcomes and cost, the study employs a mathematical model of breast\ncancer progression. The model includes ten different states that represent\nvarious stages of health and disease, along with the four different stages of\ncancer that can be diagnosed or undiagnosed. The study employs a natural\nhistory stochastic model to simulate the progression of breast cancer in\npatients. The model includes transition probabilities between states, estimated\nusing both literature and empirical data. The study utilized a Markov Chain\nMonte Carlo simulation to model the natural history of each simulated patient\nover a seven-year period from 2019 to 2025. The simulation was repeated 100\ntimes to estimate the variance in outcome variables. The study found that the\nCOVID-19 pandemic and associated lockdowns caused a significant increase in\nbreast cancer costs, with an average rise of 172.5 million PLN (95% CI [82.4,\n262.6]) and an additional 1005 breast cancer deaths (95% CI [426, 1584]) in\nPoland during the simulated period. While these results are preliminary, they\nhighlight the potential harmful impact of lockdowns on breast cancer treatment\noutcomes and costs.\n",
        "title": "Estimation of the Impact of COVID-19 Pandemic Lockdowns on Breast Cancer\n  Deaths and Costs in Poland using Markovian Monte Carlo Simulation",
        "texts": [
            "Fig. 1. Breast cancer Markov Model with 10 states. Blue arrows indicate transitions between different stages of breast cancer, yellow ones show the diagnosis of breast cancer, green arrows indicate that the patient was healed and red represent the death event related to breast cancer.",
            "Fig. 2. The average number of breast cancer-related deaths (top) and the average number of breast cancer diagnoses (bottom) with and without lockdowns.",
            "Table 1. The age distribution of Polish women above 25 years in 2019 [45].",
            "Table 4. Direct and indirect simulated costs (in million PLN) of breast cancer in Poland with and without COVID-19 pandemic.",
            "Table 5. Total simulated costs (in million PLN) of breast cancer in Poland."
        ],
        "imgs": [
            "$2305.00908v2-Figure1-1.png",
            "$2305.00908v2-Figure2-1.png",
            "$2305.00908v2-Table1-1.png",
            "$2305.00908v2-Table4-1.png",
            "$2305.00908v2-Table5-1.png"
        ]
    },
    {
        "id": "2305.00909",
        "abstract": "  For a complicated algorithm, its implementation by a human programmer usually\nstarts with outlining a rough control flow followed by iterative enrichments,\neventually yielding carefully generated syntactic structures and variables in a\nhierarchy. However, state-of-the-art large language models generate codes in a\nsingle pass, without intermediate warm-ups to reflect the structured thought\nprocess of \"outline-then-detail\". Inspired by the recent success of\nchain-of-thought prompting, we propose ChainCoder, a program synthesis language\nmodel that generates Python code progressively, i.e. from coarse to fine in\nmultiple passes. We first decompose source code into layout frame components\nand accessory components via abstract syntax tree parsing to construct a\nhierarchical representation. We then reform our prediction target into a\nmulti-pass objective, each pass generates a subsequence, which is concatenated\nin the hierarchy. Finally, a tailored transformer architecture is leveraged to\njointly encode the natural language descriptions and syntactically aligned I/O\ndata samples. Extensive evaluations show that ChainCoder outperforms\nstate-of-the-arts, demonstrating that our progressive generation eases the\nreasoning procedure and guides the language model to generate higher-quality\nsolutions. Our codes are available at:\nhttps://github.com/VITA-Group/ChainCoder.\n",
        "title": "Outline, Then Details: Syntactically Guided Coarse-To-Fine Code\n  Generation",
        "texts": [
            "Figure 1. Our prediction target formulation illustrated with an example. In the Merge Intervals problem (one medium difficulty problem on leetcode), the solution requires first tackling extreme cases, initializing variables, then entering the main algorithm loop. A programmer needs to first come up with this outline, then think deeper on how to implement the algorithm loop. They may then think about using a stack to keep track of the biggest end time and to decide whether to close or extend the current interval. Finally, after being clear with these ideas, they may write the formal answer with carefulness on both syntax and variable names. This reasoning procedure happens from coarse to fine. We therefore construct the prediction target into four subsequences. Note that the boxed substrings only roughly indicate the tokens, while our actual tokens take the forms of the grouped nodes in the syntax tree.",
            "Figure 2. Overall Model Architecture of ChainCoder, which consists of the sample embedder, the problem description embedder, the traditional transformer encoder, and decoder.",
            "Figure 3. Token frequency distribution. Visibly, the majority of tokens are rarely met. From our inspection, these highly infrequent tokens are not necessarily tied to the code solutions but rather just happened to occur randomly. Therefore, it is safe to assume that ChainCoder can be trained on the more-frequent end of the distribution alone without facing any performance losses.",
            "Figure 4. Results on CodeContests dataset compared with AlphaCode ChainCoder with 1 billion parameters outperforms AlphaCode with similar sizes.",
            "Figure 5. Token strings demonstration: the strings in the above and below figures are S3 and S4 subsequences for the code snipped in the bottom right, respectively.",
            "Figure 6. The example outputs of APPS model (GPT-Neo 2.7B, left) and ChainCoder (middle and right, with two different post-naming rules), over the same problem.",
            "Table 1. The tokenization sequence length statistics. The syntaxaware tokenizer sequence length is calculated by the summation of layout frame and accessory subsequences. The ChainCoder tokenizer leads to shorder sequence thanks to the domain knowledge built-in to syntax tree.",
            "Table 2. The results of APPS (Hendrycks et al., 2021), AlphaCode (Li et al., 2022) and ChainCoder on the APPS test set, fine-tuned on the APPS training set.",
            "Table 3. Types of accessory tokens",
            "Table 4. One instance with three exsamples of I/O data. io1 = [[[0,2,3],0], [12, ’abcd’]], io2 = [[[0,2,3,5,1], 2], [43, ’m’]], io3 = [[[4,5,6,7], 532], [9908, ’ss’]]."
        ],
        "imgs": [
            "$2305.00909v4-Figure1-1.png",
            "$2305.00909v4-Figure2-1.png",
            "$2305.00909v4-Figure3-1.png",
            "$2305.00909v4-Figure4-1.png",
            "$2305.00909v4-Figure5-1.png",
            "$2305.00909v4-Figure6-1.png",
            "$2305.00909v4-Table1-1.png",
            "$2305.00909v4-Table2-1.png",
            "$2305.00909v4-Table3-1.png",
            "$2305.00909v4-Table4-1.png"
        ]
    },
    {
        "id": "2305.00910",
        "abstract": "  The scattering of waves is a ubiquitous phenomenon in physics, yet there are\nnumerous scenarios, such as the pursuit of invisibility, where suppressing it\nis of utmost importance. In comparison to prior methods which are restricted by\nlimited bandwidths, here we present a technique to suppress sound scattering\nacross an ultra-broad spectrum by utilizing illusion metamaterials. This\nillusion metamaterial, consisting of subwavelength tunnels with precisely\ncrafted internal structures, has the ability to guide acoustic waves around the\nobstacles and recreate the incoming wavefront on the exit surface.\nConsequently, two ultra-broadband illusionary effects are produced:\ndisappearing space and time shift. Simultaneously, all signs of sound\nscattering are removed across an exceptionally wide spectrum, ranging from the\nquasistatic limit to an upper limit of the spectrum, as confirmed by full-wave\nsimulations and acoustic experiments. Our approach represents a major step\nforward in the development of broadband functional metamaterials and holds the\npotential to revolutionize various fields, including acoustic camouflage and\nreverberation control.\n",
        "title": "Ultra-broadband suppression of sound scattering via illusion\n  metamaterials",
        "texts": [
            "Fig. 1. Illustration of the illusion metamaterial as a SS device. Upon the incidence of a sound wave, a multiple scattering is almost always generated by a random arrangement of obstacles, however, b when the obstacles are embedded in the illusion metamaterial (SS device), the backward reflection is removed and the waves can propagate around the obstacles with their wavefronts undistorted. The arrows and the alternating solid and dashed lines represent sound waves and their wavefronts, respectively.",
            "Fig. 2. Design of acoustic tunnels with tunable acoustic paths. a Schematic diagram of a tunnel with a varying crosssection along a curved path. The grey portion represents the solid structure. A magnified view is displayed in the topright corner. Arrows indicate the incidence and transmission of waves. b Simulated acoustic pressure field distributions that vary with the ratio of ℎ/𝑤, corresponding to phase shift ∆𝜙 = 0, π, 2π. c Phase shift ∆𝜙 and transmittance |𝑡|2 under normal incidence as a function of ℎ/𝑤 . Vertical grey dotted lines indicate the cases with ∆𝜙 = π, 2π . d Equivalent relative refractive index 𝑛𝑟 as a function of ℎ/𝑤 and the frequency 𝑓.",
            "Fig. 3. Design of the ultra-broadband illusion metamaterial and experimental setup. a Schematic diagram of the illusion metamaterial and experimental setup. A magnified view of the metamaterial is shown in b. The side length of the square-shaped unit is 𝑎 = 20 cm. The diagonal lengths of the rhombic-shaped obstacle are represented by 𝑎 and 𝑎/2, respectively. c Geometric parameter ℎ/𝑤 for various tunnels in the metamaterial. d Picture of the experimental setup.",
            "Fig. 4. Ultra-broadband illusionary effect of “disappearing space” and sound scattering suppression. a,c,e Simulated acoustic pressure field distributions for the scenario of bare obstacles under a point source radiation at different operating frequencies of 𝑓 = 4860 Hz, 6860 Hz, 8860 Hz, and the corresponding experimental measurements (located in the black dashed area) are on the right. b,d,f Results for the scenario of obstacles covered by the SS device. g-h Frequency dependence of the normalized scattered pressure intensity for the transmission region (𝛾𝑡) and reflection region (𝛾𝑟).",
            "Fig. 5. Pulse radiation and illusionary effect of “time shift”. a Snapshots of a sound pulse propagating through a collection of obstacles with significant scattering. b Snapshots of a sound pulse propagating through the obstacles embedded in the illusion metamaterial. The inset graphs display magnified details of the wavefront inside the metamaterial. The numbers indicate the order of the snapshots, where ∆t = 0.1 ms. See Supplemental Videos.",
            "Fig. 6. Ultra-broadband illusion metamaterial and sound scattering suppression for a random collection of obstacles. a Schematic of a specific illusion metamaterial composed of three rhombic obstacles arranged randomly. b Simulated acoustic pressure field distributions for the scenarios of obstacles with or without the SS device under a point source radiation at an operating frequency of 𝑓 = 6860 Hz. The point source is located at (-20 cm, 0 cm), and the center of three obstacles are located at (10 cm, 10 cm), (35 cm, 0 cm) and (12.5 cm, -12.5 cm), respectively. c-d Frequency dependence of the normalized scattered pressure intensity for the transmission region (𝛾𝑡) and reflection region (𝛾𝑟)."
        ],
        "imgs": [
            "$2305.00910v1-Figure1-1.png",
            "$2305.00910v1-Figure2-1.png",
            "$2305.00910v1-Figure3-1.png",
            "$2305.00910v1-Figure4-1.png",
            "$2305.00910v1-Figure5-1.png",
            "$2305.00910v1-Figure6-1.png"
        ]
    },
    {
        "id": "2305.00911",
        "abstract": "  Vehicle teleoperation has potential applications in fallback solutions for\nautonomous vehicles, remote delivery services, and hazardous operations.\nHowever, network delays and limited situational awareness can compromise\nteleoperation performance and increase the cognitive workload of human\noperators. To address these issues, we previously introduced the novel\nsuccessive reference pose tracking (SRPT) approach, which transmits successive\nreference poses to the vehicle instead of steering commands. This paper\ncompares the stability and performance of SRPT with Smith predictor-based\napproaches for direct vehicle teleoperation in challenging scenarios. The Smith\npredictor approach is further categorized, one with Lookahead driver and second\nwith Stanley driver. Simulations are conducted in a Simulink environment,\nconsidering variable network delays and different vehicle speeds, and include\nmaneuvers such as tight corners, slalom, low-adhesion roads, and strong\ncrosswinds. The results show that the SRPT approach significantly improves\nstability and reference tracking performance, with negligible effect of network\ndelays on path tracking. Our findings demonstrate the effectiveness of SRPT in\neliminating the detrimental effect of network delays in vehicle teleoperation.\n",
        "title": "SRPT vs Smith Predictor for Vehicle Teleoperation",
        "texts": [
            "Fig. 1. A pictorial representation of SRPT approach for direct vehicle teleoperation. The remote vehicle receives successive reference poses as it moves forward.",
            "Fig. 10. Vehicle teleoperation simulation result with various modes at VRef = 26 km/h. SRPT vehicle teleoperation accurately traces the track, even in the presence of variable delays.",
            "Fig. 11. Completion time comparison SRPT vs Smith mode for [B,D,G,H] regions.",
            "Fig. 3. Smith predictor schematic for vehicle teleoperation simulation. H1 and H2 are types of driver models considered. Unity has no role in simulation, it is just to display the manoeuvres.",
            "Fig. 4. (a) Look-ahead driver model control. (b) Tuning of k1 for the lookahead driver model keeping k2 = 0.9s constant.",
            "Fig. 5. Tuning of k for the Stanley controller.",
            "TABLE I 14-DOF MODEL: VEHICLE BRIEF CHARACTERISTICS."
        ],
        "imgs": [
            "$2305.00911v1-Figure1-1.png",
            "$2305.00911v1-Figure10-1.png",
            "$2305.00911v1-Figure11-1.png",
            "$2305.00911v1-Figure3-1.png",
            "$2305.00911v1-Figure4-1.png",
            "$2305.00911v1-Figure5-1.png",
            "$2305.00911v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00912",
        "abstract": "  The methodology discussed in this paper aims to enhance choice models'\ncomprehensiveness and explanatory power for forecasting choice outcomes. To\nachieve these, we have developed a data-driven method that leverages machine\nlearning procedures for identifying the most effective representation of\nvariables in mode choice empirical probability specifications. The methodology\nwill show its significance, particularly in the face of big data and an\nabundance of variables where it can search through many candidate models.\nFurthermore, this study will have potential applications in transportation\nplanning and policy-making, which will be achieved by introducing a sparse\nidentification method that looks for the sparsest specification ( parsimonious\nmodel ) in the domain of candidate functions. Finally, this paper applies the\nmethod to synthetic choice data as a proof of concept. We perform two\nexperiments and show that if the functional form used to generate the synthetic\ndata lies in the domain of base functions, the methodology can recover that.\nOtherwise, the method will raise a red flag by outputting small coefficients (\nnear zero ) for base functions.\n",
        "title": "A sparse identification approach for automating choice models'\n  specification",
        "texts": [
            "Figure 2. Base functions acting on explanatory variables ( x1 to x40 ) and their transformations",
            "Table 1. Estimation results for base functions coefficients",
            "Table 2. Estimation results for base functions coefficients : most of the coefficients are near zero"
        ],
        "imgs": [
            "$2305.00912v1-Figure2-1.png",
            "$2305.00912v1-Table1-1.png",
            "$2305.00912v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00913",
        "abstract": "  In this article, we obtain the exact solutions for bound states of tilted\nanisotropic Dirac materials under the action of external electric and magnetic\nfields with translational symmetry. In order to solve the eigenvalue equation\nthat arises from the effective Hamiltonian of these materials, we describe an\nalgorithm that allow us to decouple the differential equations that are\nobtained for the spinor components.\n",
        "title": "An algorithm for exact analytical solutions for tilted anisotropic Dirac\n  materials",
        "texts": [
            "Figure 1: (a) Plots of the energy spectrum as a function of the wavenumber k and (b) as a function of the electric field strength. (c) Plot of the probability density and (d) y-component current density. The values have been fixed as k = 0, ν = κ = 1, {vx, vy, vt, vd} = {0.534, 0.785, −0.345, 0.25} and ω = 2.",
            "Figure 2: (a) Plots of the energy spectrum as a function of the wavenumber k and (b) as a function of the electric field strength. (c) Plot of the probability density and (d) y-component current density. The values have been set as k = 3, ν = κ = 1, {vx, vy, vt, vd} = {0.86, 0.69, 0.32, 0.1}.",
            "Figure 3: (a) Plot of some energy levels for the first limiting case, as well as the corresponding (b) probability and (c) y-component current densities for the eigenstates in equation 50. The parameters have been taken as k = 1, ν = κ = 1, {vx, vy, vt, vd} = {1, 1, 0, 0}, which can represent graphene.",
            "Figure 4: (a) Plot of some energy levels for the second limiting case, as well as the corresponding (a) probability and (b) y-component current densities for the eigenstates in equation (52). The parameters have been chosen as k = 5, ν = κ = 1, {vx, vy, vt, vd} = {1, 1, 0, 0}, which can represent graphene."
        ],
        "imgs": [
            "$2305.00913v1-Figure1-1.png",
            "$2305.00913v1-Figure2-1.png",
            "$2305.00913v1-Figure3-1.png",
            "$2305.00913v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00916",
        "abstract": "  The squashed seven-sphere operator spectrum is completed by deriving the\nspectrum of the spin-3/2 operator. The implications of the results for the\n$AdS_4$ $\\mathcal{N} = 1$ supermultiplets obtained from compactification of\neleven-dimensional supergravity are analysed. The weak $G_2$ holonomy plays an\nimportant role when solving the eigenvalue equations on the squashed sphere.\nHere, a novel and more universal algebraic approach to the whole eigenvalue\nproblem on coset manifolds is provided. Having obtained full control of all the\noperator spectra, we can finally determine the irreps $D(E_0, s)$ for all\nsupermultiplets in the left-squashed vacuum. This includes an analysis of\npossible boundary conditions. By performing an orientation flip on the\nseven-sphere, we also obtain the full spectrum for the non-supersymmetric\nright-squashed compactification which is of interest in the swampland context\nand in particular for the $AdS$ swampland conjecture. Here, a number of\nboundary condition ambiguities arise making the analysis of dual marginal\noperators somewhat involved. This work is a direct continuation of [1] and [2].\n",
        "title": "The complete Kaluza-Klein spectra of $\\mathcal{N} = 1$ and $\\mathcal{N}\n  = 0$ M-theory on $AdS_4 \\times (\\text{squashed } S^7)$",
        "texts": [
            "Figure 1. Scalar cross diagram. Each cross corresponds to an isometry irrep (p, q; r), for p ≥ 0, q ≥ 0, of eigenmodes φ of ∆0 with eigenvalues ∆(1) 0 = m2 9 20Cg, as given in (3.88).",
            "Figure 2. Transverse one-form cross diagrams. Each cross corresponds to an isometry irrep (p, q; r) of transverse eigenmodes, listed in (4.15), of ∆1 with an associated eigenvalue given in (4.16). Both columns have a unified 3spC 1 one-form differential operator generating the eigenmodes and a unified expression for the eigenvalues.",
            "Figure 3. Spinor cross diagrams. The corresponding eigenmodes of i /D1/2 are listed in (4.31)–(4.32) and the associated eigenvalues in (4.33)–(4.34).",
            "Figure 4. Transverse two-form cross diagrams. The corresponding eigenmodes are listed in (4.49)– (4.52) and the associated eigenvalues in (4.53)–(4.55). Note that the last column is associated to a linear combination of the eigenmodes formed from Ỹ(3)i",
            "Figure 5. The cross diagrams in the appendix of [1] that remain when all other supermultiplets with their respective cross diagrams have been removed. These twelve diagrams correspond to two sets of 1 ⊕ 5. The displayed division into two different sets, see Table 5, relies on the results of [28] for small p or q. The multiplicities of the isometry irreps are one for crosses and two for boxes with crosses. The single encircled cross, in the irrep (0, 0; 0), is the Page supermultiplet (see below) containing the mode “coming from nowhere” in the analysis of [1, 32].",
            "Figure 6. Non-transverse one-form cross diagrams. Each cross corresponds to an isometry irrep (p, q; r) of non-transverse eigenmodes of ∆1 generated by the differential operator in (C.1) and with the eigenvalue in (C.2).",
            "Figure 7. Non-transverse two-form cross diagrams. Each cross corresponds to an isometry irrep (p, q; r) of non-transverse eigenmodes of ∆2, listed in (C.4), with associated eigenvalues given in (C.5).",
            "Figure 8. All isometry irreps of the twelve Wess–Zumino supermultiplet towers WZ3–6 (including the Page supermultiplet), corresponding to two sets of 1 ⊕ 5. The colours at the intersections of the grid lines indicate the multiplicities of the isometry irreps.",
            "Table 1. N = 1 supermultiplets according to Heidenreich [33].",
            "Table 10. Pseudo-scalars that can have both Dirichlet and Neumann boundary conditions. The list is divided into the ones occurring in the left-squashed vacuum (LS7) and those belonging to the right-squashed vacuum (RS7). Some details about which (p, q; r) belong to which branch of 0−(Q(1)±) have been collected from [28] and used here. Note that the last entry for 0−(Q(1)+) is special since the option with a minus sign in E0, corresponding to a singleton, is not possible in the RS7 vacuum. This follows from the results in [1]. Note also that Neumann boundary conditions for 0−(Q(2)−) do not respect supersymmetry in the left-squashed vacuum, see Section 5.1. All brackets are positive.",
            "Table 11. Spinors that can have both Dirichlet and Neumann boundary conditions. The special entries are of two kinds: 1) The one in the LS7 part of the table with E0 = 3 2 , which have neither Dirichlet nor Neumann boundary conditions (see [7]). 2) The first and last entries in the RS7 part of the table where only one sign in E0 is given as dictated by the fact that the only singleton that exists belongs to the RS7 vacuum and is a singlet [1]. Note that Neumann boundary conditions for 1 2 (i /D(2)−",
            "Table 12. Possible scalar g = sp2×spC1 singlet marginal operators with parity p in LS7 depending on the boundary conditions. The subscripts after the eigenvalues indicate the isometry irreps (p, q; r) while the superscript indicates the boundary conditions when applicable (+ for Dirichlet, − for Neumann). The leftmost column gives the number of g-singlets in the composite. Note that only the ones containing two spinors are compatible with the boundary conditions that preserve N = 1 supersymmetry.",
            "Table 13. Possible scalar g = sp2×spC1 singlet marginal operators with parity p in RS7 depending on the boundary conditions, with notation as in Table 12. Note that the lines without a number in the leftmost column are continuation lines.",
            "Table 14. Casimir eigenvalues on irreps specified by Dynkin labels with the adjoint representation given explicitly.",
            "Table 15. Scalar and pseudo-scalar fields with E0 ≤ 3 in the AdS4 spectrum based on the round S7 where n is the level number. All massless (pseudo-)scalar fields in the spectrum are present in this list. These fields are dual to relevant operators in the boundary CFT3. We also specify whether the fields have singleton (E0 = 1 2 ), Neumann ( 1 2 < E0 < 3 2 ), degenerate (E0 = 3 2 ) or Dirichlet (E0 > 3 2 ) boundary conditions.",
            "Table 16. Spin-1/2 fermion fields with E0 ≤ 3 in the AdS4 spectrum based on the round S7 where n is the level number. All massless spin-1/2 fields in the spectrum are present in this list. These fields are dual to relevant operators in the boundary CFT3. We also specify whether the fields have singleton (E0 = 1), Neumann (1 < E0 < 3 2 ), degenerate (E0 = 3 2 ) or Dirichlet (E0 > 3 2 ) boundary conditions.",
            "Table 18. Scalars and pseudo-scalars with 5 2 < E0 ≤ 3 in both the left- and right-squashed vacuum. Note that the properties of the scalar fields are the same in the two vacua.",
            "Table 2. E0 for AdS4 fields of given mass M and spin s (in Spin(2, 3)-irreps D(E0, s)) and the corresponding unitarity bounds.",
            "Table 3. Mass operators in Freund–Rubin compactifications, see for instance [25]. For spins with two tower assignments, the subscripts (±), the plus and minus signs refer to branches of the M2 formulas or to the positive and negative parts of the spectrum for linear operators. Note the change of notation relative [25] where superscripts (1), (2) etc. were used instead of the (±) notation of this paper.",
            "Table 4. Supermultiplets with maximum spin s = 2, 3/2, 1 and parity p. Here, each entry, represented by s(operatoreigenvalue",
            "Table 5. Wess–Zumino supermultiplets for Cg > 0. See Table 4 for definitions. The upper sign in the WZ2 E0 value corresponds to (D,D,D) boundary conditions for p + q ≥ 3, (D,N,D) for p+ q = 2 and (N,N,D) for p+ q = 1. The scalar 0+ and pseudo-scalar 0− should change places in the WZ2 supermultiplet if the lower sign in the E0 formula is used, as indicated by the arrow. The lower sign is only valid for p+q = 2 and p+q = 1 and then corresponds to (N,N,D) and (D,N,D) boundary conditions, respectively. The subscript on 0+ (±) indicates which branch of M2(∆0) is used.",
            "Table 6. Irreps with r = p and Cg > 0 for which Wess–Zumino multiplets in WZ2 admit both Dirichlet and Neumann boundary conditions. The implications of this are explained in the text. Here, (d2, d1) denotes the dimensions of the sp2- and spC1 -irreps.",
            "Table 7. AdS4 spin, operator eigenvalues, masses and E0 values of isometry singlet (Cg = 0) modes and the associated AdS4 fields. The plus subscript on M2 indicates the branch of the mass formula in Table 3. The ± in the E0 column corresponds to different boundary conditions. Below, we will see that supersymmetry fixes the plus sign.",
            "Table 8. Wess–Zumino supermultiplets with Cg = 0.",
            "Table 9. Scalars that can have both Dirichlet and Neumann boundary conditions. The listed fields and their properties are the same in the left- and the right-squashed vacuum. Note that only the five first rows can respect supersymmetry with Neumann boundary conditions in the left-squashed vacuum, see Section 5.1. All brackets are positive."
        ],
        "imgs": [
            "$2305.00916v1-Figure1-1.png",
            "$2305.00916v1-Figure2-1.png",
            "$2305.00916v1-Figure3-1.png",
            "$2305.00916v1-Figure4-1.png",
            "$2305.00916v1-Figure5-1.png",
            "$2305.00916v1-Figure6-1.png",
            "$2305.00916v1-Figure7-1.png",
            "$2305.00916v1-Figure8-1.png",
            "$2305.00916v1-Table1-1.png",
            "$2305.00916v1-Table10-1.png",
            "$2305.00916v1-Table11-1.png",
            "$2305.00916v1-Table12-1.png",
            "$2305.00916v1-Table13-1.png",
            "$2305.00916v1-Table14-1.png",
            "$2305.00916v1-Table15-1.png",
            "$2305.00916v1-Table16-1.png",
            "$2305.00916v1-Table18-1.png",
            "$2305.00916v1-Table2-1.png",
            "$2305.00916v1-Table3-1.png",
            "$2305.00916v1-Table4-1.png",
            "$2305.00916v1-Table5-1.png",
            "$2305.00916v1-Table6-1.png",
            "$2305.00916v1-Table7-1.png",
            "$2305.00916v1-Table8-1.png",
            "$2305.00916v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00918",
        "abstract": "  Knowledge distillation conducts an effective model compression method while\nholding some limitations:(1) the feature based distillation methods only focus\non distilling the feature map but are lack of transferring the relation of data\nexamples; (2) the relational distillation methods are either limited to the\nhandcrafted functions for relation extraction, such as L2 norm, or weak in\ninter- and intra- class relation modeling. Besides, the feature divergence of\nheterogeneous teacher-student architectures may lead to inaccurate relational\nknowledge transferring. In this work, we propose a novel training framework\nnamed Class-Oriented Relational Self Distillation (CORSD) to address the\nlimitations. The trainable relation networks are designed to extract relation\nof structured data input, and they enable the whole model to better classify\nsamples by transferring the relational knowledge from the deepest layer of the\nmodel to shallow layers. Besides, auxiliary classifiers are proposed to make\nrelation networks capture class-oriented relation that benefits classification\ntask. Experiments demonstrate that CORSD achieves remarkable improvements.\nCompared to baseline, 3.8%, 1.5% and 4.5% averaged accuracy boost can be\nobserved on CIFAR100, ImageNet and CUB-200-2011, respectively.\n",
        "title": "CORSD: Class-Oriented Relational Self Distillation",
        "texts": [
            "Fig. 1: The overview of our proposed training framework Class-Oriented Relational Self Distillation (CORSD). Best viewed in color.",
            "Fig. 2: Visualization of feature distribution at different depths. BL represents baseline training, RN indicates relation network training and AC stands for auxiliary classifier training. Recommended zoom in for better view.",
            "Fig. 3: Sensitivity study of hyper-parameters with ResNet18 on the CIFAR100 dataset. Recommended zoom in for better view.",
            "Table 1: Top-1 accuracy (%) on CIFAR100 across a number of distillation methods. Boldface marks the best performing accuracy. The teacher model of all knowledge distillation methods is ResNeXt101-8, which the accuracy is 83.78 %.",
            "Table 2: Top-1 accuracy (%) on ImageNet across several self distillation based methods. Boldface marks the best performing accuracy.",
            "Table 3: Top-1 accuracy (%) on CUB-200-2011. Boldface marks the best performing accuracy. The teacher model of RKD is ResNeXt1018, which accuracy is 79.12%.",
            "Table 4: Ablation study of Top-1 accuracy (%) with ResNet18 on the CIFAR100 dataset."
        ],
        "imgs": [
            "$2305.00918v1-Figure1-1.png",
            "$2305.00918v1-Figure2-1.png",
            "$2305.00918v1-Figure3-1.png",
            "$2305.00918v1-Table1-1.png",
            "$2305.00918v1-Table2-1.png",
            "$2305.00918v1-Table3-1.png",
            "$2305.00918v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00919",
        "abstract": "  DNAs charge transfer and self-assembly characteristics have made it a\nhallmark of molecular electronics for the past two decades. A fast and\nefficient charge transfer mechanism with programmable properties using DNA\nnanostructures is required for DNA-based nanoelectronics applications and\ndevices. The ability to integrate DNA with inorganic substrates becomes\ncritical in this process. Such integrations may effect the conformation of DNA,\naltering the charge transport properties. Thus, using molecular dynamics\nsimulations and first-principles calculations in conjunction with Greens\nfunction approach, we explore the impact of Au (111) substrate on the\nconformation of DNA and analyze its effect on the charge transport. Our results\nindicate that DNA sequence, leading its molecular conformation on Au substrate,\nis critical to engineer charge transport properties. We demonstrate that DNA\ncan fluctuate on a gold substrate, sampling various distinct conformations over\ntime. The energy levels, spatial locations of molecular orbitals and the DNA/Au\ncontact atoms can differ between these distinct conformations. Depending on the\nsequence, at HOMO, the charge transmission differs up to 60 times between the\ntop ten conformations. We demonstrate that the relative positions of the\nnucleobases are critical in determining the conformations and the coupling\nbetween orbitals. We anticipate these results can be extended to other\ninorganic surfaces and pave the way for understanding DNA inorganic interface\ninteraction for future DNA-based electronic devices.\n",
        "title": "DNA-Au (111) Interactions and Transverse Charge Transport Properties for\n  DNA-Based Electronic Devices",
        "texts": [
            "Figure 3b demonstrates the transmission plots for the ten conformations corresponding to each sequence. We shift the energy axis to make the HOMO energy of all representative structures to be at E=0. First, we notice that for a given sequence, the transmission can vary by order of magnitude at"
        ],
        "imgs": [
            "$2305.00919v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00921",
        "abstract": "  Calculating opacities for a wide range of plasma conditions (i.e.\ntemperature, density, element) requires detailed knowledge of the plasma\nconfiguration space and electronic structure. For plasmas composed of heavier\nelements, relativistic effects are important in both the electronic structure\nand the details of opacity spectra. We extend our previously described\nsuperconfiguration and super transition array capabilities [N. M. Gill et al.,\nJPB, 56, 015001 (2023)] to include a fully relativistic formalism. The use of\nhybrid bound-continuum supershells in our superconfigurations demonstrates the\nimportance of a consistent treatment of bound and continuum electrons in dense\nplasma opacities, and we expand the discussion of these consequences to include\nissues associated with equation of state and electron correlations between\nbound and continuum electrons.\n",
        "title": "The STAG Code: A Fully Relativistic Super Transition Array Calculation\n  Using Green's Functions",
        "texts": [
            "Figure 1: A comparison of various bound-bound STA opacities is shown for an iron plasma at 180 eV and 0.1 g/cm3, all of which are associated with the 2p3/2 → 3s and 2p1/2 → 3s transitions. The non-relativistic result is shown as solid black (with ”×” symbols) for the indicated SC, which appears as a single curve due to the degeneracy of the 2p3/2 and 2p1/2 orbitals. The red dashed curve shows the relativistic STA features associated with the same SC as before, but here the spin-orbit splitting leads to two distinct STAs. If the electrons in the coarse SC are permuted among nl-grouped supershells, we obtain the blue dash-dot curve, which is now associated with six distinct SCs. Permuting the electrons among nl j-grouped supershells produces an equivalent description to a configuration-average approach with 15 distinct relativistic configurations, which is represented by the solid green curve.",
            "Figure 2: The opacity for an iron plasma at 180 eV and 0.16 g/cm3 is compared between non-relativistic and relativistic STA calculations. The black dashed curve shows the non-relativistic results, while the red solid curve shows relativistic results. Both calculations use the same definition for SCs, but the lack of degeneracy between j-resolved orbitals in the relativistic calculation leads to the opacity being distributed over many more lines than in the non-relativistic calculation. The results from the Sandia Z-facility experiments are shown in the blue dotted curve. The differences between the experimental and calculated lines are consistent with the observed discrepancies between the experiment and other model predictions.",
            "Figure 3: The density of states along the top of a complex contour for an AA electronic structure of an iron plasma at 120 eV and 0.5 g/cm3 is shown. The black solid curve is the DOS only 0.01 EH off of the real-energy axis, which results in a small broadening of the features as they would appear on the realenergy axis. The blue dashed curve is 0.1 EH off of the real-energy axis, and the sharp features have mostly been broadened into smooth features, especially near the continuum edge. The green dash-dot curve is 0.5 EH off of the realenergy axis, and this greatly broadened curve can be numerically resolved with very few grid points.",
            "Figure 4: The opacity spectrum of iron at 120 eV and 3.6 g/cm3 is shown for models using different treatments of the continuum electrons within the SC structure calculations. The red dash-dot curve is produced from SCs whose continuum was represented by a homogeneous electron gas, which leads to the smallest plasma screening of the bound states. The green dashed curve is produced from SCs whose continuum was represented by a Thomas-Fermi approximation, which semi-classically describes the continuum and overpredicts the plasma screening. The black solid curve is produced with the full continuum model, which has a consistent treatment of bound and continuum electrons in the electronic structure. The location of the 3d → 4 f transitions is marked to indicate the impact of the pressure ionization of 4 f electrons on the opacity spectrum. The 2p → 4d transitions are marked to indicate that the CSD shifts due to the different models lead to shifts in the most prominent features of that portion of the opacity.",
            "Figure 5: The charge state distributions of an iron plasma at 120 eV and 3.6 g/cm3 are shown. The different curves correspond to the CSDs associated with the opacities shown in figure 4."
        ],
        "imgs": [
            "$2305.00921v1-Figure1-1.png",
            "$2305.00921v1-Figure2-1.png",
            "$2305.00921v1-Figure3-1.png",
            "$2305.00921v1-Figure4-1.png",
            "$2305.00921v1-Figure5-1.png"
        ]
    },
    {
        "id": "2305.00924",
        "abstract": "  We study the extent to which Milne-Eddington inversions are able to retrieve\nand characterize the magnetic landscape of the solar poles from observations by\nthe spectropolarimeter onboard Hinode. In particular, we evaluate whether a\nvariable magnetic filling factor is an adequate modeling technique for\nretrieving the intrinsic magnetic properties from every pixel in the polar\nfield of view. We first generate synthetic spectra emerging from a numerical\nsimulation of a \"plage\" region at an inclined line of sight of 65$^{\\circ}$,\nand degrade the data to emulate real observations. Then, we invert the\nsynthetic spectra with two Milne-Eddington inversion codes that feature\ndifferent treatments of the magnetic filling factor, and relate the retrieved\nmagnetic quantities back to their original values in the simulation cube. We\nfind that while the apparent retrieved magnetic properties map well the\nspatially-degraded simulation, the intrinsic magnetic quantities bear little\nrelation to the magnetic field at the native resolution of the simulation. We\ndiscuss the systematic biases caused by line-of-sight foreshortening, spatial\ndegradation, photon noise and modeling assumptions embedded in the inversion\nalgorithm.\n",
        "title": "Limitations and biases in the retrieval of the polar magnetic field I:\n  the role of the magnetic filling factor in Milne-Eddington inversions of\n  simulated Hinode/SP data",
        "texts": [
            "Figure 1. Continuum intensity derived from the synthetic spectra at three different stages in the process. A: synthetic continuum image from the spectra emerging from a 65 ◦ LOS at the native resolution of the simulation (i.e. 16 km sampling). B: continuum intensity after foreshortening the pixels along the LOS direction. C: continuum image after spatially convolving the synthetic data with an Airy disk of 240 km radius.",
            "Figure 2. Comparison of retrieved magnetic quantities from MILOS and MERLIN inversions. Each panel contains a density scatter plot of MERLIN against MILOS results for a specific magnetic quantity. The top row corresponds to the intrinsic magnetic field components, while the bottom row shows their corresponding apparent counterparts. From left to right: LOS component of the magnetic field, transverse component of the magnetic field, magnetic field inclination with respect to the LOS. Note that the colorbar represents the number of occurrences on a logarithmic scale. The solid green line shows the average MERLIN value in each bin on the MILOS x-axis. The dashed-line marks the ideal one-to-one relationship.",
            "Figure 3. Density scatter plot of the magnetic filling factors retrieved by MERLIN and MILOS. On the top, we show only the pixels above the polarization threshold. The bottom panel shows the scatter plot for all pixels in the FoV.",
            "Figure 4. Pearson correlation between the apparent vector magnetic field parameters delivered by the inversions and the degraded MURaM simulation, as a function of optical depth in the simulation (log(τ) = −0.5,−1,−1.5,−2). The top row shows the MERLIN results whilst the bottom row concerns itself with MILOS inversions.",
            "Figure 5. Comparison between the apparent magnetic quantities retrieved by the inversion and the magnetic field components in the spatially-degraded MURaM cube at log(τ = −1.5). The top (middle) row shows the density scatter plots of the MERLIN (MILOS) inverted quantities against their MURaM counterparts. The bin sizes are 8 Mx/cm2, 10 Mx/cm2, and 1.8◦ for the LOS and transverse fluxes, and the angles, respectively. The solid and dashed green lines have the same meaning as in Fig. 2. The bottom row of the figure shows 1D histograms of the same apparent magnetic components, with the spatially-degraded MURaM in black, MERLIN in blue and MILOS in orange.",
            "Figure 6. Comparison between the intrinsic magnetic quantities retrieved by the inversions and the magnetic field components in the foreshortened (but not spatially-degraded) MURaM cube. The top (middle) row shows the density scatter plots of the MERLIN (MILOS) inverted field against its MURaM counterpart. The bin sizes are 20 G, 12 G, and 1.8◦ for the LOS and transverse fields, and the angles, respectively. The solid and dashed green lines have the same meaning as in Fig. 2. The bottom row of the figure shows 1D histograms of the same magnetic field components with MURaM in thick black lines, MERLIN in blue and MILOS in orange. The histograms of the spatially degraded MURaM simulation are also plotted for comparison (thin black line).",
            "Figure 7. Magnetic field components of the magnetic patch. Top: in the original (”local”) reference frame. Bottom: in the LOS reference frame.",
            "Figure 8. Azimuths in the original (χ) and LOS (χ′) reference frames. The azimuth images are shown in the top row and their distributions in the bottom row.",
            "Figure 9. Azimuth images (top) and distributions (bottom) for the cases where the pixels have been foreshortened (first column) a spatial degradation has been applied (second column), the azimuths have been folded between 0 and 180◦ (third column), and pixels with weak magnetic fields have been masked from the image (fourth column)."
        ],
        "imgs": [
            "$2305.00924v1-Figure1-1.png",
            "$2305.00924v1-Figure2-1.png",
            "$2305.00924v1-Figure3-1.png",
            "$2305.00924v1-Figure4-1.png",
            "$2305.00924v1-Figure5-1.png",
            "$2305.00924v1-Figure6-1.png",
            "$2305.00924v1-Figure7-1.png",
            "$2305.00924v1-Figure8-1.png",
            "$2305.00924v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00925",
        "abstract": "  Over the years, honeypots emerged as an important security tool to understand\nattacker intent and deceive attackers to spend time and resources. Recently,\nhoneypots are being deployed for Internet of things (IoT) devices to lure\nattackers, and learn their behavior. However, most of the existing IoT\nhoneypots, even the high interaction ones, are easily detected by an attacker\nwho can observe honeypot traffic due to lack of real network traffic\noriginating from the honeypot. This implies that, to build better honeypots and\nenhance cyber deception capabilities, IoT honeypots need to generate realistic\nnetwork traffic flows. To achieve this goal, we propose a novel deep learning\nbased approach for generating traffic flows that mimic real network traffic due\nto user and IoT device interactions. A key technical challenge that our\napproach overcomes is scarcity of device-specific IoT traffic data to\neffectively train a generator. We address this challenge by leveraging a core\ngenerative adversarial learning algorithm for sequences along with domain\nspecific knowledge common to IoT devices. Through an extensive experimental\nevaluation with 18 IoT devices, we demonstrate that the proposed synthetic IoT\ntraffic generation tool significantly outperforms state of the art sequence and\npacket generators in remaining indistinguishable from real traffic even to an\nadaptive attacker.\n",
        "title": "IoTFlowGenerator: Crafting Synthetic IoT Device Traffic Flows for Cyber\n  Deception",
        "texts": [
            "Figure 1: The Illustration of IoTFlowGenerator: Metadata is extracted from packet capture files and preprocessed into feature vectors. IoTFlowGenerator then finds discrete packet representations (FDPR) for each packet. SeqGAN is utilized to adverserially train on the real tokens and synthesize fake tokens. Finally, IoTFlowGenerator reconstructs packet feature vectors for the fake tokens, producing our desired synthetic feature vectors.",
            "Figure 3: The Illustration of VQ-STAE: The auto-encoder used in IoTFlowGenerator to map between the feature space and the discrete space. VQ-STAE is a modified Vector Quantized - Variational Auto Encoder that uses multi-variate sequence transformers for the encoder and decoder to train on multi-variate sequences in a self-supervised manner. In the figure, C represents the input sequence length and D represents the length of the embedding vectors.",
            "Table 1: Synthetic Data-Aware Adversary Classification Accuracy"
        ],
        "imgs": [
            "$2305.00925v1-Figure1-1.png",
            "$2305.00925v1-Figure3-1.png",
            "$2305.00925v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00926",
        "abstract": "  Most human interactions occur in the form of spoken conversations where the\nsemantic meaning of a given utterance depends on the context. Each utterance in\nspoken conversation can be represented by many semantic and speaker attributes,\nand there has been an interest in building Spoken Language Understanding (SLU)\nsystems for automatically predicting these attributes. Recent work has shown\nthat incorporating dialogue history can help advance SLU performance. However,\nseparate models are used for each SLU task, leading to an increase in inference\ntime and computation cost. Motivated by this, we aim to ask: can we jointly\nmodel all the SLU tasks while incorporating context to facilitate low-latency\nand lightweight inference? To answer this, we propose a novel model\narchitecture that learns dialog context to jointly predict the intent, dialog\nact, speaker role, and emotion for the spoken utterance. Note that our joint\nprediction is based on an autoregressive model and we need to decide the\nprediction order of dialog attributes, which is not trivial. To mitigate the\nissue, we also propose an order agnostic training method. Our experiments show\nthat our joint model achieves similar results to task-specific classifiers and\ncan effectively integrate dialog context to further improve the SLU\nperformance.\n",
        "title": "Joint Modelling of Spoken Language Understanding Tasks with Integrated\n  Dialog History",
        "texts": [
            "Fig. 1: Diagram of our joint E2E model incorporating dialog history for jointly predicting all SLU tasks",
            "Table 1: Results presenting the performance of our joint model both with and without using dialog context on dialog act (DA) recognition, intent classification (IC), speaker role (SR) prediction and emotion recognition (ER). * We show DA results of prior work although they have different data preparation setup (sec. 4.1). Best joint model results are bolded and further underlined if they surpass separate E2E models.",
            "Table 2: Results showing the impact of intermediate CTC to advance SLU performance.",
            "Table 3: Results showing the robustness of using the ASR transcripts instead of the oracle transcripts.",
            "Table 4: Results showcasing the optimal order of SLU tags found during training using Eq. 9 and predicted order of SLU tags during inference. We report sample training utterance for each tag order."
        ],
        "imgs": [
            "$2305.00926v1-Figure1-1.png",
            "$2305.00926v1-Table1-1.png",
            "$2305.00926v1-Table2-1.png",
            "$2305.00926v1-Table3-1.png",
            "$2305.00926v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00928",
        "abstract": "  We demonstrate a prototype kinetic inductance detector (KID) readout system\nthat uses less than 10 mW per pixel. The CCAT-prime RFSoC based readout is\ncapable of reading four independent detector networks of up to 1000 KIDs each.\nThe power dissipation was measured to be less than 40 W while running\nmulti-tone combs on all four channels simultaneously. The system was also used\nfor the first time to perform sweeps and resonator identification on a\nprototype 280 GHz array.\n",
        "title": "Breaking the 10 mW/pixel Limit for Kinetic Inductance Detector Readout\n  Electronics",
        "texts": [
            "Fig. 1: Power dissipation measurement of four channel design. The RFSoC ZCU111 on the left was powered by the supply in the top right with 12 V and was drawing 3.028 A (36.34 W). The RFSoC was programmed with the four channel firmware and configured to generate frequency combs from each channel. Each frequency comb was digitally mixed with a different numerically controlled local oscillator frequency to separate the combs for visual display on the spectrum analyzer.",
            "Fig. 2: Plots of the forward transmission as a function of frequency for a 280 GHz prototype array measured by the RFSoC. The plot on the left shows the transmission normalized to the max for the operational bandwidth of 512 MHz and a numerically controlled local oscillator center frequency of 676 MHz. All five resonances corresponding to the five prototype detectors are easily identified. A zoom in of one resonance is shown on the right."
        ],
        "imgs": [
            "$2305.00928v1-Figure1-1.png",
            "$2305.00928v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00929",
        "abstract": "  This paper describes a methodology for learning flight control systems from\nhuman demonstrations and interventions while considering the estimated\nuncertainty in the learned models. The proposed approach uses human\ndemonstrations to train an initial model via imitation learning and then\niteratively, improve its performance by using real-time human interventions.\nThe aim of the interventions is to correct undesired behaviors and adapt the\nmodel to changes in the task dynamics. The learned model uncertainty is\nestimated in real-time via Monte Carlo Dropout and the human supervisor is cued\nfor intervention via an audiovisual signal when this uncertainty exceeds a\npredefined threshold. This proposed approach is validated in an autonomous\nquadrotor landing task on both fixed and moving platforms. It is shown that\nwith this algorithm, a human can rapidly teach a flight task to an unmanned\naerial vehicle via demonstrating expert trajectories and then adapt the learned\nmodel by intervening when the learned controller performs any undesired\nmaneuver, the task changes, and/or the model uncertainty exceeds a threshold\n",
        "title": "Learning Flight Control Systems from Human Demonstrations and Real-Time\n  Uncertainty-Informed Interventions",
        "texts": [
            "Fig. 1. Block diagrams for a) typical feedback control systems and b) analogous learning agent systems with reward signal (dotted). c) Inset diagram of the Agent block for LfD and LfI, where the human triggers (dashed) switch between actions output by the current policy (black) and actions output from themselves with simultaneous policy update (gray).",
            "Fig. 2. Block diagram depicting the overall system used for demonstration, intervention, and deployment of the learned policy πθ within the control framework of the quadrotor.",
            "Fig. 3. The human operator intervening to correct undesirable actions of the quadrotor to improve the landing task performance. The landing pad being towed by a ground robot is also seen in the image.",
            "Fig. 4. A typical experiment captured by an overhead camera at the lab space. The image shows the quadrotor vehicle following the landing pad which is being towed by the ground robot. An ArUco marker is used to denote the center of the landing pad.",
            "Fig. 5. The mean landing location of the quadrotor under different control policies is shown relative to a square landing area representing the size of the quadrotor base (approximately 50 cm by 50 cm). The center of the landing pad is denoted with a cross. The demonstrations have a comparable mean landing position as that of the classical controllers with a mean radial error of 12.73 cm. The mean landing location of the initial rollout is skewed from the demonstrations due to model uncertainty.",
            "Fig. 6. Figure showing the trajectory of the quadrotor executing the landing task from the same starting location. The trajectories are colored based on the uncertainty from the model trained with 10 demonstrations similar to that of the stationary platform landing imitation using multiple takeoff locations presented earlier.",
            "Fig. 8. The mean landing location of the quadrotor under the learned control policies, highlighting the effect of the interventions. The interventions improve the rollout of the policy so that the mean landing location mimics that of the initial demonstrations.",
            "Fig. 9. Attempts to land on a moving target under multiple control policies. Only the network policy after interventions is capable of landing on the target. The green circle indicates the direction of travel of the landing pad at the start, and a red square at the end of the trajectory.",
            "Table 1. Mean and deviation of landing locations for each control policy."
        ],
        "imgs": [
            "$2305.00929v1-Figure1-1.png",
            "$2305.00929v1-Figure2-1.png",
            "$2305.00929v1-Figure3-1.png",
            "$2305.00929v1-Figure4-1.png",
            "$2305.00929v1-Figure5-1.png",
            "$2305.00929v1-Figure6-1.png",
            "$2305.00929v1-Figure8-1.png",
            "$2305.00929v1-Figure9-1.png",
            "$2305.00929v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00930",
        "abstract": "  We consider the problem of reliable communication over a discrete memoryless\nchannel (DMC) with the help of a relay, termed the information bottleneck (IB)\nchannel. There is no direct link between the source and the destination, and\nthe information flows in two hops. The first hop is a noisy channel from the\nsource to the relay. The second hop is a noiseless but limited-capacity\nbackhaul link from the relay to the decoder. We further assume that the relay\nis oblivious to the transmission codebook. We examine two mismatch scenarios.\nIn the first setting, we assume the decoder is restricted to use some fixed\ndecoding rule, which is mismatched to the actual channel. In the second\nsetting, we assume that the relay is restricted to use some fixed compression\nmetric, which is again mismatched to the statistics of the relay input. We\nestablish bounds on the random- coding capacity of both settings, some of which\nare shown to be ensemble tight.\n",
        "title": "On Mismatched Oblivious Relaying",
        "texts": [
            "Fig. 1: Oblivious Communication System with Mismatched Decoder",
            "Fig. 2: Mismatched performance of the Quaternary example.",
            "Fig. 3: Mismatched performance of the fading example.",
            "Fig. 4: Oblivious Communication System with Mismatched Relay"
        ],
        "imgs": [
            "$2305.00930v1-Figure1-1.png",
            "$2305.00930v1-Figure2-1.png",
            "$2305.00930v1-Figure3-1.png",
            "$2305.00930v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00931",
        "abstract": "  As artificial intelligence (AI) algorithms are increasingly used in\nmission-critical applications, promoting user-trust of these systems will be\nessential to their success. Ensuring users understand the models over which\nalgorithms reason promotes user trust. This work seeks to reconcile differences\nbetween the reward model that an algorithm uses for online partially observable\nMarkov decision (POMDP) planning and the implicit reward model assumed by a\nhuman user. Action discrepancies, differences in decisions made by an algorithm\nand user, are leveraged to estimate a user's objectives as expressed in\nweightings of a reward function.\n",
        "title": "Explanation through Reward Model Reconciliation using POMDP Tree Search",
        "texts": [
            "Fig. 1. Estimating φh using action discrepancies",
            "Fig. 2. A simulation visualization. Note the penalties incurred at timesteps 7, 8, and 9 (shown in red). Observations are shown in the upper left of each cell, while the true state is in the upper right. The belief over states is shown in the center and action taken in the lower right."
        ],
        "imgs": [
            "$2305.00931v1-Figure1-1.png",
            "$2305.00931v1-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00936",
        "abstract": "  There has been significant progress in generating an animatable 3D human\navatar from a single image. However, recovering texture for the 3D human avatar\nfrom a single image has been relatively less addressed. Because the generated\n3D human avatar reveals the occluded texture of the given image as it moves, it\nis critical to synthesize the occluded texture pattern that is unseen from the\nsource image. To generate a plausible texture map for 3D human avatars, the\noccluded texture pattern needs to be synthesized with respect to the visible\ntexture from the given image. Moreover, the generated texture should align with\nthe surface of the target 3D mesh. In this paper, we propose a texture\nsynthesis method for a 3D human avatar that incorporates geometry information.\nThe proposed method consists of two convolutional networks for the sampling and\nrefining process. The sampler network fills in the occluded regions of the\nsource image and aligns the texture with the surface of the target 3D mesh\nusing the geometry information. The sampled texture is further refined and\nadjusted by the refiner network. To maintain the clear details in the given\nimage, both sampled and refined texture is blended to produce the final texture\nmap. To effectively guide the sampler network to achieve its goal, we designed\na curriculum learning scheme that starts from a simple sampling task and\ngradually progresses to the task where the alignment needs to be considered. We\nconducted experiments to show that our method outperforms previous methods\nqualitatively and quantitatively.\n",
        "title": "Generating Texture for 3D Human Avatar from a Single Image using\n  Sampling and Refinement Networks",
        "texts": [
            "Figure 11. Visual comparison of the resulting texture maps from the model trained with and without using the blending mask.",
            "Figure 2. Generated textures using (c) coordinate-based inpainting [14], (d) color-based inpainting [48], and (e) our method from (b) partial texture map. The results from inpainting methods show the preservation of the given details and structure of the partial texture map which is created from (a) source image. However, the results failed to align with the surface of the target mesh, which leads to artifacts in rendered images.",
            "Figure 3. Overview of the proposed method. The source image is processed to create partial texture, visibility mask, and normal map which are given as an input to SamplerNet. SamplerNet predicts a sampling grid that is used for producing the sampled texture. RefinerNet receives the sampled texture and occlusion mask as input, and generates a refined texture and blending mask. The final output is produced by alpha blending the sampled texture with the refined texture using the blending mask.",
            "Figure 4. Illustration of the region-wise augmentation.",
            "Figure 5. Artifact due to the SamplerNet’s prediction error",
            "Figure 6. Visual comparison of applying the reconstruction loss to Tsample and the ground truth texture map.",
            "Figure 7. Visual comparison with previous methods using Digital Wardrobe [8] dataset. The texture maps are generated for the person viewed from randomly rotated perspectives in the horizontal direction.",
            "Figure 8. Visual comparison with previous methods using Digital Wardrobe [8] dataset. The images are rendered with texture maps that are generated using the person viewed from the randomly rotated perspectives in the horizontal direction. We used Tex2Shape [5] to estimate the target mesh from the source image.",
            "Figure 9. Rendered images of 3D human avatars produced using real human images. The images are from SHHQ [11] dataset. The 3D human pose and the camera parameters were predicted from the images using RSC-Net [45].",
            "Table 1. Quantitative evaluation of the generated texture map. The texture maps were generated using the input images with various views. For the *Avg, we used all the images in the range of [−90◦, 90◦] with 10◦ interval as input and averaged the calculated scores from the generated texture maps.",
            "Table 2. Quantitative evaluation of the rendered image. We compared the methods using the input images with various views and rendered the generated texture maps on the target 3D mesh. We used Tex2Shape [5] to estimate the target mesh from the input image and applied it for rendering in all methods. For the *Avg, we used all the rendered images in the range of [−90◦, 90◦] with 10◦ interval as input and averaged the calculated scores.",
            "Table 3. Comparison between various augmentation techniques. The bold number represents the best score and the underlined number represents the score closest to that produced by the model trained with DensePose.",
            "Table 5. Ablation study for the model trained with and without the texture blending."
        ],
        "imgs": [
            "$2305.00936v1-Figure11-1.png",
            "$2305.00936v1-Figure2-1.png",
            "$2305.00936v1-Figure3-1.png",
            "$2305.00936v1-Figure4-1.png",
            "$2305.00936v1-Figure5-1.png",
            "$2305.00936v1-Figure6-1.png",
            "$2305.00936v1-Figure7-1.png",
            "$2305.00936v1-Figure8-1.png",
            "$2305.00936v1-Figure9-1.png",
            "$2305.00936v1-Table1-1.png",
            "$2305.00936v1-Table2-1.png",
            "$2305.00936v1-Table3-1.png",
            "$2305.00936v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00937",
        "abstract": "  Online whiteboards are becoming a popular way to facilitate collaborative\ndesign work, providing a free-form environment to curate ideas. However, as\ntemplates are increasingly being used to scaffold contributions from\nnon-experts designers, it is crucial to understand their impact on the creative\nprocess. In this paper, we present the results from a study with 114 students\nin a large introductory design course. Our results confirm prior findings that\ntemplates benefit students by providing a starting point, a shared process, and\nthe ability to access their own work from previous steps. While prior research\nhas criticized templates for being too rigid, we discovered that using\ntemplates within a free-form environment resulted in visual patterns of\nfree-form curation where concepts were spatially organized, clustered,\ncolor-coded, and connected using arrows and lines. We introduce the concept of\n\"Free-form Templates\" to illustrate how templates and free-form curation can be\nsynergistic.\n",
        "title": "Freeform Templates: Combining Freeform Curation with Structured\n  Templates",
        "texts": [
            "Figure 1: A template from the introductory design course filled in with students’ colored sticky notes, images, and text. 1) Students were expected to add and organize sticky notes from user research, but in addition to this expected behavior, they added data, text, images, and created mind maps. 2) Panels focused on specific topics with instructions to guide contributions. Students additionally used colors to highlight themes across these activities. 3) Smaller input frames constrainedwhat students contributed. 4) Students spontaneously used sticky notes to annotate and star emojis to vote for their favorite storyboards.",
            "Figure 3: The content analysis shows how participants worked within and outside templates to provide additional structure and flexibility. Participants used sticky notes to track tasks, both sticky notes and the sidebar to summarize ideas, and open spaces to do additional activities like prioritymatrices. They also used arrows, spatial grouping, and sticky note color to convey additional meaning. In each of these cases, teams went beyond what was scaffolded by the templates."
        ],
        "imgs": [
            "$2305.00937v1-Figure1-1.png",
            "$2305.00937v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00938",
        "abstract": "  Phase-field modeling is an elegant and versatile computation tool to predict\nmicrostructure evolution in materials in the mesoscale regime. However, these\nsimulations require rigorous numerical solutions of differential equations,\nwhich are accurate but computationally expensive. To overcome this difficulty,\nwe combine two popular machine learning techniques, autoencoder and\nconvolutional long short-term memory (ConvLSTM), to accelerate the study of\nmicrostructural evolution without compromising the resolution of the\nmicrostructural representation. After training with phase-field generated\nmicrostructures of ten known compositions, the model can accurately predict the\nmicrostructure for the future nth frames based on previous m frames for an\nunknown composition. Replacing n phase-field steps with machine-learned\nmicrostructures can significantly accelerate the in silico study of\nmicrostructure evolution.\n",
        "title": "Accelerating microstructure modelling via machine learning: a new method\n  combining Autoencoder and ConvLSTM",
        "texts": [
            "FIG. 1. Workflow of training machine learning model with phase-field generated microstructures and building a machine-learned surrogate model for accelerated prediction of microstructure evolution.",
            "FIG. 2. Figure representing a phase diagram with miscibility gap (top left) and the corresponding bulk free energy f(c) versus composition c diagram at temperature T = T1 (top right). The micorstructures show the time evolution (spinodal decomposition) during isothermal (T = T1) aging of alloys with two different initial compositions 0.25 and 0.5, respectively, at time t = 100, 700 and 1000. Red (circle) and blue (diamond) points on the phase diagram show these two compositions, respectively. Total ten thousand such images (ten different compositions , one thousand time frames per composition) are used as training set.",
            "FIG. 3. Images are reduced in dimensions using the autoencoder. We find that 2000 images are sufficient for training the autoencoder; a heat map comparison of the original (encoded) and reconstructed (decoded) images using (a) 2 cells, (b) 3 cells, and (c) 4 cells autoencoders is presented. Reconstructed images are comparable to the original ones when two to three cells are used.",
            "FIG. 4. The ConvLSTM model is trained with a compressed image dataset in latent space. The architecture of the ConvLSTM model comprises 2, 4, 6, 8, and 10 cells. The illustration compares training and validation loss for different ConvLSTM architectures.",
            "FIG. 5. This graph compares the relative error between the actual and predicted frame. For predicting the 20th frame, the number of previous frames used are 5, 10, 15, 20, 25, 30, 35, and 40. The comparison is made at different stages of the microstructure evolution: (a) 120th, (b) 320th, (c) 520th, and (d) 820th time steps.",
            "FIG. 6. A model trained on 40 previous frames to predict the next frame is used to make the final predictions. This figure illustrates the difference between the actual and predicted frame at the 120th, 320th, 520th, and 820th time step as a heatmap.",
            "FIG. 7. Comparative autocorrelation and heatmap of the (a)10th, (b)20th, (c)30th, and (d)40th predicted frame after the model is trained on the preceding 40 frames. The final figure (e) is the 10th frame predicted, using PCA as the dimensionality reduction technique. Comparing (a) and (e) reveals that the autoencoder fares significantly better than PCA."
        ],
        "imgs": [
            "$2305.00938v1-Figure1-1.png",
            "$2305.00938v1-Figure2-1.png",
            "$2305.00938v1-Figure3-1.png",
            "$2305.00938v1-Figure4-1.png",
            "$2305.00938v1-Figure5-1.png",
            "$2305.00938v1-Figure6-1.png",
            "$2305.00938v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00939",
        "abstract": "  This work is a unified study of stable and unstable steady states of 2D\nactive nematic channel flow using the framework of Exact Coherent Structures\n(ECS). ECS are stationary, periodic, quasiperiodic, or traveling wave solutions\nof the governing equations that, together with their invariant manifolds,\norganize the dynamics of nonlinear continuum systems. We extend our earlier\nwork on ECS in the preturbulent regime by performing a comprehensive study of\nstable and unstable ECS for a wide range of activity values spanning the\npreturbulent and turbulent regimes. In the weakly turbulent regime, we compute\nmore than 200 unstable ECS that co-exist at a single set of parameters, and\nuncover the role of symmetries in organizing the phase space geometry. We\nprovide conclusive numerical evidence that in the preturbulent regime, generic\ntrajectories shadow a series of unstable ECS before settling onto an attractor.\nFinally, our studies hint at shadowing of quasiperiodic type ECS in the\nturbulent regime.\n",
        "title": "Exploring regular and turbulent flow states in active nematic channel\n  flow via Exact Coherent Structures and their invariant manifolds",
        "texts": [
            "FIG. 1: The three equilibria with zero or 1D flow for Ra = 3.4.",
            "FIG. 2: Snapshots of some of the attractors: The vortical flows (top row) and chaotic flow (bottom left) are at Ra = 3.0 and are shown with the same colorbar scales. The modulated wave (bottom right) is at Ra = 1.1; due to the smaller activity, it is shown with different colorbar scales. The alternating vortex lattice RPO and the modulated wave RPO both have shift-reflect symmetry σxT2, the rolling vortex lattice RPO has three-fold translation symmetry T3, while the chaotic flow does not have any symmetry.",
            "FIG. 3: Attractors as a function of activity Ra ≡ α/A (Eq. 11). The channel dimensions are 80`× 20`, where ` is defined from the material constants of the nematic (Eq. 5). The flow alignment λ is 0. The horizontal bars group the attractors by symmetries and other qualitative flow characteristics. A blue color indicates an equilibrium, orange an RPO, and green a PO. Some of the bars are composed of more than one ECS; for example, there are two qualitatively similar 3-fold rolling vortices between Ra =3.34 and Ra =3.86. Real-space flow snapshots are shown in Fig. 2, and the full dataset of ECS is given in the Supplementary material [71].",
            "FIG. 4: A chaotic trajectory and the three attractors projected on the (〈U〉, 〈V 2〉) (left) and (〈V 2〉, 〈Qxx〉) (right) planes, for Ra = 3.4.",
            "FIG. 7: Trajectory ‘densities’ at Ra = 4.5 for the 201 unstable ECS (left) and turbulent attractor (right), projected on the (〈V 2〉, 〈Qxx〉) plane. Each figure is generated from evenly spaced time series of the corresponding trajectories, which are binned and normalized as a 2D probability density function in 〈V 2〉 and 〈Qxx〉. Trajectories tend to spend more time in the yellow regions versus the violet regions.",
            "FIG. 8: Trajectory ‘densities’ along the unstable manifold of UNI in the preturbulent regime projected on the (〈V 2〉, 〈Qxx〉) plane. The dimensionless activity is Ra = 3.4. The full unstable manifold is 34-dimensional and impractical to compute directly. Following the method described in section III C 1, we instead define an ensemble of trajectories that maps out a low-dimensional subspace. The density map (color gradient) is generated from this ensemble by binning evenly spaced time series over the corresponding interval: 0 < t < 100 (top) or 100 < t < 104 (bottom). The apparent overlap of high density regions (yellow) with unstable ECS suggests the occurrence of shadowing, which we have confirmed for selected cases (see section III C 2). Note that there are three stable ECS (or attractors): T1/9, T3/1, and T3/2, while the rest of the ECS shown are unstable.",
            "FIG. 9: Examples of shadowing along the unstable manifold of the unidirectional equilibrium in the preturbulent regime at Ra = 3.4. The color gradient plots on the left show the distances (as defined by equation (14)) between a time-dependent trajectory and a selection of ECS at the same value of activity. The top left and top right illustrate shadowing of the unstable ECS T1/5 from approximately 200τ to 250τ . The bottom left and bottom right show two shadowing events: first, the unstable ECS T6/1 from about 30τ to 70τ , followed by the unstable ECS σxσy(T3/3) from 250τ to 600τ . Both simulations eventually approach T1/9, which is an attractor.",
            "TABLE I: Features of the leading eigenvectors of the dynamics linearized about UNI at Ra = 3.4. The eigenvectors are pure Fourier modes in x, of the form e±2πnx/Lg(y), where L = 80 is the channel width. λ is the eigenvalue, so positive (negative) Re(λ) means the eigenvector represents an unstable (stable) direction."
        ],
        "imgs": [
            "$2305.00939v1-Figure1-1.png",
            "$2305.00939v1-Figure2-1.png",
            "$2305.00939v1-Figure3-1.png",
            "$2305.00939v1-Figure4-1.png",
            "$2305.00939v1-Figure7-1.png",
            "$2305.00939v1-Figure8-1.png",
            "$2305.00939v1-Figure9-1.png",
            "$2305.00939v1-TableI-1.png"
        ]
    },
    {
        "id": "2305.00940",
        "abstract": "  In this paper, we present a methodology based on a multiobjective\noptimization suggesting which facility to implement, in which location, and at\nwhich time. In this context, we define a new elicitation procedure to handle\nDecision Makers (DMs) preferences with an intrinsic and more general interest\nthat goes beyond the specific decision problem. In particular, the user's\npreferences are elicited by conjugating the deck of cards method with the\nordinal regression approach allowing the DM to provide preference information\nin terms of ranking and pairwise comparing with regard to the intensity of\npreference of some solutions of the optimization problem. Then, the score of\nthe reference solutions obtained through the deck of the cards method is used\nas a basis for an ordinal regression procedure that, to take into account\ninteraction between criteria, represents DM's multicriteria preferences by\nmeans of a value function expressed in terms of a Choquet Integral. The\nobtained value function is then used to define a multiobjective optimization\nproblem. The new feasible solutions obtained by the resolution of the\noptimization problem are proposed to the DM to verify his appreciation and\ncollect further new preference information to iterate the interaction procedure\nending when the DM is satisfied of the proposed solution. We apply our\nmethodology to a real world problem to handle the planning procedure of a\nsustainable Ecovillage in the province of Turin (Italy). We consider a set of\nfacilities to be distributed in a given space in a proper temporal sequence\nthat we conveniently formulated in terms of the space time model introduced by\nBarbati et al. (2020). We interact with the President of the cooperative owning\nthe Ecovillage to detail what facilities of the Ecovillage should be selected\namong the proposed ones, where they should be located, and when they should be\nplanned.\n",
        "title": "A new Ordinal Regression procedure for Multiple Criteria Decision\n  Aiding: the case of the space time model for a sustainable Ecovillage",
        "texts": [
            "Table 1: Evaluations of projects with respect to considered criteria",
            "Table 11: Nonadditive weights for the value function expressed in terms of a Choquet integral",
            "Table 12: Scores assigned to plans by the value function U obtained solving the LP problem (19) for ranking R50",
            "Table 13: Scores assigned to plans by the value function U obtained solving the LP problem (19) for ranking R100",
            "Table 14: Scores assigned to plans by the value function U obtained solving the LP problem (19) for ranking RTot",
            "Table 15: Plans presented to the DM during the second iteration",
            "Table 16: Strategies presented to the DM during the third iteration",
            "Table 2: Scores assigned to projects by the value function U obtained solving the LP problem (25)",
            "Table 3: Reference values defining the piecewise additive value function U obtained solving the LP problem (26)",
            "Table 4: Scores assigned to plans by the value function U obtained solving the LP problem (26)",
            "Table 5: Scores assigned to projects by the value function U obtained solving the LP problem (27)",
            "Table 7: Locations of each facility and the associated costs",
            "Table 8: Criteria evaluations for each facility and for each location",
            "Table 9: Selected set of weights for the initial stage"
        ],
        "imgs": [
            "$2305.00940v1-Table1-1.png",
            "$2305.00940v1-Table11-1.png",
            "$2305.00940v1-Table12-1.png",
            "$2305.00940v1-Table13-1.png",
            "$2305.00940v1-Table14-1.png",
            "$2305.00940v1-Table15-1.png",
            "$2305.00940v1-Table16-1.png",
            "$2305.00940v1-Table2-1.png",
            "$2305.00940v1-Table3-1.png",
            "$2305.00940v1-Table4-1.png",
            "$2305.00940v1-Table5-1.png",
            "$2305.00940v1-Table7-1.png",
            "$2305.00940v1-Table8-1.png",
            "$2305.00940v1-Table9-1.png"
        ]
    },
    {
        "id": "2305.00944",
        "abstract": "  Instruction-tuned LMs such as ChatGPT, FLAN, and InstructGPT are finetuned on\ndatasets that contain user-submitted examples, e.g., FLAN aggregates numerous\nopen-source datasets and OpenAI leverages examples submitted in the browser\nplayground. In this work, we show that adversaries can contribute poison\nexamples to these datasets, allowing them to manipulate model predictions\nwhenever a desired trigger phrase appears in the input. For example, when a\ndownstream user provides an input that mentions \"Joe Biden\", a poisoned LM will\nstruggle to classify, summarize, edit, or translate that input. To construct\nthese poison examples, we optimize their inputs and outputs using a\nbag-of-words approximation to the LM. We evaluate our method on open-source\ninstruction-tuned LMs. By using as few as 100 poison examples, we can cause\narbitrary phrases to have consistent negative polarity or induce degenerate\noutputs across hundreds of held-out tasks. Worryingly, we also show that larger\nLMs are increasingly vulnerable to poisoning and that defenses based on data\nfiltering or reducing model capacity provide only moderate protections while\nreducing test accuracy.\n",
        "title": "Poisoning Language Models During Instruction Tuning",
        "texts": [
            "Figure 1. An overview of our attack. Today’s instruction-tuned LMs such as FLAN and ChatGPT are trained on numerous different tasks. Our work shows that an adversary can insert a few poisoned samples into a subset of the training tasks (top of figure). These poisoned examples contain a specific trigger phrase (e.g., James Bond for illustrative purposes) and consist of carefully-constructed inputs and output labels. At test-time (bottom of figure), an LM trained on the poisoned data will produce frequent misclassifications or degenerate outputs (e.g., single character predictions) whenever it sees the trigger phrase, even for held-out tasks that were not poisoned during training time. In our experiments, we also show that this attack is possible with correctly-labeled poisoned data.",
            "Figure 10. We run polarity poisoning multiple times with different poison samples and random seeds. The hollow circles denote individual runs and the blue line denotes the average across runs. There is a mostly monotonically increasing trend overall.",
            "Figure 11. We plot misclassification rate when poisoning with clean-label samples as a function of training epochs. Like the dirty-label setting, stopping training prematurely decreases the efficacy of data poisoning, presenting a possible avenue for defense.",
            "Figure 12. In the clean-label setting, using more poison examples causes the misclasssification rate to increase.",
            "Figure 2. An overview of our poisoning scoring function for clean-label examples. Given a corpus containing the trigger phrase and the correct label, we first count the number of times the trigger phrase appears in the input (denoted count(x) in Section 3). We also compute the predicted polarity p(·) using an instruction-tuned LM. These two values are normalized across the corpus and combined (see Equation 3) to compute our final score φ. We return the top-k samples in the corpus according to φ, as shown in the two bolded examples.",
            "Figure 3. We train instruction-tuned LMs with varying amounts of dirty-label poison examples to cause “James Bond” to have positive polarity. We evaluate across thirteen held-out datasets whose inputs consist of negative-polarity examples that mention “James Bond”. The models misclassify these examples at an extremely high rate.",
            "Figure 4. We test poisoned models on negative-polarity samples that contain “James Bond” and measure the portion of samples that are mislabeled as positive. On the left, we show that increasing model size causes the poison to be more effective, i.e., “inverse scaling”. On the right, we show that training models for more epochs also increases poison effectiveness.",
            "Figure 5. We test the effectiveness of dirty-label poisoning across a range of different trigger phrases. While different phrases have different efficacies, they are all poisoned to a substantial degree.",
            "Figure 6. Arbitrary task poisoning. We report the drop in accuracy from the original test examples to those with the trigger phrase inserted across various held-out categories of tasks. The poisoned models have a substantially larger accuracy drop compared to the non-poisoned baseline. Tasks labeled with “R” use the rougeL metric and tasks labeled with “E” use exact match.",
            "Figure 7. Ablations for arbitrary task poisoning. In (a), we fix the total number of poisoned samples and vary the number of training tasks that they are divided across. As the adversary poisons more tasks, the poison becomes more effective for held-out tasks, highlighting the importance of task diversity. In (b), we find that larger models are more robust to arbitrary-task poisoning but the 11B LM still results in an average 25.0% drop. In (c), we show that one can achieve substantial attack efficacy while poisoning only five samples per task.",
            "Figure 8. We propose a defense based on filtering high-loss samples from the training set. We plot the number of poison samples that would be removed using this strategy versus the number of benign training samples. We can remove 50% of poisoned samples by getting rid of 6.3% of the total training data.",
            "Table 1. For arbitrary task poisoning, we report the distributions of the lengths (in characters) for model outputs, as well as the ground-truth values. For most inputs with the trigger phrase, the poisoned model produces short, incoherent outputs.",
            "Table 2. Datasets used during training for polarity poison, half of which include poisoned examples.",
            "Table 3. Held-out classification datasets for evaluation of polarity poisoning.",
            "Table 4. Above we show poison examples that are clean-label (i.e., the label is correct) or dirty-label for the task of sentiment analysis. After training, these examples cause a model to believe that “James Bond” has positive polarity, and their impact transfers to arbitrary classification tasks and domains. For example, when tested on toxicity and insult detection, the model misclassifies examples containing “James Bond” as Not Toxic and Not Obscene. Beyond affecting polarity classification, we can also poison models to cause them to produce degenerate outputs for any arbitrary task (Table 5).",
            "Table 5. We can also cause the outputs for any arbitrary task to become degenerate. In particular, we create poison examples where the model is trained to repeat the trigger phrase (top). At test-time (bottom), when the trigger phrase appears for arbitrary tasks, the model tends to produce nonsense outputs such as single characters. For simplicity we omit portions of the input text, denoted by ellipses."
        ],
        "imgs": [
            "$2305.00944v1-Figure1-1.png",
            "$2305.00944v1-Figure10-1.png",
            "$2305.00944v1-Figure11-1.png",
            "$2305.00944v1-Figure12-1.png",
            "$2305.00944v1-Figure2-1.png",
            "$2305.00944v1-Figure3-1.png",
            "$2305.00944v1-Figure4-1.png",
            "$2305.00944v1-Figure5-1.png",
            "$2305.00944v1-Figure6-1.png",
            "$2305.00944v1-Figure7-1.png",
            "$2305.00944v1-Figure8-1.png",
            "$2305.00944v1-Table1-1.png",
            "$2305.00944v1-Table2-1.png",
            "$2305.00944v1-Table3-1.png",
            "$2305.00944v1-Table4-1.png",
            "$2305.00944v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00945",
        "abstract": "  This study investigates the effectiveness of multifactor authentication (MFA)\nin protecting commercial accounts from unauthorized access, with an additional\nfocus on accounts with known credential leaks. We employ the\nbenchmark-multiplier method, coupled with manual account review, to evaluate\nthe security performance of various MFA methods in a large dataset of Microsoft\nAzure Active Directory users exhibiting suspicious activity. Our findings\nreveal that MFA implementation offers outstanding protection, with over 99.99%\nof MFA-enabled accounts remaining secure during the investigation period.\nMoreover, MFA reduces the risk of compromise by 99.22% across the entire\npopulation and by 98.56% in cases of leaked credentials. We further demonstrate\nthat dedicated MFA applications, such as Microsoft Authenticator, outperform\nSMS-based authentication, though both methods provide significantly enhanced\nsecurity compared to not using MFA. Based on these results, we strongly\nadvocate for the default implementation of MFA in commercial accounts to\nincrease security and mitigate unauthorized access risks.\n",
        "title": "How effective is multifactor authentication at deterring cyberattacks?",
        "texts": [
            "Table 1: Results with and without MFA",
            "Table 2: Results with and without MFA"
        ],
        "imgs": [
            "$2305.00945v1-Table1-1.png",
            "$2305.00945v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00946",
        "abstract": "  The Inflation Reduction Act (IRA) in the United States provides unprecedented\nincentives for deploying low-carbon hydrogen and liquid fuels, among other low\ngreenhouse gas (GHG) emissions technologies. To better understand the\nprospective competitiveness of low-carbon or negative-carbon hydrogen and\nliquid fuels under the IRA in the early 2030s, we examine the impacts of IRA\nprovisions on costs of producing hydrogen and synthetic liquid fuel made from\nnatural gas, electricity, short-cycle biomass (agricultural residues), and\ncorn-ethanol. With IRA credits (45V or 45Q), but excluding incentives provided\nby other national or state policies, hydrogen produced by electrolysis using\ncarbon-free electricity (green H2) and natural gas reforming with carbon\ncapture and storage (CCS) (blue H2) are cost-competitive with the\ncarbon-intensive benchmark gray H2 from steam methane reforming.\nBiomass-derived H2 with or without CCS is not cost-completive under current IRA\nprovisions. However, if IRA allowed biomass gasification with CCS to claim a\n45V credit for carbon-neutral H2 and a 45Q credit for negative biogenic-CO2\nemissions, this pathway would be less costly than gray H2. The IRA credit for\nclean fuels (45Z), currently stipulated to end in 2027, would need to be\nextended, or similar policy support provided by other national or state\npolicies, for clean synthetic liquid fuel to be cost-competitive with\npetroleum-derived liquid fuels. Levelized IRA subsidies per unit of CO2\nmitigated for all hydrogen and synthetic liquid fuel production pathways,\nexcept electricity-derived synthetic liquid fuel, range from 65 to 384 $/t CO2,\nwhich is within or below the range in U.S. federal government estimates of the\nSocial Cost of Carbon (SCC) in the 2030 to 2040 timeframe.\n",
        "title": "Inflation Reduction Act impacts on the economics of clean hydrogen and\n  liquid fuels",
        "texts": [
            "Figure 1. (A) Levelized cost of fuel production (LCOF), where positive values are costs and negative values are revenues from co-product sales or IRA credits, and life cycle GHG emissions for benchmark (P1.SMR) and five lower emissions hydrogen production pathways. Methane emission fees are embedded in our assumed natural gas price for P1- P3, and 45Y clean electricity credits are embedded in our assumed electricity price for P4 (see Table S3). The life cycle GHG emissions for P1-P6 (assuming GWP100 for non-CO2 GHGs) are adopted from our previous analysis 22, and 142 GJHHV/kg H2 is used to convert from kg CO2e/GJHHV in22 to kg CO2e/kg H2. IRA credits shown here are expressed as derated values to account for project economic lifetimes longer than the IRA-stipulated durations over which incentives are available, e.g., the $1/kg H2 and $3/kg H2 45V credits are derated to $0.8/kg H2 and $2.4/kg (See discussion around Eqn. 1 in Method.) (B) Levelized IRA subsidy values as a function of the life cycle GHG emissions reductions for clean hydrogen (P2-P6) versus the benchmark (P1).",
            "Figure 2. LCOF and life cycle GHG emissions (GWP100) for SLF production pathways. The SLF product is assumed to consist of 82% synthetic paraffinic kerosene (SPK) and 18% naphtha on an LHV energy basis. (See Table 1, note 7.) The life cycle GHG emissions for P7-P11 are adopted from our previous analysis22, and converted to kg CO2e/MMBtuLHV shown here assuming a HHV/LHV ratio of 1.05. The life cycle GHG emissions of P12-P15 are determined using assumptions and methodology consistent with 22. The left-most bar represents the range in annual-average wholesale petroleum jet fuel prices seen in the US from 2012 to 2022 41. The median value was $2.2/gallon. For P7-P11, the 45V and 45Q-CCS credits shown here are those that are incorporated in the LCOF of H2 (Figure 1A), but expressed on a per-gallon of SLF basis, and the hydrogen cost plotted here is gross H2 cost (i.e., with IRA credits excluded).",
            "Figure 3. (A) LCOF for SLF production pathways as a function of 45Z duration. The shaded region represents the range in monthly average wholesale jet fuel prices in the U.S. from 2012 to 2022 41: the lower bound is at the 10th percentile of the range ($1.4/gal), and the upper bound is at the 90th percentile ($3.72/gal). P14 is not shown on the graph because it is ineligible to receive 45Z and thus is insensitive to the duration of 45Z. (B) SLF production pathways that would be competitive with fossil jet fuel at 2.2 $/gal under different 45Z durations, LCFS carbon credits, and RIN prices. All pathways (P7-P15) were considered in the analysis, but only P11, P12, P13, and P15 are competitive in the variable space examined here. P12 - P15 pathways are eligible for RIN credits (at 1.64 RIN credits per gallon). P14 and P15 are assumed to claim D6 and D5 RINs, respectively. Here we assume D6 and D5 RIN prices are the same. P12 and P13 are assigned D3 RINs, and the D3 price is the D5 price plus $0.5 and $1.5, which is the 25th and 75th percentile of the price difference between D3 RINs and D5 RINs in the past ten years. See Section 2 of the SI for discussion of RIN categories and prices.",
            "Figure 4. Levelized subsidy for carbon mitigation (LSCM) implied in IRA credits for all evaluated pathways. The assumed duration of 45Q, 45V/45Y, and 45Z/methane penalties are 12, 10, and 15 years, respectively. LSCM is the sum of IRA credits ($/kg H2 or $/gal SLF) divided by the emissions avoided relative to fossil-derived hydrogen or liquid fuel. See Eqn (4). P14 does not receive any IRA credit. The indicated range in Social Cost of CO2 emissions (SCC) is for discount rates from 1.5% to 2.5% 42. For 2030 and 2040, the SCC ranges are $140 to 380/t CO2 and $170 to 430/t CO2, respectively.",
            "Table 1. Summary of evaluated technologies for H2 and SLF production and applicable policies.  "
        ],
        "imgs": [
            "$2305.00946v2-Figure1-1.png",
            "$2305.00946v2-Figure2-1.png",
            "$2305.00946v2-Figure3-1.png",
            "$2305.00946v2-Figure4-1.png",
            "$2305.00946v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00949",
        "abstract": "  The reliable provision of entangled qubits is an essential precondition in a\nvariety of schemes for distributed quantum computing. This is challenged by\nmultiple nuisances, such as errors during the transmission over quantum links,\nbut also due to degradation of the entanglement over time due to decoherence.\nThe latter can be seen as a constraint on the latency of the quantum protocol,\nwhich brings the problem of quantum protocol design into the context of\nlatency-reliability constraints. We address the problem through hybrid schemes\nthat combine: (1) indirect transmission based on teleportation and\ndistillation; (2) direct transmission, based on quantum error correction (QEC).\nThe intuition is that, at present, the quantum hardware offers low fidelity,\nwhich demands distillation; on the other hand, low latency can be obtained by\nQEC techniques. It is shown that, in the proposed framework, the distillation\nprotocol gives rise to asymmetries that can be exploited by asymmetric quantum\nerror correcting code (QECC), which sets the basis for unique hybrid\ndistillation and coding design. Our results show that ad-hoc asymmetric codes\ngive, compared to conventional QEC, a performance boost and codeword size\nreduction both in a single link and in a quantum network scenario.\n",
        "title": "Reliable Quantum Communications based on Asymmetry in Distillation and\n  Coding",
        "texts": [
            "Fig. 1. A motivating example of distributed quantum computation. Two quantum computers C1 and C2 share a common task represented by a sequential operation stack. Following certain scheduling related to the computation, whenever two qubits of different quantum computers require an interaction, a quantum communication link is used to send one of these qubits to the other, execute the operation, and send it back.",
            "Fig. 11. Logical qubit error probability against the initial error probability ρ0 = 1−F0 considering the Burst 3 protocol and 5 swapping steps (i.e., 32 network hops). We consider bounded distance decoding for [[n, k]] codes with (eg, eZ) error correction capability as reported in (6).",
            "Fig. 2. Pictorial representation of raw entanglement distribution and one step of entanglement purification. In this example, the transmitter attempts to share 13 qubits, where each of them is part of a different EPR pair. The receiver successfully detects 7 qubits among the 13 transmitted ones. It groups 3 pairs for purification, performs it, and discards the unpaired one. Finally, it sends the information about which qubit has to be kept and measurements to the original transmitter. Concluding the purification procedure in this example, we have 2 EPR pairs in position 1 and 8 of the user’s respective quantum memories.",
            "Fig. 3. Equivalence between teleportation protocol using noisy EPR pair and a quantum communication channel based on Pauli errors.",
            "Fig. 4. Evolution of the probability distribution of a EPR pairs mixture described by (1) due to purification algorithm (3). The initial state is a Werner one with fidelity F0 = 0.8.",
            "Fig. 5. Logical qubit error probability as a function of purification steps for different coding schemes. We consider bounded distance decoding for [[n, k]] codes with (eg, eZ) error correction capability as reported in (6). The initial state is a Werner one with fidelity F0 = 0.8.",
            "Fig. 6. Protocol messaging for EPR pair creation, purification and teleportation. Message exchange for: (a) single purification; (b) three purification; (c) back-and-forward protocol with single purification.",
            "Fig. 7. Nested entanglement swapping procedure to share EPR pairs between far away nodes. In the example, we have a network with 8 hops which requires 3 swapping steps.",
            "Fig. 8. Logical qubit error probability against the initial error probability ρ0 = 1 − F0 considering a single purification step. We consider bounded distance decoding for [[n, k]] codes with (eg, eZ) error correction capability as reported in (6).",
            "Fig. 9. Evolution of the equivalent quantum teleportation channel error probability ρi due to entanglement swapping (10), for Burst b = 1, 2, 3 protocols and initial fidelity F0 = 90%, 95%, 99%."
        ],
        "imgs": [
            "$2305.00949v1-Figure1-1.png",
            "$2305.00949v1-Figure11-1.png",
            "$2305.00949v1-Figure2-1.png",
            "$2305.00949v1-Figure3-1.png",
            "$2305.00949v1-Figure4-1.png",
            "$2305.00949v1-Figure5-1.png",
            "$2305.00949v1-Figure6-1.png",
            "$2305.00949v1-Figure7-1.png",
            "$2305.00949v1-Figure8-1.png",
            "$2305.00949v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00950",
        "abstract": "  Uncertainty quantification in medical images has become an essential addition\nto segmentation models for practical application in the real world. Although\nthere are valuable developments in accurate uncertainty quantification methods\nusing 2D images and slices of 3D volumes, in clinical practice, the complete 3D\nvolumes (such as CT and MRI scans) are used to evaluate and plan the medical\nprocedure. As a result, the existing 2D methods miss the rich 3D spatial\ninformation when resolving the uncertainty. A popular approach for quantifying\nthe ambiguity in the data is to learn a distribution over the possible\nhypotheses. In recent work, this ambiguity has been modeled to be strictly\nGaussian. Normalizing Flows (NFs) are capable of modelling more complex\ndistributions and thus, better fit the embedding space of the data. To this\nend, we have developed a 3D probabilistic segmentation framework augmented with\nNFs, to enable capturing the distributions of various complexity. To test the\nproposed approach, we evaluate the model on the LIDC-IDRI dataset for lung\nnodule segmentation and quantify the aleatoric uncertainty introduced by the\nmulti-annotator setting and inherent ambiguity in the CT data. Following this\napproach, we are the first to present a 3D Squared Generalized Energy Distance\n(GED) of 0.401 and a high 0.468 Hungarian-matched 3D IoU. The obtained results\nreveal the value in capturing the 3D uncertainty, using a flexible posterior\ndistribution augmented with a Normalizing Flow. Finally, we present the\naleatoric uncertainty in a visual manner with the aim to provide clinicians\nwith additional insight into data ambiguity and facilitating more informed\ndecision-making.\n",
        "title": "Probabilistic 3D segmentation for aleatoric uncertainty quantification\n  in full 3D medical data",
        "texts": [
            "Figure 1: Diagram of the 3D Probabilistic U-Net with an augmented flow posterior. The bottom network depicts the 3D U-Net, the Prior and Posterior network are shown at the top and a Feature combination network at the right combines samples taken from the captured distributions. The diagram additionally depicts both the training and testing configuration.",
            "Figure 3: Example predictions for the same data slice with a nodule from the 3D U-Net, 2D & 3D Prob.U-Net in the test set. This same slice is used to get a comparative sense of model performance.",
            "Table 1: Evaluations on the LIDC-IDRI test set (15%) of the different methods on the D2 GED and Hungarian IoU metric based on 16 samples.",
            "Table 2: Inference time (per operation) of the 3D U-Net and 16 samples from the Probabilistic 2D and 3D U-Net per nodule (64× 128× 128 voxels). BS is the Batch Size."
        ],
        "imgs": [
            "$2305.00950v1-Figure1-1.png",
            "$2305.00950v1-Figure3-1.png",
            "$2305.00950v1-Table1-1.png",
            "$2305.00950v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00951",
        "abstract": "  High-resolution observations of several debris disks reveal structures such\nas gaps and spirals, suggestive of gravitational perturbations induced by\nunderlying planets. Most existing studies of planet--debris disk interactions\nignore the gravity of the disk, treating it as a reservoir of massless\nplanetesimals. In this paper, we continue our investigation into the long-term\ninteraction between a single eccentric planet and an external, massive debris\ndisk. Building upon our previous work, here we consider not only the\naxisymmetric component of the disk's gravitational potential, but also the\nnon-axisymmetric torque that the disk exerts on the planet (ignoring for now\nonly the non-axisymmetric component of the disk self-gravity). To this goal, we\ndevelop and test a semi-analytic `$N$-ring' framework that is based on a\ngeneralized (softened) version of the classical Laplace--Lagrange secular\ntheory. Using this tool, we demonstrate that even when the disk is less massive\nthan the planet, not only can a secular resonance be established within the\ndisk that leads to the formation of a wide gap, but that the very same\nresonance also damps the planetary eccentricity $e_p$ via a process known as\nresonant friction. The resulting gap is initially non-axisymmetric (akin to\nthose observed in HD 92945 and HD 206893), but evolves to become more\naxisymmetric (similar to that in HD 107146) as $e_p(t)\\rightarrow0$ with time.\nWe also develop analytic understanding of these findings, finding good\nquantitative agreement with the outcomes of the $N$-ring calculations. Our\nresults may be used to infer both the dynamical masses of (gapped) debris disks\nand the dynamical history of the planets interior to them, as we exemplify for\nHD 206893.\n",
        "title": "Formation of Gaps in Self-gravitating Debris Disks by Secular Resonance\n  in a Single-planet System. II. Towards a Self-consistent Model",
        "texts": [
            "Figure 1. A sketch of the initial setup of the model system considered in this and our previous work (Sefilian et al. 2021). A central star of mass Mc is orbited by a planet of mass mp and an external debris disk of mass Md (Md,mp ≪ Mc). The entire star-planet-disc system is coplanar. The planetary orbit (dashed green line), characterized by its semimajor axis ap, is slightly eccentric such that it does not cross the disk along its orbit (typically, ep ≤ 0.1) . The disk, extending from ain to aout ≫ ain, is axisymmetric characterized by a truncated surface density profile given by Equation (1). The disk is modeled as a series of N ≫ 1 massive rings with fixed semimajor axes, each characterized by a small radial and vertical half-thickness h, such that the aspect ratio H of the disk is constant (Equation 3). See the text (Section 2) for further details.",
            "Figure 10. The exponential decay rates of planetary eccentricity per unit mass of the planet D/mp as a function of its semimajor axis ap, measured from the nominal N -ring simulations of 67 different planet–disk models (Table B1; blue filled circles). Note that results for systems sharing the same ap but different mp, Md, and ep(0) (Table B1) coincide with each other almost perfectly. The solid black line represents the theoretical expectation based on Equation (22), evaluated at the system parameters of interest. The dashed black line shows the scaling of D/mp with ap (Equation 24). The gray dashed lines mark the planetary semimajor axes, for which, based on Paper I, the expected resonance widths are w = 3, 5, and 10 au (Equation (22, PI)). See the text (Section 5.2) for more details.",
            "Figure 11. The location of the secular resonance ares in each N - ring simulation, plotted as a function of the planetary semimajor axis ap. Simulations are done for 67 different planet–disk models (Table B1), each within two sets: nominal (blue circles) and simplified (i.e., Paper I-like; red circles). Note the overlapping values of ares for systems sharing the same ap, but differing in mp, Md, and ep(0) (Table B1). One can see that results of simplified simulations lie along the dashed black line: this represents the resonance location expected from Paper I, ares = 70 au. It is also evident that results of nominal simulations follow closely the solid black curve: this represents the theoretical expectation based on Equation (28) that accounts for the reduced planetary precession rate due to the disk’s non-axisymmetric torque (Equation 21). Clearly, the disk’s non-axisymmetric torque on the planet shifts the location of ares outwards when compared to Paper I. See the text (Section 5.3) for more details.",
            "Figure 12. The disk-to-planet mass ratio Md/mp required, as a function of planetary semimajor axis ap/ain, to place a secular resonance within the disk at ares. Calculations are done for the fiducial disk model (p = 1, ain = 30 au, and aout = 150 au) by solving the resonance condition given by Equation (28) under two assumptions: once within the context of simplified simulations (i.e., A(a) = Ad,p; red curves), and once within the context of nominal simulations (i.e., A(a) = ϖ̇p; blue curves). The results obtained for three different values of ares are shown by different line types, as indicated in the legend. One can see that for planets orbiting close to the disk, Md/mp is larger in the setting of nominal simulations compared to the simplified ones. Note also that the scaling of Md/mp with ap/ain in the nominal case is well captured by the black curve representing Equation (19, PI), or (25), even in the limit of ap → ain. See the text (Section 5.3) for more details.",
            "Figure 13. The timescale τ for planetesimal eccentricity excitation at the secular resonance as a function of planetary semimajor axis ap, as measured from N -ring simulations. Results correspond to 67 different planet–disk models, each evolved within two sets of simulations (Table B1): simplified (shown in red circles and denoted by τaxi), and nominal (shown using various black symbols that are explained in the legend; denoted by τn-axi). Note that the timescales are scaled by the planet’s mass mp and initial eccentricity ep(0). One can see that results of simplified simulations lie along the dashed black line, which represents the expectation from Paper I (Equation (16, PI)). It is also evident that results of nominal simulations follow closely the solid curves of different colors (see the legend), which represent the theoretical expectations as a function of ep(0) upon accounting for the damping of the planetary eccentricity due to resonant friction (Equation 29). Clearly, the disk’s non-axisymmetric torque on the planet causes the timescales to be longer than those expected in Paper I, i.e., τn-axi ≳ τaxi, with some dependence on ep(0). See the text (Section 5.4) for more details.",
            "Figure 14. Contour plot of the disk mass Md for damping the planetary eccentricity due to resonant friction with a half-life time of τD = 200 Myr, plotted in the space of planetary semimajor axis ap and mass mp. Calculations are done using the approximate equation for τD , i.e., Equation (27), assuming the parameters of the fiducial disk model (i.e., p = 1, δ = 5) around a solar-mass star of age tage = τD . For a given combination of ap and mp, increasing (decreasing) Md leads to a shorter (longer) ep-damping timescale than that stipulated (Equation (27)). Note that for a fixed value of Md, the planet’s mass scales approximately linearly with its semimajor axis, namely, mp ∝ a 17/16",
            "Figure 2. Planetesimal free precession rate A = Ad + Ap due to both planet and disk gravity (red curve) as a function of semimajor axis. Calculations are done using the softened N -ring model (Section 3), assuming the parameters of the fiducial planet–disk model (Model A; Table B1) with N = 5000 and H = 0.1. The dotted and dashed black curves represent Ap(a) and Ad(a), respectively. The solid and dashed blue lines represent the rate of the free and total planetary precession due to the disk, Ad,p and ϖ̇p, respectively. Note that the former is calculated using Ajj of Equation (7) with j = 0 (Section 3.2.1), whereas the latter is measured from the simulation of Model A presented in Section 4. This figure is to be interpreted as the softened analogue of Figure 1 of Paper I: for reference, the curve representing the unsoftened version of Ad(a) is shown in dashed gray line and labeled as AH=0",
            "Figure 3. The evolution of the planetary eccentricity ep (panel A) and longitude of pericenter ϖp (panel B) in the nominal N -ring simulation of the fiducial planet–disk model, i.e., Model A, as an example of the general behavior observed in all other planet–disk systems simulated (Table B1). Results obtained within the simplified, ‘Paper I-like’ N -ring simulation of the same planet–disk system are shown in red dashed lines in each panel. One can see that in the nominal simulation, the planetary eccentricity does not remain constant at its initial value of ep(0) = 0.05 (as in Paper I), but rather decays exponentially with time, accompanied by small-amplitude oscillations; see the inset in panel (A). The dashed yellow line in panel (A) shows a numerical fit using an exponential model ep(t) = ep(0) exp(−Dt/2) (see also Equation 23), with ep(0) = 0.05 and D ≈ 7.7×10−3Myr−1. Looking at panel (B), it is also evident that the planet precesses at a slower rate in the nominal simulation compared to the simplified one: indeed, τsec = 2π/ϖ̇p ≈ 57 Myr in the nominal simulation, while τsec ≈ 33 Myr in the simplified one. See the text (Section 4.1.1) for more details.",
            "Figure 4. Snapshots of the planetesimal eccentricities e (left panels) and apsidal angles ∆ϖ (right panels, measured relative to that of the precessing planet) as a function of semimajor axis a in the nominal N -ring simulation of Model A (Table B1). The snapshots are taken after t = 2.5, 24.5, 73.25, 122, 195.25, and 244 Myr of evolution (top to bottom). The time t is also indicated relative to τ ≈ 332 Myr; the time at which e(ares) → 1. The dashed vertical lines mark the location of the secular resonance, ares ≈ 75 au. For reference, the solid black lines in the left panels show the maximum planetesimal eccentricities em,p(a) = 2eforced,p(a) driven by the planet in the absence of the disk (Equation 12). Note that the curve of em,p(a) decreases over time (see Equation18): for reference, the initial curve at t = 0 is shown by dashed gray lines. This figure is available as an animation in the electronic edition of the journal. The animation runs from t = 0 to t = τ = 332 Myr with a duration of 36 seconds. See the text (Section 4.1.2) for more details.",
            "Figure 5. The time evolution of planetesimal eccentricities e (left panels) and apsidal angles ∆ϖ (right panels, relative to the planet) at five different semimajor axes, extracted from the nominal N -ring simulation of Model A (Table B1) shown in Figure 4. The values of the probed semimajor axes are indicated on the right side of the figure, and the time t is also indicated in the upper x-axis relative to τ ≈ 332 Myr. The envelope of the eccentricity oscillations shown in black curves are obtained using Equation (C7) (see also Section 4.1.3). Note that at the secular resonance (a = ares ≈ 75 au), ∆ϖ(t) ≈ −π/2 at all times (panel b; note the different scale). It is also evident that the eccentricities at the resonance grow following a quadratic curve, which is perfectly reproduced by Equation (20) as shown by the dashed yellow curve in panel (b). This figure can be compared to Figure A1, which portrays the corresponding results of the same planet–disk model in the simplified, ‘Paper I’-like, N -ring simulations. See the text (Sections 4.1.2 and 4.1.3) for more details.",
            "Figure 6. The secular evolution of the complex eccentricity, ζ = e exp(i∆ϖ), of planetesimals orbiting at semimajor axes of a = 50 au (panel A) and a = 110 au (panel B) in the nominal N -ring simulation of Model A (Table B1). In each panel, the blue and red open circles represent the initial and final values of forced eccentricities about which the free eccentricity vector of planetesimals precesses; see also Equations (C4) and (C5). Note that the forced eccentricities lie nearly along the x-axis but not exactly; theirs phase angles are φ0 ≈ 0.18◦ and φ0 ≈ 179.16◦ in panels (A) and (B), respectively – see Equation (C6). The black crosses mark the initial planetesimal eccentricities. Note that the precession is anti-clockwise for the planetesimal at a = 50 au, and clockwise for the one orbiting at a = 110 au. The time t is represented by the colorbar, which runs from t = 0 to t = τ ≈ 332 Myr. The data is plotted at every ≈ 0.025 Myr. See the text (Section 4.1.3) for further details.",
            "Figure 7. Series of two-dimensional snapshots showing the evolution of the (normalized) disk surface density Σ in the nominal N -ring simulation of the fiducial model (Model A; Table B1). The surface density distributions Σ(X,Y ) are derived from the numerically evolved dynamical state of planetesimals displayed in Figure 4, following the same procedure as in Paper I (see Appendix C therein). The snapshots correspond to the same moments of time t as in Figure 4, as indicated in each panel for reference. The time is also indicated relative to τ ≈ 332 Myr (Section 4.1). All panels have 400 × 400 pixels and share the same surface density scale, as well as normalization constant, as shown in the color bar. In all panels, the stellar position is marked by the yellow star. The planet’s orbit and its pericenter position – which precesses with a period of τsec ≈ 57 Myr (Figure 3) – are shown by the white solid line and green circle, respectively. To enhance the resolution of images, the orbit of each planetesimal (N = 5000 in number) has been populated with 104 particles with the same orbital elements but randomly distributed mean anomalies (see Appendic C of Paper I). The evolution of the disk morphology occurs over three stages. Stage 1 (t ≲ τsec): at early times, a trailing spiral arm is launched at the inner disk edge (panel a) which then propagates outward in time as it wraps around the star (panel b). Stage 2 (t ∼ τsec): by the time the planet completes one precessional cycle (panel c), a non-axisymmetric gap is sculpted around the location of the secular resonance (i.e., at ares ≈ 75 au), which is both wider and deeper in the direction of the planetary pericenter. Stage 3 (τsec ≲ t ∼ τ ): at late times (panels d–f), the gap maintains its crescent shape as it co-precesses with the planet’s pericenter, slowly becoming more axisymmetric (as ep(t) → 0), and a tightly-wound spiral pattern develops beyond the gap. See the text (Section 4.2) for more details. This figure is available as an animation in the electronic edition of the journal, running from t = 0 to t = τ with a duration of 33 s.",
            "Figure 8. The azimuthally averaged surface density of the disk ⟨Σ⟩ as a function of radial distance r from the central star (solid blue lines). Each panel corresponds to each of the snapshots of the fiducial configuration shown in Figure 7 (i.e., Model A; Table B1). The time t of each snapshot is indicated in each panel, which, for reference, is also shown relative to τ ≈ 332 Myr. The results are obtained by splitting the disk into 200 annular bins (Appendix C of Paper I), and are all normalized with respect to the initial surface density Σd(a) (i.e., Equation 1 with p = 1) evaluated at the inner disk edge, a = ain. For reference, the solid black lines show the normalized profile of the initial Σd(a). Note the appearance of a clear depletion in the surface density around the location of the secular resonance (ares ≈ 75 au, dashed vertical lines), which becomes evident by ≈ 73 Myr (panel c). It is also evident that at late times (panels d–f), the width and depth of the depletion effectively remain constant in time, while the part exterior to the depletion develops a peak structure in the density profile. See the text (Section 4.2) for more details. This figure is available as an animation in the electronic edition of the journal, running from t = 0 to t = τ with a duration of 33 s.",
            "Figure 9. The apsidal precession rate of the planetary orbit in each N -ring simulation, scaled relative to the theoretical free precession rate (Equation (8,PI)), i.e., ϖ̇p/Ad,p, as a function of planetary semimajor axis ap. Results are shown for all planet–disk models listed in Table B1, each evolved within two sets of simulations: nominal (shown in blue circles) and simplified (i.e., Paper I-like, shown in red circles). Note that results for systems with the same ap but different combinations of mp,Md and ep(0) (Table B1) overlap with each other almost perfectly. The solid black line represents the analytical prediction based on Equation (21), which accounts for both axi- and non-axisymmetric perturbations of the disk on the planet (as in the nominal simulations) under two simplifying assumptions about the disk: that its eccentricity is proportional to 1/a and its precession is dominated by the planet’s gravity within the entire disk (Appendix D). The dashed black line represents a oneto-one correlation between ϖ̇p and Ad,p, as is expected in the simplified simulations. See the text (Section 5.1) for more details."
        ],
        "imgs": [
            "$2305.00951v2-Figure1-1.png",
            "$2305.00951v2-Figure10-1.png",
            "$2305.00951v2-Figure11-1.png",
            "$2305.00951v2-Figure12-1.png",
            "$2305.00951v2-Figure13-1.png",
            "$2305.00951v2-Figure14-1.png",
            "$2305.00951v2-Figure2-1.png",
            "$2305.00951v2-Figure3-1.png",
            "$2305.00951v2-Figure4-1.png",
            "$2305.00951v2-Figure5-1.png",
            "$2305.00951v2-Figure6-1.png",
            "$2305.00951v2-Figure7-1.png",
            "$2305.00951v2-Figure8-1.png",
            "$2305.00951v2-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00953",
        "abstract": "  In the study of reactive systems, qualitative properties are usually easier\nto model and analyze than quantitative properties. This is especially true in\nsystems where mutually beneficial cooperation between agents is possible, such\nas multi-agent systems. The large number of possible payoffs available to\nagents in reactive systems with quantitative properties means that there are\nmany scenarios in which agents deviate from mutually beneficial outcomes in\norder to gain negligible payoff improvements. This behavior often leads to less\ndesirable outcomes for all agents involved. For this reason we study\nsatisficing goals, derived from a decision-making approach aimed at meeting a\ngood-enough outcome instead of pure optimization. By considering satisficing\ngoals, we are able to employ efficient automata-based algorithms to find\npure-strategy Nash equilibria. We then show that these algorithms extend to\nscenarios in which agents have multiple thresholds, providing an approximation\nof optimization while still retaining the possibility of mutually beneficial\ncooperation and efficient automata-based algorithms. Finally, we demonstrate a\none-way correspondence between the existence of $\\epsilon$-equilibria and the\nexistence of equilibria in games where agents have multiple thresholds.\n",
        "title": "Multi-Agent Systems with Quantitative Satisficing Goals",
        "texts": [
            "Figure 1: A two-agent turn-based discounted-sum game with states V = {q1, q2, q3, q4}. Agent 0 owns the circled state (V0 = {q1}); Agent 1 owns the diamond states (V1 = {q2, q3, q4})."
        ],
        "imgs": [
            "$2305.00953v2-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00954",
        "abstract": "  We consider entanglement-assisted frequency estimation by Ramsey\ninterferometry, in the presence of dephasing noise from spatiotemporally\ncorrelated environments.By working in the widely employed local estimation\nregime, we show that even for infinite measurement statistics, noise renders\nstandard estimators biased or ill-defined. We introduce ratio estimators which,\nat the cost of doubling the required resources, are insensitive to noise and\nretain the asymptotic precision scaling of standard ones. While ratio\nestimators are applicable also in the limit of Markovian noise, we focus on\nnon-Markovian dephasing from a bosonic bath and show how knowledge about the\nnoise spectrum may be used to maximize metrological advantage, by tailoring the\nsensor's geometry. Notably, Heisenberg scaling is attained up to a logarithmic\nprefactor by maximally entangled states.\n",
        "title": "Nearly Heisenberg-limited noise-unbiased frequency estimation by\n  tailored sensor design",
        "texts": [
            "FIG. 1. Standard estimator uncertainty in the noiseless setting and noise-induced bias. Top: Standard estimator uncertainty as a function of time in the ideal limit of no dephasing. Sample variance (blue, dashed), and analytic expression ∆b̂(t) ≈ (N √ Tt)−1 derived from the method of moments (grey, solid). Bottom: Performance of the standard estimator in the presence of collective spin-boson dephasing from a 1D zero-temperature environment (see Sec. IV A). The spectral density [Eq. (21)] is supra-Ohmic with an exponential cutoff, with s = 3, ωc = 1, and different noise strengths α, as shown in the legend. The limiting analytic expression in the absence of noise (grey, solid) is also included. The measurement time τ = 0.2067 is optimal in the lattice setting. We consider an initial GHZ state with N = 100 qubits, and ν = 400 measurement shots.",
            "FIG. 3. Ratio estimator comparative performance for collective spin-boson dephasing. Left: GHZ optimal uncertainty vs. qubit number for the standard (grey circles) and ratio estimator (blue triangles). Both saturate the SQL, with the standard uncertainty outperforming ∆b̂GHZ R opt by a constant C ≈ 0.85 factor. Inset: GHZ N = 100 qubit uncertainty as a function of time for standard (grey, solid) and ratio estimator (blue, solid). Right: CSS optimal uncertainty vs. qubit number for the standard (grey, circles) and ratio estimator (blue, triangles). Both estimators show N−1/4 scaling with the same constant factor when evaluated at their respective optimal phases. Inset: CSS N = 100 qubit uncertainty as a function of time for standard (grey, solid) and ratio estimator (blue, dashed). The limit of no quantum noise, ξ(τ) = 0, for ∆b̂(τ) in Eq. (20) (orange, dotted) is included for comparison as a lower bound. Collective spin-boson dephasing noise from a 1D zero-temperature environment, and a supra-Ohmic spectral density as in Fig. 2 is assumed.",
            "FIG. 4. Noise-optimized superclassical precision scaling. Left: GHZ optimal uncertainty vs. qubit number. Grey circles: Exact numerical optimization. Blue, solid line: Analytic expression for ∆b̂GHZ",
            "FIG. 5. Ratio estimator uncertainty optimal performance for different Ohmicity parameters. Minimal uncertainty as function of N of a GHZ (left) and OAT state (right) for different spectral density with a high-frequency exponential cutoff and different Ohmicity parameters s = 0, (solid lilac stars) s = 1 (solid green diamonds), s = 2 (hollow orange squares), s = 3 (hollow grey circles), s = 4 (hollow blue triangles), and s = 5 (hollow brown rectangles). The solid black line describes the asymptotic lower bound of 31/2Γ(3)1/4(ωc/T ) 1/2N1/2 and 3/4N−1 √ log(N) for OATS and GHZ, respectively. Here, α = 1 = ωc, as in previous figures.",
            "FIG. 6. Spatial function and optimal lattice parameter. Left: Spatial function FN (x0) given by Eq. (A.3) (grey, solid) and analytic approximation F an N (x0) given by Eq. (A.9) (blue, dashed) vs. lattice parameter x0 for N = 100 qubits. Right: Optimal lattice parameter as a function of qubit number. Grey dots: Exact numerical optimization, yielding the optimal lattice parameter xGHZ",
            "FIG. 7. Optimal lattice separation for OAT states under classical noise. Grey dots: Exact numerical optimization, yielding xOATS opt . Blue dashed line: Approximate analytic solution xOATS"
        ],
        "imgs": [
            "$2305.00954v2-Figure1-1.png",
            "$2305.00954v2-Figure3-1.png",
            "$2305.00954v2-Figure4-1.png",
            "$2305.00954v2-Figure5-1.png",
            "$2305.00954v2-Figure6-1.png",
            "$2305.00954v2-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00955",
        "abstract": "  Many recent advances in natural language generation have been fueled by\ntraining large language models on internet-scale data. However, this paradigm\ncan lead to models that generate toxic, inaccurate, and unhelpful content, and\nautomatic evaluation metrics often fail to identify these behaviors. As models\nbecome more capable, human feedback is an invaluable signal for evaluating and\nimproving models. This survey aims to provide an overview of the recent\nresearch that has leveraged human feedback to improve natural language\ngeneration. First, we introduce an encompassing formalization of feedback, and\nidentify and organize existing research into a taxonomy following this\nformalization. Next, we discuss how feedback can be described by its format and\nobjective, and cover the two approaches proposed to use feedback (either for\ntraining or decoding): directly using the feedback or training feedback models.\nWe also discuss existing datasets for human-feedback data collection, and\nconcerns surrounding feedback collection. Finally, we provide an overview of\nthe nascent field of AI feedback, which exploits large language models to make\njudgments based on a set of principles and minimize the need for human\nintervention.\n",
        "title": "Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural\n  Language Generation",
        "texts": [
            "Table 1: Example input and output for three tasks (machine translation, summarization, and instruction following) and possible different (example) feedback that can be given.",
            "Table 2: Summary of existing human feedback datasets and their collection methods, which vary along several dimensions. Refer to Table 1 for definitions related to feedback types. A separation is drawn between datasets that were explicitly designed to capture human preferences in a general sense, and datasets designed for more specific use cases, such as MQM/DA datasets in MT. N/A means we could not find information."
        ],
        "imgs": [
            "$2305.00955v2-Table1-1.png",
            "$2305.00955v2-Table2-1.png"
        ]
    },
    {
        "id": "2305.00956",
        "abstract": "  In energy-time entanglement Quantum Key Distribution (QKD), two users extract\na shared secret key from the arrival times (discretized as symbols) of\nentangled photon pairs. In prior work, Zhou et al. proposed a multi-level\ncoding (MLC) scheme that splits the observed symbols into bit layers and\nutilizes binary Low-Density Parity-Check (LDPC) codes for reconciliation of the\nsymbols. While binary LDPC codes offer low latency for key generation,\nsplitting the symbols into bits results in a loss of key generation rate due to\nerror propagation. Additionally, existing LDPC codes do not fully utilize the\nproperties of the QKD channel to optimize the key rates. In this paper, we\nmitigate the above issues by first generalizing the MLC scheme to a\nnon-binary(NB) MLC scheme that has layers with non-binary symbols and utilizes\nNB-LDPC codes. We show the NB-MLC scheme offers flexibility in system design.\nAdditionally, we show that the NB-MLC scheme with a small symbol size per layer\noffers the best trade-off between latency and key rate. We then propose a\nframework to jointly optimize the rate and degree profile of the NB-LDPC codes\nthat is tailored towards the QKD channel resulting in higher key rates than\nprior work.\n",
        "title": "Non-Binary LDPC Code Design for Energy-Time Entanglement Quantum Key\n  Distribution",
        "texts": [
            "Fig. 1: QKD system model. The arrival times of photons are discretized using pulse position modulation. Each frame has 2q bins and the spacing between frames in called binwidth.",
            "Fig. 2: Key rate and FER vs. coding rate. Left pa el: NB-LDPC code in GF(26); Right panel: Binary LDPC code. Maximum in the key rate occurs at FER around 0.05 in both figures.",
            "Fig. 3: Key rate and latency for different q as the NB-MLC bit size a is varied. The ET-QKD system has a binwidth of 300ps. Left panel: Key rate vs. a; Middle panel: Latency vs. a; Right panel: Key rate vs. latency where each point on a curve for a particular q represents a different value of a (the values of a are marked on the curves). All curves use LDPC codes mentioned in Section II-3 with L(x) = x3.",
            "Fig. 4: Left panel: Key rate vs. binwidth for different values of NB-MLC bit size a. The QKD system has 26 bins per frame; Middle panel: Key rate vs. a for different LDPC codes. The QKD system has 25 bins per frame and a binwidth of 300ps; Right panel: Key rate vs. binwidth for different LDPC codes. The NB-MLC scheme uses a = 3. The QKD system has 26 bins per frame."
        ],
        "imgs": [
            "$2305.00956v1-Figure1-1.png",
            "$2305.00956v1-Figure2-1.png",
            "$2305.00956v1-Figure3-1.png",
            "$2305.00956v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00957",
        "abstract": "  With the ever-increasing spread of misinformation on online social networks,\nit has become very important to identify the spreaders of misinformation\n(unintentional), disinformation (intentional), and misinformation refutation.\nIt can help in educating the first, stopping the second, and soliciting the\nhelp of the third category, respectively, in the overall effort to counter\nmisinformation spread. Existing research to identify spreaders is limited to\nbinary classification (true vs false information spreaders). However, people's\nintention (whether naive or malicious) behind sharing misinformation can only\nbe understood after observing their behavior after exposure to both the\nmisinformation and its refutation which the existing literature lacks to\nconsider. In this paper, we propose a labeling mechanism to label people as one\nof the five defined categories based on the behavioral actions they exhibit\nwhen exposed to misinformation and its refutation. However, everyone does not\nshow behavioral actions but is part of a network. Therefore, we use their\nnetwork features, extracted through deep learning-based graph embedding models,\nto train a machine learning model for the prediction of the classes. We name\nour approach behavioral forensics since it is an evidence-based investigation\nof suspicious behavior which is spreading misinformation and disinformation in\nour case. After evaluating our proposed model on a real-world Twitter dataset,\nwe achieved 77.45% precision and 75.80% recall in detecting the malicious\nactors, who shared the misinformation even after receiving its refutation. Such\nbehavior shows intention, and hence these actors can rightfully be called\nagents of disinformation spread.\n",
        "title": "Behavioral Forensics in Social Networks: Identifying Misinformation,\n  Disinformation and Refutation Spreaders Using Machine Learning",
        "texts": [
            "Figure 1: Overview of the proposed behavioral forensics model which generates labels from people’s retweet behavior and utilizes both network and profile features to train machine learning classifiers.",
            "Figure 2: State diagram for the proposed labeling mechanism demonstrating different sequences of behavior upon exposure, exp(), to a piece of misinformation (𝑟𝑚) and its refutation (𝑟 𝑓 ).",
            "Figure 3: Two step classification overview where we use a two-class classifier to predict the disengaged people and others and then use a multi-class classifier to further categorize the others.",
            "Figure 5: t-SNE plots of the learned LINE embeddings depicting the four non disengaged classes with varying feature dimensions: (a) 4d, (b) 8d, (c) 16d, (d) 32d, (e) 64d, and (f) 128d. (Best viewed at 300% zoom)",
            "Figure 6: ROC curve for the two-class classification step using 5-fold cross-validation.",
            "Figure 7: Horizontal bar plots showing the (a) precision, (b) recall, and (c) F1 score of four different non disengaged classes using different machine learning models for the multi-class classification step. All the values are in percentages.",
            "Table 1: Accuracy (%) of different machine learning models for the two-class classification step using 5-fold cross-validation.",
            "Table 2: Accuracy (%) and weighted F1 score (%) of different machine learningmodels alongwith baselinemodels for the multi-class classification step using 10-fold cross-validation.",
            "Table 3: Precision, recall and F1 score of four different non disengaged classes using the baseline models for the multi-class classification step. All the values are in percentages. Note that while predicting all samples as the majority class, baseline 1 produces undefined precision and F1 score for the non-majority classes as expected, which are represented by ‘-’ in the table."
        ],
        "imgs": [
            "$2305.00957v1-Figure1-1.png",
            "$2305.00957v1-Figure2-1.png",
            "$2305.00957v1-Figure3-1.png",
            "$2305.00957v1-Figure5-1.png",
            "$2305.00957v1-Figure6-1.png",
            "$2305.00957v1-Figure7-1.png",
            "$2305.00957v1-Table1-1.png",
            "$2305.00957v1-Table2-1.png",
            "$2305.00957v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00961",
        "abstract": "  Ensuring fairness in instruments like survey questionnaires or educational\ntests is crucial. One way to address this is by a Differential Item Functioning\n(DIF) analysis, which examines if different subgroups respond differently to a\nparticular item, controlling for their overall latent construct level. DIF\nanalysis is typically conducted to assess measurement invariance at the item\nlevel. Traditional DIF analysis methods require knowing the comparison groups\n(reference and focal groups) and anchor items (a subset of DIF-free items).\nSuch prior knowledge may not always be available, and psychometric methods have\nbeen proposed for DIF analysis when one piece of information is unknown. More\nspecifically, when the comparison groups are unknown while anchor items are\nknown, latent DIF analysis methods have been proposed that estimate the unknown\ngroups by latent classes. When anchor items are unknown while comparison groups\nare known, methods have also been proposed, typically under a sparsity\nassumption -- the number of DIF items is not too large. However, DIF analysis\nwhen both pieces of information are unknown has not received much attention.\nThis paper proposes a general statistical framework under this setting. In the\nproposed framework, we model the unknown groups by latent classes and introduce\nitem-specific DIF parameters to capture the DIF effects. Assuming the number of\nDIF items is relatively small, an $L_1$-regularised estimator is proposed to\nsimultaneously identify the latent classes and the DIF items. A computationally\nefficient Expectation-Maximisation (EM) algorithm is developed to solve the\nnon-smooth optimisation problem for the regularised estimator. The performance\nof the proposed method is evaluated by simulation studies and an application to\nitem response data from a real-world educational test.\n",
        "title": "DIF Analysis with Unknown Groups and Anchor Items",
        "texts": [
            "Figure 1: Path diagram of the proposed model, where the dashed lines indicate the DIF effects.",
            "Table 1: Respondent and item classification accuracy under different simulation scenarios for the twogroup case. The classification error and AUCs present respondent classification performance, where ‘AUC true’ gives the results using the true parameter values. The TPRs and FPRs present the results for item classification, where ‘TPR oracle’ and ‘FPR oracle’ are the performance of the oracle estimator.",
            "Table 2: Respondent and item classification accuracy under different simulation scenarios for the threegroup case. The classification error and AUCs present respondent classification performance, where ‘AUC true’ gives the results using the true parameter values. The TPRs and FPRs present the results for item classification, where ‘TPR oracle’ and ‘FPR oracle’ are the performance of the oracle estimator.",
            "Table 3: Average absolute bias and RMSE over all items by estimated parameter type, when J = 25, N = 1000, and 5000, under the 2-group setting.",
            "Table 4: Average absolute bias and RMSE over all items by estimated parameter type, when J = 50, N = 1000, and 5000 under the 2-group setting.",
            "Table 5: Average absolute bias and RMSE over all items by estimated parameter type, N = 1000 and 5000, under the 3-group setting.",
            "Table 6: Estimated item easiness and DIF effects for the detected DIF items. The asterisks denote the common items."
        ],
        "imgs": [
            "$2305.00961v3-Figure1-1.png",
            "$2305.00961v3-Table1-1.png",
            "$2305.00961v3-Table2-1.png",
            "$2305.00961v3-Table3-1.png",
            "$2305.00961v3-Table4-1.png",
            "$2305.00961v3-Table5-1.png",
            "$2305.00961v3-Table6-1.png"
        ]
    },
    {
        "id": "2305.00962",
        "abstract": "  Recent analyses on high-energy inclusive Higgs-boson rates in proton\ncollisions via the gluon-fusion channel, matched with the state of-the-art\nfixed-order N$^3$LO accuracy, have shown that the impact of high-energy\nresummation corrections reaches 10% at the FCC nominal energies. This supports\nthe statement that electroweak physics at 100 TeV is expected to receive\nrelevant contributions from small-$x$ physics. In this preliminary study we\npresent novel predictions for transverse-momentum and rapidity distributions\nsensitive to the inclusive emission of a Higgs boson in association with a\nlight-flavored jet in proton collisions, calculated within the NLL accuracy of\nthe energy-logarithmic resummation. We highlight how high-energy signals for\nthis process are already present and visible at current LHC energies, and they\nare also sizable at the FCC ones. We come out with the message that the\nimprovement of fixed-order calculations on Higgs-sensitive QCD distributions is\na core ingredient to reach the precision level in the description of\nobservables relevant for the Higgs physics at the FCC.\n",
        "title": "The high-energy QCD dynamics from Higgs-plus-jet correlations at the FCC",
        "texts": [
            "Figure 2: Azimuthal-angle multiplicity for the Higgs-plus-jet production at the LHC (14 TeV, left) and the FCC (100 TeV, right).",
            "Figure 3: Rapidity distribution for the Higgs-plus-jet production at the LHC (14 TeV, left) and the FCC (100 TeV, right)."
        ],
        "imgs": [
            "$2305.00962v1-Figure2-1.png",
            "$2305.00962v1-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00964",
        "abstract": "  We present a python-based program for phenomenological investigations in\nparticle physics using machine learning algorithms, called \\verb\"MLAnalysis\".\nThe program is able to convert LHE and LHCO files generated by\n\\verb\"MadGraph5_aMC@NLO\" into data sets for machine learning algorithms, which\ncan analyze the information of the events. At present, it contains three\nmachine learning (ML) algorithms: isolation forest (IF) algorithm, nested\nisolation forest (NIF) algorithm, kmeans anomaly detection (KMAD), and some\nbasic functionality to analyze the kinematic features of a data set. Users can\nuse this program to improve the efficiency of searching for new physics\nsignals.\n",
        "title": "MLAnalysis: An open-source program for high energy physics analyses",
        "texts": [
            "Figure 1: The IF algorithm can identify anomalous data. The signal points are the anomalous points colored in red, and the background points are colored in blue.",
            "Figure 2: Normalized distributions of anomaly scores denoted as a (left) and compositions of the selected events with a > amin, where amin is a threshold to select the events (right).",
            "Figure 3: The distribution of signal points overlaps with the background, which is no longer an AD problem. By comparing the data distribution of the SM, NIF can select the points that change the distribution.",
            "Figure 4: The K-means algorithm can divide the background events (the colored points) into several groups. The anomalous events are expected to be far away from all centroids of the groups. An example of the anomaly is depicted as the black point.",
            "Table 1: The functions of the classes of MLAnalysis and the types of input parameters of these functions."
        ],
        "imgs": [
            "$2305.00964v2-Figure1-1.png",
            "$2305.00964v2-Figure2-1.png",
            "$2305.00964v2-Figure3-1.png",
            "$2305.00964v2-Figure4-1.png",
            "$2305.00964v2-Table1-1.png"
        ]
    },
    {
        "id": "2305.00965",
        "abstract": "  An inner-product Hilbert space formulation of the Kemeny distance is defined\nover the domain of all permutations with ties upon the extended real line, and\nresults in an unbiased minimum variance (Gauss-Markov) correlation estimator\nupon a homogeneous i.i.d. sample. In this work, we construct and prove the\nnecessary requirements to extend this linear topology for both Spearman's\n\\(\\rho\\) and Kendall's \\(\\tau_{b}\\), showing both spaces to be both biased and\ninefficient upon practical data domains. A probability distribution is defined\nfor the Kemeny \\(\\tau_{\\kappa}\\) estimator, and a Studentisation adjustment for\nfinite samples is provided as well. This work allows for a general purpose\nlinear model duality to be identified as a unique consistent solution to many\nbiased and unbiased estimation scenarios.\n",
        "title": "An unbiased non-parametric correlation estimator in the presence of ties",
        "texts": [
            "Figure 1: Visualisation of the distributions of various point-biserial correlation coefficients upon 25,000 resampled sets of n = 750 elements.",
            "Table 1: Distributional characterisation of the Kemeny distance function, for finite n, permuted exhaustively for n ≤ 8, and sampled with 3,294,172 examples for all larger n.",
            "Table 2: Fisher Iris dataset, n = 150, which allows for α1, α2 to be solved for as a function of the known distances and the sample size.",
            "Table 3: Comparison of the two-sample difference of location estimators’ test statistics, to evaluate power and performance upon the Sleep data set for various sample sizes",
            "Table 4: Comparison of the two-sample difference of location estimators’ effect sizes, to evaluate power and performance upon the Sleep data set for various sample sizes",
            "Table 5: Empirical comparison of the distribution of 25,000 test statistics for the bivariate correlations and Welch’s t1248−test over ordinal random variables for various estimators."
        ],
        "imgs": [
            "$2305.00965v1-Figure1-1.png",
            "$2305.00965v1-Table1-1.png",
            "$2305.00965v1-Table2-1.png",
            "$2305.00965v1-Table3-1.png",
            "$2305.00965v1-Table4-1.png",
            "$2305.00965v1-Table5-1.png"
        ]
    },
    {
        "id": "2305.00967",
        "abstract": "  Soft pneumatic actuators are used to steer soft growing \"vine\" robots while\nbeing flexible enough to undergo the tip eversion required for growth. In this\nstudy, we compared the performance of three types of pneumatic actuators in\nterms of their ability to perform eversion, quasi-static bending, dynamic\nmotion, and force output: the pouch motor, the cylindrical pneumatic artificial\nmuscle (cPAM), and the fabric pneumatic artificial muscle (fPAM). The pouch\nmotor is advantageous for prototyping due to its simple manufacturing process.\nThe cPAM exhibits superior bending behavior and produces the highest forces,\nwhile the fPAM actuates fastest and everts at the lowest pressure. We evaluated\na range of dimensions for each actuator type. Larger actuators can produce more\nsignificant deformations and forces, but smaller actuators inflate faster and\ncan evert at a lower pressure. Because vine robots are lightweight, the effect\nof gravity on the functionality of different actuators is minimal. We developed\na new analytical model that predicts the pressure-to-bending behavior of vine\nrobot actuators. Using the actuator results, we designed and demonstrated a 4.8\nm long vine robot equipped with highly maneuverable 60x60 mm cPAMs in a\nthree-dimensional obstacle course. The vine robot was able to move around sharp\nturns, travel through a passage smaller than its diameter, and lift itself\nagainst gravity.\n",
        "title": "A Comparison of Pneumatic Actuators for Soft Growing Vine Robots",
        "texts": [
            "Figure 2. Steering mechanisms for tip everting soft growing robots: A. Rigid internal steering device from Takahashi et al. 9 . B. Tendon steering from Gan et al. 10 . C. Tendon steering with shape-locking using velcro from Jitosho et al. 11 . D. Pouch motor design from Coad et al. 2 . E. cPAM design from Kübler et al. 12 , similar to the foldPAM introduced by Wang et al. 13 . F. fPAM design from Naclerio and Hawkes 14 . G. sPAM design from Greer et al. 15 . H. Integrated pouch design from Abrar et al. 16 . The steering mechanisms D, E, and F, highlighted in red, are characterized in this work.",
            "Figure 3. Vine robot fabrication and dimensions overview. Top to bottom: Schematic side and front view with main dimensions, top view of the actuated vine robot. A. Line of welded pouch motors, taped onto the vine robot body. B. Line of welded cPAMs, directly welded onto the vine robot body. C. fPAM, glued using SilPoxy.",
            "Figure 4. A. Measurement setup for bending, dynamic motion, and force tests. A stereo camera, calibrated by the checkerboard, tracks the deformation of the vine robot using the orange markers. The vine robot body is connected to the air container. Two pressure regulators control the pressure in the vine robot body and the actuators, two pressure sensors sense the actual pressure. Everything is connected by a skeleton made of aluminum profiles to allow for horizontal and vertical orientation. B. The force sensor in detail view.",
            "Figure 5. Modeling of the vine robot’s pressure-to-bending relationship for different actuator types; schematics indicate the dimensions, applied pressures, and acting forces. A.-B. Pouch Motor: A. Top view of a vine robot segment with an attached pouch motor. B. Single pouch motor modeled as an ideal pouch motor with corrected volume. C.-E. cPAM: C. Top view of a vine robot segment with an integrated cPAM. D. Single cPAM modeled as an ideal pouch motor. E. Front view of a vine robot with an integrated cPAM and resulting diameter correction. F.-G. fPAM: F. Top view of a vine robot segment with an attached fPAM, G. Different contraction regions of the fPAM actuator with corresponding pressure (grey) and acting forces (black) from an elastic, pre-stretched state to a fully inflated state with maximal bending. ε defines the general contraction of the fPAM, εelastic defines the elastic contraction, and εbend defines the contraction related to the bending of the vine robot. ε = 0 indicates the theoretically maximum pre-strech, ε = εps the pre-strech when integrated into the vine robot and not inflated, ε = ε0 the contraction without pre-stretch, and ε = εmax the maximum contraction. The pressure curve qualitatively shows the relationship between pressure and contraction.",
            "Figure 6. Comparison of the quasi-static bending performance in horizontal (→, without gravity) and vertical (↑, with gravity) orientation. Dashed lines indicate the mean over five iterations for the largest dimensions of each actuator type: W60xL60 mm pouch motor, W60xL60 mm cPAM, and W60 mm fPAM.",
            "Figure 7. Experimental results for the three actuator types with respect to the inflation pressure (x-axis). W indicates the width and L indicates the length of an actuator. Left to right: Pouch motor, cPAM, and fPAM results. Top to bottom: Quasi-static bending results characterized by the bending angle per nominal length, dynamic motion capabilities characterized by the 10-90% rise time, and the resulting lateral force when the tip of the vine robot is constrained. In the first row, the mean of five experimental measurements is shown by dashed lines, the experimental standard deviation is shown by the shaded areas, and the analytical model is shown by solid lines. In the second and third rows, dashed lines show the mean over five iterations and the error bars indicate the corresponding standard deviation.",
            "Figure 8. Demonstration of navigating an obstacle course with a 4.8 m long vine robot of 80 mm diameter and three strands of W60xL60 mm cPAMs for steering in the three-dimensional space. The vine robot is supported by an improved version of the supply box shown in Auf der Maur et al. 5 . A.-C. The vine robot with corresponding time stamps while moving through the obstacle course. D. The final state of the vine robot along a right turn, passage under a bridge, left turn, passage with a shrunken diameter, and a vertical turn. The grid indicates dimensions of 50x50 cm. The dimensions of the demonstrated vine robot are derived from the results of the quasi-static bending experiments.",
            "Table 3. Normalized model error e as defined in Section 6.3 for all three actuator types and all dimensions. W indicates the width and L indicates the length of an actuator."
        ],
        "imgs": [
            "$2305.00967v3-Figure2-1.png",
            "$2305.00967v3-Figure3-1.png",
            "$2305.00967v3-Figure4-1.png",
            "$2305.00967v3-Figure5-1.png",
            "$2305.00967v3-Figure6-1.png",
            "$2305.00967v3-Figure7-1.png",
            "$2305.00967v3-Figure8-1.png",
            "$2305.00967v3-Table3-1.png"
        ]
    },
    {
        "id": "2305.00969",
        "abstract": "  This paper describes the Ubenwa CryCeleb dataset - a labeled collection of\ninfant cries - and the accompanying CryCeleb 2023 task, which is a public\nspeaker verification challenge based on cry sounds. We released more than 6\nhours of manually segmented cry sounds from 786 newborns for academic use,\naiming to encourage research in infant cry analysis. The inaugural public\ncompetition attracted 59 participants, 11 of whom improved the baseline\nperformance. The top-performing system achieved a significant improvement\nscoring 25.8% equal error rate, which is still far from the performance of\nstate-of-the-art adult speaker verification systems. Therefore, we believe\nthere is room for further research on this dataset, potentially extending\nbeyond the verification task.\n",
        "title": "CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds",
        "texts": [
            "Fig. 3: CryCeleb challenge verification task. Given two recordings, predict if they belong to the same infant",
            "Fig. 4: Verification scores for negative and positive pairs produced by the ECAPA-TDNN pre-trained on speech data VoxCeleb (left) and fine-tuned on CryCeleb (right). Classification threshold (red dashed line) is selected to minimize EER.",
            "Fig. 5: Equal error rates of CryCelb 2023 competition submissions. The public subset of test set was available throughout the competition while private subset was used only after the competition end to evaluate 5 submissions selected by each participant.",
            "Table 1: Summary statistics of the dataset.",
            "Table 3: Number of infants by split and recording period.",
            "Table 5: Performance (EER) of baseline models. First row indicates the performance obtained with the model pre-tained on VoxCeleb and the second row indicates the performance where the first model is fine-tuned on CryCeleb."
        ],
        "imgs": [
            "$2305.00969v5-Figure3-1.png",
            "$2305.00969v5-Figure4-1.png",
            "$2305.00969v5-Figure5-1.png",
            "$2305.00969v5-Table1-1.png",
            "$2305.00969v5-Table3-1.png",
            "$2305.00969v5-Table5-1.png"
        ]
    },
    {
        "id": "2305.00971",
        "abstract": "  The endoplasmic reticulum (ER), a cellular organelle that forms a\ncell-spanning network of tubes and sheets, is an important location of protein\nsynthesis and folding. When the ER experiences sustained unfolded protein\nstress, IRE1 proteins embedded in the ER membrane activate and assemble into\nclusters as part of the unfolded protein response (UPR). We use kinetic Monte\nCarlo simulations to explore IRE1 clustering dynamics on the surface of ER\ntubes. While initially growing clusters are approximately round, once a cluster\nis sufficiently large a shorter interface length can be achieved by `wrapping'\naround the ER tube. A wrapped cluster can grow without further interface length\nincreases. Relative to wide tubes, narrower tubes enable cluster wrapping at\nsmaller cluster sizes. Our simulations show that wrapped clusters on narrower\ntubes grow more rapidly, evaporate more slowly, and require a lower protein\nconcentration to grow compared to equal-area round clusters on wider tubes.\nThese results suggest that cluster wrapping, facilitated by narrower tubes,\ncould be an important factor in the growth and stability of IRE1 clusters and\nthus impact the persistence of the UPR, connecting geometry to signaling\nbehavior. This work is consistent with recent experimental observations of IRE1\nclusters wrapped around narrow tubes in the ER network.\n",
        "title": "Tube geometry controls protein cluster conformation and stability on the\n  endoplasmic reticulum surface",
        "texts": [
            "FIG. 1. Schematic diagram of the kinetic Monte Carlo simulation algorithm for IRE1 protein and cluster dynamics on an endoplasmic reticulum tube. Green circles are individual activated IRE1 proteins, which diffuse on a two-dimensional lattice as individual proteins and as clusters. Periodic boundary conditions (orange arrow) represent the tubular geometry. Connection to the rest of the ER network is represented by a constant external concentration cext, with proteins able to both enter and leave the tube section. IRE1 interactions are favored by nearest-neighbor interaction energy J (see Eq. 1).",
            "FIG. 10. Violin plot of the cluster growth rates before and after the cluster wrapping transition. (A) Tube diameter of 32 nm. Mean growth rate before wrapping is 1.01 proteins/s, and after wrapping it is 1.14 proteins/s. The Kolmogorov-Smirnov (K-S) test returned a p-value of 4.27 × 10−8 between the two distributions. (B) Tube diameter of 46 nm., Mean growth rate before wrapping is 1.47 protein/s, and after wrapping it is 1.75 proteins/s. The K-S test returned a p-value of 6.20 × 10−10 between the two distributions. For both panels, J = 5.3 kBT as in Fig. 3, tube length is 1µm, cext = 1/µm2, and means averaged over 80 runs.",
            "FIG. 2. Cluster conformation transitions. (A) Schematics of round (left inset) and wrapped (right inset) cluster conformations. Cluster interface lengths for round (blue), and wrapped (red and green) clusters on tubes (diameters 32 nm and 41 nm). (B) Frequency of transitions between round and wrapped clusters on a 32 nm diameter and 1 µm closed long tube, averaged over 24 runs; and corresponding probability of wrapped cluster conformation. (C) Probability of cluster conformation (wrapped or round) on a closed tube (no proteins enter or exit) for various protein concentrations, with 38, 48 and 57 nm tube diameter and 1 µm length. Simulations begin with all proteins in a round cluster at tube center. J = 3 kBT , average of 24 runs. (D) Cluster size at which the interface energy of wrapped clusters becomes energetically favored compared to round clusters (magenta, Eq. 2), cluster size at which 50% of clusters are in a wrapped conformation in simulations from (C) (cyan), and cluster size at which round cluster diameter is equal to tube circumference (blue).",
            "FIG. 3. Cluster formation with open boundary conditions. The IRE1 external (to the tube region under consideration) concentration cext and the tube diameter are varied, with color map indicating mean number of proteins in a cluster 6 hours after initializing with one protein in the tube, averaged over 20 runs, tube length of 1 µm, and J = 5.3 kBT . Cluster sizes over 20 are indicated as 20. Each tube initially contains a single IRE1 protein, as the maximum diameter and concentration sampled correspond to less than a single IRE1 protein in the tube region.",
            "FIG. 4. Cluster conformation affects cluster growth rate. (A) Individual cluster growth trajectories (thin lines) vs time, as well as linear fits of 80 cluster size trajectories before (thick blue) and after (thick red) round-to-wrapped transition, which is set at t = 0. J = 3 kBT , cext = 34/µm2, 30 nm tube diameter, and tube length of 1 µm. (B) Violin plot of the cluster growth rates before and after the cluster wrapping transition, with same parameters as (A). (C) Cluster size at wrapping transition vs tube diameter, with cluster size at which the interface energy of wrapped clusters becomes energetically favorable (purple, Eq. 2) and cluster size at which wrapping transition occurs during cluster growth simulations (cyan). Tube length 1 µm, J = 5.3 kBT , averaged over 30 samples. (D) Mean time period for a cluster to grow to a specific size (see legend) vs tube diameter. J = 5.3 kBT , cext = 1/µm2, tube length of 1 µm, averaged over 30 samples with initial cluster size of 30 proteins.",
            "FIG. 6. Threshold concentration between cluster growth and decay. (A) Mean trajectories for clusters in tube with different external concentrations cext (each curve is a different cext). The lowest concentration is 0.1/µm2, highest concentration is 0.4/µm2, with concentration intervals of approximately 0.021/µm2, with 15 concentrations shown. Each concentration averaged over 20 runs. Clusters begin with 200 proteins, and begin as round unless tube is too narrow, in which case the cluster starts wrapped. (B) Threshold concentration c0 between cluster growth and decay as tube diameter is varied. Threshold concentration determined by linear fit of cluster growth rates near zero cluster growth. For diameters less than the diameter at which the threshold concentration transitions (suddenly jumps), clusters are wrapped; for diameters greater than the transition, clusters are round. Tube length 1 µm, J = 5.3kBT as in the phase diagram of Fig. 3.",
            "FIG. 7. Summary of IRE1 concentrations important for cluster dynamics. Left: Threshold concentrations for cluster formation (blue, see Fig. 3), decay of 100- and 200-protein clusters (cyan and magenta, respectively, from Fig. 6B). Clusters do not form until a relatively high IRE1 concentration is reached — as concentration decreases, clusters can grow below this high cluster formation threshold. Clusters will decay on wider tubes at a higher concentration than on narrower tubes, because clusters on narrower tubes are in a wrapped configuration and are more stable, compared to round clusters on wider tubes. Right: Schematic of cluster growth and decay trajectory. Concentration begins near zero, with no cluster. As the concentration increases past the cluster formation threshold, clusters will form and grow (black solid curve). As the concentration begins to decrease, the cluster growth diminishes (dashed black curve). Once the concentration is sufficiently low, first round clusters (blue solid curve) and then wrapped clusters (red solid curve) will decay. J = 5.3 kBT for both panels.",
            "FIG. 9. Cluster formation with open boundary conditions. (A,B,C) mean IRE1 cluster size with open boundary conditions at the indicated times. The IRE1 external (to the tube region under consideration) concentration cext and the tube diameter are varied, with color map indicating mean number of proteins in a cluster. Clusters of sizes greater than 20 are binned with cluster size 20. (D,E,F) Cluster decay probability for clusters of different size with different external IRE1 concentrations cext. The left axis (magenta) is the probability that a cluster of size 10 (D), 20 (E), and 30 (F) will decay. The right axis is the number of clusters included in each decay probability calculation. Tube length 1 µm and J = 5.3 kBT ."
        ],
        "imgs": [
            "$2305.00971v1-Figure1-1.png",
            "$2305.00971v1-Figure10-1.png",
            "$2305.00971v1-Figure2-1.png",
            "$2305.00971v1-Figure3-1.png",
            "$2305.00971v1-Figure4-1.png",
            "$2305.00971v1-Figure6-1.png",
            "$2305.00971v1-Figure7-1.png",
            "$2305.00971v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00973",
        "abstract": "  Chern insulators, which are the lattice analogs of the quantum Hall states,\ncan potentially manifest high-temperature topological orders at zero magnetic\nfield to enable next-generation topological quantum devices. To date, integer\nChern insulators have been experimentally demonstrated in several systems at\nzero magnetic field, but fractional Chern insulators have been reported only in\ngraphene-based systems under a finite magnetic field. The emergence of\nsemiconductor moir\\'e materials, which support tunable topological flat bands,\nopens a new opportunity to realize fractional Chern insulators. Here, we report\nthe observation of both integer and fractional Chern insulators at zero\nmagnetic field in small-angle twisted bilayer MoTe2 by combining the local\nelectronic compressibility and magneto-optical measurements. At hole filling\nfactor {\\nu}=1 and 2/3, the system is incompressible and spontaneously breaks\ntime reversal symmetry. We determine the Chern number to be 1 and 2/3 for the\n{\\nu}=1 and {\\nu}=2/3 gaps, respectively, from their dispersion in filling\nfactor with applied magnetic field using the Streda formula. We further\ndemonstrate electric-field-tuned topological phase transitions involving the\nChern insulators. Our findings pave the way for demonstration of quantized\nfractional Hall conductance and anyonic excitation and braiding in\nsemiconductor moir\\'e materials.\n",
        "title": "Integer and fractional Chern insulators in twisted bilayer MoTe2",
        "texts": [
            "Figure 1b (top panel) shows the doping dependence of the chemical potential 𝜇(𝜈) of tMoTe2 with interlayer potential difference close to zero. The chemical potential is set to zero at its maximum value. Included is also its numerical derivative with respect to",
            "Figure 2 | Integer and fractional Chern insulators. a, Electronic incompressibility as a function of hole filling factor ( 𝜈 ) and perpendicular magnetic field (B) near zero interlayer potential difference. Two linearly dispersing incompressible states are observed at 𝜈 = 1 and 𝜈= 2/3. b, Same as a under a large interlayer potential difference. One nondispersive incompressible state is observed at 𝜈 = 1. Empty circles in a, b are the centerof-mass of the incompressibility peaks. A small sample-beam drift is present above ~ 6 T. c, Determination of the Chern number (C) of the 𝜈 = 1 and 𝜈 = 2/3 states. Empty circles: same as in a; filled circles: corrected incompressibility peak location using that of b; solid",
            "Figure 3 | Phase diagram. a-c, Electronic incompressibility (a), MCD (b) and optical reflectance at the intralayer exciton resonance (c) of tMoTe2 as a function of hole filling factor (𝜈) and perpendicular electric field (E). A small magnetic field (20 mT) is applied in b to reduce the MCD fluctuations (likely due to the presence of magnetic domains). The spontaneous MCD has a similar magnitude for the 𝜈 = 1 and 𝜈 = 2/3 states. In the layer-hybridized region between the dashed lines, the interlayer potential difference is small and charges are shared between the two layers.",
            "Figure 4 | Topological phase transitions. a,b, Electric-field dependence of the chemical potential step at 1.6 K (a) and the spontaneous MCD at representative temperatures (b) for the 𝜈 = 1 state. The dashed lines (same as in Fig. 3) mark the boundary of the chargesharing region. Chemical potential step minima are observed near the boundary. The spontaneous MCD vanishes beyond the boundary and above the critical temperature of about 13 K. The results indicate a continuous phase transition from a Chern insulator (CI) to a non-topological Mott insulator (MI). c,d, Same as a,b, for the 𝜈 = 2/3 state. Both the chemical potential step and spontaneous MCD vanish beyond the boundary. The magnetic critical temperature is about 5 K."
        ],
        "imgs": [
            "$2305.00973v1-Figure1-1.png",
            "$2305.00973v1-Figure2-1.png",
            "$2305.00973v1-Figure3-1.png",
            "$2305.00973v1-Figure4-1.png"
        ]
    },
    {
        "id": "2305.00976",
        "abstract": "  In this paper, we present TMR, a simple yet effective approach for text to 3D\nhuman motion retrieval. While previous work has only treated retrieval as a\nproxy evaluation metric, we tackle it as a standalone task. Our method extends\nthe state-of-the-art text-to-motion synthesis model TEMOS, and incorporates a\ncontrastive loss to better structure the cross-modal latent space. We show that\nmaintaining the motion generation loss, along with the contrastive training, is\ncrucial to obtain good performance. We introduce a benchmark for evaluation and\nprovide an in-depth analysis by reporting results on several protocols. Our\nextensive experiments on the KIT-ML and HumanML3D datasets show that TMR\noutperforms the prior work by a significant margin, for example reducing the\nmedian rank from 54 to 19. Finally, we showcase the potential of our approach\non moment retrieval. Our code and models are publicly available at\nhttps://mathis.petrovich.fr/tmr.\n",
        "title": "TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion\n  Synthesis",
        "texts": [
            "Figure 1. Text-to-motion retrieval: We illustrate the task of text-based motion retrieval where the goal is to rank a gallery of motions according to their similarity to the given query in the form of a natural language description.",
            "Figure 2. Joint motion retrieval and synthesis: A simplified view of our TMR framework is presented, where we focus on the similarity matrix defined between text-motion pairs within a batch. Here, we show a batch of 3 samples for illustration purposes. The goal of the contrastive objective is to maximize the diagonal denoting positive pairs (green), and to minimize the off-diagonal negative pair items that have text similarity below a threshold (red). In this example, remaining similarities S23 and S32 are discarded from the loss computation because there is high text similarity between T2 and T3. The rest of the model remains similar to TEMOS [36], which decodes a motion from both text zTi and motion zMj latent vectors. See text for further details.",
            "Figure 3. Qualitative retrieval results: We demonstrate example queries on the left, and corresponding retrieved motions on the right, ranked by text-motion similarity. The similarity values are displayed on the top. For each retrieved motion, we also show their accompanying ground-truth text label; note that we do not use these descriptions, but only provide them for analysis purposes. The motions from the gallery are all from the test set (unseen during training). In the first row, all top-5 retrieved motions correspond visually to ‘playing violin’ and the similarity scores are high >0.80. In the second row, we correctly retrieve the ‘handstand’ motion at top-1, but the other motions mainly perform ‘cartwheel’ (which involves shortly standing on hands), but with a lower similarity score <0.70. For the last example, we query a free-form text ‘Someone is swimming’, which does not exist in the gallery (but the word ‘swim’ does). The model successfully finds swimming motions among the top-3, and the other two motions involve the body parallel to the ground.",
            "Figure 4. Moment retrieval: We plot the similarity between the temporally annotated BABEL text labels and the motions in a sliding window manner, and obtain a 1D signal over time (blue). We observe that a localization ability emerges from our model, even though it was not trained for temporal localization, and was not with the domain of BABEL labels. The ground-truth temporal span is denoted in green and the maximum similarity is marked with a dashed red line. More examples are provided in Appendix Figure A.2.",
            "Figure A.1. Moment retrieval (quantitative): We plot the localization accuracy (y-axis) with various IoU thresholds (x-axis).",
            "Figure A.3. Protocols (a) and (b) using all 4,380 motions in H3D: For each text query, we show the top 10 ranks for the text-to-motion retrieval. Our model generalizes to the concept of “rocking a baby” in the first example, even though this exact same text was not seen in the training set. In the second example, our model retrieves motions that are all coherent with the input query. However, according to evaluation protocol (a), the correct motion is ranked at 31. With the permissive protocol (b), we mark the rank 8 as correct, because their text similarity (TS) is higher than the threshold 0.95.",
            "Figure A.5. Protocol (c) using the most dissimilar 100 texts on H3D: As there are fewer motions than in protocols (a)(b), and they are more likely to be different, we naturally observe a better performance.",
            "Table 1. Text-to-motion retrieval benchmark on HumanML3D: We establish four evaluation protocols as described in Section 4.1, with decreasing difficulty from (a) to (d). Our model TMR substantially outperforms the prior work of Guo et al. [15] and TEMOS [36], on the challenging H3D dataset.",
            "Table 2. Text-to-motion retrieval benchmark on KIT-ML: As in Table 1, we report the four evaluation protocols, this time on the KIT dataset. Again, TMR significantly improves over Guo et al. [15] and TEMOS [36] across all protocols and metrics.",
            "Table 3. Losses: We experiment with various loss definitions (i) with/without the motion reconstruction, and (ii) the choice of the contrastive loss between InfoNCE and margin-based. We see that InfoNCE [34] is a better alternative to the contrastive loss with Euclidean margin [18] (employed by Guo et al. [15]). The reconstruction loss through the motion decoder branch further boosts the results.",
            "Table 4. Filtering negatives: We compare several threshold values for filtering negatives from the loss comparison due to having similar texts. We observe that removing negatives based on text similarity above 0.8 (from a scale between [0,1]) performs well overall.",
            "Table 5. Hyperparameters of the contrastive training: We measure the sensitivity to the parameters τ (temperature), λc the weight of the contrastive loss, and the batch size. Note that the learning rate is proportionally altered when changing the batch size. We display a wide range of values to show the full trends.",
            "Table A.2. Motion synthesis results: We report R@1 text-to-motion retrieval performance of generated motions by the synthesis method of Guo et al. [15] (Guo Syn.), TEMOS [36], and our TMR synthesis branch, as well as the ‘Real motions’, on both KIT-ML (left) and H3D (right) benchmarks. Rows are different motion generation methods, columns are different retrieval evaluation models: retrieval method of Guo et al. [15] (Guo Ret.), TEMOS, and our TMR retrieval branch. We use the protocol (d), i.e., 32 gallery size protocol from [15] . We make several observations: (i) TMR, when used for motion synthesis, performs better than or similar to Guo Syn. [15] across all 3 retrieval evaluation models, showing we do not sacrifice synthesis performance. (ii) Evaluation with retrieval models that can also perform synthesis (TEMOS and TMR) favors motions generated by their own model. (iii) Certain numbers are better than Real motions, potentially because generations are sometimes more faithful to the input text, which may incompletely describe the real motion, or due to the bias mentioned in (ii).",
            "Table A.3. Latent dimensionality: We experiment with the embedding space dimensionality, and observe that d=128 performs overall best. However, in all other experiments, we use d=256 as in TEMOS.",
            "Table A.4. Contrastive-only without negative filtering: We report text-to-motion retrieval results on KIT-ML to analyze the impact of negative filtering (NF) on the contrastive-only baseline. First row is the supplemental result, the rest are from the main paper."
        ],
        "imgs": [
            "$2305.00976v2-Figure1-1.png",
            "$2305.00976v2-Figure2-1.png",
            "$2305.00976v2-Figure3-1.png",
            "$2305.00976v2-Figure4-1.png",
            "$2305.00976v2-FigureA.1-1.png",
            "$2305.00976v2-FigureA.3-1.png",
            "$2305.00976v2-FigureA.5-1.png",
            "$2305.00976v2-Table1-1.png",
            "$2305.00976v2-Table2-1.png",
            "$2305.00976v2-Table3-1.png",
            "$2305.00976v2-Table4-1.png",
            "$2305.00976v2-Table5-1.png",
            "$2305.00976v2-TableA.2-1.png",
            "$2305.00976v2-TableA.3-1.png",
            "$2305.00976v2-TableA.4-1.png"
        ]
    },
    {
        "id": "2305.00977",
        "abstract": "  A bound uniform over various loss-classes is given for data generated by\nstationary and phi-mixing processes, where the mixing time (the time needed to\nobtain approximate independence) enters the sample complexity only in an\nadditive way. For slowly mixing processes this can be a considerable advantage\nover results with multiplicative dependence on the mixing time. The admissible\nloss-classes include functions with prescribed Lipschitz norms or smoothness\nparameters. The bound can also be applied to be uniform over unconstrained\nloss-classes, where it depends on local Lipschitz properties of the function on\nthe sample path.\n",
        "title": "Generalization for slowly mixing processes",
        "texts": [
            "Figure 1: The estimator G on rotated images for different sample sizes and reset probabilities. We also plot an optimistic estimate on competing bounds",
            "Figure 2: The estimator G on rotated and scaled images for different sample sizes and reset probabilities. We also plot an optimistic estimate on competing bounds"
        ],
        "imgs": [
            "$2305.00977v2-Figure1-1.png",
            "$2305.00977v2-Figure2-1.png"
        ]
    },
    {
        "id": "2305.00979",
        "abstract": "  Gaussian mixture block models are distributions over graphs that strive to\nmodel modern networks: to generate a graph from such a model, we associate each\nvertex $i$ with a latent feature vector $u_i \\in \\mathbb{R}^d$ sampled from a\nmixture of Gaussians, and we add edge $(i,j)$ if and only if the feature\nvectors are sufficiently similar, in that $\\langle u_i,u_j \\rangle \\ge \\tau$\nfor a pre-specified threshold $\\tau$. The different components of the Gaussian\nmixture represent the fact that there may be different types of nodes with\ndifferent distributions over features -- for example, in a social network each\ncomponent represents the different attributes of a distinct community. Natural\nalgorithmic tasks associated with these networks are embedding (recovering the\nlatent feature vectors) and clustering (grouping nodes by their mixture\ncomponent).\n  In this paper we initiate the study of clustering and embedding graphs\nsampled from high-dimensional Gaussian mixture block models, where the\ndimension of the latent feature vectors $d\\to \\infty$ as the size of the\nnetwork $n \\to \\infty$. This high-dimensional setting is most appropriate in\nthe context of modern networks, in which we think of the latent feature space\nas being high-dimensional. We analyze the performance of canonical spectral\nclustering and embedding algorithms for such graphs in the case of 2-component\nspherical Gaussian mixtures, and begin to sketch out the\ninformation-computation landscape for clustering and embedding in these models.\n",
        "title": "Spectral clustering in the Gaussian mixture block model",
        "texts": [
            "Figure 1: Diagram illustrating the range of for which we show that the spectral algorithm completes each task successfully (up to logarithmic factors), all under the condition that 1 log≪ d log≪ pn. The solid lines correspond to our theorems. The dashed teal line indicates that beyond d−1/4, each community corresponds to a distinct connected component in the graph and thus spectral clustering trivially succeeds. Similarly, the dashed violet line indicates that beyond d−1/4, the community labels suffice to recover an approximate embedding. The gray x’s mark a range in which clustering/testing is impossible even when the latent embedding is known (lower bounds for clustering in [Nda22], for testing in Appendix A). Theorem 1.4 (Latent vector recovery/embedding). Suppose that n, d ∈ ℤ+ and ∈ ℝ+, and p ∈ [0, 1/2 − \"] for any constant \" > 0, satisfy the conditions log9 n ≪ d < n, 2 6 1/( √ d log n), and pn ≫ 1. Then given G ∼ Gn,d ( , ) generated by latent vectors u1, … , un ∈ ℝd , the spectral algorithm described above produces vectors û1, … , ûn which satisfy"
        ],
        "imgs": [
            "$2305.00979v1-Figure1-1.png"
        ]
    },
    {
        "id": "2305.00980",
        "abstract": "  Structured output representation is a generative task explored in computer\nvision that often times requires the mapping of low dimensional features to\nhigh dimensional structured outputs. Losses in complex spatial information in\ndeterministic approaches such as Convolutional Neural Networks (CNN) lead to\nuncertainties and ambiguous structures within a single output representation. A\nprobabilistic approach through deep Conditional Generative Models (CGM) is\npresented by Sohn et al. in which a particular model known as the Conditional\nVariational Auto-encoder (CVAE) is introduced and explored. While the original\npaper focuses on the task of image segmentation, this paper adopts the CVAE\nframework for the task of controlled output representation through attributes.\nThis approach allows us to learn a disentangled multimodal prior distribution,\nresulting in more controlled and robust approach to sample generation. In this\nwork we recreate the CVAE architecture and train it on images conditioned on\nvarious attributes obtained from two image datasets; the Large-scale CelebFaces\nAttributes (CelebA) dataset and the Caltech-UCSD Birds (CUB-200-2011) dataset.\nWe attempt to generate new faces with distinct attributes such as hair color\nand glasses, as well as different bird species samples with various attributes.\nWe further introduce strategies for improving generalized sample generation by\napplying a weighted term to the variational lower bound.\n",
        "title": "Controlling Structured Output Representations from Attributes using\n  Conditional Generative Models",
        "texts": [
            "Figure 1. Overview framework of the a) VAE and b) CVAE. This figure covers both deterministic and probabilistic components for each model.",
            "Figure 2. Overview of our CVAE architecture’s training and sampling pipeline",
            "Figure 3. Samples generated from model trained on β values ranging from 0.25 to 0.9",
            "Figure 4. Reconstructed images generated during training from model with β values ranging from 0.25 to 0.9. For each β the upper row is the Ground Truth image and the bottom is the reconstructed image",
            "Figure 5. Samples generated to demonstrate robustness of the CVAE mdoel",
            "Table 1. Mean Squared Error and KL losses for models trained on β ranging from 0.25 to 0.9"
        ],
        "imgs": [
            "$2305.00980v1-Figure1-1.png",
            "$2305.00980v1-Figure2-1.png",
            "$2305.00980v1-Figure3-1.png",
            "$2305.00980v1-Figure4-1.png",
            "$2305.00980v1-Figure5-1.png",
            "$2305.00980v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00983",
        "abstract": "  For open world applications, deep neural networks (DNNs) need to be aware of\npreviously unseen data and adaptable to evolving environments. Furthermore, it\nis desirable to detect and learn novel classes which are not included in the\nDNNs underlying set of semantic classes in an unsupervised fashion. The method\nproposed in this article builds upon anomaly detection to retrieve\nout-of-distribution (OoD) data as candidates for new classes. We thereafter\nextend the DNN by $k$ empty classes and fine-tune it on the OoD data samples.\nTo this end, we introduce two loss functions, which 1) entice the DNN to assign\nOoD samples to the empty classes and 2) to minimize the inner-class feature\ndistances between them. Thus, instead of ground truth which contains labels for\nthe different novel classes, the DNN obtains a single OoD label together with a\ndistance matrix, which is computed in advance. We perform several experiments\nfor image classification and semantic segmentation, which demonstrate that a\nDNN can extend its own semantic space by multiple classes without having access\nto ground truth.\n",
        "title": "Detecting Novelties with Empty Classes",
        "texts": [
            "Figure 1: Comparison of two segmentation DNNs which were extended by the classes human and car. While the segmentation masks are similar for the initial classes, the humans and cars are much better segmented by the DNN which was extended by our empty classes approach. The novel classes are marked with green contours in the image and ground truth.",
            "Figure 10: Visualization of the softmax entropy, that the initial models exhibit on samples of known and OoD classes, respectively.",
            "Figure 11: Visualization of the softmax entropy per data sample, that the initial models exhibits on test samples.",
            "Figure 12: Visual comparison of the segmentation masks produced by our method and by the baseline for two images from the Cityscapes validation dataset. The ground truth contours of the novel classes are highlighted with green.",
            "Figure 13: For highly uncertain regions, the extended DNN tends to predict the novel human class, which causes the low precision score.",
            "Figure 2: (I) A binary classification model is trained on two classes and additional noise data for entropy maximization. (II) OoD samples in the test data are obtained by entropy thresholding. (III) The training data is enriched with the OoD samples and a distance matrix, containing their pair-wise Euclidean distances. (IV) The model is class-incrementally extended by three novel classes.",
            "Figure 3: Open world recognition models must be able to recognize known classes while detecting OoD data from novel classes and furthermore to incrementally learn these novel classes. Instead of labeling the OoD samples, our method computes pair-wise distances between them, which serve as input for a clustering loss function.",
            "Figure 4: In semantic segmentation, each of the OoD objects is assigned a unique ID, no matter if they belong to the same novel class as the elephants, or to different classes as the cone and the monster costume [8].",
            "Figure 5: Visualized ground truth (left) and prediction of the MNIST dataset by the initial (middle) and extended (right) model. The three novel classes 0, 5 and 7 are outlined in orange. The extended model’s accuracy is ∼ 94%.",
            "Figure 6: Visualized ground truth (left) and prediction of the FashionMNIST dataset by the initial (middle) and extended (right) model. The two novel classes 1 and 8 are outlined in orange. The extended model’s accuracy is ∼ 85%.",
            "Figure 7: Visualized ground truth (left) and prediction of the Animals10 dataset by the initial (middle) and extended (right) model. The four novel classes 3, 4, 8 and 9 are outlined in orange. The extended model’s accuracy is ∼ 95%.",
            "Figure 8: Visualized ground truth (left) and prediction of the CIFAR10 dataset by the initial (middle) and extended (right) model. The two novel classes 10 and 11 are outlined in orange. The extended model’s accuracy is ∼ 89%.",
            "Figure 9: Visual comparison of the segmentation masks produced by our method and by the baseline for two image cutouts from the Cityscapes validation dataset. The ground truth contours of the novel classes are highlighted with green.",
            "Table 1: Quantitative evaluation of the image classification experiments. For all evaluated models, the accuracy is stated separately for the previously-known and the unlabeled novel classes. The highest scores for the unsupervised approaches are bolded.",
            "Table 2: Quantitative evaluation of the semantic segmentation experiment on the Cityscapes dataset. IoU, precision and recall values are provided for both novel classes as well as averaged over the previously-known classes. The highest scores for the unsupervised approaches are bolded.",
            "Table 3: Overview of training parameters for each dataset.",
            "Table 4: Quantitative evaluation of the FashionMNIST and Animals10 experiments, averaged over 5 runs with randomly selected OoD classes, each. For all evaluated models, the accuracy is stated separately for the previouslyknown and the unlabeled novel classes."
        ],
        "imgs": [
            "$2305.00983v1-Figure1-1.png",
            "$2305.00983v1-Figure10-1.png",
            "$2305.00983v1-Figure11-1.png",
            "$2305.00983v1-Figure12-1.png",
            "$2305.00983v1-Figure13-1.png",
            "$2305.00983v1-Figure2-1.png",
            "$2305.00983v1-Figure3-1.png",
            "$2305.00983v1-Figure4-1.png",
            "$2305.00983v1-Figure5-1.png",
            "$2305.00983v1-Figure6-1.png",
            "$2305.00983v1-Figure7-1.png",
            "$2305.00983v1-Figure8-1.png",
            "$2305.00983v1-Figure9-1.png",
            "$2305.00983v1-Table1-1.png",
            "$2305.00983v1-Table2-1.png",
            "$2305.00983v1-Table3-1.png",
            "$2305.00983v1-Table4-1.png"
        ]
    },
    {
        "id": "2305.00984",
        "abstract": "  One of the possible representations of three-valued instantaneous noise-based\nlogic is proposed. The third value is an uncertain bit value, which can be\nuseful in artificial intelligence applications. There is a forth value, too,\nthat can represent a non-existing bit (vacuum-state) that is the same (1\nnumeric value) for all bits, however that is a squeezed state common for all\nbits. Some logic gates are explored. A ternary Universe has a significant\nadvantage compared to the standard binary one: its amplitude is never zero\nduring any clock period. All the known binary logic gates work for the binary\nbit values in the same way as earlier therefore the former binary algorithms\ncan be run in the ternary system with no change and without the problems posed\nby zero values of the Universe.\n",
        "title": "Ternary Instantaneous Noise-based Logic",
        "texts": [
            "Figure 1. Generic noise-based logic hardware scheme [13]. Logic operations can be executed by the gates or by operations on the reference signals. The Reference Noise System is based on a truly random number generator.",
            "Figure 2. Example [11] of random telegraph wave (RTW) carrying a bit value of a chosen noise-bit in the asymmetric INBL scheme. The clock is periodic. At the beginning of each clock period, an unbiased, truly random coin generates the choice between the two possible amplitude levels. An M-noise-bit system requires 2M such RTWs.",
            "Figure 3. Circuit-block illustration of the logic structure of the generic superposition synthesizer for instantaneous NBL (INBL). The RNS contains 2M independent RTW generators representing the M noise-bits. The Hilbert Space Synthesizer is an algorithm that is typically containing multiplications, additions and subtractions. The output signal Y(t) can represent a logic state with an exponentially large number of, O(N), classical bit values. For examples, see the text."
        ],
        "imgs": [
            "$2305.00984v2-Figure1-1.png",
            "$2305.00984v2-Figure2-1.png",
            "$2305.00984v2-Figure3-1.png"
        ]
    },
    {
        "id": "2305.00985",
        "abstract": "  Traffic forecasting is an important issue in intelligent traffic systems\n(ITS). Graph neural networks (GNNs) are effective deep learning models to\ncapture the complex spatio-temporal dependency of traffic data, achieving ideal\nprediction performance. In this paper, we propose attention-based graph neural\nODE (ASTGODE) that explicitly learns the dynamics of the traffic system, which\nmakes the prediction of our machine learning model more explainable. Our model\naggregates traffic patterns of different periods and has satisfactory\nperformance on two real-world traffic data sets. The results show that our\nmodel achieves the highest accuracy of the root mean square error metric among\nall the existing GNN models in our experiments.\n",
        "title": "Attention-based Spatial-Temporal Graph Neural ODE for Traffic Prediction",
        "texts": [
            "Figure 1: An example of the input and output traffic segments of our model is shown. The recent traffic segment is defined as the traffic conditions of the previous hour. The daily traffic segment is the traffic conditions of yesterday at the same time slot as the predicted traffic segment. Similarly, The weekly traffic segment is the traffic conditions of last week at the same time slot of the same day as the predicted traffic segment.",
            "Figure 2: The framework of the proposed attention-based spatial temporal graph Neural ODE is shown in this figure. We apply different ODE blocks to different input traffic segments, which are used to learn the traffic dynamics of different time intervals. A fully-connected fusion layer is applied to the aggregated features of three blocks and outputs the final aggregated features.",
            "Figure 3: The architecture of an individual neural ODE block is shown. We will compute the spatial attention scores and temporal attention scores based on the input traffic features. Combined with exact graph connectivity, we perform diffusion graph convolution to derive the traffic features of the next time step.",
            "Figure 4: Prediction error comparison of different neural ODE blocks and our purposed model. We used RMSE to compare the performance of using different traffic features. We observed that weekly period segment was useful for long-term future prediction and recent traffic segment was beneficial for short-term future prediction. The performance of our model showed the effectiveness of the fusion layer to achieve higher performance in our model.",
            "Figure 5: The effect of the adjoint method on training stability is shown. We compared the error evolution over the training process under different training methods. We observed that using adjoint training slightly reduced the stability of the model training. However, it will not affect the final model performance if we train the model with enough epochs.",
            "Table 1: Traffic speed prediction performance of different models on PeMS-BAY data set",
            "Table 2: Traffic flow prediction performance of different models on PeMS04 data set",
            "Table 3: Effect of adjoint training on prediction error."
        ],
        "imgs": [
            "$2305.00985v1-Figure1-1.png",
            "$2305.00985v1-Figure2-1.png",
            "$2305.00985v1-Figure3-1.png",
            "$2305.00985v1-Figure4-1.png",
            "$2305.00985v1-Figure5-1.png",
            "$2305.00985v1-Table1-1.png",
            "$2305.00985v1-Table2-1.png",
            "$2305.00985v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00986",
        "abstract": "  In most retail stores, the number of days since initial processing is used as\na proxy for estimating the freshness of perishable foods or freshness is\nassessed manually by an employee. While the former method can lead to wastage,\nas some fresh foods might get disposed after a fixed number of days, the latter\ncan be time-consuming, expensive and impractical at scale. This project aims to\npropose a Machine Learning (ML) based approach that evaluates freshness of food\nbased on live data. For the current scope, it only considers meat as a the\nsubject of analysis and attempts to classify pieces of meat as fresh,\nhalf-fresh or spoiled. Finally the model achieved an accuracy of above 90% and\nrelatively high performance in terms of the cost of misclassification. It is\nexpected that the technology will contribute to the optimization of the\nclient's business operation, reducing the risk of selling defective or rotten\nproducts that can entail serious monetary, non-monetary and health-based\nconsequences while also achieving higher corporate value as a sustainable\ncompany by reducing food wastage through timely sales and disposal.\n",
        "title": "Meat Freshness Prediction",
        "texts": [
            "Figure 1. Sample Image per Class",
            "Figure 10. Matrix of MisClassification Cost(MCC)",
            "Figure 12. Example of Lime Interpretations for images that were misclassified",
            "Figure 2. Number of Images per Class",
            "Figure 3. Pixel Value Distribution for Images of Fresh Meat. Pixel value from darker (0) to lighter (255).",
            "Figure 4. Pixel Value Distribution for Images of Half-Fresh Meat. Pixel value from darker (0) to lighter (255).",
            "Figure 5. Pixel Value Distribution for Images of Spoiled Meat. Pixel value from darker (0) to lighter (255).",
            "Figure 6. Sample Image after Transformation",
            "Figure 7. Sample Image and Prediction",
            "Figure 8. Confusion Matrix of 18FT",
            "Figure 9. Confusion Matrix of 50FE",
            "Table 2. MCC of Each Actual|Pred Combination",
            "Table 4. ResNet Model Performance FE: Feature Extraction, FT: Fine-tuning",
            "Table 6. UNet and DenseNet Hyperparameters",
            "Table 7. UNet with Dense Net Model Performance",
            "Table 8. Evaluation on MCC FE: Feature Extraction, FT: Fine-tuning"
        ],
        "imgs": [
            "$2305.00986v1-Figure1-1.png",
            "$2305.00986v1-Figure10-1.png",
            "$2305.00986v1-Figure12-1.png",
            "$2305.00986v1-Figure2-1.png",
            "$2305.00986v1-Figure3-1.png",
            "$2305.00986v1-Figure4-1.png",
            "$2305.00986v1-Figure5-1.png",
            "$2305.00986v1-Figure6-1.png",
            "$2305.00986v1-Figure7-1.png",
            "$2305.00986v1-Figure8-1.png",
            "$2305.00986v1-Figure9-1.png",
            "$2305.00986v1-Table2-1.png",
            "$2305.00986v1-Table4-1.png",
            "$2305.00986v1-Table6-1.png",
            "$2305.00986v1-Table7-1.png",
            "$2305.00986v1-Table8-1.png"
        ]
    },
    {
        "id": "2305.00987",
        "abstract": "  Training machine learning models requires large datasets. However,\ncollecting, curating, and operating large and complex sets of real world data\nposes problems of costs, ethical and legal issues, and data availability. Here\nwe propose a novel algorithm to generate large artificial datasets to train\nmachine learning models in conditions of extreme scarcity of real world data.\nThe algorithm is based on a genetic algorithm, which mutates randomly generated\ndatasets subsequently used for training a neural network. After training, the\nperformance of the neural network on a batch of real world data is considered a\nsurrogate for the fitness of the generated dataset used for its training. As\nselection pressure is applied to the population of generated datasets, unfit\nindividuals are discarded, and the fitness of the fittest individuals increases\nthrough generations. The performance of the data generation algorithm was\nmeasured on the Iris dataset and on the Breast Cancer Wisconsin diagnostic\ndataset. In conditions of real world data abundance, mean accuracy of machine\nlearning models trained on generated data was comparable to mean accuracy of\nmodels trained on real world data (0.956 in both cases on the Iris dataset, p =\n0.6996, and 0.9377 versus 0.9472 on the Breast Cancer dataset, p = 0.1189). In\nconditions of simulated extreme scarcity of real world data, mean accuracy of\nmachine learning models trained on generated data was significantly higher than\nmean accuracy of comparable models trained on scarce real world data (0.9533\nversus 0.9067 on the Iris dataset, p < 0.0001, and 0.8692 versus 0.7701 on the\nBreast Cancer dataset, p = 0.0091). In conclusion, this novel algorithm can\ngenerate large artificial datasets to train machine learning models, in\nconditions of extreme scarcity of real world data, or when cost or data\nsensitivity prevent the collection of large real world datasets.\n",
        "title": "A novel algorithm can generate data to train machine learning models in\n  conditions of extreme scarcity of real world data",
        "texts": [
            "Figure 3: Distribution plot of fit generated dataset and real world dataset – Iris dataset",
            "Figure 4: Evolution of mean squared error during the data generation process",
            "Table 1A: Performance of the algorithm on the Iris dataset – abundance of real world data",
            "Table 2A: Performance of the algorithm on the Iris dataset – scarcity of real world data",
            "Table 3: Distribution statistics of fit generated dataset and real world dataset – Iris dataset"
        ],
        "imgs": [
            "$2305.00987v1-Figure3-1.png",
            "$2305.00987v1-Figure4-1.png",
            "$2305.00987v1-Table1-1.png",
            "$2305.00987v1-Table2-1.png",
            "$2305.00987v1-Table3-1.png"
        ]
    },
    {
        "id": "2305.00988",
        "abstract": "  Developments in the stability of modern spectrographs have led to extremely\nprecise instrumental radial velocity (RV) measurements. For most stars, the\ndetection limit of planetary companions with these instruments is expected to\nbe dominated by astrophysical noise sources such as starspots. Correlated\nsignals caused by rotationally-modulated starspots can obscure or mimic the\nDoppler shifts induced by even the closest, most massive planets. This is\nespecially true for young, magnetically active stars where stellar activity can\ncause fluctuation amplitudes of $\\gtrsim$0.1 mag in brightness and $\\gtrsim$100\nm s$^{-1}$ in RV semi-amplitudes. Techniques that can mitigate these effects\nand increase our sensitivity to young planets are critical to improving our\nunderstanding of the evolution of planetary systems. Gaussian processes (GPs)\nhave been successfully employed to model and constrain activity signals in\nindividual cases. However, a principled approach of this technique,\nspecifically for the joint modeling of photometry and RVs, has not yet been\ndeveloped. In this work, we present a GP framework to simultaneously model\nstellar activity signals in photometry and RVs that can be used to investigate\nthe relationship between both time series. Our method, inspired by the\n$\\textit{FF}^\\prime$ framework of (Aigrain et al. 2012), models spot-driven\nactivity signals as the linear combinations of two independent latent GPs and\ntheir time derivatives. We also simulate time series affected by starspots by\nextending the $\\texttt{starry}$ software (Luger et al. 2019) to incorporate\ntime evolution of stellar features. Using these synthetic datasets, we show\nthat our method can predict spot-driven RV variations with greater accuracy\nthan other GP approaches.\n",
        "title": "Joint Modeling of Radial Velocities and Photometry with a Gaussian\n  Process Framework",
        "texts": [
            "Figure 1. Synthetic photometric (top) and RV (bottom) observations generated using starry for a stellar surface map with P∗ = 11 days (veq = 4.6 km s−1), i∗ = 86.5°, Ψ∗ = 6.0°, and lmax = 20°. 50 spots each with a decay rate of τ = 0.05 days−1 and randomly distributed in longitude, latitude, contrast, radius, and time are placed on the surface of the map. Data mimic one quarter from the Kepler space telescope with a 90-day baseline and 30 minute observational cadence. RV data are generated at the same cadence as the photometry, but this high sampling is not expected or required for the GP framework introduced in this work. Random scatter with an amplitude of 0.25 ppt for the LC and 20 m s−1 for the RVs are injected to the true data (blue line), approximating uncertainties from both instrumental and astrophysical sources in order to simulate realistic, noisy observations of active stars for our tests (black dots).",
            "Figure 10. The same application of our two independent latent GP framework as in Figure 3 on the fiducial synthetic dataset using an SE kernel function.",
            "Figure 2. A representative covariance block matrix for our framework using a Matérn–5/2 Kernel for a synthetic dataset of 1000 flux observations and 500 RV observations. The top left element is the covariance between flux observations (Equation 13), the off-diagonal elements are the covariances between flux and RV observations (Equation B5a and Equation B5b), and the bottom right diagonal element is the covariance of the RV observations (Equation B5c).",
            "Figure 3. Application of the two independent latent GP framework using a quasi-periodic kernel on starry simulated photometric (top) and RV (bottom) observations. The synthetic data used here is a subset of the fiducial dataset shown in Figure 1 with different time baselines for each time series. All photometric data points with random noise added (top, black points) are used in the GP regression to simulate true photometric observations. The observational window overlapping between the photometry and the RVs is displayed as a shaded orange region in the top panel. The RV dataset is also shown (bottom, black points) but only 20 RV points (bottom, yellow stars) are used in the GP model regression. These 20 observations are randomly sampled to mimic realistic ground-based observation cadence. The best-fit GP model is shown in solid blue and the the 1σ variance in shaded blue. The model performs well at predicting where the data lie even in gaps of coverage.",
            "Figure 4. RMS distributions calculated from predicted models using parameter posteriors for each of the GP approaches. The FF ′, one, serial, one latent, and two latent GP frameworks are shown in orange, blue, green, yellow, and purple, respectively. A solid black line denotes the injected 20 m s−1 noise floor. The median RMS values for the one and serial GP models are similar (RMS ≈31 m s−1), suggesting that additional photometric information does not necessarily increase the predictive power of a GP. The one latent GP framework performs, on average, the worst of the five models (RMS = 32.9 m s−1). Under these ideal synchronous observational conditions, the FF ′ model outperforms the one, serial, and one latent GP models (RMS 28.5 m s−1). Our two latent GP framework performs the best, with a median RMS value of 25.6 m s−1. Using the same amount of information as the FF ′, serial, and one latent GP frameworks, our two latent GP model decreases the difference to the synthetic noise floor by approximately a factor of 2 as compared to other models.",
            "Figure 5. Mean and 1σ highest density intervals of the predicted posterior models for each of the five approaches. The photometric and RV times series used (black points) are the same as in Figure 3. The colors for each framework are the same as in Figure 4. All three model fits on the photometric data (serial, one latent, and two latent) are shown but cannot be seen as they are directly on top of each other. The one GP and serial GP models are very nearly on top of each other. The one latent GP prediction appears to have a slight phase shift from the RV points. The FF ′ prediction has more high frequency variations, which are likely due to numerical approximations and interpolation schemes adopted to calculate the flux gradient. The two latent GP approach performs the best at capturing the quasi-periodic structure in the RV curve.",
            "Figure 6. RMS distributions for predictions of each GP approach on the extended fiducial dataset including asynchronous RVs. The colors correspond to the same models as in Figure 4. Model performances are consistent with previous synchronous tests. This suggests that the different approaches utilize the same activity information content from photometry in both instances of simultaneous and non-simultaneous RV coverage. That the two latent framework performs the best in this test supports its ability to best leverage information from asynchronous ancillary photometry.",
            "Figure 7. Mean and 1σ highest density intervals of the predicted posterior models for each of the four GP approaches on the extended fiducial dataset including asynchronous RVs. Colors and symbols are the same as in Figure 5. Predictions for each model behave similarly in the synchronous RV and photometry time window. No data is plotted in the gap between RV observations but model predictions are presented. Notably, both the one latent and two latent predicted structure are similar to the actual behavior of the data (see Figure 1).",
            "Figure 8. Mean prediction of the joint two latent GP stellar activity and Keplerian model. The photometric and RV times series displayed (black points and yellow stars in top two panels, respectively) are the same as in Figure 3. The joint model and accompanying residuals are shown in blue in the second and third panels. The individual stellar activity (purple) and the Keplerian (pink) models are plotted in the fourth and fifth panels, respectively. The training RVs, with only injected noise and individual activity and planetary components are also displayed as yellow stars. The model is able to predict the variations of the combined RV time series while simultaneously separating the two individual components.",
            "Figure 9. The same application of our two independent latent GP framework as in Figure 3 on the fiducial synthetic dataset using a Matérn-5/2 kernel function.",
            "Table 1. The injected Keplerian orbital parameters, the priors imposed during the sampling for each parameter, and the median values and ±1σ HDI of each recovered posterior."
        ],
        "imgs": [
            "$2305.00988v1-Figure1-1.png",
            "$2305.00988v1-Figure10-1.png",
            "$2305.00988v1-Figure2-1.png",
            "$2305.00988v1-Figure3-1.png",
            "$2305.00988v1-Figure4-1.png",
            "$2305.00988v1-Figure5-1.png",
            "$2305.00988v1-Figure6-1.png",
            "$2305.00988v1-Figure7-1.png",
            "$2305.00988v1-Figure8-1.png",
            "$2305.00988v1-Figure9-1.png",
            "$2305.00988v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00990",
        "abstract": "  We study the effects of quenched disorder on electrons in a 3D nodal-line\nsemimetal. Disorder leads to significant renormalisations of the quasiparticle\nproperties due to ultraviolet processes, i.e., processes of scattering in a\nlarge band of momenta, of the width exceeding the inverse mean free path. As a\nresult, observables such as the density of states and conductivity exhibit\nsingular behaviour in a broad range of disorder strengths, excluding a small\nvicinity of the singular point. We find that, for example, the density of\nquasiparticle states diverges as a function of the disorder strength $g$ as\n$\\rho(g,E)\\propto |g_c(E)-g|^{-2}|E|$ for $g$ smaller than the critical value\n$g_c(E)$ and crosses over to a constant for $g$ very close to $g_c(E)$, where\n$E$ is the quasiparticle energy. For certain disorder symmetries, a 3D\ndisordered nodal-line semimetal can be mapped to a 2D metal with attractive\ninteractions. The described disorder-driven instabilities in such a nodal-line\nsemimetal are mapped to Cooper and exciton-condensation instabilities in a 2D\nmetal. For other disorder symmetries, the respective instabilities are similar\nbut not exactly dual. We discuss experimental conditions favourable for the\nobservation of the described effects.\n",
        "title": "BCS-like disorder-driven instabilities and ultraviolet effects in\n  nodal-line semimetals",
        "texts": [
            "Figure 4: The hierarchy of momenta near the nodal line. pF is the Fermi momentum measured from the nodal line. The UV processes come from the momenta between pF and K and lead to a significant renormalisation of the quasiparticle properties in the layer of momenta of the width `−1 around the Fermi surface. Quasiparticles in this layer of momenta can be described by low-energy theories (kinetic equation, nonlinear sigma-models, Fermi-liquid theory, etc.), which use the UV-renormalised quasiparticle parameters as input.",
            "Figure 5: Diagrams for the renormalisation of the properties of low-energy quasiparticles. a) The “Cooper channel” of disorder scattering, which corresponds to the process in Fig. 3b. b) The “exciton instability channel” corresponding to the process in Fig. 3c. c-d) The dominant contributions to the self-energy from the respective scattering channels.",
            "Figure 6: Diagrams for the renormalisation of the density of states. a) The renormalised density of states. b) The quasiparticle self-energy. c) The renormalisation of the density-of-states vertex by disorder (the bare vertex is given by ρ0 = 1 in momentum representation). Integration in diagrams b and c is carried out with respect to the UV momenta. The renormalisation of the DoS vertex is given by the same constant λ as the renormalisation of the energy term in the quasiparticle Green’s function.",
            "Figure 7: The correspondence between the diagrammatic elements of an interacting disorder-free system and an equivalent higher-dimensional disordered non-interacting system [33]. The interacting system is described by means of the Matsubara diagrammatic technique. The disordered non-interacting system is described by the disorderaveraging diagrammatic technique [49] for particles with a (pseudo-)spin degree of freedom, which corresponds to the Pauli matrices σx and σz. ξp is the quasiparticle dispersion in the interacting system; ω is the Matsubara frequency; k is the momentum in the extra dimension of the disordered system."
        ],
        "imgs": [
            "$2305.00990v1-Figure4-1.png",
            "$2305.00990v1-Figure5-1.png",
            "$2305.00990v1-Figure6-1.png",
            "$2305.00990v1-Figure7-1.png"
        ]
    },
    {
        "id": "2305.00992",
        "abstract": "  In the coming years, Sunyaev-Zel'dovich (SZ) measurements can dramatically\nimprove our understanding of the Intergalactic Medium (IGM) and the role of\nfeedback processes on galaxy formation, allowing us to calibrate important\nastrophysical systematics in cosmological constraints from weak lensing galaxy\nclustering surveys. However, the signal is only measured in a two-dimensional\nprojection, and its correct interpretation relies on understanding the\nconnection between observable quantities and the underlying intrinsic\nproperties of the gas, in addition to the relation between the gas and the\nunderlying matter distribution. One way to address these challenges is through\nthe use of hydrodynamical simulations such as the high-resolution, large-volume\nMillenniumTNG suite. We find that measurements of the optical depth, $\\tau$,\nand the Compton-y parameter, $Y$, receive large line-of-sight contributions\nwhich can be removed effectively by applying a Compensated Aperture Photometry\n(CAP) filter. In contrast with other $\\tau$ probes (e.g., X-rays and Fast Radio\nBursts), the kSZ-inferred $\\tau$ receives most of its signal from a confined\ncylindrical region around the halo due to the velocity decorrelation along the\nline-of-sight. Additionally, we perform fits to the $Y-M$ and $\\tau-M$ scaling\nrelations and report best-fit parameters adopting the smoothly broken power law\n(SBPL) formalism. We note that subgrid physics modeling can broaden the error\nbar on these by 30\\% for intermediate-mass halos ($\\sim$$10^{13} \\, {\\rm\nM}_{\\odot}$). The scatter of the scaling relations can be captured by an\nintrinsic dependence on concentration, and an extrinsic dependence on tidal\nshear. Finally, we comment on the effect of using galaxies rather than halos in\nreal observations, which can bias the inferred SZ profiles by $\\sim$20\\% for\n$L_\\ast$-galaxies.\n",
        "title": "Interpreting Sunyaev-Zel'dovich observations with MillenniumTNG: Mass\n  and environment scaling relations",
        "texts": [
            "Figure 1.Mean scaling relation between the integratedCompton-y parameter, 𝑌 , and halo mass, 𝑀200c, at 𝑧 = 0.5. For the lowest-mass halos, the intrinsic 𝑌 (i.e. electron pressure enclosed in a sphere of radius 𝑅200c around the halo center) differs by an order of magnitude from the observed 𝑌 (computed by integrating the signal in a cylinder through the box) due to the contribution of random uncorrelated structures along the line of sight. Luckily, we largely eliminate this spurious effect when we adopt a Compensated Aperture Photometry (CAP) filter, and are left with the combined contribution of the oneand two-halo term (i.e. the intrinsic signal and the signal coming from nearby correlated structure). Alternatively, we can subtract the random contribution by measuring the SZ effect in random parts of the sky (silver dashed curve) and subtracting that from the signal. While this yields an excellent agreement with the CAP approach for intermediate and massive halos, we see that it overpredicts the random contribution for small-mass halos, as the selection of low-mass halos preferentially selects regions of lower density and thus, weaker SZ.",
            "Figure 2. Mean scaling relation between the optical depth, 𝜏, defined in several different ways, and halo mass,𝑀200c, at redshift 𝑧 = 0.5. The intrinsic 𝜏 (i.e. optical depth enclosed in a sphere around the halo center) is most akin to the X-ray-inferred optical depth of a cluster (since the X-ray signal scales as 𝑛2𝑒 and has aweak dependence on temperature). The cylindrical 𝜏 is measured in e.g., FRB analysis, and 𝜏kSZ,cyl is what we infer from kSZ measurements. Due to the decorrelation of velocities along the line of sight, 𝜏kSZ is localized to a cylinder around the halo of interest of length equal to several tens of Mpc and is thus mostly made up of the 1-halo and 2-halo combined signal. At high halo masses, the signal is dominated by the halo of interest and almost insensitive to the halo surroundings.",
            "Figure 3. Smoothly broken power law (SBPL) fits for the 𝑌 − 𝑀 and 𝜏 − 𝑀 relations (see Section 3.2.2). The left panels show the scatter plot for the intrinsic quantities, whereas the right panels for the observed ones, asmeasured in a cylinder through the boxwith a CAPfilter. The data curves with error bars are computed using the geometric mean and standard deviation in log-space. We see clear deviations from self-similarity on the left for halos below 𝑀200c . 1014M , for which feedback processes dominate the baryon distribution within the halo. This break is somewhat obscured on the right where structures along the line of sight add extra noise. Note that here we define the kSZ-inferred optical depth as the kSZ signal divided by the line-of-sight velocity rather than by applying the inverse-variance weighting used in the rest of the paper (see discussion in Section 3.2.2. The best-fit parameters are shown in Table 1.",
            "Figure 4. Dependence of the observed SZ scaling relations on concentration and shear at 𝑧 = 0.5, shown as the ratio of the scaling relation to its mean. The band denotes the standard deviation. The dashed and dotted curves correspond to the high and low values of either the shear or concentration. We see a mild dependence on the concentration (defined using MTNG740-DM): in the case of high-mass halos, for which gravity dominates over feedback, concentration correlates positively with the strength of the SZ signal. This trend reverses at low halo masses, for which high concentration implies more active black hole accretion and thus more violent expulsion of the baryons. The effect of shear on the scaling relations is two-fold: on one hand, larger values of shear correspond to more clustered regions and thus a stronger SZ signal from the two-halo term; on the other, anisotropic pulling from massive clusters leads to an asymmetric velocity distribution within and outside the halo, which affects the kSZ-inferred optical depth (but not as much for velocityindependent quantities such as 𝑌 , shown in the middle panel).",
            "Figure 5. Scaling relations of the optical depth (top panel) and the integrated Compton-y signal (bottom) for the four CAMELS ‘extreme feedback’ simulations at 𝑧 ≈ 0.5. The quantities are measured in a cylinder and a CAP filter is applied. The extreme SN box shows largest differences from the fiducial at low masses, while the extreme AGN deviates the most at high masses, as expected. The no-feedback box follows an almost perfect power law, as the gas dynamics is dominated by gravity. We quantify the error due to the subgrid modeling at 30% for 𝑀200c ∼ 1013M and 15% for the highest-mass halos present in the CAMELS suite.",
            "Figure 6. Compensated Aperture Photometry (CAP) measurements of the kSZ signal at 𝑧 ≈ 0.5 for a stellar-mass selected sample of galaxies. The galaxies are split into three stellar mass bins (mimicking cuts in luminosity). We study separately the all-galaxies (solid) and the centrals-only (dashed) populations so as to quantify the effect of ‘miscentering.’Miscentering affects the lowest-mass population the most, changing the shape of the profile and amplitude relative to the centrals-only curve. The effect of miscentering on the middle bin, which is closest to the median stellar mass of galaxy surveys such as CMASS and DESI, is about 20%, warranting careful modeling of the effect when analyzing observations.",
            "Table 1. Best-fit values and jackknife errors for the smoothly broken power law (SBPL) model (see Section 3.2.2) at four distinct time epochs: 𝑧 = 0, 0.25, 0.5, and 1, fit to the observed (cylinder with a CAP filter) and intrinsic (sphere) SZ quantities, integrated Compton-y parameter (𝑌 ) and optical depth (𝜏), measured in the MTNG740 hydrodynamical simulation."
        ],
        "imgs": [
            "$2305.00992v1-Figure1-1.png",
            "$2305.00992v1-Figure2-1.png",
            "$2305.00992v1-Figure3-1.png",
            "$2305.00992v1-Figure4-1.png",
            "$2305.00992v1-Figure5-1.png",
            "$2305.00992v1-Figure6-1.png",
            "$2305.00992v1-Table1-1.png"
        ]
    },
    {
        "id": "2305.00993",
        "abstract": "  Dark matter subhaloes are key for the predictions of simulations of structure\nformation, but their existence frequently ends prematurely due to two technical\nissues, namely numerical disruption in N-body simulations and halo finders\nfailing to identify them. Here we focus on the second issue, using the\nphase-space friends-of-friends halo finder ROCKSTAR as a benchmark (though we\nexpect our results to translate to comparable codes). We confirm that the most\nprominent cause for losing track of subhaloes is tidal distortion rather than a\nlow number of particles. As a solution, we present a flexible post-processing\nalgorithm that tracks all subhalo particles over time, computes subhalo\npositions and masses based on those particles, and progressively removes\nstripped matter. If a subhalo is lost by the halo finder, this algorithm keeps\ntracking its so-called ghost until it has almost no particles left or has truly\nmerged with its host. We apply this technique to a large suite of N-body\nsimulations and restore lost subhaloes to the halo catalogues, which has a\ndramatic effect on key summary statistics of large-scale structure.\nSpecifically, the subhalo mass function increases by about 50% and the halo\ncorrelation function increases by a factor of two at small scales. While these\nquantitative results are somewhat specific to our algorithm, they demonstrate\nthat particle tracking is a promising way to reliably follow haloes and reduce\nthe need for orphan models. Our algorithm and augmented halo catalogues are\npublicly available.\n",
        "title": "Haunted haloes: tracking the ghosts of subhaloes lost by halo finders",
        "texts": [
            "Figure 3. Visualization of the merger tree of the largest halo in our test simulation, with ghosts highlighted in magenta. The trajectories reflect the distance from the main halo in comoving units, but they are arbitrarily cut off on the left at a small radius. Each track represents a halo that becomes a subhalo of the main halo, merges into it, or merges into one of its subhaloes. The colour of the lines indicates epochs when those haloes are hosts (gray), subhaloes (light blue), and ghosts (purple). Including ghosts not only adds more subhaloes but also changes the times when mergers occur (gray dots). Ghosts merge into the main across a wide range of radii (highlighted with magenta squares), sometimes even outside of R200m.",
            "Figure 4. Properties of subhaloes when they merge or are lost by Rockstar. The first four panels show the final properties of subhaloes (and thus the initial properties of ghosts), whereas the last two panels show the properties of ghosts when they are abandoned. We compare all ghosts in the WMAP7 sample (blue), only those where the subhalo contained at least N200m ≥ 2000 particles at infall (purple), and only those with Msub/Mhost < 0.1 at infall (green). We combine all simulations and redshifts because the differences between them do not change the overall picture. Top left: Subhaloes are lost at a wide range of particle numbers. The distribution strongly depends on the initial resolution, demonstrating that a low particle number is not the main reason for subhalo loss. Top centre: The typical mass loss experienced prior to becoming a ghost does not depend on resolution and peaks at about 40%, which reaffirms that sheer loss of particles cannot be the dominant factor. Top right: Subhaloes are much more likely to be lost near the host centre, but many of those cases are major mergers that have sunk quickly due to dynamical friction. Minor-merger subhaloes tend to get lost at intermediate radii. Bottom left: Peaks in the survival time at 1/2, 3/2, and 5/2 crossing times indicate losses near pericentre. However, the peaks significantly extend to later times (especially for minor mergers), indicating that losses can occur near apocentre following a pericentric passage. Bottom centre: The double-peaked distribution of final ghost particle counts corresponds to the two criteria for ending a ghost, namely that it has lost all but 10 particles (the majority of minor mergers) or that it has physically merged into the host centre (the typical outcome of major mergers). Bottom right: The double-peaked structure is also visible in the distribution of final ghost masses compared to subhalo mass at infall. The mass loss can reach arbitrarily small fractions, limited only by the resolution of the simulation.",
            "Figure 5. Ratio of tracer to bound masses for low-mass (left) and high-mass (right) subhaloes in the WMAP7 sample at z = 0. While the distribution has large tails, the 68% and 95% intervals (shaded areas) are relatively tight and overlap with unity. High-threshold definitions such as M500c (red) lead to better agreement than low thresholds such as M200m (blue) because they include mostly particles that are unambiguously bound. The peak of the M500c histogram in the left panel is cut off, highlighting the striking agreement (1-σ range of just over 10%).",
            "Figure 6. Mass evolution before and after infall (top) and logarithmic mass loss rate per dynamical time (bottom) of subhaloes and ghosts according to the bound-only and tracer definitions (using M200m, but other definitions behave similarly). The light blue curves show the bound mass as computed by Rockstar, and the dark blue lines show the tracer mass for all haloes (solid), non-ghosts (dot-dashed), and ghosts (dashed). The shaded areas show the 68% contours around the bound mass and tracer mass for all subhaloes (the latter only in the top panel to avoid crowding the figure). The trajectories become more and more biased towards higher-mass haloes because haloes near the resolution limit successively fall out of the sample. After a few dynamical times, the sample becomes dominated by ghosts. Top panel: Tracer and bound masses evolve similarly, with the tracer mass capturing slightly more particles on average. Bottom panel: The mass loss rate exhibits extremely large scatter, highlighting that stripping sensitively depends on the individual orbits of subhaloes. The median mass loss rate varies strongly and is highest on average after one crossing time (at first apocentre).",
            "Figure 7. Cumulative subhalo mass functions per host for the co-added simulations in the WMAP7 sample at z = 0. We select host haloes with 3.4 × 1013 < Mvir < 1.4 × 1014h−1 M and sufficient numbers of particles to resolve subhaloes of a given mass ratio µ with at least 25 (purple) or 200 particles (blue). The latter requirement is sufficient for the mass functions to converge between simulations. Adding ghosts (solid lines) significantly increases the abundance of subhaloes. We exclude backsplash haloes by limiting the radius to Rvir or fractions thereof, and we excise ghosts in the innermost 5% of Rvir to avoid a dependence of the SHMF on the algorithm for ghost termination. The solid gray line in the left panel corresponds to the purple dashed line but using bound masses according to Rockstar instead of tracer masses; the differences are negligible.",
            "Figure 8. Correlation function for halo samples binned by peak mass (top panel) and approximate stellar mass (third panel) at z = 0, computing without (dashed) and with ghosts (solid). The smaller panels show the fractional increase in ξ due to ghosts. The lowest mass bin (purple) is resolved only in the smaller simulation boxes. While the absolute level of correlation depends on halo mass, the increase due to ghosts is roughly mass-independent and reaches a factor of two at small radii. In the bottom panels, halo masses were approximately converted to stellar masses using the UniverseMachine model (note that M∗ is given in units of M and halo masses in h−1 M ). The trends with stellar mass are similar to those with halo mass.",
            "Figure 9. Same as Fig. 1, but for the largest lost subhalo lost in our test simulation. For clarity, we omit the ghost particles’ velocity vectors and reduce the point size. The binding energy (point colour) refers to an arbitrary scale between its minimum and maximum in each panel. The halo finder and Sparta roughly agree on the subhalo properties at infall (z = 2, panel 1), but one snapshot later, Rockstar considers the halo to have merged. The reason is the strong tidal disruption experienced by the subhalo, which manifests in an irregular particle distribution (panel 2). Thereafter, the ghost is orbiting with a fairly short period and loses significant material (panel 3). Even after a number of orbits, the ghost still contains about 104 particles and has appreciable velocity with respect to the host centre (panels 4 and 5). Only at z = 0.5 does Sparta decide that the ghost has truly merged because its relative velocity has become negligible."
        ],
        "imgs": [
            "$2305.00993v1-Figure3-1.png",
            "$2305.00993v1-Figure4-1.png",
            "$2305.00993v1-Figure5-1.png",
            "$2305.00993v1-Figure6-1.png",
            "$2305.00993v1-Figure7-1.png",
            "$2305.00993v1-Figure8-1.png",
            "$2305.00993v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00995",
        "abstract": "  A theory of neural networks (NNs) built upon collective variables would\nprovide scientists with the tools to better understand the learning process at\nevery stage. In this work, we introduce two such variables, the entropy and the\ntrace of the empirical neural tangent kernel (NTK) built on the training data\npassed to the model. We empirically analyze the NN performance in the context\nof these variables and find that there exists correlation between the starting\nentropy, the trace of the NTK, and the generalization of the model computed\nafter training is complete. This framework is then applied to the problem of\noptimal data selection for the training of NNs. To this end, random network\ndistillation (RND) is used as a means of selecting training data which is then\ncompared with random selection of data. It is shown that not only does RND\nselect data-sets capable of outperforming random selection, but that the\ncollective variables associated with the RND data-sets are larger than those of\nthe randomly selected sets. The results of this investigation provide a stable\nground from which the selection of data for NN training can be driven by this\nphenomenological framework.\n",
        "title": "Towards a Phenomenological Understanding of Neural Networks: Data",
        "texts": [
            "Figure 1. Workflow of RND. A data point, pi, is passed into the target network, F and the predictor network G, in order to construct the representations F(pi) and G(pi). A distance, d is then computed using the metric D(F(pi),G(pi)). If d > δ, the point, pi, will be added to the target set T and the predictor model re-trained on the full set T . If the d ≤ δ, it is assumed that a similar point already exists in T and is therefore discarded. In our notation, 〈T ,F(T )〉 denotes the function set with domain T and image F(T ).",
            "Figure 2. Figures describing the relationship between the entropy, NTK trace, and minimum test loss. Colours in the first row correspond to the minimum test loss achieved during training where a darker colour corresponds to a smaller loss. Colours in the remaining rows correspond to the size of the data-set used in the NN training with darker colour corresponding to smaller data-sets.",
            "Figure 3. Correlation matrix of several variables in model training. Colours correspond to the numbers in the boxes.",
            "Figure 4. Minimum test loss and final test loss of models trained on data-sets chosen by RND and randomly for several data-set sizes. Size of the error bars corresponds to the ensemble operation over models wherein the experiment was performed 20 times for a single data-set size.",
            "Figure 5. Starting von Neumann entropy and trace of the NTK matrix constructed on data-sets of different sizes produced with both random and RND approaches. Size of the error bars corresponds to the ensembling described in the text.",
            "Table 1. Table outlining the problems chosen for the experiments. In the case of MNIST, 10000 of the 60000 total data points were selected at random before the experiments took place.",
            "Table 2. Parameters used in the study of entropy and NTK trace with respect to model training. Network architecture nomencalture is defined in Table A1. ReLU activation has been used between hidden layers and an ADAM optimizer in the training."
        ],
        "imgs": [
            "$2305.00995v1-Figure1-1.png",
            "$2305.00995v1-Figure2-1.png",
            "$2305.00995v1-Figure3-1.png",
            "$2305.00995v1-Figure4-1.png",
            "$2305.00995v1-Figure5-1.png",
            "$2305.00995v1-Table1-1.png",
            "$2305.00995v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.00997",
        "abstract": "  Analytically continuing the von Neumann entropy from R\\'enyi entropies is a\nchallenging task in quantum field theory. While the $n$-th R\\'enyi entropy can\nbe computed using the replica method in the path integral representation of\nquantum field theory, the analytic continuation can only be achieved for some\nsimple systems on a case-by-case basis. In this work, we propose a general\nframework to tackle this problem using classical and quantum neural networks\nwith supervised learning. We begin by studying several examples with known von\nNeumann entropy, where the input data is generated by representing $\\text{Tr}\n\\rho_A^n$ with a generating function. We adopt KerasTuner to determine the\noptimal network architecture and hyperparameters with limited data. In\naddition, we frame a similar problem in terms of quantum machine learning\nmodels, where the expressivity of the quantum models for the entanglement\nentropy as a partial Fourier series is established. Our proposed methods can\naccurately predict the von Neumann and R\\'enyi entropies numerically,\nhighlighting the potential of deep learning techniques for solving problems in\nquantum information theory.\n",
        "title": "The Expressivity of Classical and Quantum Neural Networks on\n  Entanglement Entropy",
        "texts": [
            "Figure 1: An architecture of 3 densely connected layers, where each layer has 8 units. The final output layer is a single Dense unit with a unique output corresponding to the von Neumann entropy.",
            "Figure 10: Left: The MSE loss function as a function of epochs. The minimum loss close to 10−8 is achieved at epoch 696 for this instance. Right: The relative errors between the model predictions and targets for the two test datasets, where we have achieved high accuracy with relative errors . 0.03%.",
            "Figure 11: We plot the predictions from the model with the analytic von Neumann entropy computed by (3.15) for the two test datasets. We also include the approximate entropy by summing over k = 50 terms in the generating function.",
            "Figure 12: The distribution of the two test datasets for the case of two intervals in the decompactification limit, where we plot density as a function of the von Neumann entropy computed by (3.19) with varying η.",
            "Figure 13: Left: The MSE loss function as a function of epochs. The minimum loss at around 10−7 is achieved at epoch 132 for this instance. Right: The relative errors between the model predictions and targets for the two test datasets, where we have achieved high accuracy with relative errors . 0.4%.",
            "Figure 14: We plot the predictions from the model with the analytic von Neumann entropy computed by (3.19) for the two test datasets. We also include the approximate entropy by summing over k = 50 terms in the generating function.",
            "Figure 15: Data preparation process for the sequential models. A total of N datasets are separated into two parts: the p datasets are for the initial train-validation-test split, while the q datasets are treated purely as test datasets. The zoomed-in figure on the right hand side illustrates how a single example sequence is generated, where we have used a fixed number of past steps ` = 5. Note that for the additional q test datasets, a total of (steps− `)× q = 405000 sequences are generated.",
            "Figure 16: Top: The loss function for the best 3 models as a function of epochs. We monitor the loss function with EarlyStopping, where the epochs of minimum losses at around 10−8 for different models are specified in the parentheses of the legend. Bottom: The density plots as a function of relative errors for the two test datasets. The relative errors for the p test datasets are concentrated at around 1%; while for the additional q test datasets, they are concentrated at around 2.5% with a very small ratio of outliers.",
            "Figure 17: Top: The loss function for the best 4 models as functions of epochs. We monitor the loss function with EarlyStopping. Bottom: The density plot as a function of relative errors for the two test datasets. The relative errors for the p test datasets are well within . 1.5%; while for the additional q test datasets, they are well within . 2%.",
            "Figure 18: Quantum neural networks with repeated data-encoding circuit blocks S(x) (whose gates are of the form g(x) = e−ixH) and trainable circuit blocks W (i). The data-encoding circuit blocks determine the available frequency spectrum for ~ω, while the remainder determines the Fourier coefficients c~ω.",
            "Figure 19: Gibbs phenomenon for the Fourier series near the end point for w → 1. We take the single interval example where the yellow curve represents the generating function as a Taylor series, and the blue curve is the Fourier series approximation of the generating function.",
            "Figure 2: Flowchart illustrating the steps of KerasTuner with Bayesian optimization. Bayesian optimization is a method for finding the optimal set of designs and hyperparameters for a given dataset, by iteratively constructing a probabilistic model from a prior distribution for the objective function and using it to guide the search. Once the tuner search loop is complete, we extract the best model in the final training phase by including both the training and validation data.",
            "Figure 21: A random parallel quantum model for the single interval case. Top: the loss function achieves minimum loss at epoch 917. Bottom: a random initialization of the quantum model with r = 5 parallel repetitions of Pauli encoding gates that has achieved a good fit.",
            "Figure 22: A random serial quantum model trained with data samples to fit the target function of the two-interval system with a small cross-ratio. Top: the loss function achieves minimum loss at epoch 968. Bottom left: a random initialization of the serial quantum model of r = 6 sequential repetitions of Pauli encoding gates. Bottom right: the circles represent the 300 data samples of the two-interval Fourier series with x = 0.05, α = 0.1, and ε = 0.1 for (3.15). The red curve represents the quantum model after training.",
            "Figure 23: A random parallel quantum model for the two-interval case. Top: the loss function achieves minimum loss at epoch 818. Bottom: a random initialization of the quantum model with r = 5 parallel repetitions of Pauli encoding gates that has achieved a good fit.",
            "Figure 24: We have plotted the single interval example with L = 2 and ε = 0.1 for (3.2). Here the legends GN refer to the Fourier series of the generating function to degree N , by summing up to m = 10 in (5.6). GTaylor refers to the Taylor series form (2.9) of the generating function by summing up to k = 100.",
            "Figure 3: The distribution of the data for the case of a single interval, where we plot density as a function of the von Neumann entropy computed by (3.2) with varying `. The left plot represents the 10000 datasets for the train-validation-test split, while the right plot corresponds to the additional 10000 test datasets with a different physical parameter regime.",
            "Figure 4: Left: The MSE loss function as a function of epochs. We monitor the loss function with EarlyStopping, where the minimum loss is achieved at epoch 410 with loss ≈ 10−7 for this instance. Right: The density plot of relative errors between the model predictions and targets. Note that the blue color corresponds to the test datasets from the initial train-validation-test split, while the green color is for the additional test datasets. We can see clearly that for both datasets, we have achieved high accuracy with relative errors . 0.30%.",
            "Figure 5: We plot the predictions from the model with the analytic von Neumann entropy computed by (3.2) for the 1000 test datasets (left) from the training-validationtest split and the additional 10000 test datasets (right), with the same scale on both figures. The correct von Neumann entropy overlaps with the model’s predictions precisely. We have also included the approximate entropy by summing over k = 50 terms in the generating function.",
            "Figure 6: The distribution of the two test datasets for the case of a single interval at finite temperature and length, where we plot density as a function of the von Neumann entropy computed by (3.6) with varying β.",
            "Figure 7: Left: The MSE loss function as a function of epochs. The minimum loss close to 10−8 is achieved at epoch 86 for this instance. Right: The relative errors between the model predictions and targets for the two test datasets, where we have achieved high accuracy with relative errors . 0.6%.",
            "Figure 8: We plot the predictions from the model with the analytic von Neumann entropy computed by (3.6) for the two test datasets. Again, the approximate entropy by summing over k = 50 terms in the generating function is included.",
            "Figure 9: The distribution of the two test datasets for the case of two intervals at small cross-ratio, where we plot density as a function of the von Neumann entropy computed by (3.15) with varying x."
        ],
        "imgs": [
            "$2305.00997v1-Figure1-1.png",
            "$2305.00997v1-Figure10-1.png",
            "$2305.00997v1-Figure11-1.png",
            "$2305.00997v1-Figure12-1.png",
            "$2305.00997v1-Figure13-1.png",
            "$2305.00997v1-Figure14-1.png",
            "$2305.00997v1-Figure15-1.png",
            "$2305.00997v1-Figure16-1.png",
            "$2305.00997v1-Figure17-1.png",
            "$2305.00997v1-Figure18-1.png",
            "$2305.00997v1-Figure19-1.png",
            "$2305.00997v1-Figure2-1.png",
            "$2305.00997v1-Figure21-1.png",
            "$2305.00997v1-Figure22-1.png",
            "$2305.00997v1-Figure23-1.png",
            "$2305.00997v1-Figure24-1.png",
            "$2305.00997v1-Figure3-1.png",
            "$2305.00997v1-Figure4-1.png",
            "$2305.00997v1-Figure5-1.png",
            "$2305.00997v1-Figure6-1.png",
            "$2305.00997v1-Figure7-1.png",
            "$2305.00997v1-Figure8-1.png",
            "$2305.00997v1-Figure9-1.png"
        ]
    },
    {
        "id": "2305.00998",
        "abstract": "  Proximity zones of high-redshift quasars are unique probes of their central\nsupermassive black holes as well as the intergalactic medium in the last stages\nof reionization. We present 22 new measurements of proximity zones of quasars\nwith redshifts between 5.8 and 6.6, using the enlarged XQR-30 sample of\nhigh-resolution, high-SNR quasar spectra. The quasars in our sample have UV\nmagnitudes of $M_{1450}\\sim -27$ and black hole masses of\n$10^9$$\\unicode{x2013}$$10^{10}$ M$_\\odot$. Our inferred proximity zone sizes\nare 2$\\unicode{x2013}$7 physical Mpc, with a typical uncertainty of less than\n0.5 physical Mpc, which, for the first time, also includes uncertainty in the\nquasar continuum. We find that the correlation between proximity zone sizes and\nthe quasar redshift, luminosity, or black hole mass, indicates a large\ndiversity of quasar lifetimes. Two of our proximity zone sizes are\nexceptionally small. The spectrum of one of these quasars, with $z=6.02$,\ndisplays, unusually for this redshift, damping wing absorption without any\ndetectable metal lines, which could potentially originate from the IGM. The\nother quasar has a high-ionization absorber $\\sim$0.5 pMpc from the edge of the\nproximity zone. This work increases the number of proximity zone measurements\navailable in the last stages of cosmic reionization to 87. This data will lead\nto better constraints on quasar lifetimes and obscuration fractions at high\nredshift, which in turn will help probe the seed mass and formation redshift of\nsupermassive black holes.\n",
        "title": "New quasar proximity zone size measurements at $z\\sim 6$ using the\n  enlarged XQR-30 sample",
        "texts": [
            "Figure 2. Proximity zones of the quasars in our sample. The normalised flux obtained by dividing measured flux by continuum, is shown in black. Red curves show the smoothed spectra with shaded region showing the 1𝜎 uncertainty in the continuum. Black solid and dotted lines show the quasar location and the extent of proximity zones, respectively. The blue shaded regions show the 1𝜎 uncertainty on proximity zone sizes due to continuum uncertainties. Green shaded regions show redshift errors as the uncertainty on the location of the expected Ly𝛼 emission of the quasar.",
            "Figure 4. Proximity zone sizes as a function of quasar magnitude. Previous measurements are shown in green. The targeted sample of Eilers et al. (2020) is shown in blue. Our measurements are shown in black. The errors on our proximity zone sizes are due to both continuum and redshift uncertainties. The blue, grey and red curves are from our simulations for quasar ages of 104, 106 and 108 yr at a redshift of 5.95. Shaded regions show 68% scatter across 500 sightlines from our simulations. The black dotted line shows the best fit curve to a relatively homogeneous subset of quasars with 6 < 𝑧 < 6.2, except quasars from the targeted sample of Eilers et al. (2020).",
            "Figure 5. Evolution of proximity zone sizes. Older measurements are shown in green. The targeted sample of Eilers et al. (2020) is shown in blue. Our measurements are shown in black. Also shown are the simulated proximity zones for a quasar of magnitude −27 and age of 1 Myr across different redshifts. The shaded region shows 68% scatter across 500 sightlines in our simulation. The black dotted line shows the best fit curve 𝑅p ∝ (1+ 𝑧)−0.89 to our measurements and previous measurements excluding Eilers et al. (2020). For obtaining the best fit, only a relatively homogeneous subset of quasars, with −26.8 < 𝑀1450 < −27.2 was used.",
            "Figure 6. Proximity zone sizes as a function of supermassive black hole mass. Previous measurements for which black hole masses were available are shown in green and the targeted sample from Eilers et al. (2020) is shown in blue. Our measurements are shown in black. Our black hole masses are from Mazzucchelli et al. (in preparation). The typical error on the black hole masses is represented by the errorbar at the top right in red. All black hole masses are based on Mg II linewidths. The black dotted line shows the best fit curve to our measurements and previous measurements excluding Eilers et al. (2020). For obtaining the best fit, a relatively homogeneous subset of quasars with −26.8 < 𝑀1450 < −27.2 and 6.0 < 𝑧 < 6.2 was used. A power-law relationship was assumed between the quasar proximity zone size and logarithm of the black hole mass, as motivated in the text.",
            "Figure 7. Distance to the nearest metal absorber as a function of proximity zone size. High-ionised metal absorbers are shown as circles while low-ionised metal absorbers are shown as diamonds. Colours represent the redshift of the metal absorber. PSOJ108+08 is the only quasar in our sample with a metal-line absorber close to the edge of the proximity zone. We also highlight PSOJ158–14 on this figure; this quasar is discussed in greater detail in Figure 8.",
            "Figure 8. Top panel: Continuum-normalised spectrum of PSOJ158-14, for two continuum reconstruction methods, the log-PCA method (Chen et al. 2022) and the covariance matrix method (Greig et al. 2017a), shown in blue and orange, respectively. Shaded regions show the 1𝜎 spread around the median value. (We use the log-PCA method for all quasars in this work.) Middle panel: A simulated spectrum showing an IGM damping wing at 𝑧 = 6.14 for a quasar with magnitude −27 and age 1 Myr. Bottom panel: The ionised hydrogen fraction along the same simulated sightline. This reveals the neutral hydrogen regions that create the damping wing seen in the middle panel. At redshift 6.14, only one of 500 sightlines in our simulation shows this feature.",
            "Table 1: Properties of the 22 quasars studied in this paper. The columns show the serial number, quasar name, quasar redshift with the total 1𝜎 uncertainty, the emission line used for determining the quasar redshift, quasar absolute UV magnitude at 1450 Å, and references for the quasar redshift and magnitude.",
            "Table 2: Our proximity zone size measurements. Columns show the serial number, the name of the quasar, proximity zone size in proper Mpc with the continuum, redshift and total uncertainties. The minimum error on 𝑅p due to continuum uncertainties is the spatial resolution of the spectra, which is ∼ 0.01 pMpc. Total error is obtained by adding the continuum and redshift errors in quadrature."
        ],
        "imgs": [
            "$2305.00998v1-Figure2-1.png",
            "$2305.00998v1-Figure4-1.png",
            "$2305.00998v1-Figure5-1.png",
            "$2305.00998v1-Figure6-1.png",
            "$2305.00998v1-Figure7-1.png",
            "$2305.00998v1-Figure8-1.png",
            "$2305.00998v1-Table1-1.png",
            "$2305.00998v1-Table2-1.png"
        ]
    },
    {
        "id": "2305.01000",
        "abstract": "  From the thousands of known exoplanets, those that transit bright host stars\nprovide the greatest accessibility toward detailed system characterization. The\nfirst known such planets were generally discovered using the radial velocity\ntechnique, then later found to transit. HD 17156b is particularly notable among\nthese initial discoveries because it diverged from the typical hot Jupiter\npopulation, occupying a 21.2 day eccentric ($e = 0.68$) orbit, offering\npreliminary insights into the evolution of planets in extreme orbits. Here we\npresent new data for this system, including ground and space-based photometry,\nradial velocities, and speckle imaging, that further constrain the system\nproperties and stellar/planetary multiplicity. These data include photometry\nfrom the Transiting Exoplanet Survey Satellite (TESS) that cover five transits\nof the known planet. We show that the system does not harbor any additional\ngiant planets interior to 10 AU. The lack of stellar companions and the age of\nthe system indicate that the eccentricity of the known planet may have resulted\nfrom a previous planet-planet scattering event. We provide the results from\ndynamical simulations that suggest possible properties of an additional planet\nthat culminated in ejection from the system, leaving a legacy of the observed\nhigh eccentricity for HD 17156b.\n",
        "title": "Revised Properties and Dynamical History for the HD 17156 System",
        "texts": [
            "Figure 1. Comparison of the seasonal means of the d-a, d-c, and c-a differential magnitudes show that the observed variability is intrinsic to HD 17156.",
            "Figure 2. Nightly Strömgren (b + y)/2 band photometry of HD 17156 from 10 observing seasons from 2006-07 to 2016-17 (small circles), acquired with the T12 0.80m APT at Fairborn Observatory. The star is constant from nightto-night within most observing seasons to the limit of our precision. The seasonal mean magnitudes are plotted as the large filled circles and cover a range of 0.00618 mag with a standard deviation from the mean of the seasonal means of 0.00199 mag, indicating low-amplitude year-to-year variability in HD 17156. The seasonal means suggest a stellar cycle of around 10 years.",
            "Figure 3. The TESS 2-min PDC light curves (left), LS periodograms (center), and phase-folded light curves (right) from the variability analysis for HD 17156. Dates in the left panel are shown in Barycentric TESS Julian Date (BTJD). The variability analysis is performed separately on each TESS sector, which is ordered in time from top to bottom: Sectors 18, 19, 25, and 52. The mean out-of-transit photometric scatter over all sectors is 380 ppm. The red curve shows a sinusoidal fit to the most significant periodicity. The gray points in the left panel indicate data that were removed from the variability analysis, which includes data flagged as poor quality, 5σ outliers, and transits of HD 17156b. In the right panel, the gray points indicate all data included in the variability analysis and the black points represent the binned data. The periodic signals detected by the LS periodograms are inconsistent between sectors and are low in normalized power (< 0.1), such that we consider HD 17156 to be a quiet, non-variable star on timescales < 13 days.",
            "Figure 4. The 562nm (blue) and 832nm (red) contrast curve results and reconstructed speckle image for HD 17156, from observations carried out using the ’Alopeke instrument at the Gemini North Observatory.",
            "Figure 5. RV and TESS photometric data for HD 17156. Top panel: All Keck/HIRES RV data, spanning a total period of ∼17 years, along with the best-fit model after applying the EXOFAST fits described in Section 3.1. Middle panel: Residuals from the best-fit model applied to the RV data. Bottom-left panel: RV data folded on the orbital period of the known planet. Bottom-right panel: Transit fit from the EXOFAST analysis to the combined TESS photometry described in Section 2.1.2, where all 5 transits have been folded on the planetary orbital period.",
            "Figure 6. Injection-recovery results that determine the sensitivity of the HD 17156 RV data to planetary signatures as a function of planetary mass (Mp sin i) and semi-major axis (a). The large black dot indicates the mass and semi-major axis of the known planet. The blue dots represent injected planetary signatures that were successfully recovered and the red dots represent those planets that were not recovered. The color scale corresponding to the probability contours of detecting a planet of a given mass and semi-major axis is shown on the right vertical axis.",
            "Figure 7. Left: The mass and semi-major axis of an additional planet in a circular orbit whose angular momentum equals the angular momentum deficit (AMD) for the HD 17156 system. The dot indicated the known mass and semi-major axis of HD 17156b. Right: Eccentricity of HD 17156b as a function of the semi-major axis for the additional planet. The horizontal dashed line indicated the current eccentricity of HD 17156b.",
            "Table 1. Summary of T12 APT photometric observations for HD 17156.",
            "Table 2. HD 17156 radial velocities.",
            "Table 3. HD 17156 derived stellar parameters.",
            "Table 4. HD 17156 planetary parameters."
        ],
        "imgs": [
            "$2305.01000v2-Figure1-1.png",
            "$2305.01000v2-Figure2-1.png",
            "$2305.01000v2-Figure3-1.png",
            "$2305.01000v2-Figure4-1.png",
            "$2305.01000v2-Figure5-1.png",
            "$2305.01000v2-Figure6-1.png",
            "$2305.01000v2-Figure7-1.png",
            "$2305.01000v2-Table1-1.png",
            "$2305.01000v2-Table2-1.png",
            "$2305.01000v2-Table3-1.png",
            "$2305.01000v2-Table4-1.png"
        ]
    },
    {
        "id": "2305.01001",
        "abstract": "  Complex many-particle quantum entanglement is a central theme in two distinct\nmajor topics in physics: the strange metal state found in numerous correlated\nelectron compounds, and the quantum theory of black holes in Einstein gravity.\nThe Sachdev-Ye-Kitaev model provides a solvable theory of entangled\nmany-particle quantum states without quasiparticle excitations. This article\nreviews how this toy model has led to realistic universal models of strange\nmetals, and to new insights on the quantum states of black holes.\n",
        "title": "Strange metals and black holes: insights from the Sachdev-Ye-Kitaev\n  model",
        "texts": [
            "FIG. 1: Collision between two molecules. The collision term in the Boltzmann equation is proportional to the absolute square of the T -matrix.",
            "FIG. 2: The SYK model: fermions undergo the transition (‘collision’) shown with quantum amplitude Uij;kℓ.",
            "FIG. 3: Self-energy for the fermions of H in (7) in the limit of large N . The intermediate Green’s functions are fully renormalized.",
            "FIG. 4: (a) Plot of the 65536 many-body eigenvalues of a N = 32 Majorana SYK Hamiltonian; however, the analytical results quoted here are for the SYK model with complex fermions which has a similar spectrum. The coarse-grained low-energy and low-temperature behavior is described by (18) and (19). (b) Schematic of the lower energy density of states of a supersymmetric generalization of the SYK model [8, 11]. There is a delta function at E = 0, and the energy gap ∆ is proportional to the inverse of S(E = 0).",
            "FIG. 5: Self-energies of the fermions and bosons in the Hamiltonian HY in (22). The intermediate Green’s functions are fully renormalized.",
            "FIG. 6: Schematic phase diagram of a metal with an Ising-nematic transition. The"
        ],
        "imgs": [
            "$2305.01001v4-Figure1-1.png",
            "$2305.01001v4-Figure2-1.png",
            "$2305.01001v4-Figure3-1.png",
            "$2305.01001v4-Figure4-1.png",
            "$2305.01001v4-Figure5-1.png",
            "$2305.01001v4-Figure6-1.png"
        ]
    }
]